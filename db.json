{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"source/favicon.png","path":"favicon.png","modified":0,"renderable":0},{"_id":"source/avatar.jpeg","path":"avatar.jpeg","modified":0,"renderable":0},{"_id":"themes/next/source/css/main.styl","path":"css/main.styl","modified":0,"renderable":1},{"_id":"themes/next/source/images/algolia_logo.svg","path":"images/algolia_logo.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/apple-touch-icon-next.png","path":"images/apple-touch-icon-next.png","modified":0,"renderable":1},{"_id":"themes/next/source/images/avatar.gif","path":"images/avatar.gif","modified":0,"renderable":1},{"_id":"themes/next/source/images/apple-icon-180x180.png","path":"images/apple-icon-180x180.png","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","path":"images/cc-by-nc-nd.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","path":"images/cc-by-nc-sa.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc.svg","path":"images/cc-by-nc.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nd.svg","path":"images/cc-by-nd.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-sa.svg","path":"images/cc-by-sa.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by.svg","path":"images/cc-by.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/favicon-16x16-next.png","path":"images/favicon-16x16-next.png","modified":0,"renderable":1},{"_id":"themes/next/source/images/favicon-32x32-next.png","path":"images/favicon-32x32-next.png","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-zero.svg","path":"images/cc-zero.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/favicon-16x16.png","path":"images/favicon-16x16.png","modified":0,"renderable":1},{"_id":"themes/next/source/images/favicon-32x32.png","path":"images/favicon-32x32.png","modified":0,"renderable":1},{"_id":"themes/next/source/images/loading.gif","path":"images/loading.gif","modified":0,"renderable":1},{"_id":"themes/next/source/images/placeholder.gif","path":"images/placeholder.gif","modified":0,"renderable":1},{"_id":"themes/next/source/images/logo.svg","path":"images/logo.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/quote-l.svg","path":"images/quote-l.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/quote-r.svg","path":"images/quote-r.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/searchicon.png","path":"images/searchicon.png","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/affix.js","path":"js/src/affix.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/algolia-search.js","path":"js/src/algolia-search.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/bootstrap.js","path":"js/src/bootstrap.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/exturl.js","path":"js/src/exturl.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/hook-duoshuo.js","path":"js/src/hook-duoshuo.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/js.cookie.js","path":"js/src/js.cookie.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/post-details.js","path":"js/src/post-details.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/motion.js","path":"js/src/motion.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/scroll-cookie.js","path":"js/src/scroll-cookie.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/utils.js","path":"js/src/utils.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/scrollspy.js","path":"js/src/scrollspy.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.css","path":"lib/algolia-instant-search/instantsearch.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/canvas-nest/canvas-nest.min.js","path":"lib/canvas-nest/canvas-nest.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/canvas-ribbon/canvas-ribbon.js","path":"lib/canvas-ribbon/canvas-ribbon.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/LICENSE","path":"lib/fastclick/LICENSE","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/README.md","path":"lib/fastclick/README.md","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/bower.json","path":"lib/fastclick/bower.json","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/HELP-US-OUT.txt","path":"lib/font-awesome/HELP-US-OUT.txt","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/bower.json","path":"lib/font-awesome/bower.json","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/CONTRIBUTING.md","path":"lib/jquery_lazyload/CONTRIBUTING.md","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/bower.json","path":"lib/jquery_lazyload/bower.json","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/README.md","path":"lib/jquery_lazyload/README.md","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.scrollstop.js","path":"lib/jquery_lazyload/jquery.scrollstop.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.lazyload.js","path":"lib/jquery_lazyload/jquery.lazyload.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/needsharebutton/needsharebutton.css","path":"lib/needsharebutton/needsharebutton.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/needsharebutton/font-embedded.css","path":"lib/needsharebutton/font-embedded.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-barber-shop.min.css","path":"lib/pace/pace-theme-barber-shop.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/needsharebutton/needsharebutton.js","path":"lib/needsharebutton/needsharebutton.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-bounce.min.css","path":"lib/pace/pace-theme-bounce.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-big-counter.min.css","path":"lib/pace/pace-theme-big-counter.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-atom.min.css","path":"lib/pace/pace-theme-center-atom.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-circle.min.css","path":"lib/pace/pace-theme-center-circle.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-radar.min.css","path":"lib/pace/pace-theme-center-radar.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-simple.min.css","path":"lib/pace/pace-theme-center-simple.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-fill-left.min.css","path":"lib/pace/pace-theme-fill-left.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-corner-indicator.min.css","path":"lib/pace/pace-theme-corner-indicator.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-flash.min.css","path":"lib/pace/pace-theme-flash.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-mac-osx.min.css","path":"lib/pace/pace-theme-mac-osx.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-loading-bar.min.css","path":"lib/pace/pace-theme-loading-bar.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-minimal.min.css","path":"lib/pace/pace-theme-minimal.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace.min.js","path":"lib/pace/pace.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/three/three-waves.min.js","path":"lib/three/three-waves.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/three/canvas_lines.min.js","path":"lib/three/canvas_lines.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/three/canvas_sphere.min.js","path":"lib/three/canvas_sphere.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/bower.json","path":"lib/velocity/bower.json","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","path":"lib/velocity/velocity.ui.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.min.js","path":"lib/velocity/velocity.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.ui.js","path":"lib/velocity/velocity.ui.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery/index.js","path":"lib/jquery/index.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/schemes/pisces.js","path":"js/src/schemes/pisces.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.min.css","path":"lib/Han/dist/han.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.css","path":"lib/Han/dist/han.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.min.js","path":"lib/Han/dist/han.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/blank.gif","path":"lib/fancybox/source/blank.gif","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading.gif","path":"lib/fancybox/source/fancybox_loading.gif","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading@2x.gif","path":"lib/fancybox/source/fancybox_loading@2x.gif","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_overlay.png","path":"lib/fancybox/source/fancybox_overlay.png","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite@2x.png","path":"lib/fancybox/source/fancybox_sprite@2x.png","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite.png","path":"lib/fancybox/source/fancybox_sprite.png","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.css","path":"lib/fancybox/source/jquery.fancybox.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.js","path":"lib/fancybox/source/jquery.fancybox.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.pack.js","path":"lib/fancybox/source/jquery.fancybox.pack.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.js","path":"lib/fastclick/lib/fastclick.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.min.js","path":"lib/fastclick/lib/fastclick.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css","path":"lib/font-awesome/css/font-awesome.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css.map","path":"lib/font-awesome/css/font-awesome.css.map","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.min.css","path":"lib/font-awesome/css/font-awesome.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.min.js","path":"lib/ua-parser-js/dist/ua-parser.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.pack.js","path":"lib/ua-parser-js/dist/ua-parser.pack.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.js","path":"lib/Han/dist/han.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff2","path":"lib/font-awesome/fonts/fontawesome-webfont.woff2","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han-space.woff","path":"lib/Han/dist/font/han-space.woff","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han-space.otf","path":"lib/Han/dist/font/han-space.otf","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han.woff2","path":"lib/Han/dist/font/han.woff2","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han.woff","path":"lib/Han/dist/font/han.woff","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han.otf","path":"lib/Han/dist/font/han.otf","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/fancybox_buttons.png","path":"lib/fancybox/source/helpers/fancybox_buttons.png","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","path":"lib/fancybox/source/helpers/jquery.fancybox-buttons.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-media.js","path":"lib/fancybox/source/helpers/jquery.fancybox-media.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","path":"lib/fancybox/source/helpers/jquery.fancybox-buttons.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","path":"lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","path":"lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff","path":"lib/font-awesome/fonts/fontawesome-webfont.woff","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.js","path":"lib/velocity/velocity.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.eot","path":"lib/font-awesome/fonts/fontawesome-webfont.eot","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/FontAwesome.otf","path":"lib/font-awesome/fonts/FontAwesome.otf","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.ttf","path":"lib/font-awesome/fonts/fontawesome-webfont.ttf","modified":0,"renderable":1},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.js","path":"lib/algolia-instant-search/instantsearch.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/three/three.min.js","path":"lib/three/three.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.svg","path":"lib/font-awesome/fonts/fontawesome-webfont.svg","modified":0,"renderable":1}],"Cache":[{"_id":"source/.DS_Store","hash":"6974ddb0953597b845d10c3aec9016f9ed161fbb","modified":1537887087000},{"_id":"source/favicon.png","hash":"8b6513c2f96de00094a4496111a8998bae91bc94","modified":1520401170000},{"_id":"source/avatar.jpeg","hash":"79005cf5724dc4a1e775db01eda46a2c8decf14f","modified":1520401170000},{"_id":"themes/next/.bowerrc","hash":"3228a58ed0ece9f85e1e3136352094080b8dece1","modified":1520401170000},{"_id":"themes/next/.editorconfig","hash":"792fd2bd8174ece1a75d5fd24ab16594886f3a7f","modified":1520401170000},{"_id":"themes/next/.gitignore","hash":"0b5c2ffd41f66eb1849d6426ba8cf9649eeed329","modified":1520401170000},{"_id":"themes/next/.gitattributes","hash":"44bd4729c74ccb88110804f41746fec07bf487d4","modified":1520401170000},{"_id":"themes/next/.hound.yml","hash":"b76daa84c9ca3ad292c78412603370a367cc2bc3","modified":1520401170000},{"_id":"themes/next/.javascript_ignore","hash":"8a224b381155f10e6eb132a4d815c5b52962a9d1","modified":1520401170000},{"_id":"themes/next/.jshintrc","hash":"9928f81bd822f6a8d67fdbc909b517178533bca9","modified":1520401170000},{"_id":"themes/next/.stylintrc","hash":"b28e24704a5d8de08346c45286574c8e76cc109f","modified":1520401170000},{"_id":"themes/next/.travis.yml","hash":"d60d4a5375fea23d53b2156b764a99b2e56fa660","modified":1520401170000},{"_id":"themes/next/LICENSE","hash":"f293bcfcdc06c0b77ba13570bb8af55eb5c059fd","modified":1520401170000},{"_id":"themes/next/README.cn.md","hash":"6d9177e7dad87e6129760e4b559bd3f7a15429d7","modified":1520401170000},{"_id":"themes/next/README.md","hash":"529d53dfa97678f8ce4c95620b26e61154162a29","modified":1520401170000},{"_id":"themes/next/_config.yml","hash":"46dfc26d2ff19e83626882da4221a1c8cda27125","modified":1539683814000},{"_id":"themes/next/bower.json","hash":"6d6ae7531cf3fedc97c58cdad664f5793eb3cc88","modified":1520401170000},{"_id":"themes/next/gulpfile.coffee","hash":"031bffc483e417b20e90eceb6cf358e7596d2e69","modified":1520401170000},{"_id":"themes/next/package.json","hash":"93a74dbc0fe3a1208a02e9cec3c15c2375339cc1","modified":1520401170000},{"_id":"source/_posts/.DS_Store","hash":"9b6e2e6a9225269d6a05eb6aa616dcd47368e57c","modified":1544340962000},{"_id":"source/_posts/centos-net.md","hash":"eba42b59a4db9fa9e61084861cc547d637e3c65a","modified":1520401170000},{"_id":"source/_posts/ceph-ansible.md","hash":"da7b4356aa3c2858c89e71f37b39f095509b56c6","modified":1543383214000},{"_id":"source/_posts/ceph-deploy.md","hash":"740f74f2ad71b613152a8f2e26dc5924f7193027","modified":1543302409000},{"_id":"source/_posts/ceph-mgr-restful.md","hash":"f7b9ed203b788fbcf922f8ff4f6b3fcacfdc7a05","modified":1544526659000},{"_id":"source/_posts/disk-extend.md","hash":"88d01dcf927d94e79602b99564d63b49c1a3f8ee","modified":1548944016000},{"_id":"source/_posts/git-patch.md","hash":"51f4a81123c4e46655acbd9a024f981b5f46588b","modified":1520492657000},{"_id":"source/_posts/install-k8s.md","hash":"fc2fb9089a3c7f6901d24dc9e16ef7fdc3115961","modified":1544271438000},{"_id":"source/_posts/logrotate.md","hash":"56a97fe6051cb00fc2abb17a205c9c28a14cb6bf","modified":1520401170000},{"_id":"source/_posts/mysql-replication.md","hash":"218c33c7f17c15c38e577557b0d5e7acfa7eb0e5","modified":1537933672000},{"_id":"source/_posts/linux-performance-tools.md","hash":"a9a51a71cc81980924652d6ff6e147d4e5da9e92","modified":1571031646209},{"_id":"source/_posts/nextcloud-ceph.md","hash":"7ab0aee624b7a59d913237b4ceac365b6ce8e759","modified":1537934293000},{"_id":"source/_posts/pacemaker-mysql.md","hash":"c4c475ffa9a29f56ab5623e12c09490776974186","modified":1537933642000},{"_id":"source/_posts/redis-persistence.md","hash":"c28a1dacb606ed1c463859b1927490ad7049d4f3","modified":1537711964000},{"_id":"source/_posts/reposync.md","hash":"d06b04813be0df05f64289f72280b070cf4974c1","modified":1529740328000},{"_id":"source/_posts/rgw-with-ec.md","hash":"b1a0dccc87f2b208a46aa8b3225344b6182888ed","modified":1552546088000},{"_id":"source/_posts/rgw-multi-site.md","hash":"b59589a76649dc8fdde71c1b30f907e34eb698df","modified":1552199540000},{"_id":"source/_posts/rook.md","hash":"fdec59ade0df66f74e5b8d5aed20809af51265a9","modified":1552662868000},{"_id":"source/_posts/rpm-mock.md","hash":"52fb57aebd272464efd52d49d49555e9fa98387d","modified":1537929862000},{"_id":"source/_posts/s3cmd.md","hash":"149eb0c68224b358990b235f2c858daacfc09c0c","modified":1520401170000},{"_id":"source/_posts/service-too-quickly.md","hash":"c5ab35240185a9236d03d8aadffa9db31b4d79a5","modified":1520401170000},{"_id":"source/_posts/sql-join.md","hash":"d857d48393f77f6c3b0616b69a0d96ac5e90cabe","modified":1544366952000},{"_id":"source/_posts/string-join.md","hash":"927d45f9d19f2ee10f01978a6735fe63e78c5e3f","modified":1520401170000},{"_id":"source/_posts/timedatectl.md","hash":"ef6154d8ea0228976783d46afe0d30ea1613d5de","modified":1520401170000},{"_id":"source/tags/index.md","hash":"6339a266bf00be9a47cd54cc212aac4a11bc8c47","modified":1520401170000},{"_id":"source/_posts/tidb-k8s.md","hash":"7e8a52c5c368753fd6da5600c20ad07a44477b0b","modified":1552901126000},{"_id":"themes/next/.github/CONTRIBUTING.md","hash":"3b5eafd32abb718e56ccf8d1cee0607ad8ce611d","modified":1520401170000},{"_id":"themes/next/.github/ISSUE_TEMPLATE.md","hash":"352093a1b210c72136687fd2eee649244cee402c","modified":1520401170000},{"_id":"themes/next/.github/PULL_REQUEST_TEMPLATE.md","hash":"902f627155a65099e0a37842ff396a58d0dc306f","modified":1520401170000},{"_id":"themes/next/.github/browserstack_logo.png","hash":"a6c43887f64a7f48a2814e3714eaa1215e542037","modified":1520401170000},{"_id":"themes/next/languages/de.yml","hash":"057e7df11ddeb1c8c15a5d7c5ff29430d725ec6b","modified":1520401170000},{"_id":"themes/next/languages/default.yml","hash":"44ef3f26917f467459326c2c8be2f73e4d947f35","modified":1520401170000},{"_id":"themes/next/languages/en.yml","hash":"7e680d9bb8f3a3a9d1ba1c9d312b3d257183dded","modified":1520401170000},{"_id":"themes/next/languages/fr-FR.yml","hash":"7e4eb7011b8feee641cfb11c6e73180b0ded1c0f","modified":1520401170000},{"_id":"themes/next/languages/id.yml","hash":"b5de1ea66dd9ef54cac9a1440eaa4e3f5fc011f5","modified":1520401170000},{"_id":"themes/next/languages/it.yml","hash":"aa595f2bda029f73ef7bfa104b4c55c3f4e9fb4c","modified":1520401170000},{"_id":"themes/next/languages/ja.yml","hash":"3c76e16fd19b262864475faa6854b718bc08c4d8","modified":1520401170000},{"_id":"themes/next/languages/ko.yml","hash":"ea5b46056e73ebcee121d5551627af35cbffc900","modified":1520401170000},{"_id":"themes/next/languages/nl-NL.yml","hash":"edca4f3598857dbc3cbf19ed412213329b6edd47","modified":1520401170000},{"_id":"themes/next/languages/pt-BR.yml","hash":"b1694ae766ed90277bcc4daca4b1cfa19cdcb72b","modified":1520401170000},{"_id":"themes/next/languages/pt.yml","hash":"44b61f2d085b827b507909a0b8f8ce31c6ef5d04","modified":1520401170000},{"_id":"themes/next/languages/ru.yml","hash":"98ec6f0b7183282e11cffc7ff586ceb82400dd75","modified":1520401170000},{"_id":"themes/next/languages/zh-Hans.yml","hash":"16ef56d0dea94638de7d200984c90ae56f26b4fe","modified":1520401170000},{"_id":"themes/next/languages/zh-hk.yml","hash":"9396f41ae76e4fef99b257c93c7354e661f6e0fa","modified":1520401170000},{"_id":"themes/next/languages/zh-tw.yml","hash":"50b71abb3ecc0686f9739e179e2f829cd074ecd9","modified":1520401170000},{"_id":"themes/next/layout/_layout.swig","hash":"da0929166674ea637e0ad454f85ad0d7bac4aff2","modified":1520401170000},{"_id":"themes/next/layout/archive.swig","hash":"f0a8225feafd971419837cdb4bcfec98a4a59b2f","modified":1520401170000},{"_id":"themes/next/layout/category.swig","hash":"4472255f4a3e3dd6d79201523a9526dcabdfbf18","modified":1520401170000},{"_id":"themes/next/layout/index.swig","hash":"783611349c941848a0e26ee2f1dc44dd14879bd1","modified":1520401170000},{"_id":"themes/next/layout/page.swig","hash":"969caaee05bdea725e99016eb63d810893a73e99","modified":1520401170000},{"_id":"themes/next/layout/post.swig","hash":"b3589a8e46288a10d20e41c7a5985d2493725aec","modified":1520401170000},{"_id":"themes/next/layout/schedule.swig","hash":"d86f8de4e118f8c4d778b285c140474084a271db","modified":1520401170000},{"_id":"themes/next/scripts/merge-configs.js","hash":"cb617ddf692f56e6b6129564d52e302f50b28243","modified":1520401170000},{"_id":"themes/next/layout/tag.swig","hash":"7e0a7d7d832883eddb1297483ad22c184e4368de","modified":1520401170000},{"_id":"themes/next/scripts/merge.js","hash":"9130dabe6a674c54b535f322b17d75fe6081472f","modified":1520401170000},{"_id":"themes/next/test/.jshintrc","hash":"19f93d13d1689fe033c82eb2d5f3ce30b6543cc0","modified":1520401170000},{"_id":"themes/next/test/helpers.js","hash":"a1f5de25154c3724ffc24a91ddc576cdbd60864f","modified":1520401170000},{"_id":"themes/next/test/intern.js","hash":"11fa8a4f5c3b4119a179ae0a2584c8187f907a73","modified":1520401170000},{"_id":"themes/next/source/fonts/.gitkeep","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1520401170000},{"_id":"source/_posts/ceph-deploy/cephfs.png","hash":"0b64ac3702174a4baec644fd5a0f50f21e2c51a2","modified":1543302180000},{"_id":"source/_posts/ceph-deploy/cephstatus.png","hash":"cc0227ecb8f825281ccbefcd99bc195cc42ade84","modified":1543302189000},{"_id":"source/_posts/nextcloud-ceph/nextcloud2.png","hash":"67ac9bdf470677adb9cdb399e32b1f0b104fdaf2","modified":1520401170000},{"_id":"source/_posts/nextcloud-ceph/nextcloud5.png","hash":"9c054e9097d1467ca4433f3d14b3e1cfeb3c2706","modified":1520401170000},{"_id":"source/_posts/nextcloud-ceph/nextcloud6.png","hash":"c97fe7001376ff8359afb9890e798de641dada3e","modified":1520401170000},{"_id":"themes/next/layout/_custom/header.swig","hash":"adc83b19e793491b1c6ea0fd8b46cd9f32e592fc","modified":1520401170000},{"_id":"themes/next/layout/_custom/sidebar.swig","hash":"adc83b19e793491b1c6ea0fd8b46cd9f32e592fc","modified":1520401170000},{"_id":"themes/next/layout/_macro/post-collapse.swig","hash":"31322a7f57936cf2dc62e824af5490da5354cf02","modified":1520401170000},{"_id":"themes/next/layout/_macro/post-copyright.swig","hash":"665a928604f99d2ba7dc4a4a9150178229568cc6","modified":1520401170000},{"_id":"themes/next/layout/_macro/reward.swig","hash":"56e8d8556cf474c56ae1bef9cb7bbd26554adb07","modified":1520401170000},{"_id":"themes/next/layout/_macro/post.swig","hash":"446a35a2cd389f8cfc3aa38973a9b44ad0740134","modified":1520401170000},{"_id":"themes/next/layout/_macro/sidebar.swig","hash":"9efc455894921a66bbc074055d3b39c8a34a48a4","modified":1520401170000},{"_id":"themes/next/layout/_macro/wechat-subscriber.swig","hash":"39852700e4084ecccffa6d4669168e5cc0514c9e","modified":1520401170000},{"_id":"themes/next/layout/_partials/footer.swig","hash":"c4d6181f5d3db5365e622f78714af8cc58d7a45e","modified":1520401170000},{"_id":"themes/next/layout/_partials/comments.swig","hash":"4a6f5b1792b2e5262b7fdab9a716b3108e2f09c7","modified":1520401170000},{"_id":"themes/next/layout/_partials/head.swig","hash":"775d07963021badb3eb864419f36e61df497a5c6","modified":1537946498000},{"_id":"themes/next/layout/_partials/header.swig","hash":"ed042be6252848058c90109236ec988e392d91d4","modified":1520401170000},{"_id":"themes/next/layout/_partials/page-header.swig","hash":"1efd925d34a5d4ba2dc0838d9c86ba911e705fc9","modified":1520401170000},{"_id":"themes/next/layout/_partials/pagination.swig","hash":"9e8e21d194ef44d271b1cca0bc1448c14d7edf4f","modified":1520401170000},{"_id":"themes/next/layout/_partials/search.swig","hash":"9dbd378e94abfcb3f864a5b8dbbf18d212ca2ee0","modified":1520401170000},{"_id":"themes/next/layout/_scripts/boostrap.swig","hash":"03aaebe9d50f6acb007ec38cc04acd1cfceb404d","modified":1520401170000},{"_id":"themes/next/layout/_scripts/commons.swig","hash":"766b2bdda29523ed6cd8d7aa197f996022f8fd94","modified":1520401170000},{"_id":"themes/next/layout/_scripts/vendors.swig","hash":"a266f96ad06ee87bdeae6e105a4b53cd587bbd04","modified":1520401170000},{"_id":"themes/next/layout/_third-party/duoshuo-hot-articles.swig","hash":"5d4638c46aef65bf32a01681495b62416ccc98db","modified":1520401170000},{"_id":"themes/next/layout/_third-party/exturl.swig","hash":"7c04a42319d728be356746363aff8ea247791d24","modified":1520401170000},{"_id":"themes/next/layout/_third-party/mathjax.swig","hash":"6d25596d6a7c57700d37b607f8d9a62d89708683","modified":1520401170000},{"_id":"themes/next/layout/_third-party/needsharebutton.swig","hash":"5fe0447cc88a5a63b530cf0426f93c4634811876","modified":1520401170000},{"_id":"themes/next/layout/_third-party/schedule.swig","hash":"22369026c87fc23893c35a7f250b42f3bb1b60f1","modified":1520401170000},{"_id":"themes/next/layout/_third-party/rating.swig","hash":"fc93b1a7e6aed0dddb1f3910142b48d8ab61174e","modified":1520401170000},{"_id":"themes/next/layout/_third-party/scroll-cookie.swig","hash":"1ddb2336a1a19b47af3017047012c01ec5f54529","modified":1520401170000},{"_id":"themes/next/scripts/tags/button.js","hash":"d023f10a00077f47082b0517e2ad666e6e994f60","modified":1520401170000},{"_id":"themes/next/scripts/tags/center-quote.js","hash":"535fc542781021c4326dec24d8495cbb1387634a","modified":1520401170000},{"_id":"themes/next/scripts/tags/exturl.js","hash":"8d7e60f60779bde050d20fd76f6fdc36fc85e06d","modified":1520401170000},{"_id":"themes/next/scripts/tags/full-image.js","hash":"8eeb3fb89540299bdbb799edfdfdac3743b50596","modified":1520401170000},{"_id":"themes/next/scripts/tags/group-pictures.js","hash":"49252824cd53184dc9b97b2f2d87ff28e1b3ef27","modified":1520401170000},{"_id":"themes/next/scripts/tags/label.js","hash":"2f8f41a7316372f0d1ed6b51190dc4acd3e16fff","modified":1520401170000},{"_id":"themes/next/scripts/tags/lazy-image.js","hash":"eeeabede68cf263de9e6593ecf682f620da16f0a","modified":1520401170000},{"_id":"themes/next/scripts/tags/note.js","hash":"64de4e9d01cf3b491ffc7d53afdf148ee5ad9779","modified":1520401170000},{"_id":"themes/next/scripts/tags/tabs.js","hash":"5786545d51c38e8ca38d1bfc7dd9e946fc70a316","modified":1520401170000},{"_id":"themes/next/source/css/main.styl","hash":"20702c48d6053c92c5bcdbc68e8d0ef1369848a0","modified":1520401170000},{"_id":"themes/next/source/images/algolia_logo.svg","hash":"ec119560b382b2624e00144ae01c137186e91621","modified":1520401170000},{"_id":"themes/next/source/images/apple-touch-icon-next.png","hash":"2959dbc97f31c80283e67104fe0854e2369e40aa","modified":1520401170000},{"_id":"themes/next/source/images/avatar.gif","hash":"264082bb3a1af70d5499c7d22b0902cb454b6d12","modified":1520401170000},{"_id":"themes/next/source/images/apple-icon-180x180.png","hash":"5c4fcc68f5d16ebadbf09092b0a8ea359ac2349c","modified":1520401170000},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","hash":"c6524ece3f8039a5f612feaf865d21ec8a794564","modified":1520401170000},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","hash":"3031be41e8753c70508aa88e84ed8f4f653f157e","modified":1520401170000},{"_id":"themes/next/source/images/cc-by-nc.svg","hash":"8d39b39d88f8501c0d27f8df9aae47136ebc59b7","modified":1520401170000},{"_id":"themes/next/source/images/cc-by-nd.svg","hash":"c563508ce9ced1e66948024ba1153400ac0e0621","modified":1520401170000},{"_id":"themes/next/source/images/cc-by-sa.svg","hash":"aa4742d733c8af8d38d4c183b8adbdcab045872e","modified":1520401170000},{"_id":"themes/next/source/images/cc-by.svg","hash":"28a0a4fe355a974a5e42f68031652b76798d4f7e","modified":1520401170000},{"_id":"themes/next/source/images/favicon-16x16-next.png","hash":"943a0d67a9cdf8c198109b28f9dbd42f761d11c3","modified":1520401170000},{"_id":"themes/next/source/images/favicon-32x32-next.png","hash":"0749d7b24b0d2fae1c8eb7f671ad4646ee1894b1","modified":1520401170000},{"_id":"themes/next/source/images/cc-zero.svg","hash":"87669bf8ac268a91d027a0a4802c92a1473e9030","modified":1520401170000},{"_id":"themes/next/source/images/favicon-16x16.png","hash":"277d209fb68a803ab37ba5a857fc8c2853a39404","modified":1520401170000},{"_id":"themes/next/source/images/favicon-32x32.png","hash":"ce722d5b180618a4c75d609ae51fe8c437dcda2f","modified":1520401170000},{"_id":"themes/next/source/images/loading.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1520401170000},{"_id":"themes/next/source/images/placeholder.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1520401170000},{"_id":"themes/next/source/images/logo.svg","hash":"d29cacbae1bdc4bbccb542107ee0524fe55ad6de","modified":1520401170000},{"_id":"themes/next/source/images/quote-l.svg","hash":"94e870b4c8c48da61d09522196d4dd40e277a98f","modified":1520401170000},{"_id":"themes/next/source/images/quote-r.svg","hash":"e60ae504f9d99b712c793c3740c6b100d057d4ec","modified":1520401170000},{"_id":"themes/next/source/images/searchicon.png","hash":"67727a6a969be0b2659b908518fa6706eed307b8","modified":1520401170000},{"_id":"source/_posts/disk-extend/disk3.png","hash":"69bb55e919772f50741fb2300450325dcd86c929","modified":1548864733000},{"_id":"source/_posts/nextcloud-ceph/nextcloud1.png","hash":"3456f10df865f274a6e9882e0bf1921e8d411f7c","modified":1520401170000},{"_id":"source/_posts/nextcloud-ceph/nextcloud3.png","hash":"bde680ab7c41e852acb22334579a65a8cb1ced59","modified":1520401170000},{"_id":"source/_posts/nextcloud-ceph/nextcloud4.png","hash":"51bdcb2e431fb9b7e0db1ebe7a51033d210e0a02","modified":1520401170000},{"_id":"themes/next/layout/_scripts/schemes/mist.swig","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1520401170000},{"_id":"themes/next/layout/_scripts/schemes/muse.swig","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1520401170000},{"_id":"themes/next/source/css/_mixins/Mist.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1520401170000},{"_id":"themes/next/source/css/_mixins/Muse.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1520401170000},{"_id":"themes/next/source/css/_mixins/custom.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1520401170000},{"_id":"themes/next/source/css/_variables/Muse.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1520401170000},{"_id":"themes/next/source/css/_variables/custom.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1520401170000},{"_id":"source/_posts/disk-extend/disk4.png","hash":"523be5b2ac03f35d78b5dbe75dcf83a0d585ec7a","modified":1548864938000},{"_id":"source/_posts/disk-extend/disk7.png","hash":"4569e36ef1b54f1a9eabb84eabf4244eb056dad5","modified":1548866554000},{"_id":"themes/next/layout/_partials/head/custom-head.swig","hash":"9e1b9666efa77f4cf8d8261bcfa445a9ac608e53","modified":1520401170000},{"_id":"themes/next/layout/_partials/head/external-fonts.swig","hash":"7ce76358411184482bb0934e70037949dd0da8ca","modified":1520401170000},{"_id":"themes/next/layout/_partials/search/localsearch.swig","hash":"957701729b85fb0c5bfcf2fb99c19d54582f91ed","modified":1520401170000},{"_id":"themes/next/layout/_partials/search/swiftype.swig","hash":"959b7e04a96a5596056e4009b73b6489c117597e","modified":1520401170000},{"_id":"themes/next/layout/_partials/search/tinysou.swig","hash":"eefe2388ff3d424694045eda21346989b123977c","modified":1520401170000},{"_id":"themes/next/layout/_partials/share/add-this.swig","hash":"23e23dc0f76ef3c631f24c65277adf7ea517b383","modified":1520401170000},{"_id":"themes/next/layout/_partials/share/baidushare.swig","hash":"1f1107468aaf03f7d0dcd7eb2b653e2813a675b4","modified":1520401170000},{"_id":"themes/next/layout/_partials/share/duoshuo_share.swig","hash":"89c5a5240ecb223acfe1d12377df5562a943fd5d","modified":1520401170000},{"_id":"themes/next/layout/_partials/share/jiathis.swig","hash":"048fd5e98149469f8c28c21ba3561a7a67952c9b","modified":1520401170000},{"_id":"themes/next/layout/_scripts/pages/post-details.swig","hash":"069d1357c717572256e5cdee09574ebce529cbae","modified":1520401170000},{"_id":"themes/next/layout/_scripts/schemes/gemini.swig","hash":"a44acf9b0d0f44ef3dfc767376a95c984cc127de","modified":1520401170000},{"_id":"themes/next/layout/_scripts/schemes/pisces.swig","hash":"a44acf9b0d0f44ef3dfc767376a95c984cc127de","modified":1520401170000},{"_id":"themes/next/layout/_third-party/analytics/application-insights.swig","hash":"60426bf73f8a89ba61fb1be2df3ad5398e32c4ef","modified":1520401170000},{"_id":"themes/next/layout/_third-party/analytics/analytics-with-widget.swig","hash":"98df9d72e37dd071e882f2d5623c9d817815b139","modified":1520401170000},{"_id":"themes/next/layout/_third-party/analytics/baidu-analytics.swig","hash":"deda6a814ed48debc694c4e0c466f06c127163d0","modified":1520401170000},{"_id":"themes/next/layout/_third-party/analytics/busuanzi-counter.swig","hash":"18e7bef8923d83ea42df6c97405e515a876cede4","modified":1520401170000},{"_id":"themes/next/layout/_third-party/analytics/cnzz-analytics.swig","hash":"8160b27bee0aa372c7dc7c8476c05bae57f58d0f","modified":1520401170000},{"_id":"themes/next/layout/_third-party/analytics/facebook-sdk.swig","hash":"a234c5cd1f75ca5731e814d0dbb92fdcf9240d1b","modified":1520401170000},{"_id":"themes/next/layout/_third-party/analytics/firestore.swig","hash":"1cd01c6e92ab1913d48e556a92bb4f28b6dc4996","modified":1520401170000},{"_id":"themes/next/layout/_third-party/analytics/google-analytics.swig","hash":"5d9943d74cc2e0a91badcf4f755c6de77eab193a","modified":1520401170000},{"_id":"themes/next/layout/_third-party/analytics/index.swig","hash":"5e9bb24c750b49513d9a65799e832f07410002ac","modified":1520401170000},{"_id":"themes/next/layout/_third-party/analytics/lean-analytics.swig","hash":"fc65b9c98a0a8ab43a5e7aabff6c5f03838e09c8","modified":1520401170000},{"_id":"themes/next/layout/_third-party/analytics/tencent-analytics.swig","hash":"3658414379e0e8a34c45c40feadc3edc8dc55f88","modified":1520401170000},{"_id":"themes/next/layout/_third-party/analytics/tencent-mta.swig","hash":"0ddc94ed4ba0c19627765fdf1abc4d8efbe53d5a","modified":1520401170000},{"_id":"themes/next/layout/_third-party/analytics/vkontakte-api.swig","hash":"c3971fd154d781088e1cc665035f8561a4098f4c","modified":1520401170000},{"_id":"themes/next/layout/_third-party/comments/changyan.swig","hash":"0e3378f7c39b2b0f69638290873ede6b6b6825c0","modified":1520401170000},{"_id":"themes/next/layout/_third-party/comments/disqus.swig","hash":"c316758546dc9ba6c60cb4d852c17ca6bb6d6724","modified":1520401170000},{"_id":"themes/next/layout/_third-party/comments/duoshuo.swig","hash":"a356b2185d40914447fde817eb3d358ab6b3e4c3","modified":1520401170000},{"_id":"themes/next/layout/_third-party/comments/gitment.swig","hash":"10160daceaa6f1ecf632323d422ebe2caae49ddf","modified":1520401170000},{"_id":"themes/next/layout/_third-party/comments/hypercomments.swig","hash":"3e8dc5c6c912628a37e3b5f886bec7b2e5ed14ea","modified":1520401170000},{"_id":"themes/next/layout/_third-party/comments/index.swig","hash":"aa0629277d751c55c6d973e7691bf84af9b17a60","modified":1520401170000},{"_id":"themes/next/layout/_third-party/comments/livere.swig","hash":"8a2e393d2e49f7bf560766d8a07cd461bf3fce4f","modified":1520401170000},{"_id":"themes/next/layout/_third-party/comments/valine.swig","hash":"4617daf810f42b3f3908a40f246538cb1e5970da","modified":1520401170000},{"_id":"themes/next/layout/_third-party/comments/youyan.swig","hash":"8b6650f77fe0a824c8075b2659e0403e0c78a705","modified":1520401170000},{"_id":"themes/next/layout/_third-party/search/localsearch.swig","hash":"385c066af96bee30be2459dbec8aae1f15d382f5","modified":1520401170000},{"_id":"themes/next/layout/_third-party/search/tinysou.swig","hash":"cb3a5d36dbe1630bab84e03a52733a46df7c219b","modified":1520401170000},{"_id":"themes/next/layout/_third-party/seo/baidu-push.swig","hash":"c057b17f79e8261680fbae8dc4e81317a127c799","modified":1520401170000},{"_id":"themes/next/layout/_third-party/search/index.swig","hash":"c747fb5c6b1f500e8f0c583e44195878b66e4e29","modified":1520401170000},{"_id":"themes/next/source/css/_custom/custom.styl","hash":"328d9a9696cc2ccf59c67d3c26000d569f46344c","modified":1520401170000},{"_id":"themes/next/source/css/_mixins/Gemini.styl","hash":"2aa5b7166a85a8aa34b17792ae4f58a5a96df6cc","modified":1520401170000},{"_id":"themes/next/source/css/_mixins/Pisces.styl","hash":"9ab65361ba0a12a986edd103e56492644c2db0b8","modified":1520401170000},{"_id":"themes/next/source/css/_mixins/base.styl","hash":"82f9055955920ed88a2ab6a20ab02169abb2c634","modified":1520401170000},{"_id":"themes/next/source/css/_variables/Gemini.styl","hash":"99fbb4686ea9a3e03a4726ed7cf4d8f529034452","modified":1520401170000},{"_id":"themes/next/source/css/_variables/Mist.styl","hash":"be087dcc060e8179f7e7f60ab4feb65817bd3d9f","modified":1520401170000},{"_id":"themes/next/source/css/_variables/Pisces.styl","hash":"f29165e36489a87ba32d17dddfd2720d84e3f3ec","modified":1520401170000},{"_id":"themes/next/source/css/_variables/base.styl","hash":"29c261fa6b4046322559074d75239c6b272fb8a3","modified":1520401170000},{"_id":"themes/next/source/js/src/affix.js","hash":"978e0422b5bf1b560236d8d10ebc1adcf66392e3","modified":1520401170000},{"_id":"themes/next/source/js/src/algolia-search.js","hash":"b172f697ed339a24b1e80261075232978d164c35","modified":1520401170000},{"_id":"themes/next/source/js/src/bootstrap.js","hash":"034bc8113e0966fe2096ba5b56061bbf10ef0512","modified":1520401170000},{"_id":"themes/next/source/js/src/exturl.js","hash":"e42e2aaab7bf4c19a0c8e779140e079c6aa5c0b1","modified":1520401170000},{"_id":"themes/next/source/js/src/hook-duoshuo.js","hash":"a6119070c0119f33e08b29da7d2cce2635eb40a0","modified":1520401170000},{"_id":"themes/next/source/js/src/js.cookie.js","hash":"9b37973a90fd50e71ea91682265715e45ae82c75","modified":1520401170000},{"_id":"themes/next/source/js/src/post-details.js","hash":"a13f45f7aa8291cf7244ec5ba93907d119c5dbdd","modified":1520401170000},{"_id":"themes/next/source/js/src/motion.js","hash":"754b294394f102c8fd9423a1789ddb1201677898","modified":1520401170000},{"_id":"themes/next/source/js/src/scroll-cookie.js","hash":"09dc828cbf5f31158ff6250d2bf7c3cde6365c67","modified":1520401170000},{"_id":"themes/next/source/js/src/utils.js","hash":"dbdc3d1300eec7da9632608ebc0e5b697779dad7","modified":1520401170000},{"_id":"themes/next/source/js/src/scrollspy.js","hash":"fe4da1b9fe73518226446f5f27d2831e4426fc35","modified":1520401170000},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.css","hash":"90ef19edc982645b118b095615838d9c5eaba0de","modified":1520401170000},{"_id":"themes/next/source/lib/canvas-nest/canvas-nest.min.js","hash":"0387e75e23b1db108a755073fe52a0d03eb391a7","modified":1520401170000},{"_id":"themes/next/source/lib/canvas-ribbon/canvas-ribbon.js","hash":"ff5915eb2596e890a2fc6697c864f861a1995ec0","modified":1520401170000},{"_id":"themes/next/source/lib/fastclick/LICENSE","hash":"dcd5b6b43095d9e90353a28b09cb269de8d4838e","modified":1520401170000},{"_id":"themes/next/source/lib/fastclick/README.md","hash":"1decd8e1adad2cd6db0ab50cf56de6035156f4ea","modified":1520401170000},{"_id":"themes/next/source/lib/font-awesome/.gitignore","hash":"69d152fa46b517141ec3b1114dd6134724494d83","modified":1520401170000},{"_id":"themes/next/source/lib/fastclick/.bower.json","hash":"93ebd5b35e632f714dcf1753e1f6db77ec74449b","modified":1520401170000},{"_id":"themes/next/source/lib/fastclick/bower.json","hash":"13379463c7463b4b96d13556b46faa4cc38d81e6","modified":1520401170000},{"_id":"themes/next/source/lib/font-awesome/.bower.json","hash":"a2aaaf12378db56bd10596ba3daae30950eac051","modified":1520401170000},{"_id":"themes/next/source/lib/font-awesome/.npmignore","hash":"dcf470ab3a358103bb896a539cc03caeda10fa8b","modified":1520401170000},{"_id":"themes/next/source/lib/font-awesome/HELP-US-OUT.txt","hash":"4f7bf961f1bed448f6ba99aeb9219fabf930ba96","modified":1520401170000},{"_id":"themes/next/source/lib/font-awesome/bower.json","hash":"279a8a718ab6c930a67c41237f0aac166c1b9440","modified":1520401170000},{"_id":"themes/next/source/lib/jquery/.bower.json","hash":"91745c2cc6c946c7275f952b2b0760b880cea69e","modified":1520401170000},{"_id":"themes/next/source/lib/jquery_lazyload/.bower.json","hash":"b7638afc93e9cd350d0783565ee9a7da6805ad8e","modified":1520401170000},{"_id":"themes/next/source/lib/jquery_lazyload/CONTRIBUTING.md","hash":"4891864c24c28efecd81a6a8d3f261145190f901","modified":1520401170000},{"_id":"themes/next/source/lib/jquery_lazyload/bower.json","hash":"65bc85d12197e71c40a55c0cd7f6823995a05222","modified":1520401170000},{"_id":"themes/next/source/lib/jquery_lazyload/README.md","hash":"895d50fa29759af7835256522e9dd7dac597765c","modified":1520401170000},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.scrollstop.js","hash":"0e9a81785a011c98be5ea821a8ed7d411818cfd1","modified":1520401170000},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.lazyload.js","hash":"481fd478650e12b67c201a0ea41e92743f8b45a3","modified":1520401170000},{"_id":"themes/next/source/lib/needsharebutton/needsharebutton.css","hash":"3ef0020a1815ca6151ea4886cd0d37421ae3695c","modified":1520401170000},{"_id":"themes/next/source/lib/needsharebutton/font-embedded.css","hash":"c39d37278c1e178838732af21bd26cd0baeddfe0","modified":1520401170000},{"_id":"themes/next/source/lib/pace/pace-theme-barber-shop.min.css","hash":"ee0d51446cb4ffe1bb96bd7bc8c8e046dddfcf46","modified":1520401170000},{"_id":"themes/next/source/lib/needsharebutton/needsharebutton.js","hash":"9885fd9bea5e7ebafc5b1de9d17be5e106248d96","modified":1520401170000},{"_id":"themes/next/source/lib/pace/pace-theme-bounce.min.css","hash":"f6bdb9a785b7979dd8ec5c60e278af955ef1e585","modified":1520401170000},{"_id":"themes/next/source/lib/pace/pace-theme-big-counter.min.css","hash":"5b561dc328af4c4d512e20a76fe964d113a32ba8","modified":1520401170000},{"_id":"themes/next/source/lib/pace/pace-theme-center-atom.min.css","hash":"dcf79c24fe5350fb73d8038573a104e73639e9d3","modified":1520401170000},{"_id":"themes/next/source/lib/pace/pace-theme-center-circle.min.css","hash":"a4066769c78affbfbc5e30a600e2c7862cd532e0","modified":1520401170000},{"_id":"themes/next/source/lib/pace/pace-theme-center-radar.min.css","hash":"ab7cba998bf4c03b13df342bf43647fa4f419783","modified":1520401170000},{"_id":"themes/next/source/lib/pace/pace-theme-center-simple.min.css","hash":"67f44c947548bd4d77e7590d3f59e236cbf9e98a","modified":1520401170000},{"_id":"themes/next/source/lib/pace/pace-theme-fill-left.min.css","hash":"0bec1e235a4a2cccda3f993b205424e1441a44ae","modified":1520401170000},{"_id":"themes/next/source/lib/pace/pace-theme-corner-indicator.min.css","hash":"b3c64c973f31884e3d8145989476707333406b9a","modified":1520401170000},{"_id":"themes/next/source/lib/pace/pace-theme-flash.min.css","hash":"13ace22c40312d7bbd8d9c1e50eff897a7a497d8","modified":1520401170000},{"_id":"themes/next/source/lib/pace/pace-theme-mac-osx.min.css","hash":"9f2e7b51b084da407863826b25265b31150b3821","modified":1520401170000},{"_id":"themes/next/source/lib/pace/pace-theme-loading-bar.min.css","hash":"7ee28875dfc1230d76c537f6605766e8d4011e9f","modified":1520401170000},{"_id":"themes/next/source/lib/pace/pace-theme-minimal.min.css","hash":"9cd783cceb8a191f3c8b5d81f7a430ecc3e489d3","modified":1520401170000},{"_id":"themes/next/source/lib/pace/pace.min.js","hash":"9944dfb7814b911090e96446cea4d36e2b487234","modified":1520401170000},{"_id":"themes/next/source/lib/three/three-waves.min.js","hash":"d968cba6b3a50b3626a02d67b544f349d83b147c","modified":1520401170000},{"_id":"themes/next/source/lib/three/canvas_lines.min.js","hash":"dce4a3b65f8bf958f973690caa7ec4952f353b0c","modified":1520401170000},{"_id":"themes/next/source/lib/three/canvas_sphere.min.js","hash":"d8ea241a53c135a650f7335d2b6982b899fd58a9","modified":1520401170000},{"_id":"themes/next/source/lib/velocity/.bower.json","hash":"05f960846f1c7a93dab1d3f9a1121e86812e8c88","modified":1520401170000},{"_id":"themes/next/source/lib/velocity/bower.json","hash":"2ec99573e84c7117368beccb9e94b6bf35d2db03","modified":1520401170000},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","hash":"ed5e534cd680a25d8d14429af824f38a2c7d9908","modified":1520401170000},{"_id":"source/_posts/disk-extend/disk1.png","hash":"2cce96f053ba365c4c2f8fba8fc444435020688e","modified":1548864103000},{"_id":"themes/next/source/lib/velocity/velocity.min.js","hash":"2f1afadc12e4cf59ef3b405308d21baa97e739c6","modified":1520401170000},{"_id":"themes/next/source/lib/velocity/velocity.ui.js","hash":"6a1d101eab3de87527bb54fcc8c7b36b79d8f0df","modified":1520401170000},{"_id":"source/_posts/disk-extend/disk6.png","hash":"f397ed9553c6f179b22aaba5c245823b0e0bc6f2","modified":1548865955000},{"_id":"themes/next/source/lib/jquery/index.js","hash":"41b4bfbaa96be6d1440db6e78004ade1c134e276","modified":1520401170000},{"_id":"source/_posts/disk-extend/disk2.png","hash":"2e72f193206333a4fbd2b2b24120aed837f03499","modified":1548864714000},{"_id":"source/_posts/disk-extend/disk8.png","hash":"fabf0598ad38319d7669fd47b2de650303a0017b","modified":1548866615000},{"_id":"source/_posts/disk-extend/disk9.png","hash":"454954fd8848a75eb9be24e9f03e98c7e613b294","modified":1548866657000},{"_id":"themes/next/layout/_third-party/search/algolia-search/dom.swig","hash":"ba698f49dd3a868c95b240d802f5b1b24ff287e4","modified":1520401170000},{"_id":"themes/next/layout/_third-party/search/algolia-search/assets.swig","hash":"28ff4ed6714c59124569ffcbd10f1173d53ca923","modified":1520401170000},{"_id":"themes/next/source/css/_common/components/back-to-top-sidebar.styl","hash":"4719ce717962663c5c33ef97b1119a0b3a4ecdc3","modified":1520401170000},{"_id":"themes/next/source/css/_common/components/back-to-top.styl","hash":"31050fc7a25784805b4843550151c93bfa55c9c8","modified":1520401170000},{"_id":"themes/next/source/css/_common/components/buttons.styl","hash":"7e509c7c28c59f905b847304dd3d14d94b6f3b8e","modified":1520401170000},{"_id":"themes/next/source/css/_common/components/comments.styl","hash":"471f1627891aca5c0e1973e09fbcb01e1510d193","modified":1520401170000},{"_id":"themes/next/source/css/_common/components/components.styl","hash":"a6bb5256be6195e76addbda12f4ed7c662d65e7a","modified":1520401170000},{"_id":"themes/next/source/css/_common/components/pagination.styl","hash":"c5d48863f332ff8ce7c88dec2c893f709d7331d3","modified":1520401170000},{"_id":"themes/next/source/css/_common/components/tag-cloud.styl","hash":"dd8a3b22fc2f222ac6e6c05bd8a773fb039169c0","modified":1520401170000},{"_id":"themes/next/source/css/_common/outline/outline.styl","hash":"2186be20e317505cd31886f1291429cc21f76703","modified":1520401170000},{"_id":"themes/next/source/css/_common/scaffolding/base.styl","hash":"f7c44b0ee46cf2cf82a4c9455ba8d8b55299976f","modified":1520401170000},{"_id":"themes/next/source/css/_common/scaffolding/helpers.styl","hash":"9c25c75311e1bd4d68df031d3f2ae6d141a90766","modified":1520401170000},{"_id":"themes/next/source/css/_common/scaffolding/mobile.styl","hash":"47a46583a1f3731157a3f53f80ed1ed5e2753e8e","modified":1520401170000},{"_id":"themes/next/source/css/_common/scaffolding/normalize.styl","hash":"ece571f38180febaf02ace8187ead8318a300ea7","modified":1520401170000},{"_id":"themes/next/source/css/_common/scaffolding/scaffolding.styl","hash":"a280a583b7615e939aaddbf778f5c108ef8a2a6c","modified":1520401170000},{"_id":"themes/next/source/css/_common/scaffolding/tables.styl","hash":"64f5d56c08d74a338813df1265580ca0cbf0190b","modified":1520401170000},{"_id":"themes/next/source/css/_schemes/Gemini/index.styl","hash":"18c3336ee3d09bd2da6a876e1336539f03d5a973","modified":1520401170000},{"_id":"themes/next/source/css/_schemes/Mist/_base.styl","hash":"c2d079788d6fc2e9a191ccdae94e50d55bf849dc","modified":1520401170000},{"_id":"themes/next/source/css/_schemes/Mist/_header.styl","hash":"5ae7906dc7c1d9468c7f4b4a6feddddc555797a1","modified":1520401170000},{"_id":"themes/next/source/css/_schemes/Mist/_logo.styl","hash":"38e5df90c8689a71c978fd83ba74af3d4e4e5386","modified":1520401170000},{"_id":"themes/next/source/css/_schemes/Mist/_menu.styl","hash":"b0dcca862cd0cc6e732e33d975b476d744911742","modified":1520401170000},{"_id":"themes/next/source/css/_schemes/Mist/_search.styl","hash":"1452cbe674cc1d008e1e9640eb4283841058fc64","modified":1520401170000},{"_id":"themes/next/source/css/_schemes/Mist/_posts-expanded.styl","hash":"3b25edfa187d1bbbd0d38b50dd013cef54758abf","modified":1520401170000},{"_id":"themes/next/source/css/_schemes/Mist/index.styl","hash":"9a5581a770af8964064fef7afd3e16963e45547f","modified":1520401170000},{"_id":"themes/next/source/css/_schemes/Muse/_logo.styl","hash":"8829bc556ca38bfec4add4f15a2f028092ac6d46","modified":1520401170000},{"_id":"themes/next/source/css/_schemes/Muse/_layout.styl","hash":"0efa036a15c18f5abb058b7c0fad1dd9ac5eed4c","modified":1520401170000},{"_id":"themes/next/source/css/_schemes/Muse/_menu.styl","hash":"02fb8fa6b6c252b6bed469539cd057716606a787","modified":1520401170000},{"_id":"themes/next/source/css/_schemes/Muse/_search.styl","hash":"1452cbe674cc1d008e1e9640eb4283841058fc64","modified":1520401170000},{"_id":"themes/next/source/css/_schemes/Muse/index.styl","hash":"a0e2030a606c934fb2c5c7373aaae04a1caac4c5","modified":1520401170000},{"_id":"themes/next/source/css/_schemes/Pisces/_brand.styl","hash":"c4ed249798296f60bda02351fe6404fb3ef2126f","modified":1520401170000},{"_id":"themes/next/source/css/_schemes/Pisces/_menu.styl","hash":"215de948be49bcf14f06d500cef9f7035e406a43","modified":1520401170000},{"_id":"themes/next/source/css/_schemes/Pisces/_layout.styl","hash":"5b93958239d3d2bf9aeaede44eced2434d784462","modified":1520401170000},{"_id":"themes/next/source/css/_schemes/Pisces/_posts.styl","hash":"2f878213cb24c5ddc18877f6d15ec5c5f57745ac","modified":1520401170000},{"_id":"themes/next/source/css/_schemes/Pisces/_sidebar.styl","hash":"bcf52192942c0afc410c74a0fb458e7936ddc3d5","modified":1520401170000},{"_id":"themes/next/source/css/_schemes/Pisces/index.styl","hash":"69ecd6c97e7cdfd822ac8102b45ad0ede85050db","modified":1520401170000},{"_id":"themes/next/source/js/src/schemes/pisces.js","hash":"8050a5b2683d1d77238c5762b6bd89c543daed6e","modified":1520401170000},{"_id":"themes/next/source/lib/Han/dist/han.min.css","hash":"a0c9e32549a8b8cf327ab9227b037f323cdb60ee","modified":1520401170000},{"_id":"themes/next/source/lib/Han/dist/han.css","hash":"bd40da3fba8735df5850956814e312bd7b3193d7","modified":1520401170000},{"_id":"themes/next/source/lib/Han/dist/han.min.js","hash":"f559c68a25065a14f47da954a7617d87263e409d","modified":1520401170000},{"_id":"themes/next/source/lib/fancybox/source/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1520401170000},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1520401170000},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1520401170000},{"_id":"themes/next/source/lib/fancybox/source/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1520401170000},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1520401170000},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1520401170000},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.css","hash":"5f163444617b6cf267342f06ac166a237bb62df9","modified":1520401170000},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.js","hash":"1cf3d47b5ccb7cb6e9019c64f2a88d03a64853e4","modified":1520401170000},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.pack.js","hash":"53360764b429c212f424399384417ccc233bb3be","modified":1520401170000},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.js","hash":"06cef196733a710e77ad7e386ced6963f092dc55","modified":1520401170000},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.min.js","hash":"2cae0f5a6c5d6f3cb993015e6863f9483fc4de18","modified":1520401170000},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css","hash":"0140952c64e3f2b74ef64e050f2fe86eab6624c8","modified":1520401170000},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css.map","hash":"0189d278706509412bac4745f96c83984e1d59f4","modified":1520401170000},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.min.css","hash":"512c7d79033e3028a9be61b540cf1a6870c896f8","modified":1520401170000},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.min.js","hash":"38628e75e4412cc6f11074e03e1c6d257aae495b","modified":1520401170000},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.pack.js","hash":"214dad442a92d36af77ed0ca1d9092b16687f02f","modified":1520401170000},{"_id":"source/_posts/disk-extend/disk5.png","hash":"6c33ae4a119130b6104bcd1b2b5820ef656f9c02","modified":1548865161000},{"_id":"themes/next/source/lib/Han/dist/han.js","hash":"e345397e0585c9fed1449e614ec13e0224acf2ab","modified":1520401170000},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff2","hash":"d6f48cba7d076fb6f2fd6ba993a75b9dc1ecbf0c","modified":1520401170000},{"_id":"themes/next/source/css/_common/components/footer/footer.styl","hash":"7905a7f625702b45645d8be1268cb8af3f698c70","modified":1520401170000},{"_id":"themes/next/source/css/_common/components/highlight/diff.styl","hash":"96f32ea6c3265a3889e6abe57587f6e2a2a40dfb","modified":1520401170000},{"_id":"themes/next/source/css/_common/components/highlight/theme.styl","hash":"b76387934fb6bb75212b23c1a194486892cc495e","modified":1520401170000},{"_id":"themes/next/source/css/_common/components/highlight/highlight.styl","hash":"25dc25f61a232f03ca72472b7852f882448ec185","modified":1520401170000},{"_id":"themes/next/source/css/_common/components/header/header.styl","hash":"ae1ca14e51de67b07dba8f61ec79ee0e2e344574","modified":1520401170000},{"_id":"themes/next/source/css/_common/components/header/headerband.styl","hash":"d27448f199fc2f9980b601bc22b87f08b5d64dd1","modified":1520401170000},{"_id":"themes/next/source/css/_common/components/header/site-meta.styl","hash":"6c00f6e0978f4d8f9a846a15579963728aaa6a17","modified":1520401170000},{"_id":"themes/next/source/css/_common/components/header/menu.styl","hash":"8a2421cb9005352905fae9d41a847ae56957247e","modified":1520401170000},{"_id":"themes/next/source/css/_common/components/header/site-nav.styl","hash":"49c2b2c14a1e7fcc810c6be4b632975d0204c281","modified":1520401170000},{"_id":"themes/next/source/css/_common/components/pages/archive.styl","hash":"f5aa2ba3bfffc15475e7e72a55b5c9d18609fdf5","modified":1520401170000},{"_id":"themes/next/source/css/_common/components/pages/categories.styl","hash":"4eff5b252d7b614e500fc7d52c97ce325e57d3ab","modified":1520401170000},{"_id":"themes/next/source/css/_common/components/pages/pages.styl","hash":"2039590632bba3943c39319d80ef630af7928185","modified":1520401170000},{"_id":"themes/next/source/css/_common/components/pages/post-detail.styl","hash":"9bf4362a4d0ae151ada84b219d39fbe5bb8c790e","modified":1520401170000},{"_id":"themes/next/source/css/_common/components/pages/schedule.styl","hash":"a82afbb72d83ee394aedc7b37ac0008a9823b4f4","modified":1520401170000},{"_id":"themes/next/source/css/_common/components/post/post-button.styl","hash":"e72a89e0f421444453e149ba32c77a64bd8e44e8","modified":1520401170000},{"_id":"themes/next/source/css/_common/components/post/post-collapse.styl","hash":"0f7f522cc6bfb3401d5afd62b0fcdf48bb2d604b","modified":1520401170000},{"_id":"themes/next/source/css/_common/components/post/post-copyright.styl","hash":"f54367c0feda6986c030cc4d15a0ca6ceea14bcb","modified":1520401170000},{"_id":"themes/next/source/css/_common/components/post/post-eof.styl","hash":"2cdc094ecf907a02fce25ad4a607cd5c40da0f2b","modified":1520401170000},{"_id":"themes/next/source/css/_common/components/post/post-expand.styl","hash":"535b3b4f8cb1eec2558e094320e7dfb01f94c0e7","modified":1520401170000},{"_id":"themes/next/source/css/_common/components/post/post-gallery.styl","hash":"387ce23bba52b22a586b2dfb4ec618fe1ffd3926","modified":1520401170000},{"_id":"themes/next/source/css/_common/components/post/post-meta.styl","hash":"aea21141015ca8c409d8b33e3e34ec505f464e93","modified":1520401170000},{"_id":"themes/next/source/css/_common/components/post/post-nav.styl","hash":"a5d8617a24d7cb6c5ad91ea621183ca2c0917331","modified":1520401170000},{"_id":"themes/next/source/css/_common/components/post/post-reward.styl","hash":"36332c8a91f089f545f3c3e8ea90d08aa4d6e60c","modified":1520401170000},{"_id":"themes/next/source/css/_common/components/post/post-rtl.styl","hash":"017074ef58166e2d69c53bb7590a0e7a8947a1ed","modified":1520401170000},{"_id":"themes/next/source/css/_common/components/post/post-title.styl","hash":"d5a4e4fc17f1f7e7c3a61b52d8e2e9677e139de7","modified":1520401170000},{"_id":"themes/next/source/css/_common/components/post/post-type.styl","hash":"10251257aceecb117233c9554dcf8ecfef8e2104","modified":1520401170000},{"_id":"themes/next/source/css/_common/components/post/post-tags.styl","hash":"a352ae5b1f8857393bf770d2e638bf15f0c9585d","modified":1520401170000},{"_id":"themes/next/source/css/_common/components/post/post-widgets.styl","hash":"e4055a0d2cd2b0ad9dc55928e2f3e7bd4e499da3","modified":1520401170000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-author-links.styl","hash":"0a6c0efffdf18bddbc1d1238feaed282b09cd0fe","modified":1520401170000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-author.styl","hash":"920343e41c124221a17f050bbb989494d44f7a24","modified":1520401170000},{"_id":"themes/next/source/css/_common/components/post/post.styl","hash":"262debfd4442fa03d9919ceb88b948339df03fb0","modified":1520401170000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-blogroll.styl","hash":"89dd4f8b1f1cce3ad46cf2256038472712387d02","modified":1520401170000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-dimmer.styl","hash":"efa5e5022e205b52786ce495d4879f5e7b8f84b2","modified":1520401170000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-feed-link.styl","hash":"9486ddd2cb255227db102d09a7df4cae0fabad72","modified":1520401170000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-nav.styl","hash":"45fa7193435a8eae9960267438750b4c9fa9587f","modified":1520401170000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-toggle.styl","hash":"f7784aba0c1cd20d824c918c120012d57a5eaa2a","modified":1520401170000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-toc.styl","hash":"77c92a449ce84d558d26d052681f2e0dd77c70c9","modified":1520401170000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar.styl","hash":"50305b6ad7d09d2ffa4854e39f41ec1f4fe984fd","modified":1520401170000},{"_id":"themes/next/source/css/_common/components/sidebar/site-state.styl","hash":"3623e7fa4324ec1307370f33d8f287a9e20a5578","modified":1520401170000},{"_id":"themes/next/source/css/_common/components/tags/blockquote-center.styl","hash":"c2abe4d87148e23e15d49ee225bc650de60baf46","modified":1520401170000},{"_id":"themes/next/source/css/_common/components/tags/exturl.styl","hash":"1b3cc9f4e5a7f6e05b4100e9990b37b20d4a2005","modified":1520401170000},{"_id":"themes/next/source/css/_common/components/tags/group-pictures.styl","hash":"4851b981020c5cbc354a1af9b831a2dcb3cf9d39","modified":1520401170000},{"_id":"themes/next/source/css/_common/components/tags/full-image.styl","hash":"b8969e1654eec89a0fd10d88b337fee9cb03cd44","modified":1520401170000},{"_id":"themes/next/source/css/_common/components/tags/label.styl","hash":"4a457d265d62f287c63d48764ce45d9bcfc9ec5a","modified":1520401170000},{"_id":"themes/next/source/css/_common/components/tags/note-modern.styl","hash":"ee7528900578ef4753effe05b346381c40de5499","modified":1520401170000},{"_id":"themes/next/source/css/_common/components/tags/note.styl","hash":"32c9156bea5bac9e9ad0b4c08ffbca8b3d9aac4b","modified":1520401170000},{"_id":"themes/next/source/css/_common/components/tags/tabs.styl","hash":"4ab5deed8c3b0c338212380f678f8382672e1bcb","modified":1520401170000},{"_id":"themes/next/source/css/_common/components/tags/tags.styl","hash":"ead0d0f2321dc71505788c7f689f92257cf14947","modified":1520401170000},{"_id":"themes/next/source/css/_common/components/third-party/algolia-search.styl","hash":"fd42777b9125fd8969dc39d4f15473e2b91b4142","modified":1520401170000},{"_id":"themes/next/source/css/_common/components/third-party/baidushare.styl","hash":"93b08815c4d17e2b96fef8530ec1f1064dede6ef","modified":1520401170000},{"_id":"themes/next/source/css/_common/components/third-party/busuanzi-counter.styl","hash":"d4e6d8d7b34dc69994593c208f875ae8f7e8a3ae","modified":1520401170000},{"_id":"themes/next/source/css/_common/components/third-party/gitment.styl","hash":"34935b40237c074be5f5e8818c14ccfd802b7439","modified":1520401170000},{"_id":"themes/next/source/css/_common/components/third-party/han.styl","hash":"cce6772e2cdb4db85d35486ae4c6c59367fbdd40","modified":1520401170000},{"_id":"themes/next/source/css/_common/components/third-party/duoshuo.styl","hash":"2340dd9b3202c61d73cc708b790fac5adddbfc7f","modified":1520401170000},{"_id":"themes/next/source/css/_common/components/third-party/jiathis.styl","hash":"327b5f63d55ec26f7663185c1a778440588d9803","modified":1520401170000},{"_id":"themes/next/source/css/_common/components/third-party/localsearch.styl","hash":"d89c4b562b528e4746696b2ad8935764d133bdae","modified":1520401170000},{"_id":"themes/next/source/css/_common/components/third-party/third-party.styl","hash":"1ccfbd4d0f5754b2dc2719a91245c95f547a7652","modified":1520401170000},{"_id":"themes/next/source/css/_common/components/third-party/needsharebutton.styl","hash":"a5e3e6b4b4b814a9fe40b34d784fed67d6d977fa","modified":1520401170000},{"_id":"themes/next/source/css/_schemes/Mist/outline/outline.styl","hash":"5dc4859c66305f871e56cba78f64bfe3bf1b5f01","modified":1520401170000},{"_id":"themes/next/source/css/_schemes/Mist/sidebar/sidebar-blogroll.styl","hash":"817587e46df49e819858c8ecbafa08b53d5ff040","modified":1520401170000},{"_id":"themes/next/source/css/_schemes/Muse/sidebar/sidebar-blogroll.styl","hash":"817587e46df49e819858c8ecbafa08b53d5ff040","modified":1520401170000},{"_id":"themes/next/source/lib/Han/dist/font/han-space.woff","hash":"7a635062b10bf5662ae1d218ba0980171005d060","modified":1520401170000},{"_id":"themes/next/source/lib/Han/dist/font/han-space.otf","hash":"07436f011b44051f61b8329c99de4bec64e86f4b","modified":1520401170000},{"_id":"themes/next/source/lib/Han/dist/font/han.woff2","hash":"623af3ed5423371ac136a4fe0e8cc7bb7396037a","modified":1520401170000},{"_id":"themes/next/source/lib/Han/dist/font/han.woff","hash":"f38ff9b2eecaa17b50b66aa2dae87e9e7436d195","modified":1520401170000},{"_id":"themes/next/source/lib/Han/dist/font/han.otf","hash":"f1f6bb8f461f5672e000380195d3d2358a28494c","modified":1520401170000},{"_id":"themes/next/source/lib/fancybox/source/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1520401170000},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","hash":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8","modified":1520401170000},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-media.js","hash":"3bdf69ed2469e4fb57f5a95f17300eef891ff90d","modified":1520401170000},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","hash":"91e41741c2e93f732c82aaacec4cfc6e3f3ec876","modified":1520401170000},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","hash":"4ac329c16a5277592fc12a37cca3d72ca4ec292f","modified":1520401170000},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","hash":"53e194f4a72e649c04fb586dd57762b8c022800b","modified":1520401170000},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff","hash":"28b782240b3e76db824e12c02754a9731a167527","modified":1520401170000},{"_id":"themes/next/source/lib/velocity/velocity.js","hash":"9f08181baea0cc0e906703b7e5df9111b9ef3373","modified":1520401170000},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.eot","hash":"d980c2ce873dc43af460d4d572d441304499f400","modified":1520401170000},{"_id":"themes/next/source/lib/font-awesome/fonts/FontAwesome.otf","hash":"048707bc52ac4b6563aaa383bfe8660a0ddc908c","modified":1520401170000},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.ttf","hash":"13b1eab65a983c7a73bc7997c479d66943f7c6cb","modified":1520401170000},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.js","hash":"9ccc6f8144f54e86df9a3fd33a18368d81cf3a4f","modified":1520401170000},{"_id":"themes/next/source/lib/three/three.min.js","hash":"73f4cdc17e51a72b9bf5b9291f65386d615c483b","modified":1520401170000},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.svg","hash":"98a8aa5cf7d62c2eff5f07ede8d844b874ef06ed","modified":1520401170000},{"_id":"source/_posts/linux-performance-tools/linux_perf_tools_full.pdf","hash":"f398e27cbf3a874ef6f09c8abe6c014cb4f1e076","modified":1571030908340},{"_id":"source/_posts/linux-performance-tools/linux_perf_tools_full.png","hash":"c61f9ab05e0ddd788dae496142975f8495b234f5","modified":1571031503655}],"Category":[],"Data":[],"Page":[{"title":"tags","date":"2017-07-03T02:11:04.000Z","type":"tags","_content":"\n","source":"tags/index.md","raw":"---\ntitle: tags\ndate: 2017-07-03 10:11:04\ntype: \"tags\"\n---\n\n","updated":"2018-03-07T05:39:30.000Z","path":"tags/index.html","comments":1,"layout":"page","_id":"ck1pzbtlc001mtp75s9byfpd6","content":"","site":{"data":{}},"excerpt":"","more":""}],"Post":[{"title":"Centos7 修改网卡为ethX","date":"2017-10-10T09:57:57.000Z","_content":"Centos7之后默认的网卡名变成enp0s3这种样子，不再是ethX\n\n通过下面的步骤可以把网卡名变回ethX\n\n+ vim /etc/default/grub\n\n\t在GRUB_CMDLINE_LINUX的最后，加上 <span style=\"color:red\">net.ifnames=0 biosdevname=0</span> 的参数\n\t\n\t```\n\tGRUB_TIMEOUT=5\n\tGRUB_DISTRIBUTOR=”$(sed ‘s, release .*$,,g’ /etc/system-release)”\n\tGRUB_DEFAULT=saved\n\tGRUB_DISABLE_SUBMENU=true\n\tGRUB_TERMINAL_OUTPUT=”console”\n\tGRUB_CMDLINE_LINUX=”rd.lvm.lv=rootvg/usrlv rd.lvm.lv=rootvg/swaplv crashkernel=auto vconsole.keymap=us rd.lvm.lv=rootvg/rootlv vconsole.font=latarcyrheb-sun16 rhgb quiet net.ifnames=0 biosdevname=0”\n\tGRUB_DISABLE_RECOVERY=”true”\n\t```\n\t\n+ grub2-mkconfig -o /boot/grub2/grub.cfg\n+ mv /etc/sysconfig/network-scripts/ifcfg-enp0s3  /etc/sysconfig/network-scripts/ifcfg-eth0\n+ reboot\n\n\n ","source":"_posts/centos-net.md","raw":"---\ntitle: Centos7 修改网卡为ethX\ndate: 2017-10-10 17:57:57\ntags:\n---\nCentos7之后默认的网卡名变成enp0s3这种样子，不再是ethX\n\n通过下面的步骤可以把网卡名变回ethX\n\n+ vim /etc/default/grub\n\n\t在GRUB_CMDLINE_LINUX的最后，加上 <span style=\"color:red\">net.ifnames=0 biosdevname=0</span> 的参数\n\t\n\t```\n\tGRUB_TIMEOUT=5\n\tGRUB_DISTRIBUTOR=”$(sed ‘s, release .*$,,g’ /etc/system-release)”\n\tGRUB_DEFAULT=saved\n\tGRUB_DISABLE_SUBMENU=true\n\tGRUB_TERMINAL_OUTPUT=”console”\n\tGRUB_CMDLINE_LINUX=”rd.lvm.lv=rootvg/usrlv rd.lvm.lv=rootvg/swaplv crashkernel=auto vconsole.keymap=us rd.lvm.lv=rootvg/rootlv vconsole.font=latarcyrheb-sun16 rhgb quiet net.ifnames=0 biosdevname=0”\n\tGRUB_DISABLE_RECOVERY=”true”\n\t```\n\t\n+ grub2-mkconfig -o /boot/grub2/grub.cfg\n+ mv /etc/sysconfig/network-scripts/ifcfg-enp0s3  /etc/sysconfig/network-scripts/ifcfg-eth0\n+ reboot\n\n\n ","slug":"centos-net","published":1,"updated":"2018-03-07T05:39:30.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck1pzbtge0000tp75vvi4p4k4","content":"<p>Centos7之后默认的网卡名变成enp0s3这种样子，不再是ethX</p>\n<p>通过下面的步骤可以把网卡名变回ethX</p>\n<ul>\n<li><p>vim /etc/default/grub</p>\n<p>  在GRUB_CMDLINE_LINUX的最后，加上 <span style=\"color:red\">net.ifnames=0 biosdevname=0</span> 的参数</p>\n  <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">GRUB_TIMEOUT=5</span><br><span class=\"line\">GRUB_DISTRIBUTOR=”$(sed ‘s, release .*$,,g’ /etc/system-release)”</span><br><span class=\"line\">GRUB_DEFAULT=saved</span><br><span class=\"line\">GRUB_DISABLE_SUBMENU=true</span><br><span class=\"line\">GRUB_TERMINAL_OUTPUT=”console”</span><br><span class=\"line\">GRUB_CMDLINE_LINUX=”rd.lvm.lv=rootvg/usrlv rd.lvm.lv=rootvg/swaplv crashkernel=auto vconsole.keymap=us rd.lvm.lv=rootvg/rootlv vconsole.font=latarcyrheb-sun16 rhgb quiet net.ifnames=0 biosdevname=0”</span><br><span class=\"line\">GRUB_DISABLE_RECOVERY=”true”</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<ul>\n<li>grub2-mkconfig -o /boot/grub2/grub.cfg</li>\n<li>mv /etc/sysconfig/network-scripts/ifcfg-enp0s3  /etc/sysconfig/network-scripts/ifcfg-eth0</li>\n<li>reboot</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<p>Centos7之后默认的网卡名变成enp0s3这种样子，不再是ethX</p>\n<p>通过下面的步骤可以把网卡名变回ethX</p>\n<ul>\n<li><p>vim /etc/default/grub</p>\n<p>  在GRUB_CMDLINE_LINUX的最后，加上 <span style=\"color:red\">net.ifnames=0 biosdevname=0</span> 的参数</p>\n  <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">GRUB_TIMEOUT=5</span><br><span class=\"line\">GRUB_DISTRIBUTOR=”$(sed ‘s, release .*$,,g’ /etc/system-release)”</span><br><span class=\"line\">GRUB_DEFAULT=saved</span><br><span class=\"line\">GRUB_DISABLE_SUBMENU=true</span><br><span class=\"line\">GRUB_TERMINAL_OUTPUT=”console”</span><br><span class=\"line\">GRUB_CMDLINE_LINUX=”rd.lvm.lv=rootvg/usrlv rd.lvm.lv=rootvg/swaplv crashkernel=auto vconsole.keymap=us rd.lvm.lv=rootvg/rootlv vconsole.font=latarcyrheb-sun16 rhgb quiet net.ifnames=0 biosdevname=0”</span><br><span class=\"line\">GRUB_DISABLE_RECOVERY=”true”</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<ul>\n<li>grub2-mkconfig -o /boot/grub2/grub.cfg</li>\n<li>mv /etc/sysconfig/network-scripts/ifcfg-enp0s3  /etc/sysconfig/network-scripts/ifcfg-eth0</li>\n<li>reboot</li>\n</ul>\n"},{"title":"ceph-ansible","date":"2018-02-06T15:13:09.000Z","_content":"\n通过本文了解如果通过ceph-ansible来安装ceph\n\n前提条件\n\n- 配置免密\n- 关闭防火墙\n- 关闭selinux\n\n安装ansible\n\n    pip install ansible==2.3.1.0\n    \n    mkdir /etc/ansible\n    \n    touch /etc/ansible/hosts\n\n下载ceph-ansible\n\n    git clone https://github.com/ceph/ceph-ansible.git\n    \n    cd ceph-ansible\n    \n    git checkout -b stable-3.0 origin/stable-3.0\n\n修改配置\n\n规划好要部署的服务器及组件\n\n例如，需要在ceph0节点上部署mon，mgr和osd，则在/etc/ansible/hosts文件中添加如下内容\n\n    [mons]\n    ceph0\n    \n    [osds]\n    ceph0\n    \n    [mgrs]\n    ceph0\n    \n\n修改ceph-ansible配置\n\n    cd ceph-ansible/group_vars\n    cp all.yml.sample all.yml\n    cp mons.yml.sample mons.yml\n    cp mgrs.yml.sample mgrs.yml\n    cp osds.yml.sample osds.yml\n    \n\n把all.yml文件改成如下内容\n\n    dummy:\n    ceph_origin: repository\n    ceph_repository: community\n    ceph_mirror: http://mirrors.ustc.edu.cn/ceph\n    ceph_stable_key: http://mirrors.ustc.edu.cn/ceph/keys/release.asc\n    ceph_stable_release: luminous\n    ceph_stable_redhat_distro: el7\n    monitor_interface: ens160\n    monitor_address: 0.0.0.0\n    public_network: 123.59.153.0/24\n    cluster_network: 10.10.20.0/24\n    osd_objectstore: bluestore\n    handler_health_osd_check: false\n\n具体配置含义及其他一些配置内容可以参考相应的all.yml.sample\n\nmonitor_interface, public_network 和 cluster_network 根据实际情况调整\n\nosd_objectstore可以选择bluestore和filestore\n\n假设ceph0节点上有3块硬盘（sdb,sdc,sddd）用户部署OSD\n\n把osds.yml 改成如下内容\n\n    ---\n    dummy:\n    devices:\n      - /dev/sdb\n      - /dev/sdc\n      - /dev/sdd\n    osd_scenario: collocated\n\nosds.yml.sample中定了多种osd部署方式，可以根据需要灵活调整。\n\n上面这个例子中，会把一块硬盘分区两个分区，一个分区100M，一个占满磁盘的剩余空间。\n\n100M的分区会作为ceph block, ceph block.db, ceph block.wal, 另一个分区作为 ceph data。\n\n部署ceph\n\n    cd ceph-ansible\n    cp site.yml.sample site.yml\n    \n    ansible-playbook site.yml \n    \n\n修改crush rule\n\n部署完成后默认的crush rule的故障域是host，如果ceph是部署在一个server上，在创建多副本pool的情况下会存在问题。\n\n通过修改crush rule的故障域为osd，可以解决这个问题。\n\n    ceph osd getcrushmap -o crushmap\n    \n    crushtool -d crushmap -o crushmap.txt\n    \n\n修改crushmap.txt 文件中内容如下，把故障域从host改成osd\n\n    rule replicated_rule {\n            id 0\n            type replicated\n            min_size 1\n            max_size 10\n            step take default\n            step chooseleaf firstn 0 type osd\n            step emit\n    }\n    \n\n导入新的crushmap\n\n    crushtool -c crushmap.txt -o crushmap\n    ceph osd setcrushmap -i crushmap\n    \n\n创建POOL\n\n根据需要创建POOL\n\n    ceph osd pool create testpool 32\n    \n\n清理ceph\n\n    cd ceph-ansible\n    \n    cp infrastructure-playbooks/purge-cluster.yml .\n    \n    ansible-playbook purge-cluster.yml\n\n\n","source":"_posts/ceph-ansible.md","raw":"---\ntitle: ceph-ansible\ndate: 2018-02-06 23:13:09\ntags: ceph\n---\n\n通过本文了解如果通过ceph-ansible来安装ceph\n\n前提条件\n\n- 配置免密\n- 关闭防火墙\n- 关闭selinux\n\n安装ansible\n\n    pip install ansible==2.3.1.0\n    \n    mkdir /etc/ansible\n    \n    touch /etc/ansible/hosts\n\n下载ceph-ansible\n\n    git clone https://github.com/ceph/ceph-ansible.git\n    \n    cd ceph-ansible\n    \n    git checkout -b stable-3.0 origin/stable-3.0\n\n修改配置\n\n规划好要部署的服务器及组件\n\n例如，需要在ceph0节点上部署mon，mgr和osd，则在/etc/ansible/hosts文件中添加如下内容\n\n    [mons]\n    ceph0\n    \n    [osds]\n    ceph0\n    \n    [mgrs]\n    ceph0\n    \n\n修改ceph-ansible配置\n\n    cd ceph-ansible/group_vars\n    cp all.yml.sample all.yml\n    cp mons.yml.sample mons.yml\n    cp mgrs.yml.sample mgrs.yml\n    cp osds.yml.sample osds.yml\n    \n\n把all.yml文件改成如下内容\n\n    dummy:\n    ceph_origin: repository\n    ceph_repository: community\n    ceph_mirror: http://mirrors.ustc.edu.cn/ceph\n    ceph_stable_key: http://mirrors.ustc.edu.cn/ceph/keys/release.asc\n    ceph_stable_release: luminous\n    ceph_stable_redhat_distro: el7\n    monitor_interface: ens160\n    monitor_address: 0.0.0.0\n    public_network: 123.59.153.0/24\n    cluster_network: 10.10.20.0/24\n    osd_objectstore: bluestore\n    handler_health_osd_check: false\n\n具体配置含义及其他一些配置内容可以参考相应的all.yml.sample\n\nmonitor_interface, public_network 和 cluster_network 根据实际情况调整\n\nosd_objectstore可以选择bluestore和filestore\n\n假设ceph0节点上有3块硬盘（sdb,sdc,sddd）用户部署OSD\n\n把osds.yml 改成如下内容\n\n    ---\n    dummy:\n    devices:\n      - /dev/sdb\n      - /dev/sdc\n      - /dev/sdd\n    osd_scenario: collocated\n\nosds.yml.sample中定了多种osd部署方式，可以根据需要灵活调整。\n\n上面这个例子中，会把一块硬盘分区两个分区，一个分区100M，一个占满磁盘的剩余空间。\n\n100M的分区会作为ceph block, ceph block.db, ceph block.wal, 另一个分区作为 ceph data。\n\n部署ceph\n\n    cd ceph-ansible\n    cp site.yml.sample site.yml\n    \n    ansible-playbook site.yml \n    \n\n修改crush rule\n\n部署完成后默认的crush rule的故障域是host，如果ceph是部署在一个server上，在创建多副本pool的情况下会存在问题。\n\n通过修改crush rule的故障域为osd，可以解决这个问题。\n\n    ceph osd getcrushmap -o crushmap\n    \n    crushtool -d crushmap -o crushmap.txt\n    \n\n修改crushmap.txt 文件中内容如下，把故障域从host改成osd\n\n    rule replicated_rule {\n            id 0\n            type replicated\n            min_size 1\n            max_size 10\n            step take default\n            step chooseleaf firstn 0 type osd\n            step emit\n    }\n    \n\n导入新的crushmap\n\n    crushtool -c crushmap.txt -o crushmap\n    ceph osd setcrushmap -i crushmap\n    \n\n创建POOL\n\n根据需要创建POOL\n\n    ceph osd pool create testpool 32\n    \n\n清理ceph\n\n    cd ceph-ansible\n    \n    cp infrastructure-playbooks/purge-cluster.yml .\n    \n    ansible-playbook purge-cluster.yml\n\n\n","slug":"ceph-ansible","published":1,"updated":"2018-11-28T05:33:34.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck1pzbtgh0001tp75l29uodaw","content":"<p>通过本文了解如果通过ceph-ansible来安装ceph</p>\n<p>前提条件</p>\n<ul>\n<li>配置免密</li>\n<li>关闭防火墙</li>\n<li>关闭selinux</li>\n</ul>\n<p>安装ansible</p>\n<pre><code>pip install ansible==2.3.1.0\n\nmkdir /etc/ansible\n\ntouch /etc/ansible/hosts\n</code></pre><p>下载ceph-ansible</p>\n<pre><code>git clone https://github.com/ceph/ceph-ansible.git\n\ncd ceph-ansible\n\ngit checkout -b stable-3.0 origin/stable-3.0\n</code></pre><p>修改配置</p>\n<p>规划好要部署的服务器及组件</p>\n<p>例如，需要在ceph0节点上部署mon，mgr和osd，则在/etc/ansible/hosts文件中添加如下内容</p>\n<pre><code>[mons]\nceph0\n\n[osds]\nceph0\n\n[mgrs]\nceph0\n</code></pre><p>修改ceph-ansible配置</p>\n<pre><code>cd ceph-ansible/group_vars\ncp all.yml.sample all.yml\ncp mons.yml.sample mons.yml\ncp mgrs.yml.sample mgrs.yml\ncp osds.yml.sample osds.yml\n</code></pre><p>把all.yml文件改成如下内容</p>\n<pre><code>dummy:\nceph_origin: repository\nceph_repository: community\nceph_mirror: http://mirrors.ustc.edu.cn/ceph\nceph_stable_key: http://mirrors.ustc.edu.cn/ceph/keys/release.asc\nceph_stable_release: luminous\nceph_stable_redhat_distro: el7\nmonitor_interface: ens160\nmonitor_address: 0.0.0.0\npublic_network: 123.59.153.0/24\ncluster_network: 10.10.20.0/24\nosd_objectstore: bluestore\nhandler_health_osd_check: false\n</code></pre><p>具体配置含义及其他一些配置内容可以参考相应的all.yml.sample</p>\n<p>monitor_interface, public_network 和 cluster_network 根据实际情况调整</p>\n<p>osd_objectstore可以选择bluestore和filestore</p>\n<p>假设ceph0节点上有3块硬盘（sdb,sdc,sddd）用户部署OSD</p>\n<p>把osds.yml 改成如下内容</p>\n<pre><code>---\ndummy:\ndevices:\n  - /dev/sdb\n  - /dev/sdc\n  - /dev/sdd\nosd_scenario: collocated\n</code></pre><p>osds.yml.sample中定了多种osd部署方式，可以根据需要灵活调整。</p>\n<p>上面这个例子中，会把一块硬盘分区两个分区，一个分区100M，一个占满磁盘的剩余空间。</p>\n<p>100M的分区会作为ceph block, ceph block.db, ceph block.wal, 另一个分区作为 ceph data。</p>\n<p>部署ceph</p>\n<pre><code>cd ceph-ansible\ncp site.yml.sample site.yml\n\nansible-playbook site.yml \n</code></pre><p>修改crush rule</p>\n<p>部署完成后默认的crush rule的故障域是host，如果ceph是部署在一个server上，在创建多副本pool的情况下会存在问题。</p>\n<p>通过修改crush rule的故障域为osd，可以解决这个问题。</p>\n<pre><code>ceph osd getcrushmap -o crushmap\n\ncrushtool -d crushmap -o crushmap.txt\n</code></pre><p>修改crushmap.txt 文件中内容如下，把故障域从host改成osd</p>\n<pre><code>rule replicated_rule {\n        id 0\n        type replicated\n        min_size 1\n        max_size 10\n        step take default\n        step chooseleaf firstn 0 type osd\n        step emit\n}\n</code></pre><p>导入新的crushmap</p>\n<pre><code>crushtool -c crushmap.txt -o crushmap\nceph osd setcrushmap -i crushmap\n</code></pre><p>创建POOL</p>\n<p>根据需要创建POOL</p>\n<pre><code>ceph osd pool create testpool 32\n</code></pre><p>清理ceph</p>\n<pre><code>cd ceph-ansible\n\ncp infrastructure-playbooks/purge-cluster.yml .\n\nansible-playbook purge-cluster.yml\n</code></pre>","site":{"data":{}},"excerpt":"","more":"<p>通过本文了解如果通过ceph-ansible来安装ceph</p>\n<p>前提条件</p>\n<ul>\n<li>配置免密</li>\n<li>关闭防火墙</li>\n<li>关闭selinux</li>\n</ul>\n<p>安装ansible</p>\n<pre><code>pip install ansible==2.3.1.0\n\nmkdir /etc/ansible\n\ntouch /etc/ansible/hosts\n</code></pre><p>下载ceph-ansible</p>\n<pre><code>git clone https://github.com/ceph/ceph-ansible.git\n\ncd ceph-ansible\n\ngit checkout -b stable-3.0 origin/stable-3.0\n</code></pre><p>修改配置</p>\n<p>规划好要部署的服务器及组件</p>\n<p>例如，需要在ceph0节点上部署mon，mgr和osd，则在/etc/ansible/hosts文件中添加如下内容</p>\n<pre><code>[mons]\nceph0\n\n[osds]\nceph0\n\n[mgrs]\nceph0\n</code></pre><p>修改ceph-ansible配置</p>\n<pre><code>cd ceph-ansible/group_vars\ncp all.yml.sample all.yml\ncp mons.yml.sample mons.yml\ncp mgrs.yml.sample mgrs.yml\ncp osds.yml.sample osds.yml\n</code></pre><p>把all.yml文件改成如下内容</p>\n<pre><code>dummy:\nceph_origin: repository\nceph_repository: community\nceph_mirror: http://mirrors.ustc.edu.cn/ceph\nceph_stable_key: http://mirrors.ustc.edu.cn/ceph/keys/release.asc\nceph_stable_release: luminous\nceph_stable_redhat_distro: el7\nmonitor_interface: ens160\nmonitor_address: 0.0.0.0\npublic_network: 123.59.153.0/24\ncluster_network: 10.10.20.0/24\nosd_objectstore: bluestore\nhandler_health_osd_check: false\n</code></pre><p>具体配置含义及其他一些配置内容可以参考相应的all.yml.sample</p>\n<p>monitor_interface, public_network 和 cluster_network 根据实际情况调整</p>\n<p>osd_objectstore可以选择bluestore和filestore</p>\n<p>假设ceph0节点上有3块硬盘（sdb,sdc,sddd）用户部署OSD</p>\n<p>把osds.yml 改成如下内容</p>\n<pre><code>---\ndummy:\ndevices:\n  - /dev/sdb\n  - /dev/sdc\n  - /dev/sdd\nosd_scenario: collocated\n</code></pre><p>osds.yml.sample中定了多种osd部署方式，可以根据需要灵活调整。</p>\n<p>上面这个例子中，会把一块硬盘分区两个分区，一个分区100M，一个占满磁盘的剩余空间。</p>\n<p>100M的分区会作为ceph block, ceph block.db, ceph block.wal, 另一个分区作为 ceph data。</p>\n<p>部署ceph</p>\n<pre><code>cd ceph-ansible\ncp site.yml.sample site.yml\n\nansible-playbook site.yml \n</code></pre><p>修改crush rule</p>\n<p>部署完成后默认的crush rule的故障域是host，如果ceph是部署在一个server上，在创建多副本pool的情况下会存在问题。</p>\n<p>通过修改crush rule的故障域为osd，可以解决这个问题。</p>\n<pre><code>ceph osd getcrushmap -o crushmap\n\ncrushtool -d crushmap -o crushmap.txt\n</code></pre><p>修改crushmap.txt 文件中内容如下，把故障域从host改成osd</p>\n<pre><code>rule replicated_rule {\n        id 0\n        type replicated\n        min_size 1\n        max_size 10\n        step take default\n        step chooseleaf firstn 0 type osd\n        step emit\n}\n</code></pre><p>导入新的crushmap</p>\n<pre><code>crushtool -c crushmap.txt -o crushmap\nceph osd setcrushmap -i crushmap\n</code></pre><p>创建POOL</p>\n<p>根据需要创建POOL</p>\n<pre><code>ceph osd pool create testpool 32\n</code></pre><p>清理ceph</p>\n<pre><code>cd ceph-ansible\n\ncp infrastructure-playbooks/purge-cluster.yml .\n\nansible-playbook purge-cluster.yml\n</code></pre>"},{"title":"通过ceph-deploy部署ceph","date":"2018-11-27T06:58:11.000Z","_content":"\n之前一直使用ceph-ansible来部署ceph，ceph-ansible在大规模部署的情况下比较合适，而且支持各种部署方式。  \n现在遇到的场景是是集群需要动态的调整，一开始是一个小规模的集群，后续需要动态增删服务来动态调整集群。  \nceph-ansible并没有单独添加删除某个服务的脚本，并不适合这种情况；而ceph-deploy可以比较方便的支持服务的添加和删除，可以满足这种场景。 \n \n下面通过实验来验证ceph-deploy部署ceph集群的各种服务。\n\n# 环境信息\n\n本次实验共有4台虚拟机，具体信息如下\n\n| Hostname | OS | Public network | Cluster network | Role |\n| ----- | ----- | ----- | ----- | ----- |\n| ceph001 | CentOS Linux release 7.5.1804 (Core) | 172.16.143.151 | 172.16.140.151| ceph-deply |\n| ceph002 | CentOS Linux release 7.5.1804 (Core) | 172.16.143.152 | 172.16.140.152| mon osd mgr rgw mds |\n| ceph003 | CentOS Linux release 7.5.1804 (Core) | 172.16.143.153 | 172.16.140.153| mon osd mgr rgw mds |\n| ceph004 | CentOS Linux release 7.5.1804 (Core) | 172.16.143.154 | 172.16.140.154| mon osd mgr rgw mds |\n\n# 配置\n* 关闭防火墙和SELinux\n* 配置ceph001到ceph002~4的免密登录\n* 配置ceph的国内源\n\nceph源配置，本次实验安装的ceph版本是**luminous**\n\n```\n[ceph_stable]\nbaseurl = http://mirrors.ustc.edu.cn/ceph/rpm-luminous/el7/$basearch\ngpgcheck = 1\ngpgkey = http://mirrors.ustc.edu.cn/ceph/keys/release.asc\nname = Ceph Stable repo\n\n[ceph_noarch]\nname=Ceph noarch packages\nbaseurl=http://mirrors.ustc.edu.cn/ceph/rpm-luminous/el7/noarch/\ngpgcheck=1\ngpgkey=http://mirrors.ustc.edu.cn/ceph/keys/release.asc\n```\n\n# 安装\n\n## 安装软件\n在ceph001节点安装ceph-deploy，并且创建ceph集群\n\n```\nyum install ceph-deploy -y\nceph-deploy install --release luminous ceph002 ceph003 ceph004\nceph-deploy new --cluster-network 172.16.140.0/24 --public-network 172.16.143.0/24 ceph002 ceph003 ceph004\n\n```\n\n当前目录下会生成ceph.conf和 ceph.mon.keying\n\nceph.conf\n\n```\n[global]\nfsid = 9ef68d6d-5117-4064-8969-39f51e91557e\npublic_network = 172.16.143.0/24\ncluster_network = 172.16.140.0/24\nmon_initial_members = ceph002, ceph003, ceph004\nmon_host = 172.16.143.152,172.16.143.153,172.16.143.154\nauth_cluster_required = cephx\nauth_service_required = cephx\nauth_client_required = cephx\n```\n\n\n## 部署MON\n\n```\nceph-deploy mon create ceph002 ceph003 ceph004\n```\n\n## 收集key\n\n```\nceph-deploy gatherkeys ceph002 ceph003 ceph004\n```\n\n## 创建OSD\n\n```\nceph-deploy osd create ceph002 --data /dev/sdb\nceph-deploy osd create ceph003 --data /dev/sdb\nceph-deploy osd create ceph004 --data /dev/sdb\n```\n\n## 部署MGR\n\n```\nceph-deploy mgr create ceph002 ceph003 ceph004\n```\n\n## 允许管理员执行ceph命令\n\n```\nceph-deploy admin ceph002 ceph003 ceph004\n```\n\n## 部署RGW\n\n```\nceph-deploy rgw create ceph002 ceph003 ceph004\n```\n\n## 部署MDS\n\n```\nceph-deploy mds create ceph002 ceph003 ceph004\n```\n\n```\nceph osd pool create cephfs_metadata 8 8\nceph osd pool create cephfs_data 8 8\nceph fs new cephfs_demo cephfs_metadata cephfs_data\n```\n\n# 截图\n\n{% asset_img cephstatus.png 集群状态 %}\n\n{% asset_img cephfs.png cephfs状态 %}\n\n\n# 总结\n\nceph-deploy适合小规模集群的部署，并且可以满足集群的动态调整。  \n另外，当前版本的ceph-deploy已经使用ceph-volume替换ceph-disk。\n\n","source":"_posts/ceph-deploy.md","raw":"---\ntitle: 通过ceph-deploy部署ceph\ndate: 2018-11-27 14:58:11\ntags: ceph\n---\n\n之前一直使用ceph-ansible来部署ceph，ceph-ansible在大规模部署的情况下比较合适，而且支持各种部署方式。  \n现在遇到的场景是是集群需要动态的调整，一开始是一个小规模的集群，后续需要动态增删服务来动态调整集群。  \nceph-ansible并没有单独添加删除某个服务的脚本，并不适合这种情况；而ceph-deploy可以比较方便的支持服务的添加和删除，可以满足这种场景。 \n \n下面通过实验来验证ceph-deploy部署ceph集群的各种服务。\n\n# 环境信息\n\n本次实验共有4台虚拟机，具体信息如下\n\n| Hostname | OS | Public network | Cluster network | Role |\n| ----- | ----- | ----- | ----- | ----- |\n| ceph001 | CentOS Linux release 7.5.1804 (Core) | 172.16.143.151 | 172.16.140.151| ceph-deply |\n| ceph002 | CentOS Linux release 7.5.1804 (Core) | 172.16.143.152 | 172.16.140.152| mon osd mgr rgw mds |\n| ceph003 | CentOS Linux release 7.5.1804 (Core) | 172.16.143.153 | 172.16.140.153| mon osd mgr rgw mds |\n| ceph004 | CentOS Linux release 7.5.1804 (Core) | 172.16.143.154 | 172.16.140.154| mon osd mgr rgw mds |\n\n# 配置\n* 关闭防火墙和SELinux\n* 配置ceph001到ceph002~4的免密登录\n* 配置ceph的国内源\n\nceph源配置，本次实验安装的ceph版本是**luminous**\n\n```\n[ceph_stable]\nbaseurl = http://mirrors.ustc.edu.cn/ceph/rpm-luminous/el7/$basearch\ngpgcheck = 1\ngpgkey = http://mirrors.ustc.edu.cn/ceph/keys/release.asc\nname = Ceph Stable repo\n\n[ceph_noarch]\nname=Ceph noarch packages\nbaseurl=http://mirrors.ustc.edu.cn/ceph/rpm-luminous/el7/noarch/\ngpgcheck=1\ngpgkey=http://mirrors.ustc.edu.cn/ceph/keys/release.asc\n```\n\n# 安装\n\n## 安装软件\n在ceph001节点安装ceph-deploy，并且创建ceph集群\n\n```\nyum install ceph-deploy -y\nceph-deploy install --release luminous ceph002 ceph003 ceph004\nceph-deploy new --cluster-network 172.16.140.0/24 --public-network 172.16.143.0/24 ceph002 ceph003 ceph004\n\n```\n\n当前目录下会生成ceph.conf和 ceph.mon.keying\n\nceph.conf\n\n```\n[global]\nfsid = 9ef68d6d-5117-4064-8969-39f51e91557e\npublic_network = 172.16.143.0/24\ncluster_network = 172.16.140.0/24\nmon_initial_members = ceph002, ceph003, ceph004\nmon_host = 172.16.143.152,172.16.143.153,172.16.143.154\nauth_cluster_required = cephx\nauth_service_required = cephx\nauth_client_required = cephx\n```\n\n\n## 部署MON\n\n```\nceph-deploy mon create ceph002 ceph003 ceph004\n```\n\n## 收集key\n\n```\nceph-deploy gatherkeys ceph002 ceph003 ceph004\n```\n\n## 创建OSD\n\n```\nceph-deploy osd create ceph002 --data /dev/sdb\nceph-deploy osd create ceph003 --data /dev/sdb\nceph-deploy osd create ceph004 --data /dev/sdb\n```\n\n## 部署MGR\n\n```\nceph-deploy mgr create ceph002 ceph003 ceph004\n```\n\n## 允许管理员执行ceph命令\n\n```\nceph-deploy admin ceph002 ceph003 ceph004\n```\n\n## 部署RGW\n\n```\nceph-deploy rgw create ceph002 ceph003 ceph004\n```\n\n## 部署MDS\n\n```\nceph-deploy mds create ceph002 ceph003 ceph004\n```\n\n```\nceph osd pool create cephfs_metadata 8 8\nceph osd pool create cephfs_data 8 8\nceph fs new cephfs_demo cephfs_metadata cephfs_data\n```\n\n# 截图\n\n{% asset_img cephstatus.png 集群状态 %}\n\n{% asset_img cephfs.png cephfs状态 %}\n\n\n# 总结\n\nceph-deploy适合小规模集群的部署，并且可以满足集群的动态调整。  \n另外，当前版本的ceph-deploy已经使用ceph-volume替换ceph-disk。\n\n","slug":"ceph-deploy","published":1,"updated":"2018-11-27T07:06:49.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck1pzbtgj0002tp758efsfpwk","content":"<p>之前一直使用ceph-ansible来部署ceph，ceph-ansible在大规模部署的情况下比较合适，而且支持各种部署方式。<br>现在遇到的场景是是集群需要动态的调整，一开始是一个小规模的集群，后续需要动态增删服务来动态调整集群。<br>ceph-ansible并没有单独添加删除某个服务的脚本，并不适合这种情况；而ceph-deploy可以比较方便的支持服务的添加和删除，可以满足这种场景。 </p>\n<p>下面通过实验来验证ceph-deploy部署ceph集群的各种服务。</p>\n<h1 id=\"环境信息\"><a href=\"#环境信息\" class=\"headerlink\" title=\"环境信息\"></a>环境信息</h1><p>本次实验共有4台虚拟机，具体信息如下</p>\n<table>\n<thead>\n<tr>\n<th>Hostname</th>\n<th>OS</th>\n<th>Public network</th>\n<th>Cluster network</th>\n<th>Role</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>ceph001</td>\n<td>CentOS Linux release 7.5.1804 (Core)</td>\n<td>172.16.143.151</td>\n<td>172.16.140.151</td>\n<td>ceph-deply</td>\n</tr>\n<tr>\n<td>ceph002</td>\n<td>CentOS Linux release 7.5.1804 (Core)</td>\n<td>172.16.143.152</td>\n<td>172.16.140.152</td>\n<td>mon osd mgr rgw mds</td>\n</tr>\n<tr>\n<td>ceph003</td>\n<td>CentOS Linux release 7.5.1804 (Core)</td>\n<td>172.16.143.153</td>\n<td>172.16.140.153</td>\n<td>mon osd mgr rgw mds</td>\n</tr>\n<tr>\n<td>ceph004</td>\n<td>CentOS Linux release 7.5.1804 (Core)</td>\n<td>172.16.143.154</td>\n<td>172.16.140.154</td>\n<td>mon osd mgr rgw mds</td>\n</tr>\n</tbody>\n</table>\n<h1 id=\"配置\"><a href=\"#配置\" class=\"headerlink\" title=\"配置\"></a>配置</h1><ul>\n<li>关闭防火墙和SELinux</li>\n<li>配置ceph001到ceph002~4的免密登录</li>\n<li>配置ceph的国内源</li>\n</ul>\n<p>ceph源配置，本次实验安装的ceph版本是<strong>luminous</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[ceph_stable]</span><br><span class=\"line\">baseurl = http://mirrors.ustc.edu.cn/ceph/rpm-luminous/el7/$basearch</span><br><span class=\"line\">gpgcheck = 1</span><br><span class=\"line\">gpgkey = http://mirrors.ustc.edu.cn/ceph/keys/release.asc</span><br><span class=\"line\">name = Ceph Stable repo</span><br><span class=\"line\"></span><br><span class=\"line\">[ceph_noarch]</span><br><span class=\"line\">name=Ceph noarch packages</span><br><span class=\"line\">baseurl=http://mirrors.ustc.edu.cn/ceph/rpm-luminous/el7/noarch/</span><br><span class=\"line\">gpgcheck=1</span><br><span class=\"line\">gpgkey=http://mirrors.ustc.edu.cn/ceph/keys/release.asc</span><br></pre></td></tr></table></figure>\n<h1 id=\"安装\"><a href=\"#安装\" class=\"headerlink\" title=\"安装\"></a>安装</h1><h2 id=\"安装软件\"><a href=\"#安装软件\" class=\"headerlink\" title=\"安装软件\"></a>安装软件</h2><p>在ceph001节点安装ceph-deploy，并且创建ceph集群</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">yum install ceph-deploy -y</span><br><span class=\"line\">ceph-deploy install --release luminous ceph002 ceph003 ceph004</span><br><span class=\"line\">ceph-deploy new --cluster-network 172.16.140.0/24 --public-network 172.16.143.0/24 ceph002 ceph003 ceph004</span><br></pre></td></tr></table></figure>\n<p>当前目录下会生成ceph.conf和 ceph.mon.keying</p>\n<p>ceph.conf</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[global]</span><br><span class=\"line\">fsid = 9ef68d6d-5117-4064-8969-39f51e91557e</span><br><span class=\"line\">public_network = 172.16.143.0/24</span><br><span class=\"line\">cluster_network = 172.16.140.0/24</span><br><span class=\"line\">mon_initial_members = ceph002, ceph003, ceph004</span><br><span class=\"line\">mon_host = 172.16.143.152,172.16.143.153,172.16.143.154</span><br><span class=\"line\">auth_cluster_required = cephx</span><br><span class=\"line\">auth_service_required = cephx</span><br><span class=\"line\">auth_client_required = cephx</span><br></pre></td></tr></table></figure>\n<h2 id=\"部署MON\"><a href=\"#部署MON\" class=\"headerlink\" title=\"部署MON\"></a>部署MON</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ceph-deploy mon create ceph002 ceph003 ceph004</span><br></pre></td></tr></table></figure>\n<h2 id=\"收集key\"><a href=\"#收集key\" class=\"headerlink\" title=\"收集key\"></a>收集key</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ceph-deploy gatherkeys ceph002 ceph003 ceph004</span><br></pre></td></tr></table></figure>\n<h2 id=\"创建OSD\"><a href=\"#创建OSD\" class=\"headerlink\" title=\"创建OSD\"></a>创建OSD</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ceph-deploy osd create ceph002 --data /dev/sdb</span><br><span class=\"line\">ceph-deploy osd create ceph003 --data /dev/sdb</span><br><span class=\"line\">ceph-deploy osd create ceph004 --data /dev/sdb</span><br></pre></td></tr></table></figure>\n<h2 id=\"部署MGR\"><a href=\"#部署MGR\" class=\"headerlink\" title=\"部署MGR\"></a>部署MGR</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ceph-deploy mgr create ceph002 ceph003 ceph004</span><br></pre></td></tr></table></figure>\n<h2 id=\"允许管理员执行ceph命令\"><a href=\"#允许管理员执行ceph命令\" class=\"headerlink\" title=\"允许管理员执行ceph命令\"></a>允许管理员执行ceph命令</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ceph-deploy admin ceph002 ceph003 ceph004</span><br></pre></td></tr></table></figure>\n<h2 id=\"部署RGW\"><a href=\"#部署RGW\" class=\"headerlink\" title=\"部署RGW\"></a>部署RGW</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ceph-deploy rgw create ceph002 ceph003 ceph004</span><br></pre></td></tr></table></figure>\n<h2 id=\"部署MDS\"><a href=\"#部署MDS\" class=\"headerlink\" title=\"部署MDS\"></a>部署MDS</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ceph-deploy mds create ceph002 ceph003 ceph004</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ceph osd pool create cephfs_metadata 8 8</span><br><span class=\"line\">ceph osd pool create cephfs_data 8 8</span><br><span class=\"line\">ceph fs new cephfs_demo cephfs_metadata cephfs_data</span><br></pre></td></tr></table></figure>\n<h1 id=\"截图\"><a href=\"#截图\" class=\"headerlink\" title=\"截图\"></a>截图</h1><img src=\"/2018/11/27/ceph-deploy/cephstatus.png\" title=\"集群状态\">\n<img src=\"/2018/11/27/ceph-deploy/cephfs.png\" title=\"cephfs状态\">\n<h1 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h1><p>ceph-deploy适合小规模集群的部署，并且可以满足集群的动态调整。<br>另外，当前版本的ceph-deploy已经使用ceph-volume替换ceph-disk。</p>\n","site":{"data":{}},"excerpt":"","more":"<p>之前一直使用ceph-ansible来部署ceph，ceph-ansible在大规模部署的情况下比较合适，而且支持各种部署方式。<br>现在遇到的场景是是集群需要动态的调整，一开始是一个小规模的集群，后续需要动态增删服务来动态调整集群。<br>ceph-ansible并没有单独添加删除某个服务的脚本，并不适合这种情况；而ceph-deploy可以比较方便的支持服务的添加和删除，可以满足这种场景。 </p>\n<p>下面通过实验来验证ceph-deploy部署ceph集群的各种服务。</p>\n<h1 id=\"环境信息\"><a href=\"#环境信息\" class=\"headerlink\" title=\"环境信息\"></a>环境信息</h1><p>本次实验共有4台虚拟机，具体信息如下</p>\n<table>\n<thead>\n<tr>\n<th>Hostname</th>\n<th>OS</th>\n<th>Public network</th>\n<th>Cluster network</th>\n<th>Role</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>ceph001</td>\n<td>CentOS Linux release 7.5.1804 (Core)</td>\n<td>172.16.143.151</td>\n<td>172.16.140.151</td>\n<td>ceph-deply</td>\n</tr>\n<tr>\n<td>ceph002</td>\n<td>CentOS Linux release 7.5.1804 (Core)</td>\n<td>172.16.143.152</td>\n<td>172.16.140.152</td>\n<td>mon osd mgr rgw mds</td>\n</tr>\n<tr>\n<td>ceph003</td>\n<td>CentOS Linux release 7.5.1804 (Core)</td>\n<td>172.16.143.153</td>\n<td>172.16.140.153</td>\n<td>mon osd mgr rgw mds</td>\n</tr>\n<tr>\n<td>ceph004</td>\n<td>CentOS Linux release 7.5.1804 (Core)</td>\n<td>172.16.143.154</td>\n<td>172.16.140.154</td>\n<td>mon osd mgr rgw mds</td>\n</tr>\n</tbody>\n</table>\n<h1 id=\"配置\"><a href=\"#配置\" class=\"headerlink\" title=\"配置\"></a>配置</h1><ul>\n<li>关闭防火墙和SELinux</li>\n<li>配置ceph001到ceph002~4的免密登录</li>\n<li>配置ceph的国内源</li>\n</ul>\n<p>ceph源配置，本次实验安装的ceph版本是<strong>luminous</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[ceph_stable]</span><br><span class=\"line\">baseurl = http://mirrors.ustc.edu.cn/ceph/rpm-luminous/el7/$basearch</span><br><span class=\"line\">gpgcheck = 1</span><br><span class=\"line\">gpgkey = http://mirrors.ustc.edu.cn/ceph/keys/release.asc</span><br><span class=\"line\">name = Ceph Stable repo</span><br><span class=\"line\"></span><br><span class=\"line\">[ceph_noarch]</span><br><span class=\"line\">name=Ceph noarch packages</span><br><span class=\"line\">baseurl=http://mirrors.ustc.edu.cn/ceph/rpm-luminous/el7/noarch/</span><br><span class=\"line\">gpgcheck=1</span><br><span class=\"line\">gpgkey=http://mirrors.ustc.edu.cn/ceph/keys/release.asc</span><br></pre></td></tr></table></figure>\n<h1 id=\"安装\"><a href=\"#安装\" class=\"headerlink\" title=\"安装\"></a>安装</h1><h2 id=\"安装软件\"><a href=\"#安装软件\" class=\"headerlink\" title=\"安装软件\"></a>安装软件</h2><p>在ceph001节点安装ceph-deploy，并且创建ceph集群</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">yum install ceph-deploy -y</span><br><span class=\"line\">ceph-deploy install --release luminous ceph002 ceph003 ceph004</span><br><span class=\"line\">ceph-deploy new --cluster-network 172.16.140.0/24 --public-network 172.16.143.0/24 ceph002 ceph003 ceph004</span><br></pre></td></tr></table></figure>\n<p>当前目录下会生成ceph.conf和 ceph.mon.keying</p>\n<p>ceph.conf</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[global]</span><br><span class=\"line\">fsid = 9ef68d6d-5117-4064-8969-39f51e91557e</span><br><span class=\"line\">public_network = 172.16.143.0/24</span><br><span class=\"line\">cluster_network = 172.16.140.0/24</span><br><span class=\"line\">mon_initial_members = ceph002, ceph003, ceph004</span><br><span class=\"line\">mon_host = 172.16.143.152,172.16.143.153,172.16.143.154</span><br><span class=\"line\">auth_cluster_required = cephx</span><br><span class=\"line\">auth_service_required = cephx</span><br><span class=\"line\">auth_client_required = cephx</span><br></pre></td></tr></table></figure>\n<h2 id=\"部署MON\"><a href=\"#部署MON\" class=\"headerlink\" title=\"部署MON\"></a>部署MON</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ceph-deploy mon create ceph002 ceph003 ceph004</span><br></pre></td></tr></table></figure>\n<h2 id=\"收集key\"><a href=\"#收集key\" class=\"headerlink\" title=\"收集key\"></a>收集key</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ceph-deploy gatherkeys ceph002 ceph003 ceph004</span><br></pre></td></tr></table></figure>\n<h2 id=\"创建OSD\"><a href=\"#创建OSD\" class=\"headerlink\" title=\"创建OSD\"></a>创建OSD</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ceph-deploy osd create ceph002 --data /dev/sdb</span><br><span class=\"line\">ceph-deploy osd create ceph003 --data /dev/sdb</span><br><span class=\"line\">ceph-deploy osd create ceph004 --data /dev/sdb</span><br></pre></td></tr></table></figure>\n<h2 id=\"部署MGR\"><a href=\"#部署MGR\" class=\"headerlink\" title=\"部署MGR\"></a>部署MGR</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ceph-deploy mgr create ceph002 ceph003 ceph004</span><br></pre></td></tr></table></figure>\n<h2 id=\"允许管理员执行ceph命令\"><a href=\"#允许管理员执行ceph命令\" class=\"headerlink\" title=\"允许管理员执行ceph命令\"></a>允许管理员执行ceph命令</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ceph-deploy admin ceph002 ceph003 ceph004</span><br></pre></td></tr></table></figure>\n<h2 id=\"部署RGW\"><a href=\"#部署RGW\" class=\"headerlink\" title=\"部署RGW\"></a>部署RGW</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ceph-deploy rgw create ceph002 ceph003 ceph004</span><br></pre></td></tr></table></figure>\n<h2 id=\"部署MDS\"><a href=\"#部署MDS\" class=\"headerlink\" title=\"部署MDS\"></a>部署MDS</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ceph-deploy mds create ceph002 ceph003 ceph004</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ceph osd pool create cephfs_metadata 8 8</span><br><span class=\"line\">ceph osd pool create cephfs_data 8 8</span><br><span class=\"line\">ceph fs new cephfs_demo cephfs_metadata cephfs_data</span><br></pre></td></tr></table></figure>\n<h1 id=\"截图\"><a href=\"#截图\" class=\"headerlink\" title=\"截图\"></a>截图</h1><img src=\"/2018/11/27/ceph-deploy/cephstatus.png\" title=\"集群状态\">\n<img src=\"/2018/11/27/ceph-deploy/cephfs.png\" title=\"cephfs状态\">\n<h1 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h1><p>ceph-deploy适合小规模集群的部署，并且可以满足集群的动态调整。<br>另外，当前版本的ceph-deploy已经使用ceph-volume替换ceph-disk。</p>\n"},{"title":"Centos 磁盘扩容","date":"2019-01-30T06:10:15.000Z","_content":"\n# 概述\n本文主要介绍如何在vmware环境中给centos7虚拟机进行扩容。  \ncentos7默认磁盘用lvm管理，系统盘挂在一个xfs的lv上。\n\n# 扩容前\n先看一下扩容前的样子  \n {% asset_img disk1.png 扩容前 %}  \n 虚拟机有一个40G的硬盘，根分区挂在了centos-root的lv上，大小是37.5G\n \n# 扩容\n先关闭虚拟机，通过vmware软件来给虚拟机的硬盘扩容。  \n{% asset_img disk2.png 虚拟机配置 %}  \n{% asset_img disk3.png 磁盘扩容 %}  \n通过上面的步骤，磁盘的空间扩展到了50G\n\n{% asset_img disk4.png 磁盘空间 %}  \n可以看到，磁盘的空间已经是50G，接下来通过parted命令，把剩余的10G空间做出lvm分区。  \n{% asset_img disk5.png 分区 %}  \n{% asset_img disk6.png 调整分区类型 %}  \n把新创建的分区作为PV，并且添加到VG中。  \n{% asset_img disk7.png 增加VG %}  \n扩大LV的空间  \n{% asset_img disk8.png LV扩容 %}\n通过xfs_growfs命令来动态调整xfs文件系统的容量  \n{% asset_img disk9.png XFS扩容 %}  \n\n最终我们可以看到根分区的文件系统扩大了10G。  \n\n\n\n\n\n","source":"_posts/disk-extend.md","raw":"---\ntitle: Centos 磁盘扩容\ndate: 2019-01-30 14:10:15\ntags: centos\n---\n\n# 概述\n本文主要介绍如何在vmware环境中给centos7虚拟机进行扩容。  \ncentos7默认磁盘用lvm管理，系统盘挂在一个xfs的lv上。\n\n# 扩容前\n先看一下扩容前的样子  \n {% asset_img disk1.png 扩容前 %}  \n 虚拟机有一个40G的硬盘，根分区挂在了centos-root的lv上，大小是37.5G\n \n# 扩容\n先关闭虚拟机，通过vmware软件来给虚拟机的硬盘扩容。  \n{% asset_img disk2.png 虚拟机配置 %}  \n{% asset_img disk3.png 磁盘扩容 %}  \n通过上面的步骤，磁盘的空间扩展到了50G\n\n{% asset_img disk4.png 磁盘空间 %}  \n可以看到，磁盘的空间已经是50G，接下来通过parted命令，把剩余的10G空间做出lvm分区。  \n{% asset_img disk5.png 分区 %}  \n{% asset_img disk6.png 调整分区类型 %}  \n把新创建的分区作为PV，并且添加到VG中。  \n{% asset_img disk7.png 增加VG %}  \n扩大LV的空间  \n{% asset_img disk8.png LV扩容 %}\n通过xfs_growfs命令来动态调整xfs文件系统的容量  \n{% asset_img disk9.png XFS扩容 %}  \n\n最终我们可以看到根分区的文件系统扩大了10G。  \n\n\n\n\n\n","slug":"disk-extend","published":1,"updated":"2019-01-31T14:13:36.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck1pzbtgm0004tp75xb925oiw","content":"<h1 id=\"概述\"><a href=\"#概述\" class=\"headerlink\" title=\"概述\"></a>概述</h1><p>本文主要介绍如何在vmware环境中给centos7虚拟机进行扩容。<br>centos7默认磁盘用lvm管理，系统盘挂在一个xfs的lv上。</p>\n<h1 id=\"扩容前\"><a href=\"#扩容前\" class=\"headerlink\" title=\"扩容前\"></a>扩容前</h1><p>先看一下扩容前的样子<br> <img src=\"/2019/01/30/disk-extend/disk1.png\" title=\"扩容前\"><br> 虚拟机有一个40G的硬盘，根分区挂在了centos-root的lv上，大小是37.5G</p>\n<h1 id=\"扩容\"><a href=\"#扩容\" class=\"headerlink\" title=\"扩容\"></a>扩容</h1><p>先关闭虚拟机，通过vmware软件来给虚拟机的硬盘扩容。<br><img src=\"/2019/01/30/disk-extend/disk2.png\" title=\"虚拟机配置\"><br><img src=\"/2019/01/30/disk-extend/disk3.png\" title=\"磁盘扩容\"><br>通过上面的步骤，磁盘的空间扩展到了50G</p>\n<img src=\"/2019/01/30/disk-extend/disk4.png\" title=\"磁盘空间\">  \n<p>可以看到，磁盘的空间已经是50G，接下来通过parted命令，把剩余的10G空间做出lvm分区。<br><img src=\"/2019/01/30/disk-extend/disk5.png\" title=\"分区\"><br><img src=\"/2019/01/30/disk-extend/disk6.png\" title=\"调整分区类型\"><br>把新创建的分区作为PV，并且添加到VG中。<br><img src=\"/2019/01/30/disk-extend/disk7.png\" title=\"增加VG\"><br>扩大LV的空间<br><img src=\"/2019/01/30/disk-extend/disk8.png\" title=\"LV扩容\"><br>通过xfs_growfs命令来动态调整xfs文件系统的容量<br><img src=\"/2019/01/30/disk-extend/disk9.png\" title=\"XFS扩容\">  </p>\n<p>最终我们可以看到根分区的文件系统扩大了10G。  </p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"概述\"><a href=\"#概述\" class=\"headerlink\" title=\"概述\"></a>概述</h1><p>本文主要介绍如何在vmware环境中给centos7虚拟机进行扩容。<br>centos7默认磁盘用lvm管理，系统盘挂在一个xfs的lv上。</p>\n<h1 id=\"扩容前\"><a href=\"#扩容前\" class=\"headerlink\" title=\"扩容前\"></a>扩容前</h1><p>先看一下扩容前的样子<br> <img src=\"/2019/01/30/disk-extend/disk1.png\" title=\"扩容前\"><br> 虚拟机有一个40G的硬盘，根分区挂在了centos-root的lv上，大小是37.5G</p>\n<h1 id=\"扩容\"><a href=\"#扩容\" class=\"headerlink\" title=\"扩容\"></a>扩容</h1><p>先关闭虚拟机，通过vmware软件来给虚拟机的硬盘扩容。<br><img src=\"/2019/01/30/disk-extend/disk2.png\" title=\"虚拟机配置\"><br><img src=\"/2019/01/30/disk-extend/disk3.png\" title=\"磁盘扩容\"><br>通过上面的步骤，磁盘的空间扩展到了50G</p>\n<img src=\"/2019/01/30/disk-extend/disk4.png\" title=\"磁盘空间\">  \n<p>可以看到，磁盘的空间已经是50G，接下来通过parted命令，把剩余的10G空间做出lvm分区。<br><img src=\"/2019/01/30/disk-extend/disk5.png\" title=\"分区\"><br><img src=\"/2019/01/30/disk-extend/disk6.png\" title=\"调整分区类型\"><br>把新创建的分区作为PV，并且添加到VG中。<br><img src=\"/2019/01/30/disk-extend/disk7.png\" title=\"增加VG\"><br>扩大LV的空间<br><img src=\"/2019/01/30/disk-extend/disk8.png\" title=\"LV扩容\"><br>通过xfs_growfs命令来动态调整xfs文件系统的容量<br><img src=\"/2019/01/30/disk-extend/disk9.png\" title=\"XFS扩容\">  </p>\n<p>最终我们可以看到根分区的文件系统扩大了10G。  </p>\n"},{"title":"Ceph mgr启动restful插件","date":"2018-12-10T09:03:33.000Z","_content":"\n# 概述\n本文主要介绍如何开启ceph mgr restful插件，并通过这个restful接口获取ceph的数据。\n\n环境信息如下:\n\n```\n[root@ceph11 ~]# ceph -s\n  cluster:\n    id:     f8b6141c-5039-464d-be1e-61816208a006\n    health: HEALTH_OK\n\n  services:\n    mon:     3 daemons, quorum ceph12,ceph13,ceph14\n    mgr:     ceph14(active), standbys: ceph12, ceph13\n    mds:     cephfs-1/1/1 up  {0=umstor12=up:active}\n    osd:     7 osds: 7 up, 7 in\n    rgw:     3 daemons active\n    rgw-nfs: 3 daemons active\n\n  data:\n    pools:   9 pools, 762 pgs\n    objects: 8835 objects, 5352 MB\n    usage:   24008 MB used, 6496 GB / 6519 GB avail\n    pgs:     762 active+clean\n\n  io:\n    client:   127 B/s wr, 0 op/s rd, 1 op/s wr\n    recovery: 71 B/s, 0 objects/s\n    \n```\n\n# 启动插件\n\n```\nceph mgr module enable restful\n\n```\n\n发现restful服务并没有启动，8003端口没有监听，要启动restful服务，还需要配置SSL cetificate(证书)。\n\n下面的命令生产自签名证书：\n\n```\nceph restful create-self-signed-cert\n```\n\n这个时候可以查看在active的mgr节点(ceph14)上，restful服务已经启动\n\n```\n[root@ceph14 ~]# netstat -nltp | grep 8003\ntcp6       0      0 :::8003                 :::*                    LISTEN      3551433/ceph-mgr\n\n```\n\n默认情况下，当前active的ceph-mgr daemon将绑定主机上任何可用的IPv4或IPv6地址的8003端口\n\n## 指定IP和PORT\n\n```\nceph config-key set mgr/restful/server_addr $IP\nceph config-key set mgr/restful/server_port $PORT\n```\n\n如果没有配置IP，则restful将会监听全部ip  \n如果没有配置Port，则restful将会监听在8003端口\n\n上面的配置是针对全部mgr的，如果要针对某个mgr的配置，需要在配置中指定相应的mgr的hostname\n\n```\nceph config-key set mgr/restful/$name/server_addr $IP\nceph config-key set mgr/restful/$name/server_port $PORT\n```\n\n## 创建用户\n\n```\n[root@ceph14 ~]# ceph restful create-key admin01\n144276ee-1fdc-48ca-a358-0fb59bbb689f\n```\n后面的访问restful接口需要用到这个用户和密码\n\n## 验证\n启动restful插件后，可以通过浏览器进行访问并验证。\n\n```\nhttps://192.168.180.138:8003/\n\n{\n    \"api_version\": 1,\n    \"auth\": \"Use \\\"ceph restful create-key <key>\\\" to create a key pair, pass it as HTTP Basic auth to authenticate\",\n    \"doc\": \"See /doc endpoint\",\n    \"info\": \"Ceph Manager RESTful API server\"\n}\n```\n\n获取全部存储池的信息  \n\n```\nhttps://192.168.180.138:8003/pool\n\n[\n    {\n        \"application_metadata\": {\n            \"rgw\": {}\n        },\n        \"auid\": 0,\n        \"cache_min_evict_age\": 0,\n        \"cache_min_flush_age\": 0,\n        \"cache_mode\": \"none\",\n        \"cache_target_dirty_high_ratio_micro\": 600000,\n        \"cache_target_dirty_ratio_micro\": 400000,\n        \"cache_target_full_ratio_micro\": 800000,\n        \"crash_replay_interval\": 0,\n        \"crush_rule\": 1,\n        \"erasure_code_profile\": \"\",\n        \"expected_num_objects\": 0,\n        \"fast_read\": false,\n        \"flags\": 1,\n        \"flags_names\": \"hashpspool\",\n        \"grade_table\": [],\n        \"hit_set_count\": 0,\n        \"hit_set_grade_decay_rate\": 0,\n        \"hit_set_params\": {\n            \"type\": \"none\"\n        },\n        \"hit_set_period\": 0,\n        \"hit_set_search_last_n\": 0,\n        \"last_change\": \"61\",\n        \"last_force_op_resend\": \"0\",\n        \"last_force_op_resend_preluminous\": \"0\",\n        \"min_read_recency_for_promote\": 0,\n        \"min_size\": 2,\n        \"min_write_recency_for_promote\": 0,\n        \"object_hash\": 2,\n        \"options\": {},\n        \"pg_num\": 8,\n        \"pgp_num\": 8,\n        \"pool\": 1,\n        \"pool_name\": \".rgw.root\",\n        \"pool_snaps\": [],\n        \"quota_max_bytes\": 0,\n        \"quota_max_objects\": 0,\n        \"read_tier\": -1,\n        \"removed_snaps\": \"[]\",\n        \"size\": 3,\n        \"snap_epoch\": 0,\n        \"snap_mode\": \"selfmanaged\",\n        \"snap_seq\": 0,\n        \"stripe_width\": 0,\n        \"target_max_bytes\": 0,\n        \"target_max_objects\": 0,\n        \"tier_of\": -1,\n        \"tiers\": [],\n        \"type\": 1,\n        \"use_gmt_hitset\": false,\n        \"write_tier\": -1\n    },\n    {\n        \"application_metadata\": {\n            \"rgw\": {}\n        },\n        \"auid\": -1,\n        \"cache_min_evict_age\": 0,\n        \"cache_min_flush_age\": 0,\n        \"cache_mode\": \"none\",\n        \"cache_target_dirty_high_ratio_micro\": 600000,\n        \"cache_target_dirty_ratio_micro\": 400000,\n        \"cache_target_full_ratio_micro\": 800000,\n        \"crash_replay_interval\": 0,\n        \"crush_rule\": 1,\n        \"erasure_code_profile\": \"\",\n        \"expected_num_objects\": 0,\n        \"fast_read\": false,\n        \"flags\": 1,\n        \"flags_names\": \"hashpspool\",\n        \"grade_table\": [],\n        \"hit_set_count\": 0,\n        \"hit_set_grade_decay_rate\": 0,\n        \"hit_set_params\": {\n            \"type\": \"none\"\n        },\n        \"hit_set_period\": 0,\n        \"hit_set_search_last_n\": 0,\n        \"last_change\": \"64\",\n        \"last_force_op_resend\": \"0\",\n        \"last_force_op_resend_preluminous\": \"0\",\n        \"min_read_recency_for_promote\": 0,\n        \"min_size\": 2,\n        \"min_write_recency_for_promote\": 0,\n        \"object_hash\": 2,\n        \"options\": {},\n        \"pg_num\": 8,\n        \"pgp_num\": 8,\n        \"pool\": 2,\n        \"pool_name\": \"default.rgw.control\",\n        \"pool_snaps\": [],\n        \"quota_max_bytes\": 0,\n        \"quota_max_objects\": 0,\n        \"read_tier\": -1,\n        \"removed_snaps\": \"[]\",\n        \"size\": 3,\n        \"snap_epoch\": 0,\n        \"snap_mode\": \"selfmanaged\",\n        \"snap_seq\": 0,\n        \"stripe_width\": 0,\n        \"target_max_bytes\": 0,\n        \"target_max_objects\": 0,\n        \"tier_of\": -1,\n        \"tiers\": [],\n        \"type\": 1,\n        \"use_gmt_hitset\": true,\n        \"write_tier\": -1\n    },\n    {\n        \"application_metadata\": {\n            \"rgw\": {}\n        },\n        \"auid\": -1,\n        \"cache_min_evict_age\": 0,\n        \"cache_min_flush_age\": 0,\n        \"cache_mode\": \"none\",\n        \"cache_target_dirty_high_ratio_micro\": 600000,\n        \"cache_target_dirty_ratio_micro\": 400000,\n        \"cache_target_full_ratio_micro\": 800000,\n        \"crash_replay_interval\": 0,\n        \"crush_rule\": 1,\n        \"erasure_code_profile\": \"\",\n        \"expected_num_objects\": 0,\n        \"fast_read\": false,\n        \"flags\": 1,\n        \"flags_names\": \"hashpspool\",\n        \"grade_table\": [],\n        \"hit_set_count\": 0,\n        \"hit_set_grade_decay_rate\": 0,\n        \"hit_set_params\": {\n            \"type\": \"none\"\n        },\n        \"hit_set_period\": 0,\n        \"hit_set_search_last_n\": 0,\n        \"last_change\": \"67\",\n        \"last_force_op_resend\": \"0\",\n        \"last_force_op_resend_preluminous\": \"0\",\n        \"min_read_recency_for_promote\": 0,\n        \"min_size\": 2,\n        \"min_write_recency_for_promote\": 0,\n        \"object_hash\": 2,\n        \"options\": {},\n        \"pg_num\": 8,\n        \"pgp_num\": 8,\n        \"pool\": 3,\n        \"pool_name\": \"default.rgw.meta\",\n        \"pool_snaps\": [],\n        \"quota_max_bytes\": 0,\n        \"quota_max_objects\": 0,\n        \"read_tier\": -1,\n        \"removed_snaps\": \"[]\",\n        \"size\": 3,\n        \"snap_epoch\": 0,\n        \"snap_mode\": \"selfmanaged\",\n        \"snap_seq\": 0,\n        \"stripe_width\": 0,\n        \"target_max_bytes\": 0,\n        \"target_max_objects\": 0,\n        \"tier_of\": -1,\n        \"tiers\": [],\n        \"type\": 1,\n        \"use_gmt_hitset\": true,\n        \"write_tier\": -1\n    },\n    {\n        \"application_metadata\": {\n            \"rgw\": {}\n        },\n        \"auid\": -1,\n        \"cache_min_evict_age\": 0,\n        \"cache_min_flush_age\": 0,\n        \"cache_mode\": \"none\",\n        \"cache_target_dirty_high_ratio_micro\": 600000,\n        \"cache_target_dirty_ratio_micro\": 400000,\n        \"cache_target_full_ratio_micro\": 800000,\n        \"crash_replay_interval\": 0,\n        \"crush_rule\": 1,\n        \"erasure_code_profile\": \"\",\n        \"expected_num_objects\": 0,\n        \"fast_read\": false,\n        \"flags\": 1,\n        \"flags_names\": \"hashpspool\",\n        \"grade_table\": [],\n        \"hit_set_count\": 0,\n        \"hit_set_grade_decay_rate\": 0,\n        \"hit_set_params\": {\n            \"type\": \"none\"\n        },\n        \"hit_set_period\": 0,\n        \"hit_set_search_last_n\": 0,\n        \"last_change\": \"70\",\n        \"last_force_op_resend\": \"0\",\n        \"last_force_op_resend_preluminous\": \"0\",\n        \"min_read_recency_for_promote\": 0,\n        \"min_size\": 2,\n        \"min_write_recency_for_promote\": 0,\n        \"object_hash\": 2,\n        \"options\": {},\n        \"pg_num\": 8,\n        \"pgp_num\": 8,\n        \"pool\": 4,\n        \"pool_name\": \"default.rgw.log\",\n        \"pool_snaps\": [],\n        \"quota_max_bytes\": 0,\n        \"quota_max_objects\": 0,\n        \"read_tier\": -1,\n        \"removed_snaps\": \"[]\",\n        \"size\": 3,\n        \"snap_epoch\": 0,\n        \"snap_mode\": \"selfmanaged\",\n        \"snap_seq\": 0,\n        \"stripe_width\": 0,\n        \"target_max_bytes\": 0,\n        \"target_max_objects\": 0,\n        \"tier_of\": -1,\n        \"tiers\": [],\n        \"type\": 1,\n        \"use_gmt_hitset\": true,\n        \"write_tier\": -1\n    },\n    {\n        \"application_metadata\": {\n            \"rgw\": {}\n        },\n        \"auid\": 0,\n        \"cache_min_evict_age\": 0,\n        \"cache_min_flush_age\": 0,\n        \"cache_mode\": \"none\",\n        \"cache_target_dirty_high_ratio_micro\": 600000,\n        \"cache_target_dirty_ratio_micro\": 400000,\n        \"cache_target_full_ratio_micro\": 800000,\n        \"crash_replay_interval\": 0,\n        \"crush_rule\": 1,\n        \"erasure_code_profile\": \"rule_rgw\",\n        \"expected_num_objects\": 0,\n        \"fast_read\": false,\n        \"flags\": 1,\n        \"flags_names\": \"hashpspool\",\n        \"grade_table\": [],\n        \"hit_set_count\": 0,\n        \"hit_set_grade_decay_rate\": 0,\n        \"hit_set_params\": {\n            \"type\": \"none\"\n        },\n        \"hit_set_period\": 0,\n        \"hit_set_search_last_n\": 0,\n        \"last_change\": \"57\",\n        \"last_force_op_resend\": \"0\",\n        \"last_force_op_resend_preluminous\": \"0\",\n        \"min_read_recency_for_promote\": 0,\n        \"min_size\": 2,\n        \"min_write_recency_for_promote\": 0,\n        \"object_hash\": 2,\n        \"options\": {},\n        \"pg_num\": 16,\n        \"pgp_num\": 16,\n        \"pool\": 5,\n        \"pool_name\": \"default.rgw.buckets.index\",\n        \"pool_snaps\": [],\n        \"quota_max_bytes\": 0,\n        \"quota_max_objects\": 0,\n        \"read_tier\": -1,\n        \"removed_snaps\": \"[]\",\n        \"size\": 3,\n        \"snap_epoch\": 0,\n        \"snap_mode\": \"selfmanaged\",\n        \"snap_seq\": 0,\n        \"stripe_width\": 0,\n        \"target_max_bytes\": 0,\n        \"target_max_objects\": 0,\n        \"tier_of\": -1,\n        \"tiers\": [],\n        \"type\": 1,\n        \"use_gmt_hitset\": true,\n        \"write_tier\": -1\n    },\n    {\n        \"application_metadata\": {\n            \"rgw\": {}\n        },\n        \"auid\": 0,\n        \"cache_min_evict_age\": 0,\n        \"cache_min_flush_age\": 0,\n        \"cache_mode\": \"none\",\n        \"cache_target_dirty_high_ratio_micro\": 600000,\n        \"cache_target_dirty_ratio_micro\": 400000,\n        \"cache_target_full_ratio_micro\": 800000,\n        \"crash_replay_interval\": 0,\n        \"crush_rule\": 1,\n        \"erasure_code_profile\": \"rule_rgw\",\n        \"expected_num_objects\": 0,\n        \"fast_read\": false,\n        \"flags\": 1,\n        \"flags_names\": \"hashpspool\",\n        \"grade_table\": [],\n        \"hit_set_count\": 0,\n        \"hit_set_grade_decay_rate\": 0,\n        \"hit_set_params\": {\n            \"type\": \"none\"\n        },\n        \"hit_set_period\": 0,\n        \"hit_set_search_last_n\": 0,\n        \"last_change\": \"790\",\n        \"last_force_op_resend\": \"0\",\n        \"last_force_op_resend_preluminous\": \"788\",\n        \"min_read_recency_for_promote\": 0,\n        \"min_size\": 2,\n        \"min_write_recency_for_promote\": 0,\n        \"object_hash\": 2,\n        \"options\": {},\n        \"pg_num\": 514,\n        \"pgp_num\": 514,\n        \"pool\": 6,\n        \"pool_name\": \"default.rgw.buckets.data\",\n        \"pool_snaps\": [],\n        \"quota_max_bytes\": 0,\n        \"quota_max_objects\": 0,\n        \"read_tier\": -1,\n        \"removed_snaps\": \"[]\",\n        \"size\": 3,\n        \"snap_epoch\": 0,\n        \"snap_mode\": \"selfmanaged\",\n        \"snap_seq\": 0,\n        \"stripe_width\": 0,\n        \"target_max_bytes\": 0,\n        \"target_max_objects\": 0,\n        \"tier_of\": -1,\n        \"tiers\": [],\n        \"type\": 1,\n        \"use_gmt_hitset\": true,\n        \"write_tier\": -1\n    },\n    {\n        \"application_metadata\": {\n            \"cephfs\": {}\n        },\n        \"auid\": 0,\n        \"cache_min_evict_age\": 0,\n        \"cache_min_flush_age\": 0,\n        \"cache_mode\": \"none\",\n        \"cache_target_dirty_high_ratio_micro\": 600000,\n        \"cache_target_dirty_ratio_micro\": 400000,\n        \"cache_target_full_ratio_micro\": 800000,\n        \"crash_replay_interval\": 0,\n        \"crush_rule\": 0,\n        \"erasure_code_profile\": \"\",\n        \"expected_num_objects\": 0,\n        \"fast_read\": false,\n        \"flags\": 1,\n        \"flags_names\": \"hashpspool\",\n        \"grade_table\": [],\n        \"hit_set_count\": 0,\n        \"hit_set_grade_decay_rate\": 0,\n        \"hit_set_params\": {\n            \"type\": \"none\"\n        },\n        \"hit_set_period\": 0,\n        \"hit_set_search_last_n\": 0,\n        \"last_change\": \"136\",\n        \"last_force_op_resend\": \"0\",\n        \"last_force_op_resend_preluminous\": \"0\",\n        \"min_read_recency_for_promote\": 0,\n        \"min_size\": 2,\n        \"min_write_recency_for_promote\": 0,\n        \"object_hash\": 2,\n        \"options\": {},\n        \"pg_num\": 128,\n        \"pgp_num\": 128,\n        \"pool\": 7,\n        \"pool_name\": \"fs_data\",\n        \"pool_snaps\": [],\n        \"quota_max_bytes\": 0,\n        \"quota_max_objects\": 0,\n        \"read_tier\": -1,\n        \"removed_snaps\": \"[]\",\n        \"size\": 3,\n        \"snap_epoch\": 0,\n        \"snap_mode\": \"selfmanaged\",\n        \"snap_seq\": 0,\n        \"stripe_width\": 0,\n        \"target_max_bytes\": 0,\n        \"target_max_objects\": 0,\n        \"tier_of\": -1,\n        \"tiers\": [],\n        \"type\": 1,\n        \"use_gmt_hitset\": true,\n        \"write_tier\": -1\n    },\n    {\n        \"application_metadata\": {\n            \"cephfs\": {}\n        },\n        \"auid\": 0,\n        \"cache_min_evict_age\": 0,\n        \"cache_min_flush_age\": 0,\n        \"cache_mode\": \"none\",\n        \"cache_target_dirty_high_ratio_micro\": 600000,\n        \"cache_target_dirty_ratio_micro\": 400000,\n        \"cache_target_full_ratio_micro\": 800000,\n        \"crash_replay_interval\": 0,\n        \"crush_rule\": 0,\n        \"erasure_code_profile\": \"\",\n        \"expected_num_objects\": 0,\n        \"fast_read\": false,\n        \"flags\": 1,\n        \"flags_names\": \"hashpspool\",\n        \"grade_table\": [],\n        \"hit_set_count\": 0,\n        \"hit_set_grade_decay_rate\": 0,\n        \"hit_set_params\": {\n            \"type\": \"none\"\n        },\n        \"hit_set_period\": 0,\n        \"hit_set_search_last_n\": 0,\n        \"last_change\": \"136\",\n        \"last_force_op_resend\": \"0\",\n        \"last_force_op_resend_preluminous\": \"0\",\n        \"min_read_recency_for_promote\": 0,\n        \"min_size\": 2,\n        \"min_write_recency_for_promote\": 0,\n        \"object_hash\": 2,\n        \"options\": {},\n        \"pg_num\": 64,\n        \"pgp_num\": 64,\n        \"pool\": 8,\n        \"pool_name\": \"fs_metadata\",\n        \"pool_snaps\": [],\n        \"quota_max_bytes\": 0,\n        \"quota_max_objects\": 0,\n        \"read_tier\": -1,\n        \"removed_snaps\": \"[]\",\n        \"size\": 3,\n        \"snap_epoch\": 0,\n        \"snap_mode\": \"selfmanaged\",\n        \"snap_seq\": 0,\n        \"stripe_width\": 0,\n        \"target_max_bytes\": 0,\n        \"target_max_objects\": 0,\n        \"tier_of\": -1,\n        \"tiers\": [],\n        \"type\": 1,\n        \"use_gmt_hitset\": true,\n        \"write_tier\": -1\n    },\n    {\n        \"application_metadata\": {\n            \"rgw\": {}\n        },\n        \"auid\": 0,\n        \"cache_min_evict_age\": 0,\n        \"cache_min_flush_age\": 0,\n        \"cache_mode\": \"none\",\n        \"cache_target_dirty_high_ratio_micro\": 600000,\n        \"cache_target_dirty_ratio_micro\": 400000,\n        \"cache_target_full_ratio_micro\": 800000,\n        \"crash_replay_interval\": 0,\n        \"crush_rule\": 0,\n        \"erasure_code_profile\": \"\",\n        \"expected_num_objects\": 0,\n        \"fast_read\": false,\n        \"flags\": 1,\n        \"flags_names\": \"hashpspool\",\n        \"grade_table\": [],\n        \"hit_set_count\": 0,\n        \"hit_set_grade_decay_rate\": 0,\n        \"hit_set_params\": {\n            \"type\": \"none\"\n        },\n        \"hit_set_period\": 0,\n        \"hit_set_search_last_n\": 0,\n        \"last_change\": \"139\",\n        \"last_force_op_resend\": \"0\",\n        \"last_force_op_resend_preluminous\": \"0\",\n        \"min_read_recency_for_promote\": 0,\n        \"min_size\": 2,\n        \"min_write_recency_for_promote\": 0,\n        \"object_hash\": 2,\n        \"options\": {},\n        \"pg_num\": 8,\n        \"pgp_num\": 8,\n        \"pool\": 9,\n        \"pool_name\": \"default.rgw.buckets.non-ec\",\n        \"pool_snaps\": [],\n        \"quota_max_bytes\": 0,\n        \"quota_max_objects\": 0,\n        \"read_tier\": -1,\n        \"removed_snaps\": \"[]\",\n        \"size\": 3,\n        \"snap_epoch\": 0,\n        \"snap_mode\": \"selfmanaged\",\n        \"snap_seq\": 0,\n        \"stripe_width\": 0,\n        \"target_max_bytes\": 0,\n        \"target_max_objects\": 0,\n        \"tier_of\": -1,\n        \"tiers\": [],\n        \"type\": 1,\n        \"use_gmt_hitset\": true,\n        \"write_tier\": -1\n    }\n]\n```\n\n\n# Python调用\n\n可以通过requests来调用ceph mgr restful的接口，下面通过Python来获取全部存储池信息。\n\n```\n#! /usr/bin/env python3\n\nimport requests\n\nr = requests.get('https://192.168.180.138:8003/pool',verify=False, auth=('admin','839df177-560e-421a-95fc-9f6a1c08236e'))\nprint(r.json())\n```\n\n# 参考\n- https://lnsyyj.github.io/2017/11/27/CEPH-MANAGER-DAEMON-RESTful-plugin/","source":"_posts/ceph-mgr-restful.md","raw":"---\ntitle: Ceph mgr启动restful插件\ndate: 2018-12-10 17:03:33\ntags: ceph\n---\n\n# 概述\n本文主要介绍如何开启ceph mgr restful插件，并通过这个restful接口获取ceph的数据。\n\n环境信息如下:\n\n```\n[root@ceph11 ~]# ceph -s\n  cluster:\n    id:     f8b6141c-5039-464d-be1e-61816208a006\n    health: HEALTH_OK\n\n  services:\n    mon:     3 daemons, quorum ceph12,ceph13,ceph14\n    mgr:     ceph14(active), standbys: ceph12, ceph13\n    mds:     cephfs-1/1/1 up  {0=umstor12=up:active}\n    osd:     7 osds: 7 up, 7 in\n    rgw:     3 daemons active\n    rgw-nfs: 3 daemons active\n\n  data:\n    pools:   9 pools, 762 pgs\n    objects: 8835 objects, 5352 MB\n    usage:   24008 MB used, 6496 GB / 6519 GB avail\n    pgs:     762 active+clean\n\n  io:\n    client:   127 B/s wr, 0 op/s rd, 1 op/s wr\n    recovery: 71 B/s, 0 objects/s\n    \n```\n\n# 启动插件\n\n```\nceph mgr module enable restful\n\n```\n\n发现restful服务并没有启动，8003端口没有监听，要启动restful服务，还需要配置SSL cetificate(证书)。\n\n下面的命令生产自签名证书：\n\n```\nceph restful create-self-signed-cert\n```\n\n这个时候可以查看在active的mgr节点(ceph14)上，restful服务已经启动\n\n```\n[root@ceph14 ~]# netstat -nltp | grep 8003\ntcp6       0      0 :::8003                 :::*                    LISTEN      3551433/ceph-mgr\n\n```\n\n默认情况下，当前active的ceph-mgr daemon将绑定主机上任何可用的IPv4或IPv6地址的8003端口\n\n## 指定IP和PORT\n\n```\nceph config-key set mgr/restful/server_addr $IP\nceph config-key set mgr/restful/server_port $PORT\n```\n\n如果没有配置IP，则restful将会监听全部ip  \n如果没有配置Port，则restful将会监听在8003端口\n\n上面的配置是针对全部mgr的，如果要针对某个mgr的配置，需要在配置中指定相应的mgr的hostname\n\n```\nceph config-key set mgr/restful/$name/server_addr $IP\nceph config-key set mgr/restful/$name/server_port $PORT\n```\n\n## 创建用户\n\n```\n[root@ceph14 ~]# ceph restful create-key admin01\n144276ee-1fdc-48ca-a358-0fb59bbb689f\n```\n后面的访问restful接口需要用到这个用户和密码\n\n## 验证\n启动restful插件后，可以通过浏览器进行访问并验证。\n\n```\nhttps://192.168.180.138:8003/\n\n{\n    \"api_version\": 1,\n    \"auth\": \"Use \\\"ceph restful create-key <key>\\\" to create a key pair, pass it as HTTP Basic auth to authenticate\",\n    \"doc\": \"See /doc endpoint\",\n    \"info\": \"Ceph Manager RESTful API server\"\n}\n```\n\n获取全部存储池的信息  \n\n```\nhttps://192.168.180.138:8003/pool\n\n[\n    {\n        \"application_metadata\": {\n            \"rgw\": {}\n        },\n        \"auid\": 0,\n        \"cache_min_evict_age\": 0,\n        \"cache_min_flush_age\": 0,\n        \"cache_mode\": \"none\",\n        \"cache_target_dirty_high_ratio_micro\": 600000,\n        \"cache_target_dirty_ratio_micro\": 400000,\n        \"cache_target_full_ratio_micro\": 800000,\n        \"crash_replay_interval\": 0,\n        \"crush_rule\": 1,\n        \"erasure_code_profile\": \"\",\n        \"expected_num_objects\": 0,\n        \"fast_read\": false,\n        \"flags\": 1,\n        \"flags_names\": \"hashpspool\",\n        \"grade_table\": [],\n        \"hit_set_count\": 0,\n        \"hit_set_grade_decay_rate\": 0,\n        \"hit_set_params\": {\n            \"type\": \"none\"\n        },\n        \"hit_set_period\": 0,\n        \"hit_set_search_last_n\": 0,\n        \"last_change\": \"61\",\n        \"last_force_op_resend\": \"0\",\n        \"last_force_op_resend_preluminous\": \"0\",\n        \"min_read_recency_for_promote\": 0,\n        \"min_size\": 2,\n        \"min_write_recency_for_promote\": 0,\n        \"object_hash\": 2,\n        \"options\": {},\n        \"pg_num\": 8,\n        \"pgp_num\": 8,\n        \"pool\": 1,\n        \"pool_name\": \".rgw.root\",\n        \"pool_snaps\": [],\n        \"quota_max_bytes\": 0,\n        \"quota_max_objects\": 0,\n        \"read_tier\": -1,\n        \"removed_snaps\": \"[]\",\n        \"size\": 3,\n        \"snap_epoch\": 0,\n        \"snap_mode\": \"selfmanaged\",\n        \"snap_seq\": 0,\n        \"stripe_width\": 0,\n        \"target_max_bytes\": 0,\n        \"target_max_objects\": 0,\n        \"tier_of\": -1,\n        \"tiers\": [],\n        \"type\": 1,\n        \"use_gmt_hitset\": false,\n        \"write_tier\": -1\n    },\n    {\n        \"application_metadata\": {\n            \"rgw\": {}\n        },\n        \"auid\": -1,\n        \"cache_min_evict_age\": 0,\n        \"cache_min_flush_age\": 0,\n        \"cache_mode\": \"none\",\n        \"cache_target_dirty_high_ratio_micro\": 600000,\n        \"cache_target_dirty_ratio_micro\": 400000,\n        \"cache_target_full_ratio_micro\": 800000,\n        \"crash_replay_interval\": 0,\n        \"crush_rule\": 1,\n        \"erasure_code_profile\": \"\",\n        \"expected_num_objects\": 0,\n        \"fast_read\": false,\n        \"flags\": 1,\n        \"flags_names\": \"hashpspool\",\n        \"grade_table\": [],\n        \"hit_set_count\": 0,\n        \"hit_set_grade_decay_rate\": 0,\n        \"hit_set_params\": {\n            \"type\": \"none\"\n        },\n        \"hit_set_period\": 0,\n        \"hit_set_search_last_n\": 0,\n        \"last_change\": \"64\",\n        \"last_force_op_resend\": \"0\",\n        \"last_force_op_resend_preluminous\": \"0\",\n        \"min_read_recency_for_promote\": 0,\n        \"min_size\": 2,\n        \"min_write_recency_for_promote\": 0,\n        \"object_hash\": 2,\n        \"options\": {},\n        \"pg_num\": 8,\n        \"pgp_num\": 8,\n        \"pool\": 2,\n        \"pool_name\": \"default.rgw.control\",\n        \"pool_snaps\": [],\n        \"quota_max_bytes\": 0,\n        \"quota_max_objects\": 0,\n        \"read_tier\": -1,\n        \"removed_snaps\": \"[]\",\n        \"size\": 3,\n        \"snap_epoch\": 0,\n        \"snap_mode\": \"selfmanaged\",\n        \"snap_seq\": 0,\n        \"stripe_width\": 0,\n        \"target_max_bytes\": 0,\n        \"target_max_objects\": 0,\n        \"tier_of\": -1,\n        \"tiers\": [],\n        \"type\": 1,\n        \"use_gmt_hitset\": true,\n        \"write_tier\": -1\n    },\n    {\n        \"application_metadata\": {\n            \"rgw\": {}\n        },\n        \"auid\": -1,\n        \"cache_min_evict_age\": 0,\n        \"cache_min_flush_age\": 0,\n        \"cache_mode\": \"none\",\n        \"cache_target_dirty_high_ratio_micro\": 600000,\n        \"cache_target_dirty_ratio_micro\": 400000,\n        \"cache_target_full_ratio_micro\": 800000,\n        \"crash_replay_interval\": 0,\n        \"crush_rule\": 1,\n        \"erasure_code_profile\": \"\",\n        \"expected_num_objects\": 0,\n        \"fast_read\": false,\n        \"flags\": 1,\n        \"flags_names\": \"hashpspool\",\n        \"grade_table\": [],\n        \"hit_set_count\": 0,\n        \"hit_set_grade_decay_rate\": 0,\n        \"hit_set_params\": {\n            \"type\": \"none\"\n        },\n        \"hit_set_period\": 0,\n        \"hit_set_search_last_n\": 0,\n        \"last_change\": \"67\",\n        \"last_force_op_resend\": \"0\",\n        \"last_force_op_resend_preluminous\": \"0\",\n        \"min_read_recency_for_promote\": 0,\n        \"min_size\": 2,\n        \"min_write_recency_for_promote\": 0,\n        \"object_hash\": 2,\n        \"options\": {},\n        \"pg_num\": 8,\n        \"pgp_num\": 8,\n        \"pool\": 3,\n        \"pool_name\": \"default.rgw.meta\",\n        \"pool_snaps\": [],\n        \"quota_max_bytes\": 0,\n        \"quota_max_objects\": 0,\n        \"read_tier\": -1,\n        \"removed_snaps\": \"[]\",\n        \"size\": 3,\n        \"snap_epoch\": 0,\n        \"snap_mode\": \"selfmanaged\",\n        \"snap_seq\": 0,\n        \"stripe_width\": 0,\n        \"target_max_bytes\": 0,\n        \"target_max_objects\": 0,\n        \"tier_of\": -1,\n        \"tiers\": [],\n        \"type\": 1,\n        \"use_gmt_hitset\": true,\n        \"write_tier\": -1\n    },\n    {\n        \"application_metadata\": {\n            \"rgw\": {}\n        },\n        \"auid\": -1,\n        \"cache_min_evict_age\": 0,\n        \"cache_min_flush_age\": 0,\n        \"cache_mode\": \"none\",\n        \"cache_target_dirty_high_ratio_micro\": 600000,\n        \"cache_target_dirty_ratio_micro\": 400000,\n        \"cache_target_full_ratio_micro\": 800000,\n        \"crash_replay_interval\": 0,\n        \"crush_rule\": 1,\n        \"erasure_code_profile\": \"\",\n        \"expected_num_objects\": 0,\n        \"fast_read\": false,\n        \"flags\": 1,\n        \"flags_names\": \"hashpspool\",\n        \"grade_table\": [],\n        \"hit_set_count\": 0,\n        \"hit_set_grade_decay_rate\": 0,\n        \"hit_set_params\": {\n            \"type\": \"none\"\n        },\n        \"hit_set_period\": 0,\n        \"hit_set_search_last_n\": 0,\n        \"last_change\": \"70\",\n        \"last_force_op_resend\": \"0\",\n        \"last_force_op_resend_preluminous\": \"0\",\n        \"min_read_recency_for_promote\": 0,\n        \"min_size\": 2,\n        \"min_write_recency_for_promote\": 0,\n        \"object_hash\": 2,\n        \"options\": {},\n        \"pg_num\": 8,\n        \"pgp_num\": 8,\n        \"pool\": 4,\n        \"pool_name\": \"default.rgw.log\",\n        \"pool_snaps\": [],\n        \"quota_max_bytes\": 0,\n        \"quota_max_objects\": 0,\n        \"read_tier\": -1,\n        \"removed_snaps\": \"[]\",\n        \"size\": 3,\n        \"snap_epoch\": 0,\n        \"snap_mode\": \"selfmanaged\",\n        \"snap_seq\": 0,\n        \"stripe_width\": 0,\n        \"target_max_bytes\": 0,\n        \"target_max_objects\": 0,\n        \"tier_of\": -1,\n        \"tiers\": [],\n        \"type\": 1,\n        \"use_gmt_hitset\": true,\n        \"write_tier\": -1\n    },\n    {\n        \"application_metadata\": {\n            \"rgw\": {}\n        },\n        \"auid\": 0,\n        \"cache_min_evict_age\": 0,\n        \"cache_min_flush_age\": 0,\n        \"cache_mode\": \"none\",\n        \"cache_target_dirty_high_ratio_micro\": 600000,\n        \"cache_target_dirty_ratio_micro\": 400000,\n        \"cache_target_full_ratio_micro\": 800000,\n        \"crash_replay_interval\": 0,\n        \"crush_rule\": 1,\n        \"erasure_code_profile\": \"rule_rgw\",\n        \"expected_num_objects\": 0,\n        \"fast_read\": false,\n        \"flags\": 1,\n        \"flags_names\": \"hashpspool\",\n        \"grade_table\": [],\n        \"hit_set_count\": 0,\n        \"hit_set_grade_decay_rate\": 0,\n        \"hit_set_params\": {\n            \"type\": \"none\"\n        },\n        \"hit_set_period\": 0,\n        \"hit_set_search_last_n\": 0,\n        \"last_change\": \"57\",\n        \"last_force_op_resend\": \"0\",\n        \"last_force_op_resend_preluminous\": \"0\",\n        \"min_read_recency_for_promote\": 0,\n        \"min_size\": 2,\n        \"min_write_recency_for_promote\": 0,\n        \"object_hash\": 2,\n        \"options\": {},\n        \"pg_num\": 16,\n        \"pgp_num\": 16,\n        \"pool\": 5,\n        \"pool_name\": \"default.rgw.buckets.index\",\n        \"pool_snaps\": [],\n        \"quota_max_bytes\": 0,\n        \"quota_max_objects\": 0,\n        \"read_tier\": -1,\n        \"removed_snaps\": \"[]\",\n        \"size\": 3,\n        \"snap_epoch\": 0,\n        \"snap_mode\": \"selfmanaged\",\n        \"snap_seq\": 0,\n        \"stripe_width\": 0,\n        \"target_max_bytes\": 0,\n        \"target_max_objects\": 0,\n        \"tier_of\": -1,\n        \"tiers\": [],\n        \"type\": 1,\n        \"use_gmt_hitset\": true,\n        \"write_tier\": -1\n    },\n    {\n        \"application_metadata\": {\n            \"rgw\": {}\n        },\n        \"auid\": 0,\n        \"cache_min_evict_age\": 0,\n        \"cache_min_flush_age\": 0,\n        \"cache_mode\": \"none\",\n        \"cache_target_dirty_high_ratio_micro\": 600000,\n        \"cache_target_dirty_ratio_micro\": 400000,\n        \"cache_target_full_ratio_micro\": 800000,\n        \"crash_replay_interval\": 0,\n        \"crush_rule\": 1,\n        \"erasure_code_profile\": \"rule_rgw\",\n        \"expected_num_objects\": 0,\n        \"fast_read\": false,\n        \"flags\": 1,\n        \"flags_names\": \"hashpspool\",\n        \"grade_table\": [],\n        \"hit_set_count\": 0,\n        \"hit_set_grade_decay_rate\": 0,\n        \"hit_set_params\": {\n            \"type\": \"none\"\n        },\n        \"hit_set_period\": 0,\n        \"hit_set_search_last_n\": 0,\n        \"last_change\": \"790\",\n        \"last_force_op_resend\": \"0\",\n        \"last_force_op_resend_preluminous\": \"788\",\n        \"min_read_recency_for_promote\": 0,\n        \"min_size\": 2,\n        \"min_write_recency_for_promote\": 0,\n        \"object_hash\": 2,\n        \"options\": {},\n        \"pg_num\": 514,\n        \"pgp_num\": 514,\n        \"pool\": 6,\n        \"pool_name\": \"default.rgw.buckets.data\",\n        \"pool_snaps\": [],\n        \"quota_max_bytes\": 0,\n        \"quota_max_objects\": 0,\n        \"read_tier\": -1,\n        \"removed_snaps\": \"[]\",\n        \"size\": 3,\n        \"snap_epoch\": 0,\n        \"snap_mode\": \"selfmanaged\",\n        \"snap_seq\": 0,\n        \"stripe_width\": 0,\n        \"target_max_bytes\": 0,\n        \"target_max_objects\": 0,\n        \"tier_of\": -1,\n        \"tiers\": [],\n        \"type\": 1,\n        \"use_gmt_hitset\": true,\n        \"write_tier\": -1\n    },\n    {\n        \"application_metadata\": {\n            \"cephfs\": {}\n        },\n        \"auid\": 0,\n        \"cache_min_evict_age\": 0,\n        \"cache_min_flush_age\": 0,\n        \"cache_mode\": \"none\",\n        \"cache_target_dirty_high_ratio_micro\": 600000,\n        \"cache_target_dirty_ratio_micro\": 400000,\n        \"cache_target_full_ratio_micro\": 800000,\n        \"crash_replay_interval\": 0,\n        \"crush_rule\": 0,\n        \"erasure_code_profile\": \"\",\n        \"expected_num_objects\": 0,\n        \"fast_read\": false,\n        \"flags\": 1,\n        \"flags_names\": \"hashpspool\",\n        \"grade_table\": [],\n        \"hit_set_count\": 0,\n        \"hit_set_grade_decay_rate\": 0,\n        \"hit_set_params\": {\n            \"type\": \"none\"\n        },\n        \"hit_set_period\": 0,\n        \"hit_set_search_last_n\": 0,\n        \"last_change\": \"136\",\n        \"last_force_op_resend\": \"0\",\n        \"last_force_op_resend_preluminous\": \"0\",\n        \"min_read_recency_for_promote\": 0,\n        \"min_size\": 2,\n        \"min_write_recency_for_promote\": 0,\n        \"object_hash\": 2,\n        \"options\": {},\n        \"pg_num\": 128,\n        \"pgp_num\": 128,\n        \"pool\": 7,\n        \"pool_name\": \"fs_data\",\n        \"pool_snaps\": [],\n        \"quota_max_bytes\": 0,\n        \"quota_max_objects\": 0,\n        \"read_tier\": -1,\n        \"removed_snaps\": \"[]\",\n        \"size\": 3,\n        \"snap_epoch\": 0,\n        \"snap_mode\": \"selfmanaged\",\n        \"snap_seq\": 0,\n        \"stripe_width\": 0,\n        \"target_max_bytes\": 0,\n        \"target_max_objects\": 0,\n        \"tier_of\": -1,\n        \"tiers\": [],\n        \"type\": 1,\n        \"use_gmt_hitset\": true,\n        \"write_tier\": -1\n    },\n    {\n        \"application_metadata\": {\n            \"cephfs\": {}\n        },\n        \"auid\": 0,\n        \"cache_min_evict_age\": 0,\n        \"cache_min_flush_age\": 0,\n        \"cache_mode\": \"none\",\n        \"cache_target_dirty_high_ratio_micro\": 600000,\n        \"cache_target_dirty_ratio_micro\": 400000,\n        \"cache_target_full_ratio_micro\": 800000,\n        \"crash_replay_interval\": 0,\n        \"crush_rule\": 0,\n        \"erasure_code_profile\": \"\",\n        \"expected_num_objects\": 0,\n        \"fast_read\": false,\n        \"flags\": 1,\n        \"flags_names\": \"hashpspool\",\n        \"grade_table\": [],\n        \"hit_set_count\": 0,\n        \"hit_set_grade_decay_rate\": 0,\n        \"hit_set_params\": {\n            \"type\": \"none\"\n        },\n        \"hit_set_period\": 0,\n        \"hit_set_search_last_n\": 0,\n        \"last_change\": \"136\",\n        \"last_force_op_resend\": \"0\",\n        \"last_force_op_resend_preluminous\": \"0\",\n        \"min_read_recency_for_promote\": 0,\n        \"min_size\": 2,\n        \"min_write_recency_for_promote\": 0,\n        \"object_hash\": 2,\n        \"options\": {},\n        \"pg_num\": 64,\n        \"pgp_num\": 64,\n        \"pool\": 8,\n        \"pool_name\": \"fs_metadata\",\n        \"pool_snaps\": [],\n        \"quota_max_bytes\": 0,\n        \"quota_max_objects\": 0,\n        \"read_tier\": -1,\n        \"removed_snaps\": \"[]\",\n        \"size\": 3,\n        \"snap_epoch\": 0,\n        \"snap_mode\": \"selfmanaged\",\n        \"snap_seq\": 0,\n        \"stripe_width\": 0,\n        \"target_max_bytes\": 0,\n        \"target_max_objects\": 0,\n        \"tier_of\": -1,\n        \"tiers\": [],\n        \"type\": 1,\n        \"use_gmt_hitset\": true,\n        \"write_tier\": -1\n    },\n    {\n        \"application_metadata\": {\n            \"rgw\": {}\n        },\n        \"auid\": 0,\n        \"cache_min_evict_age\": 0,\n        \"cache_min_flush_age\": 0,\n        \"cache_mode\": \"none\",\n        \"cache_target_dirty_high_ratio_micro\": 600000,\n        \"cache_target_dirty_ratio_micro\": 400000,\n        \"cache_target_full_ratio_micro\": 800000,\n        \"crash_replay_interval\": 0,\n        \"crush_rule\": 0,\n        \"erasure_code_profile\": \"\",\n        \"expected_num_objects\": 0,\n        \"fast_read\": false,\n        \"flags\": 1,\n        \"flags_names\": \"hashpspool\",\n        \"grade_table\": [],\n        \"hit_set_count\": 0,\n        \"hit_set_grade_decay_rate\": 0,\n        \"hit_set_params\": {\n            \"type\": \"none\"\n        },\n        \"hit_set_period\": 0,\n        \"hit_set_search_last_n\": 0,\n        \"last_change\": \"139\",\n        \"last_force_op_resend\": \"0\",\n        \"last_force_op_resend_preluminous\": \"0\",\n        \"min_read_recency_for_promote\": 0,\n        \"min_size\": 2,\n        \"min_write_recency_for_promote\": 0,\n        \"object_hash\": 2,\n        \"options\": {},\n        \"pg_num\": 8,\n        \"pgp_num\": 8,\n        \"pool\": 9,\n        \"pool_name\": \"default.rgw.buckets.non-ec\",\n        \"pool_snaps\": [],\n        \"quota_max_bytes\": 0,\n        \"quota_max_objects\": 0,\n        \"read_tier\": -1,\n        \"removed_snaps\": \"[]\",\n        \"size\": 3,\n        \"snap_epoch\": 0,\n        \"snap_mode\": \"selfmanaged\",\n        \"snap_seq\": 0,\n        \"stripe_width\": 0,\n        \"target_max_bytes\": 0,\n        \"target_max_objects\": 0,\n        \"tier_of\": -1,\n        \"tiers\": [],\n        \"type\": 1,\n        \"use_gmt_hitset\": true,\n        \"write_tier\": -1\n    }\n]\n```\n\n\n# Python调用\n\n可以通过requests来调用ceph mgr restful的接口，下面通过Python来获取全部存储池信息。\n\n```\n#! /usr/bin/env python3\n\nimport requests\n\nr = requests.get('https://192.168.180.138:8003/pool',verify=False, auth=('admin','839df177-560e-421a-95fc-9f6a1c08236e'))\nprint(r.json())\n```\n\n# 参考\n- https://lnsyyj.github.io/2017/11/27/CEPH-MANAGER-DAEMON-RESTful-plugin/","slug":"ceph-mgr-restful","published":1,"updated":"2018-12-11T11:10:59.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck1pzbtgn0005tp75uykrv7vu","content":"<h1 id=\"概述\"><a href=\"#概述\" class=\"headerlink\" title=\"概述\"></a>概述</h1><p>本文主要介绍如何开启ceph mgr restful插件，并通过这个restful接口获取ceph的数据。</p>\n<p>环境信息如下:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@ceph11 ~]# ceph -s</span><br><span class=\"line\">  cluster:</span><br><span class=\"line\">    id:     f8b6141c-5039-464d-be1e-61816208a006</span><br><span class=\"line\">    health: HEALTH_OK</span><br><span class=\"line\"></span><br><span class=\"line\">  services:</span><br><span class=\"line\">    mon:     3 daemons, quorum ceph12,ceph13,ceph14</span><br><span class=\"line\">    mgr:     ceph14(active), standbys: ceph12, ceph13</span><br><span class=\"line\">    mds:     cephfs-1/1/1 up  &#123;0=umstor12=up:active&#125;</span><br><span class=\"line\">    osd:     7 osds: 7 up, 7 in</span><br><span class=\"line\">    rgw:     3 daemons active</span><br><span class=\"line\">    rgw-nfs: 3 daemons active</span><br><span class=\"line\"></span><br><span class=\"line\">  data:</span><br><span class=\"line\">    pools:   9 pools, 762 pgs</span><br><span class=\"line\">    objects: 8835 objects, 5352 MB</span><br><span class=\"line\">    usage:   24008 MB used, 6496 GB / 6519 GB avail</span><br><span class=\"line\">    pgs:     762 active+clean</span><br><span class=\"line\"></span><br><span class=\"line\">  io:</span><br><span class=\"line\">    client:   127 B/s wr, 0 op/s rd, 1 op/s wr</span><br><span class=\"line\">    recovery: 71 B/s, 0 objects/s</span><br></pre></td></tr></table></figure>\n<h1 id=\"启动插件\"><a href=\"#启动插件\" class=\"headerlink\" title=\"启动插件\"></a>启动插件</h1><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ceph mgr module enable restful</span><br></pre></td></tr></table></figure>\n<p>发现restful服务并没有启动，8003端口没有监听，要启动restful服务，还需要配置SSL cetificate(证书)。</p>\n<p>下面的命令生产自签名证书：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ceph restful create-self-signed-cert</span><br></pre></td></tr></table></figure>\n<p>这个时候可以查看在active的mgr节点(ceph14)上，restful服务已经启动</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@ceph14 ~]# netstat -nltp | grep 8003</span><br><span class=\"line\">tcp6       0      0 :::8003                 :::*                    LISTEN      3551433/ceph-mgr</span><br></pre></td></tr></table></figure>\n<p>默认情况下，当前active的ceph-mgr daemon将绑定主机上任何可用的IPv4或IPv6地址的8003端口</p>\n<h2 id=\"指定IP和PORT\"><a href=\"#指定IP和PORT\" class=\"headerlink\" title=\"指定IP和PORT\"></a>指定IP和PORT</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ceph config-key set mgr/restful/server_addr $IP</span><br><span class=\"line\">ceph config-key set mgr/restful/server_port $PORT</span><br></pre></td></tr></table></figure>\n<p>如果没有配置IP，则restful将会监听全部ip<br>如果没有配置Port，则restful将会监听在8003端口</p>\n<p>上面的配置是针对全部mgr的，如果要针对某个mgr的配置，需要在配置中指定相应的mgr的hostname</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ceph config-key set mgr/restful/$name/server_addr $IP</span><br><span class=\"line\">ceph config-key set mgr/restful/$name/server_port $PORT</span><br></pre></td></tr></table></figure>\n<h2 id=\"创建用户\"><a href=\"#创建用户\" class=\"headerlink\" title=\"创建用户\"></a>创建用户</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@ceph14 ~]# ceph restful create-key admin01</span><br><span class=\"line\">144276ee-1fdc-48ca-a358-0fb59bbb689f</span><br></pre></td></tr></table></figure>\n<p>后面的访问restful接口需要用到这个用户和密码</p>\n<h2 id=\"验证\"><a href=\"#验证\" class=\"headerlink\" title=\"验证\"></a>验证</h2><p>启动restful插件后，可以通过浏览器进行访问并验证。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">https://192.168.180.138:8003/</span><br><span class=\"line\"></span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    &quot;api_version&quot;: 1,</span><br><span class=\"line\">    &quot;auth&quot;: &quot;Use \\&quot;ceph restful create-key &lt;key&gt;\\&quot; to create a key pair, pass it as HTTP Basic auth to authenticate&quot;,</span><br><span class=\"line\">    &quot;doc&quot;: &quot;See /doc endpoint&quot;,</span><br><span class=\"line\">    &quot;info&quot;: &quot;Ceph Manager RESTful API server&quot;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>获取全部存储池的信息  </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br><span class=\"line\">145</span><br><span class=\"line\">146</span><br><span class=\"line\">147</span><br><span class=\"line\">148</span><br><span class=\"line\">149</span><br><span class=\"line\">150</span><br><span class=\"line\">151</span><br><span class=\"line\">152</span><br><span class=\"line\">153</span><br><span class=\"line\">154</span><br><span class=\"line\">155</span><br><span class=\"line\">156</span><br><span class=\"line\">157</span><br><span class=\"line\">158</span><br><span class=\"line\">159</span><br><span class=\"line\">160</span><br><span class=\"line\">161</span><br><span class=\"line\">162</span><br><span class=\"line\">163</span><br><span class=\"line\">164</span><br><span class=\"line\">165</span><br><span class=\"line\">166</span><br><span class=\"line\">167</span><br><span class=\"line\">168</span><br><span class=\"line\">169</span><br><span class=\"line\">170</span><br><span class=\"line\">171</span><br><span class=\"line\">172</span><br><span class=\"line\">173</span><br><span class=\"line\">174</span><br><span class=\"line\">175</span><br><span class=\"line\">176</span><br><span class=\"line\">177</span><br><span class=\"line\">178</span><br><span class=\"line\">179</span><br><span class=\"line\">180</span><br><span class=\"line\">181</span><br><span class=\"line\">182</span><br><span class=\"line\">183</span><br><span class=\"line\">184</span><br><span class=\"line\">185</span><br><span class=\"line\">186</span><br><span class=\"line\">187</span><br><span class=\"line\">188</span><br><span class=\"line\">189</span><br><span class=\"line\">190</span><br><span class=\"line\">191</span><br><span class=\"line\">192</span><br><span class=\"line\">193</span><br><span class=\"line\">194</span><br><span class=\"line\">195</span><br><span class=\"line\">196</span><br><span class=\"line\">197</span><br><span class=\"line\">198</span><br><span class=\"line\">199</span><br><span class=\"line\">200</span><br><span class=\"line\">201</span><br><span class=\"line\">202</span><br><span class=\"line\">203</span><br><span class=\"line\">204</span><br><span class=\"line\">205</span><br><span class=\"line\">206</span><br><span class=\"line\">207</span><br><span class=\"line\">208</span><br><span class=\"line\">209</span><br><span class=\"line\">210</span><br><span class=\"line\">211</span><br><span class=\"line\">212</span><br><span class=\"line\">213</span><br><span class=\"line\">214</span><br><span class=\"line\">215</span><br><span class=\"line\">216</span><br><span class=\"line\">217</span><br><span class=\"line\">218</span><br><span class=\"line\">219</span><br><span class=\"line\">220</span><br><span class=\"line\">221</span><br><span class=\"line\">222</span><br><span class=\"line\">223</span><br><span class=\"line\">224</span><br><span class=\"line\">225</span><br><span class=\"line\">226</span><br><span class=\"line\">227</span><br><span class=\"line\">228</span><br><span class=\"line\">229</span><br><span class=\"line\">230</span><br><span class=\"line\">231</span><br><span class=\"line\">232</span><br><span class=\"line\">233</span><br><span class=\"line\">234</span><br><span class=\"line\">235</span><br><span class=\"line\">236</span><br><span class=\"line\">237</span><br><span class=\"line\">238</span><br><span class=\"line\">239</span><br><span class=\"line\">240</span><br><span class=\"line\">241</span><br><span class=\"line\">242</span><br><span class=\"line\">243</span><br><span class=\"line\">244</span><br><span class=\"line\">245</span><br><span class=\"line\">246</span><br><span class=\"line\">247</span><br><span class=\"line\">248</span><br><span class=\"line\">249</span><br><span class=\"line\">250</span><br><span class=\"line\">251</span><br><span class=\"line\">252</span><br><span class=\"line\">253</span><br><span class=\"line\">254</span><br><span class=\"line\">255</span><br><span class=\"line\">256</span><br><span class=\"line\">257</span><br><span class=\"line\">258</span><br><span class=\"line\">259</span><br><span class=\"line\">260</span><br><span class=\"line\">261</span><br><span class=\"line\">262</span><br><span class=\"line\">263</span><br><span class=\"line\">264</span><br><span class=\"line\">265</span><br><span class=\"line\">266</span><br><span class=\"line\">267</span><br><span class=\"line\">268</span><br><span class=\"line\">269</span><br><span class=\"line\">270</span><br><span class=\"line\">271</span><br><span class=\"line\">272</span><br><span class=\"line\">273</span><br><span class=\"line\">274</span><br><span class=\"line\">275</span><br><span class=\"line\">276</span><br><span class=\"line\">277</span><br><span class=\"line\">278</span><br><span class=\"line\">279</span><br><span class=\"line\">280</span><br><span class=\"line\">281</span><br><span class=\"line\">282</span><br><span class=\"line\">283</span><br><span class=\"line\">284</span><br><span class=\"line\">285</span><br><span class=\"line\">286</span><br><span class=\"line\">287</span><br><span class=\"line\">288</span><br><span class=\"line\">289</span><br><span class=\"line\">290</span><br><span class=\"line\">291</span><br><span class=\"line\">292</span><br><span class=\"line\">293</span><br><span class=\"line\">294</span><br><span class=\"line\">295</span><br><span class=\"line\">296</span><br><span class=\"line\">297</span><br><span class=\"line\">298</span><br><span class=\"line\">299</span><br><span class=\"line\">300</span><br><span class=\"line\">301</span><br><span class=\"line\">302</span><br><span class=\"line\">303</span><br><span class=\"line\">304</span><br><span class=\"line\">305</span><br><span class=\"line\">306</span><br><span class=\"line\">307</span><br><span class=\"line\">308</span><br><span class=\"line\">309</span><br><span class=\"line\">310</span><br><span class=\"line\">311</span><br><span class=\"line\">312</span><br><span class=\"line\">313</span><br><span class=\"line\">314</span><br><span class=\"line\">315</span><br><span class=\"line\">316</span><br><span class=\"line\">317</span><br><span class=\"line\">318</span><br><span class=\"line\">319</span><br><span class=\"line\">320</span><br><span class=\"line\">321</span><br><span class=\"line\">322</span><br><span class=\"line\">323</span><br><span class=\"line\">324</span><br><span class=\"line\">325</span><br><span class=\"line\">326</span><br><span class=\"line\">327</span><br><span class=\"line\">328</span><br><span class=\"line\">329</span><br><span class=\"line\">330</span><br><span class=\"line\">331</span><br><span class=\"line\">332</span><br><span class=\"line\">333</span><br><span class=\"line\">334</span><br><span class=\"line\">335</span><br><span class=\"line\">336</span><br><span class=\"line\">337</span><br><span class=\"line\">338</span><br><span class=\"line\">339</span><br><span class=\"line\">340</span><br><span class=\"line\">341</span><br><span class=\"line\">342</span><br><span class=\"line\">343</span><br><span class=\"line\">344</span><br><span class=\"line\">345</span><br><span class=\"line\">346</span><br><span class=\"line\">347</span><br><span class=\"line\">348</span><br><span class=\"line\">349</span><br><span class=\"line\">350</span><br><span class=\"line\">351</span><br><span class=\"line\">352</span><br><span class=\"line\">353</span><br><span class=\"line\">354</span><br><span class=\"line\">355</span><br><span class=\"line\">356</span><br><span class=\"line\">357</span><br><span class=\"line\">358</span><br><span class=\"line\">359</span><br><span class=\"line\">360</span><br><span class=\"line\">361</span><br><span class=\"line\">362</span><br><span class=\"line\">363</span><br><span class=\"line\">364</span><br><span class=\"line\">365</span><br><span class=\"line\">366</span><br><span class=\"line\">367</span><br><span class=\"line\">368</span><br><span class=\"line\">369</span><br><span class=\"line\">370</span><br><span class=\"line\">371</span><br><span class=\"line\">372</span><br><span class=\"line\">373</span><br><span class=\"line\">374</span><br><span class=\"line\">375</span><br><span class=\"line\">376</span><br><span class=\"line\">377</span><br><span class=\"line\">378</span><br><span class=\"line\">379</span><br><span class=\"line\">380</span><br><span class=\"line\">381</span><br><span class=\"line\">382</span><br><span class=\"line\">383</span><br><span class=\"line\">384</span><br><span class=\"line\">385</span><br><span class=\"line\">386</span><br><span class=\"line\">387</span><br><span class=\"line\">388</span><br><span class=\"line\">389</span><br><span class=\"line\">390</span><br><span class=\"line\">391</span><br><span class=\"line\">392</span><br><span class=\"line\">393</span><br><span class=\"line\">394</span><br><span class=\"line\">395</span><br><span class=\"line\">396</span><br><span class=\"line\">397</span><br><span class=\"line\">398</span><br><span class=\"line\">399</span><br><span class=\"line\">400</span><br><span class=\"line\">401</span><br><span class=\"line\">402</span><br><span class=\"line\">403</span><br><span class=\"line\">404</span><br><span class=\"line\">405</span><br><span class=\"line\">406</span><br><span class=\"line\">407</span><br><span class=\"line\">408</span><br><span class=\"line\">409</span><br><span class=\"line\">410</span><br><span class=\"line\">411</span><br><span class=\"line\">412</span><br><span class=\"line\">413</span><br><span class=\"line\">414</span><br><span class=\"line\">415</span><br><span class=\"line\">416</span><br><span class=\"line\">417</span><br><span class=\"line\">418</span><br><span class=\"line\">419</span><br><span class=\"line\">420</span><br><span class=\"line\">421</span><br><span class=\"line\">422</span><br><span class=\"line\">423</span><br><span class=\"line\">424</span><br><span class=\"line\">425</span><br><span class=\"line\">426</span><br><span class=\"line\">427</span><br><span class=\"line\">428</span><br><span class=\"line\">429</span><br><span class=\"line\">430</span><br><span class=\"line\">431</span><br><span class=\"line\">432</span><br><span class=\"line\">433</span><br><span class=\"line\">434</span><br><span class=\"line\">435</span><br><span class=\"line\">436</span><br><span class=\"line\">437</span><br><span class=\"line\">438</span><br><span class=\"line\">439</span><br><span class=\"line\">440</span><br><span class=\"line\">441</span><br><span class=\"line\">442</span><br><span class=\"line\">443</span><br><span class=\"line\">444</span><br><span class=\"line\">445</span><br><span class=\"line\">446</span><br><span class=\"line\">447</span><br><span class=\"line\">448</span><br><span class=\"line\">449</span><br><span class=\"line\">450</span><br><span class=\"line\">451</span><br><span class=\"line\">452</span><br><span class=\"line\">453</span><br><span class=\"line\">454</span><br><span class=\"line\">455</span><br><span class=\"line\">456</span><br><span class=\"line\">457</span><br><span class=\"line\">458</span><br><span class=\"line\">459</span><br><span class=\"line\">460</span><br><span class=\"line\">461</span><br><span class=\"line\">462</span><br><span class=\"line\">463</span><br><span class=\"line\">464</span><br><span class=\"line\">465</span><br><span class=\"line\">466</span><br><span class=\"line\">467</span><br><span class=\"line\">468</span><br><span class=\"line\">469</span><br><span class=\"line\">470</span><br><span class=\"line\">471</span><br><span class=\"line\">472</span><br><span class=\"line\">473</span><br><span class=\"line\">474</span><br><span class=\"line\">475</span><br><span class=\"line\">476</span><br><span class=\"line\">477</span><br><span class=\"line\">478</span><br><span class=\"line\">479</span><br><span class=\"line\">480</span><br><span class=\"line\">481</span><br><span class=\"line\">482</span><br><span class=\"line\">483</span><br><span class=\"line\">484</span><br><span class=\"line\">485</span><br><span class=\"line\">486</span><br><span class=\"line\">487</span><br><span class=\"line\">488</span><br><span class=\"line\">489</span><br><span class=\"line\">490</span><br><span class=\"line\">491</span><br><span class=\"line\">492</span><br><span class=\"line\">493</span><br><span class=\"line\">494</span><br><span class=\"line\">495</span><br><span class=\"line\">496</span><br><span class=\"line\">497</span><br><span class=\"line\">498</span><br><span class=\"line\">499</span><br><span class=\"line\">500</span><br><span class=\"line\">501</span><br><span class=\"line\">502</span><br><span class=\"line\">503</span><br><span class=\"line\">504</span><br><span class=\"line\">505</span><br><span class=\"line\">506</span><br><span class=\"line\">507</span><br><span class=\"line\">508</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">https://192.168.180.138:8003/pool</span><br><span class=\"line\"></span><br><span class=\"line\">[</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        &quot;application_metadata&quot;: &#123;</span><br><span class=\"line\">            &quot;rgw&quot;: &#123;&#125;</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        &quot;auid&quot;: 0,</span><br><span class=\"line\">        &quot;cache_min_evict_age&quot;: 0,</span><br><span class=\"line\">        &quot;cache_min_flush_age&quot;: 0,</span><br><span class=\"line\">        &quot;cache_mode&quot;: &quot;none&quot;,</span><br><span class=\"line\">        &quot;cache_target_dirty_high_ratio_micro&quot;: 600000,</span><br><span class=\"line\">        &quot;cache_target_dirty_ratio_micro&quot;: 400000,</span><br><span class=\"line\">        &quot;cache_target_full_ratio_micro&quot;: 800000,</span><br><span class=\"line\">        &quot;crash_replay_interval&quot;: 0,</span><br><span class=\"line\">        &quot;crush_rule&quot;: 1,</span><br><span class=\"line\">        &quot;erasure_code_profile&quot;: &quot;&quot;,</span><br><span class=\"line\">        &quot;expected_num_objects&quot;: 0,</span><br><span class=\"line\">        &quot;fast_read&quot;: false,</span><br><span class=\"line\">        &quot;flags&quot;: 1,</span><br><span class=\"line\">        &quot;flags_names&quot;: &quot;hashpspool&quot;,</span><br><span class=\"line\">        &quot;grade_table&quot;: [],</span><br><span class=\"line\">        &quot;hit_set_count&quot;: 0,</span><br><span class=\"line\">        &quot;hit_set_grade_decay_rate&quot;: 0,</span><br><span class=\"line\">        &quot;hit_set_params&quot;: &#123;</span><br><span class=\"line\">            &quot;type&quot;: &quot;none&quot;</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        &quot;hit_set_period&quot;: 0,</span><br><span class=\"line\">        &quot;hit_set_search_last_n&quot;: 0,</span><br><span class=\"line\">        &quot;last_change&quot;: &quot;61&quot;,</span><br><span class=\"line\">        &quot;last_force_op_resend&quot;: &quot;0&quot;,</span><br><span class=\"line\">        &quot;last_force_op_resend_preluminous&quot;: &quot;0&quot;,</span><br><span class=\"line\">        &quot;min_read_recency_for_promote&quot;: 0,</span><br><span class=\"line\">        &quot;min_size&quot;: 2,</span><br><span class=\"line\">        &quot;min_write_recency_for_promote&quot;: 0,</span><br><span class=\"line\">        &quot;object_hash&quot;: 2,</span><br><span class=\"line\">        &quot;options&quot;: &#123;&#125;,</span><br><span class=\"line\">        &quot;pg_num&quot;: 8,</span><br><span class=\"line\">        &quot;pgp_num&quot;: 8,</span><br><span class=\"line\">        &quot;pool&quot;: 1,</span><br><span class=\"line\">        &quot;pool_name&quot;: &quot;.rgw.root&quot;,</span><br><span class=\"line\">        &quot;pool_snaps&quot;: [],</span><br><span class=\"line\">        &quot;quota_max_bytes&quot;: 0,</span><br><span class=\"line\">        &quot;quota_max_objects&quot;: 0,</span><br><span class=\"line\">        &quot;read_tier&quot;: -1,</span><br><span class=\"line\">        &quot;removed_snaps&quot;: &quot;[]&quot;,</span><br><span class=\"line\">        &quot;size&quot;: 3,</span><br><span class=\"line\">        &quot;snap_epoch&quot;: 0,</span><br><span class=\"line\">        &quot;snap_mode&quot;: &quot;selfmanaged&quot;,</span><br><span class=\"line\">        &quot;snap_seq&quot;: 0,</span><br><span class=\"line\">        &quot;stripe_width&quot;: 0,</span><br><span class=\"line\">        &quot;target_max_bytes&quot;: 0,</span><br><span class=\"line\">        &quot;target_max_objects&quot;: 0,</span><br><span class=\"line\">        &quot;tier_of&quot;: -1,</span><br><span class=\"line\">        &quot;tiers&quot;: [],</span><br><span class=\"line\">        &quot;type&quot;: 1,</span><br><span class=\"line\">        &quot;use_gmt_hitset&quot;: false,</span><br><span class=\"line\">        &quot;write_tier&quot;: -1</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        &quot;application_metadata&quot;: &#123;</span><br><span class=\"line\">            &quot;rgw&quot;: &#123;&#125;</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        &quot;auid&quot;: -1,</span><br><span class=\"line\">        &quot;cache_min_evict_age&quot;: 0,</span><br><span class=\"line\">        &quot;cache_min_flush_age&quot;: 0,</span><br><span class=\"line\">        &quot;cache_mode&quot;: &quot;none&quot;,</span><br><span class=\"line\">        &quot;cache_target_dirty_high_ratio_micro&quot;: 600000,</span><br><span class=\"line\">        &quot;cache_target_dirty_ratio_micro&quot;: 400000,</span><br><span class=\"line\">        &quot;cache_target_full_ratio_micro&quot;: 800000,</span><br><span class=\"line\">        &quot;crash_replay_interval&quot;: 0,</span><br><span class=\"line\">        &quot;crush_rule&quot;: 1,</span><br><span class=\"line\">        &quot;erasure_code_profile&quot;: &quot;&quot;,</span><br><span class=\"line\">        &quot;expected_num_objects&quot;: 0,</span><br><span class=\"line\">        &quot;fast_read&quot;: false,</span><br><span class=\"line\">        &quot;flags&quot;: 1,</span><br><span class=\"line\">        &quot;flags_names&quot;: &quot;hashpspool&quot;,</span><br><span class=\"line\">        &quot;grade_table&quot;: [],</span><br><span class=\"line\">        &quot;hit_set_count&quot;: 0,</span><br><span class=\"line\">        &quot;hit_set_grade_decay_rate&quot;: 0,</span><br><span class=\"line\">        &quot;hit_set_params&quot;: &#123;</span><br><span class=\"line\">            &quot;type&quot;: &quot;none&quot;</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        &quot;hit_set_period&quot;: 0,</span><br><span class=\"line\">        &quot;hit_set_search_last_n&quot;: 0,</span><br><span class=\"line\">        &quot;last_change&quot;: &quot;64&quot;,</span><br><span class=\"line\">        &quot;last_force_op_resend&quot;: &quot;0&quot;,</span><br><span class=\"line\">        &quot;last_force_op_resend_preluminous&quot;: &quot;0&quot;,</span><br><span class=\"line\">        &quot;min_read_recency_for_promote&quot;: 0,</span><br><span class=\"line\">        &quot;min_size&quot;: 2,</span><br><span class=\"line\">        &quot;min_write_recency_for_promote&quot;: 0,</span><br><span class=\"line\">        &quot;object_hash&quot;: 2,</span><br><span class=\"line\">        &quot;options&quot;: &#123;&#125;,</span><br><span class=\"line\">        &quot;pg_num&quot;: 8,</span><br><span class=\"line\">        &quot;pgp_num&quot;: 8,</span><br><span class=\"line\">        &quot;pool&quot;: 2,</span><br><span class=\"line\">        &quot;pool_name&quot;: &quot;default.rgw.control&quot;,</span><br><span class=\"line\">        &quot;pool_snaps&quot;: [],</span><br><span class=\"line\">        &quot;quota_max_bytes&quot;: 0,</span><br><span class=\"line\">        &quot;quota_max_objects&quot;: 0,</span><br><span class=\"line\">        &quot;read_tier&quot;: -1,</span><br><span class=\"line\">        &quot;removed_snaps&quot;: &quot;[]&quot;,</span><br><span class=\"line\">        &quot;size&quot;: 3,</span><br><span class=\"line\">        &quot;snap_epoch&quot;: 0,</span><br><span class=\"line\">        &quot;snap_mode&quot;: &quot;selfmanaged&quot;,</span><br><span class=\"line\">        &quot;snap_seq&quot;: 0,</span><br><span class=\"line\">        &quot;stripe_width&quot;: 0,</span><br><span class=\"line\">        &quot;target_max_bytes&quot;: 0,</span><br><span class=\"line\">        &quot;target_max_objects&quot;: 0,</span><br><span class=\"line\">        &quot;tier_of&quot;: -1,</span><br><span class=\"line\">        &quot;tiers&quot;: [],</span><br><span class=\"line\">        &quot;type&quot;: 1,</span><br><span class=\"line\">        &quot;use_gmt_hitset&quot;: true,</span><br><span class=\"line\">        &quot;write_tier&quot;: -1</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        &quot;application_metadata&quot;: &#123;</span><br><span class=\"line\">            &quot;rgw&quot;: &#123;&#125;</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        &quot;auid&quot;: -1,</span><br><span class=\"line\">        &quot;cache_min_evict_age&quot;: 0,</span><br><span class=\"line\">        &quot;cache_min_flush_age&quot;: 0,</span><br><span class=\"line\">        &quot;cache_mode&quot;: &quot;none&quot;,</span><br><span class=\"line\">        &quot;cache_target_dirty_high_ratio_micro&quot;: 600000,</span><br><span class=\"line\">        &quot;cache_target_dirty_ratio_micro&quot;: 400000,</span><br><span class=\"line\">        &quot;cache_target_full_ratio_micro&quot;: 800000,</span><br><span class=\"line\">        &quot;crash_replay_interval&quot;: 0,</span><br><span class=\"line\">        &quot;crush_rule&quot;: 1,</span><br><span class=\"line\">        &quot;erasure_code_profile&quot;: &quot;&quot;,</span><br><span class=\"line\">        &quot;expected_num_objects&quot;: 0,</span><br><span class=\"line\">        &quot;fast_read&quot;: false,</span><br><span class=\"line\">        &quot;flags&quot;: 1,</span><br><span class=\"line\">        &quot;flags_names&quot;: &quot;hashpspool&quot;,</span><br><span class=\"line\">        &quot;grade_table&quot;: [],</span><br><span class=\"line\">        &quot;hit_set_count&quot;: 0,</span><br><span class=\"line\">        &quot;hit_set_grade_decay_rate&quot;: 0,</span><br><span class=\"line\">        &quot;hit_set_params&quot;: &#123;</span><br><span class=\"line\">            &quot;type&quot;: &quot;none&quot;</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        &quot;hit_set_period&quot;: 0,</span><br><span class=\"line\">        &quot;hit_set_search_last_n&quot;: 0,</span><br><span class=\"line\">        &quot;last_change&quot;: &quot;67&quot;,</span><br><span class=\"line\">        &quot;last_force_op_resend&quot;: &quot;0&quot;,</span><br><span class=\"line\">        &quot;last_force_op_resend_preluminous&quot;: &quot;0&quot;,</span><br><span class=\"line\">        &quot;min_read_recency_for_promote&quot;: 0,</span><br><span class=\"line\">        &quot;min_size&quot;: 2,</span><br><span class=\"line\">        &quot;min_write_recency_for_promote&quot;: 0,</span><br><span class=\"line\">        &quot;object_hash&quot;: 2,</span><br><span class=\"line\">        &quot;options&quot;: &#123;&#125;,</span><br><span class=\"line\">        &quot;pg_num&quot;: 8,</span><br><span class=\"line\">        &quot;pgp_num&quot;: 8,</span><br><span class=\"line\">        &quot;pool&quot;: 3,</span><br><span class=\"line\">        &quot;pool_name&quot;: &quot;default.rgw.meta&quot;,</span><br><span class=\"line\">        &quot;pool_snaps&quot;: [],</span><br><span class=\"line\">        &quot;quota_max_bytes&quot;: 0,</span><br><span class=\"line\">        &quot;quota_max_objects&quot;: 0,</span><br><span class=\"line\">        &quot;read_tier&quot;: -1,</span><br><span class=\"line\">        &quot;removed_snaps&quot;: &quot;[]&quot;,</span><br><span class=\"line\">        &quot;size&quot;: 3,</span><br><span class=\"line\">        &quot;snap_epoch&quot;: 0,</span><br><span class=\"line\">        &quot;snap_mode&quot;: &quot;selfmanaged&quot;,</span><br><span class=\"line\">        &quot;snap_seq&quot;: 0,</span><br><span class=\"line\">        &quot;stripe_width&quot;: 0,</span><br><span class=\"line\">        &quot;target_max_bytes&quot;: 0,</span><br><span class=\"line\">        &quot;target_max_objects&quot;: 0,</span><br><span class=\"line\">        &quot;tier_of&quot;: -1,</span><br><span class=\"line\">        &quot;tiers&quot;: [],</span><br><span class=\"line\">        &quot;type&quot;: 1,</span><br><span class=\"line\">        &quot;use_gmt_hitset&quot;: true,</span><br><span class=\"line\">        &quot;write_tier&quot;: -1</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        &quot;application_metadata&quot;: &#123;</span><br><span class=\"line\">            &quot;rgw&quot;: &#123;&#125;</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        &quot;auid&quot;: -1,</span><br><span class=\"line\">        &quot;cache_min_evict_age&quot;: 0,</span><br><span class=\"line\">        &quot;cache_min_flush_age&quot;: 0,</span><br><span class=\"line\">        &quot;cache_mode&quot;: &quot;none&quot;,</span><br><span class=\"line\">        &quot;cache_target_dirty_high_ratio_micro&quot;: 600000,</span><br><span class=\"line\">        &quot;cache_target_dirty_ratio_micro&quot;: 400000,</span><br><span class=\"line\">        &quot;cache_target_full_ratio_micro&quot;: 800000,</span><br><span class=\"line\">        &quot;crash_replay_interval&quot;: 0,</span><br><span class=\"line\">        &quot;crush_rule&quot;: 1,</span><br><span class=\"line\">        &quot;erasure_code_profile&quot;: &quot;&quot;,</span><br><span class=\"line\">        &quot;expected_num_objects&quot;: 0,</span><br><span class=\"line\">        &quot;fast_read&quot;: false,</span><br><span class=\"line\">        &quot;flags&quot;: 1,</span><br><span class=\"line\">        &quot;flags_names&quot;: &quot;hashpspool&quot;,</span><br><span class=\"line\">        &quot;grade_table&quot;: [],</span><br><span class=\"line\">        &quot;hit_set_count&quot;: 0,</span><br><span class=\"line\">        &quot;hit_set_grade_decay_rate&quot;: 0,</span><br><span class=\"line\">        &quot;hit_set_params&quot;: &#123;</span><br><span class=\"line\">            &quot;type&quot;: &quot;none&quot;</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        &quot;hit_set_period&quot;: 0,</span><br><span class=\"line\">        &quot;hit_set_search_last_n&quot;: 0,</span><br><span class=\"line\">        &quot;last_change&quot;: &quot;70&quot;,</span><br><span class=\"line\">        &quot;last_force_op_resend&quot;: &quot;0&quot;,</span><br><span class=\"line\">        &quot;last_force_op_resend_preluminous&quot;: &quot;0&quot;,</span><br><span class=\"line\">        &quot;min_read_recency_for_promote&quot;: 0,</span><br><span class=\"line\">        &quot;min_size&quot;: 2,</span><br><span class=\"line\">        &quot;min_write_recency_for_promote&quot;: 0,</span><br><span class=\"line\">        &quot;object_hash&quot;: 2,</span><br><span class=\"line\">        &quot;options&quot;: &#123;&#125;,</span><br><span class=\"line\">        &quot;pg_num&quot;: 8,</span><br><span class=\"line\">        &quot;pgp_num&quot;: 8,</span><br><span class=\"line\">        &quot;pool&quot;: 4,</span><br><span class=\"line\">        &quot;pool_name&quot;: &quot;default.rgw.log&quot;,</span><br><span class=\"line\">        &quot;pool_snaps&quot;: [],</span><br><span class=\"line\">        &quot;quota_max_bytes&quot;: 0,</span><br><span class=\"line\">        &quot;quota_max_objects&quot;: 0,</span><br><span class=\"line\">        &quot;read_tier&quot;: -1,</span><br><span class=\"line\">        &quot;removed_snaps&quot;: &quot;[]&quot;,</span><br><span class=\"line\">        &quot;size&quot;: 3,</span><br><span class=\"line\">        &quot;snap_epoch&quot;: 0,</span><br><span class=\"line\">        &quot;snap_mode&quot;: &quot;selfmanaged&quot;,</span><br><span class=\"line\">        &quot;snap_seq&quot;: 0,</span><br><span class=\"line\">        &quot;stripe_width&quot;: 0,</span><br><span class=\"line\">        &quot;target_max_bytes&quot;: 0,</span><br><span class=\"line\">        &quot;target_max_objects&quot;: 0,</span><br><span class=\"line\">        &quot;tier_of&quot;: -1,</span><br><span class=\"line\">        &quot;tiers&quot;: [],</span><br><span class=\"line\">        &quot;type&quot;: 1,</span><br><span class=\"line\">        &quot;use_gmt_hitset&quot;: true,</span><br><span class=\"line\">        &quot;write_tier&quot;: -1</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        &quot;application_metadata&quot;: &#123;</span><br><span class=\"line\">            &quot;rgw&quot;: &#123;&#125;</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        &quot;auid&quot;: 0,</span><br><span class=\"line\">        &quot;cache_min_evict_age&quot;: 0,</span><br><span class=\"line\">        &quot;cache_min_flush_age&quot;: 0,</span><br><span class=\"line\">        &quot;cache_mode&quot;: &quot;none&quot;,</span><br><span class=\"line\">        &quot;cache_target_dirty_high_ratio_micro&quot;: 600000,</span><br><span class=\"line\">        &quot;cache_target_dirty_ratio_micro&quot;: 400000,</span><br><span class=\"line\">        &quot;cache_target_full_ratio_micro&quot;: 800000,</span><br><span class=\"line\">        &quot;crash_replay_interval&quot;: 0,</span><br><span class=\"line\">        &quot;crush_rule&quot;: 1,</span><br><span class=\"line\">        &quot;erasure_code_profile&quot;: &quot;rule_rgw&quot;,</span><br><span class=\"line\">        &quot;expected_num_objects&quot;: 0,</span><br><span class=\"line\">        &quot;fast_read&quot;: false,</span><br><span class=\"line\">        &quot;flags&quot;: 1,</span><br><span class=\"line\">        &quot;flags_names&quot;: &quot;hashpspool&quot;,</span><br><span class=\"line\">        &quot;grade_table&quot;: [],</span><br><span class=\"line\">        &quot;hit_set_count&quot;: 0,</span><br><span class=\"line\">        &quot;hit_set_grade_decay_rate&quot;: 0,</span><br><span class=\"line\">        &quot;hit_set_params&quot;: &#123;</span><br><span class=\"line\">            &quot;type&quot;: &quot;none&quot;</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        &quot;hit_set_period&quot;: 0,</span><br><span class=\"line\">        &quot;hit_set_search_last_n&quot;: 0,</span><br><span class=\"line\">        &quot;last_change&quot;: &quot;57&quot;,</span><br><span class=\"line\">        &quot;last_force_op_resend&quot;: &quot;0&quot;,</span><br><span class=\"line\">        &quot;last_force_op_resend_preluminous&quot;: &quot;0&quot;,</span><br><span class=\"line\">        &quot;min_read_recency_for_promote&quot;: 0,</span><br><span class=\"line\">        &quot;min_size&quot;: 2,</span><br><span class=\"line\">        &quot;min_write_recency_for_promote&quot;: 0,</span><br><span class=\"line\">        &quot;object_hash&quot;: 2,</span><br><span class=\"line\">        &quot;options&quot;: &#123;&#125;,</span><br><span class=\"line\">        &quot;pg_num&quot;: 16,</span><br><span class=\"line\">        &quot;pgp_num&quot;: 16,</span><br><span class=\"line\">        &quot;pool&quot;: 5,</span><br><span class=\"line\">        &quot;pool_name&quot;: &quot;default.rgw.buckets.index&quot;,</span><br><span class=\"line\">        &quot;pool_snaps&quot;: [],</span><br><span class=\"line\">        &quot;quota_max_bytes&quot;: 0,</span><br><span class=\"line\">        &quot;quota_max_objects&quot;: 0,</span><br><span class=\"line\">        &quot;read_tier&quot;: -1,</span><br><span class=\"line\">        &quot;removed_snaps&quot;: &quot;[]&quot;,</span><br><span class=\"line\">        &quot;size&quot;: 3,</span><br><span class=\"line\">        &quot;snap_epoch&quot;: 0,</span><br><span class=\"line\">        &quot;snap_mode&quot;: &quot;selfmanaged&quot;,</span><br><span class=\"line\">        &quot;snap_seq&quot;: 0,</span><br><span class=\"line\">        &quot;stripe_width&quot;: 0,</span><br><span class=\"line\">        &quot;target_max_bytes&quot;: 0,</span><br><span class=\"line\">        &quot;target_max_objects&quot;: 0,</span><br><span class=\"line\">        &quot;tier_of&quot;: -1,</span><br><span class=\"line\">        &quot;tiers&quot;: [],</span><br><span class=\"line\">        &quot;type&quot;: 1,</span><br><span class=\"line\">        &quot;use_gmt_hitset&quot;: true,</span><br><span class=\"line\">        &quot;write_tier&quot;: -1</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        &quot;application_metadata&quot;: &#123;</span><br><span class=\"line\">            &quot;rgw&quot;: &#123;&#125;</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        &quot;auid&quot;: 0,</span><br><span class=\"line\">        &quot;cache_min_evict_age&quot;: 0,</span><br><span class=\"line\">        &quot;cache_min_flush_age&quot;: 0,</span><br><span class=\"line\">        &quot;cache_mode&quot;: &quot;none&quot;,</span><br><span class=\"line\">        &quot;cache_target_dirty_high_ratio_micro&quot;: 600000,</span><br><span class=\"line\">        &quot;cache_target_dirty_ratio_micro&quot;: 400000,</span><br><span class=\"line\">        &quot;cache_target_full_ratio_micro&quot;: 800000,</span><br><span class=\"line\">        &quot;crash_replay_interval&quot;: 0,</span><br><span class=\"line\">        &quot;crush_rule&quot;: 1,</span><br><span class=\"line\">        &quot;erasure_code_profile&quot;: &quot;rule_rgw&quot;,</span><br><span class=\"line\">        &quot;expected_num_objects&quot;: 0,</span><br><span class=\"line\">        &quot;fast_read&quot;: false,</span><br><span class=\"line\">        &quot;flags&quot;: 1,</span><br><span class=\"line\">        &quot;flags_names&quot;: &quot;hashpspool&quot;,</span><br><span class=\"line\">        &quot;grade_table&quot;: [],</span><br><span class=\"line\">        &quot;hit_set_count&quot;: 0,</span><br><span class=\"line\">        &quot;hit_set_grade_decay_rate&quot;: 0,</span><br><span class=\"line\">        &quot;hit_set_params&quot;: &#123;</span><br><span class=\"line\">            &quot;type&quot;: &quot;none&quot;</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        &quot;hit_set_period&quot;: 0,</span><br><span class=\"line\">        &quot;hit_set_search_last_n&quot;: 0,</span><br><span class=\"line\">        &quot;last_change&quot;: &quot;790&quot;,</span><br><span class=\"line\">        &quot;last_force_op_resend&quot;: &quot;0&quot;,</span><br><span class=\"line\">        &quot;last_force_op_resend_preluminous&quot;: &quot;788&quot;,</span><br><span class=\"line\">        &quot;min_read_recency_for_promote&quot;: 0,</span><br><span class=\"line\">        &quot;min_size&quot;: 2,</span><br><span class=\"line\">        &quot;min_write_recency_for_promote&quot;: 0,</span><br><span class=\"line\">        &quot;object_hash&quot;: 2,</span><br><span class=\"line\">        &quot;options&quot;: &#123;&#125;,</span><br><span class=\"line\">        &quot;pg_num&quot;: 514,</span><br><span class=\"line\">        &quot;pgp_num&quot;: 514,</span><br><span class=\"line\">        &quot;pool&quot;: 6,</span><br><span class=\"line\">        &quot;pool_name&quot;: &quot;default.rgw.buckets.data&quot;,</span><br><span class=\"line\">        &quot;pool_snaps&quot;: [],</span><br><span class=\"line\">        &quot;quota_max_bytes&quot;: 0,</span><br><span class=\"line\">        &quot;quota_max_objects&quot;: 0,</span><br><span class=\"line\">        &quot;read_tier&quot;: -1,</span><br><span class=\"line\">        &quot;removed_snaps&quot;: &quot;[]&quot;,</span><br><span class=\"line\">        &quot;size&quot;: 3,</span><br><span class=\"line\">        &quot;snap_epoch&quot;: 0,</span><br><span class=\"line\">        &quot;snap_mode&quot;: &quot;selfmanaged&quot;,</span><br><span class=\"line\">        &quot;snap_seq&quot;: 0,</span><br><span class=\"line\">        &quot;stripe_width&quot;: 0,</span><br><span class=\"line\">        &quot;target_max_bytes&quot;: 0,</span><br><span class=\"line\">        &quot;target_max_objects&quot;: 0,</span><br><span class=\"line\">        &quot;tier_of&quot;: -1,</span><br><span class=\"line\">        &quot;tiers&quot;: [],</span><br><span class=\"line\">        &quot;type&quot;: 1,</span><br><span class=\"line\">        &quot;use_gmt_hitset&quot;: true,</span><br><span class=\"line\">        &quot;write_tier&quot;: -1</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        &quot;application_metadata&quot;: &#123;</span><br><span class=\"line\">            &quot;cephfs&quot;: &#123;&#125;</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        &quot;auid&quot;: 0,</span><br><span class=\"line\">        &quot;cache_min_evict_age&quot;: 0,</span><br><span class=\"line\">        &quot;cache_min_flush_age&quot;: 0,</span><br><span class=\"line\">        &quot;cache_mode&quot;: &quot;none&quot;,</span><br><span class=\"line\">        &quot;cache_target_dirty_high_ratio_micro&quot;: 600000,</span><br><span class=\"line\">        &quot;cache_target_dirty_ratio_micro&quot;: 400000,</span><br><span class=\"line\">        &quot;cache_target_full_ratio_micro&quot;: 800000,</span><br><span class=\"line\">        &quot;crash_replay_interval&quot;: 0,</span><br><span class=\"line\">        &quot;crush_rule&quot;: 0,</span><br><span class=\"line\">        &quot;erasure_code_profile&quot;: &quot;&quot;,</span><br><span class=\"line\">        &quot;expected_num_objects&quot;: 0,</span><br><span class=\"line\">        &quot;fast_read&quot;: false,</span><br><span class=\"line\">        &quot;flags&quot;: 1,</span><br><span class=\"line\">        &quot;flags_names&quot;: &quot;hashpspool&quot;,</span><br><span class=\"line\">        &quot;grade_table&quot;: [],</span><br><span class=\"line\">        &quot;hit_set_count&quot;: 0,</span><br><span class=\"line\">        &quot;hit_set_grade_decay_rate&quot;: 0,</span><br><span class=\"line\">        &quot;hit_set_params&quot;: &#123;</span><br><span class=\"line\">            &quot;type&quot;: &quot;none&quot;</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        &quot;hit_set_period&quot;: 0,</span><br><span class=\"line\">        &quot;hit_set_search_last_n&quot;: 0,</span><br><span class=\"line\">        &quot;last_change&quot;: &quot;136&quot;,</span><br><span class=\"line\">        &quot;last_force_op_resend&quot;: &quot;0&quot;,</span><br><span class=\"line\">        &quot;last_force_op_resend_preluminous&quot;: &quot;0&quot;,</span><br><span class=\"line\">        &quot;min_read_recency_for_promote&quot;: 0,</span><br><span class=\"line\">        &quot;min_size&quot;: 2,</span><br><span class=\"line\">        &quot;min_write_recency_for_promote&quot;: 0,</span><br><span class=\"line\">        &quot;object_hash&quot;: 2,</span><br><span class=\"line\">        &quot;options&quot;: &#123;&#125;,</span><br><span class=\"line\">        &quot;pg_num&quot;: 128,</span><br><span class=\"line\">        &quot;pgp_num&quot;: 128,</span><br><span class=\"line\">        &quot;pool&quot;: 7,</span><br><span class=\"line\">        &quot;pool_name&quot;: &quot;fs_data&quot;,</span><br><span class=\"line\">        &quot;pool_snaps&quot;: [],</span><br><span class=\"line\">        &quot;quota_max_bytes&quot;: 0,</span><br><span class=\"line\">        &quot;quota_max_objects&quot;: 0,</span><br><span class=\"line\">        &quot;read_tier&quot;: -1,</span><br><span class=\"line\">        &quot;removed_snaps&quot;: &quot;[]&quot;,</span><br><span class=\"line\">        &quot;size&quot;: 3,</span><br><span class=\"line\">        &quot;snap_epoch&quot;: 0,</span><br><span class=\"line\">        &quot;snap_mode&quot;: &quot;selfmanaged&quot;,</span><br><span class=\"line\">        &quot;snap_seq&quot;: 0,</span><br><span class=\"line\">        &quot;stripe_width&quot;: 0,</span><br><span class=\"line\">        &quot;target_max_bytes&quot;: 0,</span><br><span class=\"line\">        &quot;target_max_objects&quot;: 0,</span><br><span class=\"line\">        &quot;tier_of&quot;: -1,</span><br><span class=\"line\">        &quot;tiers&quot;: [],</span><br><span class=\"line\">        &quot;type&quot;: 1,</span><br><span class=\"line\">        &quot;use_gmt_hitset&quot;: true,</span><br><span class=\"line\">        &quot;write_tier&quot;: -1</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        &quot;application_metadata&quot;: &#123;</span><br><span class=\"line\">            &quot;cephfs&quot;: &#123;&#125;</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        &quot;auid&quot;: 0,</span><br><span class=\"line\">        &quot;cache_min_evict_age&quot;: 0,</span><br><span class=\"line\">        &quot;cache_min_flush_age&quot;: 0,</span><br><span class=\"line\">        &quot;cache_mode&quot;: &quot;none&quot;,</span><br><span class=\"line\">        &quot;cache_target_dirty_high_ratio_micro&quot;: 600000,</span><br><span class=\"line\">        &quot;cache_target_dirty_ratio_micro&quot;: 400000,</span><br><span class=\"line\">        &quot;cache_target_full_ratio_micro&quot;: 800000,</span><br><span class=\"line\">        &quot;crash_replay_interval&quot;: 0,</span><br><span class=\"line\">        &quot;crush_rule&quot;: 0,</span><br><span class=\"line\">        &quot;erasure_code_profile&quot;: &quot;&quot;,</span><br><span class=\"line\">        &quot;expected_num_objects&quot;: 0,</span><br><span class=\"line\">        &quot;fast_read&quot;: false,</span><br><span class=\"line\">        &quot;flags&quot;: 1,</span><br><span class=\"line\">        &quot;flags_names&quot;: &quot;hashpspool&quot;,</span><br><span class=\"line\">        &quot;grade_table&quot;: [],</span><br><span class=\"line\">        &quot;hit_set_count&quot;: 0,</span><br><span class=\"line\">        &quot;hit_set_grade_decay_rate&quot;: 0,</span><br><span class=\"line\">        &quot;hit_set_params&quot;: &#123;</span><br><span class=\"line\">            &quot;type&quot;: &quot;none&quot;</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        &quot;hit_set_period&quot;: 0,</span><br><span class=\"line\">        &quot;hit_set_search_last_n&quot;: 0,</span><br><span class=\"line\">        &quot;last_change&quot;: &quot;136&quot;,</span><br><span class=\"line\">        &quot;last_force_op_resend&quot;: &quot;0&quot;,</span><br><span class=\"line\">        &quot;last_force_op_resend_preluminous&quot;: &quot;0&quot;,</span><br><span class=\"line\">        &quot;min_read_recency_for_promote&quot;: 0,</span><br><span class=\"line\">        &quot;min_size&quot;: 2,</span><br><span class=\"line\">        &quot;min_write_recency_for_promote&quot;: 0,</span><br><span class=\"line\">        &quot;object_hash&quot;: 2,</span><br><span class=\"line\">        &quot;options&quot;: &#123;&#125;,</span><br><span class=\"line\">        &quot;pg_num&quot;: 64,</span><br><span class=\"line\">        &quot;pgp_num&quot;: 64,</span><br><span class=\"line\">        &quot;pool&quot;: 8,</span><br><span class=\"line\">        &quot;pool_name&quot;: &quot;fs_metadata&quot;,</span><br><span class=\"line\">        &quot;pool_snaps&quot;: [],</span><br><span class=\"line\">        &quot;quota_max_bytes&quot;: 0,</span><br><span class=\"line\">        &quot;quota_max_objects&quot;: 0,</span><br><span class=\"line\">        &quot;read_tier&quot;: -1,</span><br><span class=\"line\">        &quot;removed_snaps&quot;: &quot;[]&quot;,</span><br><span class=\"line\">        &quot;size&quot;: 3,</span><br><span class=\"line\">        &quot;snap_epoch&quot;: 0,</span><br><span class=\"line\">        &quot;snap_mode&quot;: &quot;selfmanaged&quot;,</span><br><span class=\"line\">        &quot;snap_seq&quot;: 0,</span><br><span class=\"line\">        &quot;stripe_width&quot;: 0,</span><br><span class=\"line\">        &quot;target_max_bytes&quot;: 0,</span><br><span class=\"line\">        &quot;target_max_objects&quot;: 0,</span><br><span class=\"line\">        &quot;tier_of&quot;: -1,</span><br><span class=\"line\">        &quot;tiers&quot;: [],</span><br><span class=\"line\">        &quot;type&quot;: 1,</span><br><span class=\"line\">        &quot;use_gmt_hitset&quot;: true,</span><br><span class=\"line\">        &quot;write_tier&quot;: -1</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        &quot;application_metadata&quot;: &#123;</span><br><span class=\"line\">            &quot;rgw&quot;: &#123;&#125;</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        &quot;auid&quot;: 0,</span><br><span class=\"line\">        &quot;cache_min_evict_age&quot;: 0,</span><br><span class=\"line\">        &quot;cache_min_flush_age&quot;: 0,</span><br><span class=\"line\">        &quot;cache_mode&quot;: &quot;none&quot;,</span><br><span class=\"line\">        &quot;cache_target_dirty_high_ratio_micro&quot;: 600000,</span><br><span class=\"line\">        &quot;cache_target_dirty_ratio_micro&quot;: 400000,</span><br><span class=\"line\">        &quot;cache_target_full_ratio_micro&quot;: 800000,</span><br><span class=\"line\">        &quot;crash_replay_interval&quot;: 0,</span><br><span class=\"line\">        &quot;crush_rule&quot;: 0,</span><br><span class=\"line\">        &quot;erasure_code_profile&quot;: &quot;&quot;,</span><br><span class=\"line\">        &quot;expected_num_objects&quot;: 0,</span><br><span class=\"line\">        &quot;fast_read&quot;: false,</span><br><span class=\"line\">        &quot;flags&quot;: 1,</span><br><span class=\"line\">        &quot;flags_names&quot;: &quot;hashpspool&quot;,</span><br><span class=\"line\">        &quot;grade_table&quot;: [],</span><br><span class=\"line\">        &quot;hit_set_count&quot;: 0,</span><br><span class=\"line\">        &quot;hit_set_grade_decay_rate&quot;: 0,</span><br><span class=\"line\">        &quot;hit_set_params&quot;: &#123;</span><br><span class=\"line\">            &quot;type&quot;: &quot;none&quot;</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        &quot;hit_set_period&quot;: 0,</span><br><span class=\"line\">        &quot;hit_set_search_last_n&quot;: 0,</span><br><span class=\"line\">        &quot;last_change&quot;: &quot;139&quot;,</span><br><span class=\"line\">        &quot;last_force_op_resend&quot;: &quot;0&quot;,</span><br><span class=\"line\">        &quot;last_force_op_resend_preluminous&quot;: &quot;0&quot;,</span><br><span class=\"line\">        &quot;min_read_recency_for_promote&quot;: 0,</span><br><span class=\"line\">        &quot;min_size&quot;: 2,</span><br><span class=\"line\">        &quot;min_write_recency_for_promote&quot;: 0,</span><br><span class=\"line\">        &quot;object_hash&quot;: 2,</span><br><span class=\"line\">        &quot;options&quot;: &#123;&#125;,</span><br><span class=\"line\">        &quot;pg_num&quot;: 8,</span><br><span class=\"line\">        &quot;pgp_num&quot;: 8,</span><br><span class=\"line\">        &quot;pool&quot;: 9,</span><br><span class=\"line\">        &quot;pool_name&quot;: &quot;default.rgw.buckets.non-ec&quot;,</span><br><span class=\"line\">        &quot;pool_snaps&quot;: [],</span><br><span class=\"line\">        &quot;quota_max_bytes&quot;: 0,</span><br><span class=\"line\">        &quot;quota_max_objects&quot;: 0,</span><br><span class=\"line\">        &quot;read_tier&quot;: -1,</span><br><span class=\"line\">        &quot;removed_snaps&quot;: &quot;[]&quot;,</span><br><span class=\"line\">        &quot;size&quot;: 3,</span><br><span class=\"line\">        &quot;snap_epoch&quot;: 0,</span><br><span class=\"line\">        &quot;snap_mode&quot;: &quot;selfmanaged&quot;,</span><br><span class=\"line\">        &quot;snap_seq&quot;: 0,</span><br><span class=\"line\">        &quot;stripe_width&quot;: 0,</span><br><span class=\"line\">        &quot;target_max_bytes&quot;: 0,</span><br><span class=\"line\">        &quot;target_max_objects&quot;: 0,</span><br><span class=\"line\">        &quot;tier_of&quot;: -1,</span><br><span class=\"line\">        &quot;tiers&quot;: [],</span><br><span class=\"line\">        &quot;type&quot;: 1,</span><br><span class=\"line\">        &quot;use_gmt_hitset&quot;: true,</span><br><span class=\"line\">        &quot;write_tier&quot;: -1</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">]</span><br></pre></td></tr></table></figure>\n<h1 id=\"Python调用\"><a href=\"#Python调用\" class=\"headerlink\" title=\"Python调用\"></a>Python调用</h1><p>可以通过requests来调用ceph mgr restful的接口，下面通过Python来获取全部存储池信息。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#! /usr/bin/env python3</span><br><span class=\"line\"></span><br><span class=\"line\">import requests</span><br><span class=\"line\"></span><br><span class=\"line\">r = requests.get(&apos;https://192.168.180.138:8003/pool&apos;,verify=False, auth=(&apos;admin&apos;,&apos;839df177-560e-421a-95fc-9f6a1c08236e&apos;))</span><br><span class=\"line\">print(r.json())</span><br></pre></td></tr></table></figure>\n<h1 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h1><ul>\n<li><a href=\"https://lnsyyj.github.io/2017/11/27/CEPH-MANAGER-DAEMON-RESTful-plugin/\" target=\"_blank\" rel=\"noopener\">https://lnsyyj.github.io/2017/11/27/CEPH-MANAGER-DAEMON-RESTful-plugin/</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"概述\"><a href=\"#概述\" class=\"headerlink\" title=\"概述\"></a>概述</h1><p>本文主要介绍如何开启ceph mgr restful插件，并通过这个restful接口获取ceph的数据。</p>\n<p>环境信息如下:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@ceph11 ~]# ceph -s</span><br><span class=\"line\">  cluster:</span><br><span class=\"line\">    id:     f8b6141c-5039-464d-be1e-61816208a006</span><br><span class=\"line\">    health: HEALTH_OK</span><br><span class=\"line\"></span><br><span class=\"line\">  services:</span><br><span class=\"line\">    mon:     3 daemons, quorum ceph12,ceph13,ceph14</span><br><span class=\"line\">    mgr:     ceph14(active), standbys: ceph12, ceph13</span><br><span class=\"line\">    mds:     cephfs-1/1/1 up  &#123;0=umstor12=up:active&#125;</span><br><span class=\"line\">    osd:     7 osds: 7 up, 7 in</span><br><span class=\"line\">    rgw:     3 daemons active</span><br><span class=\"line\">    rgw-nfs: 3 daemons active</span><br><span class=\"line\"></span><br><span class=\"line\">  data:</span><br><span class=\"line\">    pools:   9 pools, 762 pgs</span><br><span class=\"line\">    objects: 8835 objects, 5352 MB</span><br><span class=\"line\">    usage:   24008 MB used, 6496 GB / 6519 GB avail</span><br><span class=\"line\">    pgs:     762 active+clean</span><br><span class=\"line\"></span><br><span class=\"line\">  io:</span><br><span class=\"line\">    client:   127 B/s wr, 0 op/s rd, 1 op/s wr</span><br><span class=\"line\">    recovery: 71 B/s, 0 objects/s</span><br></pre></td></tr></table></figure>\n<h1 id=\"启动插件\"><a href=\"#启动插件\" class=\"headerlink\" title=\"启动插件\"></a>启动插件</h1><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ceph mgr module enable restful</span><br></pre></td></tr></table></figure>\n<p>发现restful服务并没有启动，8003端口没有监听，要启动restful服务，还需要配置SSL cetificate(证书)。</p>\n<p>下面的命令生产自签名证书：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ceph restful create-self-signed-cert</span><br></pre></td></tr></table></figure>\n<p>这个时候可以查看在active的mgr节点(ceph14)上，restful服务已经启动</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@ceph14 ~]# netstat -nltp | grep 8003</span><br><span class=\"line\">tcp6       0      0 :::8003                 :::*                    LISTEN      3551433/ceph-mgr</span><br></pre></td></tr></table></figure>\n<p>默认情况下，当前active的ceph-mgr daemon将绑定主机上任何可用的IPv4或IPv6地址的8003端口</p>\n<h2 id=\"指定IP和PORT\"><a href=\"#指定IP和PORT\" class=\"headerlink\" title=\"指定IP和PORT\"></a>指定IP和PORT</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ceph config-key set mgr/restful/server_addr $IP</span><br><span class=\"line\">ceph config-key set mgr/restful/server_port $PORT</span><br></pre></td></tr></table></figure>\n<p>如果没有配置IP，则restful将会监听全部ip<br>如果没有配置Port，则restful将会监听在8003端口</p>\n<p>上面的配置是针对全部mgr的，如果要针对某个mgr的配置，需要在配置中指定相应的mgr的hostname</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ceph config-key set mgr/restful/$name/server_addr $IP</span><br><span class=\"line\">ceph config-key set mgr/restful/$name/server_port $PORT</span><br></pre></td></tr></table></figure>\n<h2 id=\"创建用户\"><a href=\"#创建用户\" class=\"headerlink\" title=\"创建用户\"></a>创建用户</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@ceph14 ~]# ceph restful create-key admin01</span><br><span class=\"line\">144276ee-1fdc-48ca-a358-0fb59bbb689f</span><br></pre></td></tr></table></figure>\n<p>后面的访问restful接口需要用到这个用户和密码</p>\n<h2 id=\"验证\"><a href=\"#验证\" class=\"headerlink\" title=\"验证\"></a>验证</h2><p>启动restful插件后，可以通过浏览器进行访问并验证。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">https://192.168.180.138:8003/</span><br><span class=\"line\"></span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    &quot;api_version&quot;: 1,</span><br><span class=\"line\">    &quot;auth&quot;: &quot;Use \\&quot;ceph restful create-key &lt;key&gt;\\&quot; to create a key pair, pass it as HTTP Basic auth to authenticate&quot;,</span><br><span class=\"line\">    &quot;doc&quot;: &quot;See /doc endpoint&quot;,</span><br><span class=\"line\">    &quot;info&quot;: &quot;Ceph Manager RESTful API server&quot;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>获取全部存储池的信息  </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br><span class=\"line\">145</span><br><span class=\"line\">146</span><br><span class=\"line\">147</span><br><span class=\"line\">148</span><br><span class=\"line\">149</span><br><span class=\"line\">150</span><br><span class=\"line\">151</span><br><span class=\"line\">152</span><br><span class=\"line\">153</span><br><span class=\"line\">154</span><br><span class=\"line\">155</span><br><span class=\"line\">156</span><br><span class=\"line\">157</span><br><span class=\"line\">158</span><br><span class=\"line\">159</span><br><span class=\"line\">160</span><br><span class=\"line\">161</span><br><span class=\"line\">162</span><br><span class=\"line\">163</span><br><span class=\"line\">164</span><br><span class=\"line\">165</span><br><span class=\"line\">166</span><br><span class=\"line\">167</span><br><span class=\"line\">168</span><br><span class=\"line\">169</span><br><span class=\"line\">170</span><br><span class=\"line\">171</span><br><span class=\"line\">172</span><br><span class=\"line\">173</span><br><span class=\"line\">174</span><br><span class=\"line\">175</span><br><span class=\"line\">176</span><br><span class=\"line\">177</span><br><span class=\"line\">178</span><br><span class=\"line\">179</span><br><span class=\"line\">180</span><br><span class=\"line\">181</span><br><span class=\"line\">182</span><br><span class=\"line\">183</span><br><span class=\"line\">184</span><br><span class=\"line\">185</span><br><span class=\"line\">186</span><br><span class=\"line\">187</span><br><span class=\"line\">188</span><br><span class=\"line\">189</span><br><span class=\"line\">190</span><br><span class=\"line\">191</span><br><span class=\"line\">192</span><br><span class=\"line\">193</span><br><span class=\"line\">194</span><br><span class=\"line\">195</span><br><span class=\"line\">196</span><br><span class=\"line\">197</span><br><span class=\"line\">198</span><br><span class=\"line\">199</span><br><span class=\"line\">200</span><br><span class=\"line\">201</span><br><span class=\"line\">202</span><br><span class=\"line\">203</span><br><span class=\"line\">204</span><br><span class=\"line\">205</span><br><span class=\"line\">206</span><br><span class=\"line\">207</span><br><span class=\"line\">208</span><br><span class=\"line\">209</span><br><span class=\"line\">210</span><br><span class=\"line\">211</span><br><span class=\"line\">212</span><br><span class=\"line\">213</span><br><span class=\"line\">214</span><br><span class=\"line\">215</span><br><span class=\"line\">216</span><br><span class=\"line\">217</span><br><span class=\"line\">218</span><br><span class=\"line\">219</span><br><span class=\"line\">220</span><br><span class=\"line\">221</span><br><span class=\"line\">222</span><br><span class=\"line\">223</span><br><span class=\"line\">224</span><br><span class=\"line\">225</span><br><span class=\"line\">226</span><br><span class=\"line\">227</span><br><span class=\"line\">228</span><br><span class=\"line\">229</span><br><span class=\"line\">230</span><br><span class=\"line\">231</span><br><span class=\"line\">232</span><br><span class=\"line\">233</span><br><span class=\"line\">234</span><br><span class=\"line\">235</span><br><span class=\"line\">236</span><br><span class=\"line\">237</span><br><span class=\"line\">238</span><br><span class=\"line\">239</span><br><span class=\"line\">240</span><br><span class=\"line\">241</span><br><span class=\"line\">242</span><br><span class=\"line\">243</span><br><span class=\"line\">244</span><br><span class=\"line\">245</span><br><span class=\"line\">246</span><br><span class=\"line\">247</span><br><span class=\"line\">248</span><br><span class=\"line\">249</span><br><span class=\"line\">250</span><br><span class=\"line\">251</span><br><span class=\"line\">252</span><br><span class=\"line\">253</span><br><span class=\"line\">254</span><br><span class=\"line\">255</span><br><span class=\"line\">256</span><br><span class=\"line\">257</span><br><span class=\"line\">258</span><br><span class=\"line\">259</span><br><span class=\"line\">260</span><br><span class=\"line\">261</span><br><span class=\"line\">262</span><br><span class=\"line\">263</span><br><span class=\"line\">264</span><br><span class=\"line\">265</span><br><span class=\"line\">266</span><br><span class=\"line\">267</span><br><span class=\"line\">268</span><br><span class=\"line\">269</span><br><span class=\"line\">270</span><br><span class=\"line\">271</span><br><span class=\"line\">272</span><br><span class=\"line\">273</span><br><span class=\"line\">274</span><br><span class=\"line\">275</span><br><span class=\"line\">276</span><br><span class=\"line\">277</span><br><span class=\"line\">278</span><br><span class=\"line\">279</span><br><span class=\"line\">280</span><br><span class=\"line\">281</span><br><span class=\"line\">282</span><br><span class=\"line\">283</span><br><span class=\"line\">284</span><br><span class=\"line\">285</span><br><span class=\"line\">286</span><br><span class=\"line\">287</span><br><span class=\"line\">288</span><br><span class=\"line\">289</span><br><span class=\"line\">290</span><br><span class=\"line\">291</span><br><span class=\"line\">292</span><br><span class=\"line\">293</span><br><span class=\"line\">294</span><br><span class=\"line\">295</span><br><span class=\"line\">296</span><br><span class=\"line\">297</span><br><span class=\"line\">298</span><br><span class=\"line\">299</span><br><span class=\"line\">300</span><br><span class=\"line\">301</span><br><span class=\"line\">302</span><br><span class=\"line\">303</span><br><span class=\"line\">304</span><br><span class=\"line\">305</span><br><span class=\"line\">306</span><br><span class=\"line\">307</span><br><span class=\"line\">308</span><br><span class=\"line\">309</span><br><span class=\"line\">310</span><br><span class=\"line\">311</span><br><span class=\"line\">312</span><br><span class=\"line\">313</span><br><span class=\"line\">314</span><br><span class=\"line\">315</span><br><span class=\"line\">316</span><br><span class=\"line\">317</span><br><span class=\"line\">318</span><br><span class=\"line\">319</span><br><span class=\"line\">320</span><br><span class=\"line\">321</span><br><span class=\"line\">322</span><br><span class=\"line\">323</span><br><span class=\"line\">324</span><br><span class=\"line\">325</span><br><span class=\"line\">326</span><br><span class=\"line\">327</span><br><span class=\"line\">328</span><br><span class=\"line\">329</span><br><span class=\"line\">330</span><br><span class=\"line\">331</span><br><span class=\"line\">332</span><br><span class=\"line\">333</span><br><span class=\"line\">334</span><br><span class=\"line\">335</span><br><span class=\"line\">336</span><br><span class=\"line\">337</span><br><span class=\"line\">338</span><br><span class=\"line\">339</span><br><span class=\"line\">340</span><br><span class=\"line\">341</span><br><span class=\"line\">342</span><br><span class=\"line\">343</span><br><span class=\"line\">344</span><br><span class=\"line\">345</span><br><span class=\"line\">346</span><br><span class=\"line\">347</span><br><span class=\"line\">348</span><br><span class=\"line\">349</span><br><span class=\"line\">350</span><br><span class=\"line\">351</span><br><span class=\"line\">352</span><br><span class=\"line\">353</span><br><span class=\"line\">354</span><br><span class=\"line\">355</span><br><span class=\"line\">356</span><br><span class=\"line\">357</span><br><span class=\"line\">358</span><br><span class=\"line\">359</span><br><span class=\"line\">360</span><br><span class=\"line\">361</span><br><span class=\"line\">362</span><br><span class=\"line\">363</span><br><span class=\"line\">364</span><br><span class=\"line\">365</span><br><span class=\"line\">366</span><br><span class=\"line\">367</span><br><span class=\"line\">368</span><br><span class=\"line\">369</span><br><span class=\"line\">370</span><br><span class=\"line\">371</span><br><span class=\"line\">372</span><br><span class=\"line\">373</span><br><span class=\"line\">374</span><br><span class=\"line\">375</span><br><span class=\"line\">376</span><br><span class=\"line\">377</span><br><span class=\"line\">378</span><br><span class=\"line\">379</span><br><span class=\"line\">380</span><br><span class=\"line\">381</span><br><span class=\"line\">382</span><br><span class=\"line\">383</span><br><span class=\"line\">384</span><br><span class=\"line\">385</span><br><span class=\"line\">386</span><br><span class=\"line\">387</span><br><span class=\"line\">388</span><br><span class=\"line\">389</span><br><span class=\"line\">390</span><br><span class=\"line\">391</span><br><span class=\"line\">392</span><br><span class=\"line\">393</span><br><span class=\"line\">394</span><br><span class=\"line\">395</span><br><span class=\"line\">396</span><br><span class=\"line\">397</span><br><span class=\"line\">398</span><br><span class=\"line\">399</span><br><span class=\"line\">400</span><br><span class=\"line\">401</span><br><span class=\"line\">402</span><br><span class=\"line\">403</span><br><span class=\"line\">404</span><br><span class=\"line\">405</span><br><span class=\"line\">406</span><br><span class=\"line\">407</span><br><span class=\"line\">408</span><br><span class=\"line\">409</span><br><span class=\"line\">410</span><br><span class=\"line\">411</span><br><span class=\"line\">412</span><br><span class=\"line\">413</span><br><span class=\"line\">414</span><br><span class=\"line\">415</span><br><span class=\"line\">416</span><br><span class=\"line\">417</span><br><span class=\"line\">418</span><br><span class=\"line\">419</span><br><span class=\"line\">420</span><br><span class=\"line\">421</span><br><span class=\"line\">422</span><br><span class=\"line\">423</span><br><span class=\"line\">424</span><br><span class=\"line\">425</span><br><span class=\"line\">426</span><br><span class=\"line\">427</span><br><span class=\"line\">428</span><br><span class=\"line\">429</span><br><span class=\"line\">430</span><br><span class=\"line\">431</span><br><span class=\"line\">432</span><br><span class=\"line\">433</span><br><span class=\"line\">434</span><br><span class=\"line\">435</span><br><span class=\"line\">436</span><br><span class=\"line\">437</span><br><span class=\"line\">438</span><br><span class=\"line\">439</span><br><span class=\"line\">440</span><br><span class=\"line\">441</span><br><span class=\"line\">442</span><br><span class=\"line\">443</span><br><span class=\"line\">444</span><br><span class=\"line\">445</span><br><span class=\"line\">446</span><br><span class=\"line\">447</span><br><span class=\"line\">448</span><br><span class=\"line\">449</span><br><span class=\"line\">450</span><br><span class=\"line\">451</span><br><span class=\"line\">452</span><br><span class=\"line\">453</span><br><span class=\"line\">454</span><br><span class=\"line\">455</span><br><span class=\"line\">456</span><br><span class=\"line\">457</span><br><span class=\"line\">458</span><br><span class=\"line\">459</span><br><span class=\"line\">460</span><br><span class=\"line\">461</span><br><span class=\"line\">462</span><br><span class=\"line\">463</span><br><span class=\"line\">464</span><br><span class=\"line\">465</span><br><span class=\"line\">466</span><br><span class=\"line\">467</span><br><span class=\"line\">468</span><br><span class=\"line\">469</span><br><span class=\"line\">470</span><br><span class=\"line\">471</span><br><span class=\"line\">472</span><br><span class=\"line\">473</span><br><span class=\"line\">474</span><br><span class=\"line\">475</span><br><span class=\"line\">476</span><br><span class=\"line\">477</span><br><span class=\"line\">478</span><br><span class=\"line\">479</span><br><span class=\"line\">480</span><br><span class=\"line\">481</span><br><span class=\"line\">482</span><br><span class=\"line\">483</span><br><span class=\"line\">484</span><br><span class=\"line\">485</span><br><span class=\"line\">486</span><br><span class=\"line\">487</span><br><span class=\"line\">488</span><br><span class=\"line\">489</span><br><span class=\"line\">490</span><br><span class=\"line\">491</span><br><span class=\"line\">492</span><br><span class=\"line\">493</span><br><span class=\"line\">494</span><br><span class=\"line\">495</span><br><span class=\"line\">496</span><br><span class=\"line\">497</span><br><span class=\"line\">498</span><br><span class=\"line\">499</span><br><span class=\"line\">500</span><br><span class=\"line\">501</span><br><span class=\"line\">502</span><br><span class=\"line\">503</span><br><span class=\"line\">504</span><br><span class=\"line\">505</span><br><span class=\"line\">506</span><br><span class=\"line\">507</span><br><span class=\"line\">508</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">https://192.168.180.138:8003/pool</span><br><span class=\"line\"></span><br><span class=\"line\">[</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        &quot;application_metadata&quot;: &#123;</span><br><span class=\"line\">            &quot;rgw&quot;: &#123;&#125;</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        &quot;auid&quot;: 0,</span><br><span class=\"line\">        &quot;cache_min_evict_age&quot;: 0,</span><br><span class=\"line\">        &quot;cache_min_flush_age&quot;: 0,</span><br><span class=\"line\">        &quot;cache_mode&quot;: &quot;none&quot;,</span><br><span class=\"line\">        &quot;cache_target_dirty_high_ratio_micro&quot;: 600000,</span><br><span class=\"line\">        &quot;cache_target_dirty_ratio_micro&quot;: 400000,</span><br><span class=\"line\">        &quot;cache_target_full_ratio_micro&quot;: 800000,</span><br><span class=\"line\">        &quot;crash_replay_interval&quot;: 0,</span><br><span class=\"line\">        &quot;crush_rule&quot;: 1,</span><br><span class=\"line\">        &quot;erasure_code_profile&quot;: &quot;&quot;,</span><br><span class=\"line\">        &quot;expected_num_objects&quot;: 0,</span><br><span class=\"line\">        &quot;fast_read&quot;: false,</span><br><span class=\"line\">        &quot;flags&quot;: 1,</span><br><span class=\"line\">        &quot;flags_names&quot;: &quot;hashpspool&quot;,</span><br><span class=\"line\">        &quot;grade_table&quot;: [],</span><br><span class=\"line\">        &quot;hit_set_count&quot;: 0,</span><br><span class=\"line\">        &quot;hit_set_grade_decay_rate&quot;: 0,</span><br><span class=\"line\">        &quot;hit_set_params&quot;: &#123;</span><br><span class=\"line\">            &quot;type&quot;: &quot;none&quot;</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        &quot;hit_set_period&quot;: 0,</span><br><span class=\"line\">        &quot;hit_set_search_last_n&quot;: 0,</span><br><span class=\"line\">        &quot;last_change&quot;: &quot;61&quot;,</span><br><span class=\"line\">        &quot;last_force_op_resend&quot;: &quot;0&quot;,</span><br><span class=\"line\">        &quot;last_force_op_resend_preluminous&quot;: &quot;0&quot;,</span><br><span class=\"line\">        &quot;min_read_recency_for_promote&quot;: 0,</span><br><span class=\"line\">        &quot;min_size&quot;: 2,</span><br><span class=\"line\">        &quot;min_write_recency_for_promote&quot;: 0,</span><br><span class=\"line\">        &quot;object_hash&quot;: 2,</span><br><span class=\"line\">        &quot;options&quot;: &#123;&#125;,</span><br><span class=\"line\">        &quot;pg_num&quot;: 8,</span><br><span class=\"line\">        &quot;pgp_num&quot;: 8,</span><br><span class=\"line\">        &quot;pool&quot;: 1,</span><br><span class=\"line\">        &quot;pool_name&quot;: &quot;.rgw.root&quot;,</span><br><span class=\"line\">        &quot;pool_snaps&quot;: [],</span><br><span class=\"line\">        &quot;quota_max_bytes&quot;: 0,</span><br><span class=\"line\">        &quot;quota_max_objects&quot;: 0,</span><br><span class=\"line\">        &quot;read_tier&quot;: -1,</span><br><span class=\"line\">        &quot;removed_snaps&quot;: &quot;[]&quot;,</span><br><span class=\"line\">        &quot;size&quot;: 3,</span><br><span class=\"line\">        &quot;snap_epoch&quot;: 0,</span><br><span class=\"line\">        &quot;snap_mode&quot;: &quot;selfmanaged&quot;,</span><br><span class=\"line\">        &quot;snap_seq&quot;: 0,</span><br><span class=\"line\">        &quot;stripe_width&quot;: 0,</span><br><span class=\"line\">        &quot;target_max_bytes&quot;: 0,</span><br><span class=\"line\">        &quot;target_max_objects&quot;: 0,</span><br><span class=\"line\">        &quot;tier_of&quot;: -1,</span><br><span class=\"line\">        &quot;tiers&quot;: [],</span><br><span class=\"line\">        &quot;type&quot;: 1,</span><br><span class=\"line\">        &quot;use_gmt_hitset&quot;: false,</span><br><span class=\"line\">        &quot;write_tier&quot;: -1</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        &quot;application_metadata&quot;: &#123;</span><br><span class=\"line\">            &quot;rgw&quot;: &#123;&#125;</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        &quot;auid&quot;: -1,</span><br><span class=\"line\">        &quot;cache_min_evict_age&quot;: 0,</span><br><span class=\"line\">        &quot;cache_min_flush_age&quot;: 0,</span><br><span class=\"line\">        &quot;cache_mode&quot;: &quot;none&quot;,</span><br><span class=\"line\">        &quot;cache_target_dirty_high_ratio_micro&quot;: 600000,</span><br><span class=\"line\">        &quot;cache_target_dirty_ratio_micro&quot;: 400000,</span><br><span class=\"line\">        &quot;cache_target_full_ratio_micro&quot;: 800000,</span><br><span class=\"line\">        &quot;crash_replay_interval&quot;: 0,</span><br><span class=\"line\">        &quot;crush_rule&quot;: 1,</span><br><span class=\"line\">        &quot;erasure_code_profile&quot;: &quot;&quot;,</span><br><span class=\"line\">        &quot;expected_num_objects&quot;: 0,</span><br><span class=\"line\">        &quot;fast_read&quot;: false,</span><br><span class=\"line\">        &quot;flags&quot;: 1,</span><br><span class=\"line\">        &quot;flags_names&quot;: &quot;hashpspool&quot;,</span><br><span class=\"line\">        &quot;grade_table&quot;: [],</span><br><span class=\"line\">        &quot;hit_set_count&quot;: 0,</span><br><span class=\"line\">        &quot;hit_set_grade_decay_rate&quot;: 0,</span><br><span class=\"line\">        &quot;hit_set_params&quot;: &#123;</span><br><span class=\"line\">            &quot;type&quot;: &quot;none&quot;</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        &quot;hit_set_period&quot;: 0,</span><br><span class=\"line\">        &quot;hit_set_search_last_n&quot;: 0,</span><br><span class=\"line\">        &quot;last_change&quot;: &quot;64&quot;,</span><br><span class=\"line\">        &quot;last_force_op_resend&quot;: &quot;0&quot;,</span><br><span class=\"line\">        &quot;last_force_op_resend_preluminous&quot;: &quot;0&quot;,</span><br><span class=\"line\">        &quot;min_read_recency_for_promote&quot;: 0,</span><br><span class=\"line\">        &quot;min_size&quot;: 2,</span><br><span class=\"line\">        &quot;min_write_recency_for_promote&quot;: 0,</span><br><span class=\"line\">        &quot;object_hash&quot;: 2,</span><br><span class=\"line\">        &quot;options&quot;: &#123;&#125;,</span><br><span class=\"line\">        &quot;pg_num&quot;: 8,</span><br><span class=\"line\">        &quot;pgp_num&quot;: 8,</span><br><span class=\"line\">        &quot;pool&quot;: 2,</span><br><span class=\"line\">        &quot;pool_name&quot;: &quot;default.rgw.control&quot;,</span><br><span class=\"line\">        &quot;pool_snaps&quot;: [],</span><br><span class=\"line\">        &quot;quota_max_bytes&quot;: 0,</span><br><span class=\"line\">        &quot;quota_max_objects&quot;: 0,</span><br><span class=\"line\">        &quot;read_tier&quot;: -1,</span><br><span class=\"line\">        &quot;removed_snaps&quot;: &quot;[]&quot;,</span><br><span class=\"line\">        &quot;size&quot;: 3,</span><br><span class=\"line\">        &quot;snap_epoch&quot;: 0,</span><br><span class=\"line\">        &quot;snap_mode&quot;: &quot;selfmanaged&quot;,</span><br><span class=\"line\">        &quot;snap_seq&quot;: 0,</span><br><span class=\"line\">        &quot;stripe_width&quot;: 0,</span><br><span class=\"line\">        &quot;target_max_bytes&quot;: 0,</span><br><span class=\"line\">        &quot;target_max_objects&quot;: 0,</span><br><span class=\"line\">        &quot;tier_of&quot;: -1,</span><br><span class=\"line\">        &quot;tiers&quot;: [],</span><br><span class=\"line\">        &quot;type&quot;: 1,</span><br><span class=\"line\">        &quot;use_gmt_hitset&quot;: true,</span><br><span class=\"line\">        &quot;write_tier&quot;: -1</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        &quot;application_metadata&quot;: &#123;</span><br><span class=\"line\">            &quot;rgw&quot;: &#123;&#125;</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        &quot;auid&quot;: -1,</span><br><span class=\"line\">        &quot;cache_min_evict_age&quot;: 0,</span><br><span class=\"line\">        &quot;cache_min_flush_age&quot;: 0,</span><br><span class=\"line\">        &quot;cache_mode&quot;: &quot;none&quot;,</span><br><span class=\"line\">        &quot;cache_target_dirty_high_ratio_micro&quot;: 600000,</span><br><span class=\"line\">        &quot;cache_target_dirty_ratio_micro&quot;: 400000,</span><br><span class=\"line\">        &quot;cache_target_full_ratio_micro&quot;: 800000,</span><br><span class=\"line\">        &quot;crash_replay_interval&quot;: 0,</span><br><span class=\"line\">        &quot;crush_rule&quot;: 1,</span><br><span class=\"line\">        &quot;erasure_code_profile&quot;: &quot;&quot;,</span><br><span class=\"line\">        &quot;expected_num_objects&quot;: 0,</span><br><span class=\"line\">        &quot;fast_read&quot;: false,</span><br><span class=\"line\">        &quot;flags&quot;: 1,</span><br><span class=\"line\">        &quot;flags_names&quot;: &quot;hashpspool&quot;,</span><br><span class=\"line\">        &quot;grade_table&quot;: [],</span><br><span class=\"line\">        &quot;hit_set_count&quot;: 0,</span><br><span class=\"line\">        &quot;hit_set_grade_decay_rate&quot;: 0,</span><br><span class=\"line\">        &quot;hit_set_params&quot;: &#123;</span><br><span class=\"line\">            &quot;type&quot;: &quot;none&quot;</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        &quot;hit_set_period&quot;: 0,</span><br><span class=\"line\">        &quot;hit_set_search_last_n&quot;: 0,</span><br><span class=\"line\">        &quot;last_change&quot;: &quot;67&quot;,</span><br><span class=\"line\">        &quot;last_force_op_resend&quot;: &quot;0&quot;,</span><br><span class=\"line\">        &quot;last_force_op_resend_preluminous&quot;: &quot;0&quot;,</span><br><span class=\"line\">        &quot;min_read_recency_for_promote&quot;: 0,</span><br><span class=\"line\">        &quot;min_size&quot;: 2,</span><br><span class=\"line\">        &quot;min_write_recency_for_promote&quot;: 0,</span><br><span class=\"line\">        &quot;object_hash&quot;: 2,</span><br><span class=\"line\">        &quot;options&quot;: &#123;&#125;,</span><br><span class=\"line\">        &quot;pg_num&quot;: 8,</span><br><span class=\"line\">        &quot;pgp_num&quot;: 8,</span><br><span class=\"line\">        &quot;pool&quot;: 3,</span><br><span class=\"line\">        &quot;pool_name&quot;: &quot;default.rgw.meta&quot;,</span><br><span class=\"line\">        &quot;pool_snaps&quot;: [],</span><br><span class=\"line\">        &quot;quota_max_bytes&quot;: 0,</span><br><span class=\"line\">        &quot;quota_max_objects&quot;: 0,</span><br><span class=\"line\">        &quot;read_tier&quot;: -1,</span><br><span class=\"line\">        &quot;removed_snaps&quot;: &quot;[]&quot;,</span><br><span class=\"line\">        &quot;size&quot;: 3,</span><br><span class=\"line\">        &quot;snap_epoch&quot;: 0,</span><br><span class=\"line\">        &quot;snap_mode&quot;: &quot;selfmanaged&quot;,</span><br><span class=\"line\">        &quot;snap_seq&quot;: 0,</span><br><span class=\"line\">        &quot;stripe_width&quot;: 0,</span><br><span class=\"line\">        &quot;target_max_bytes&quot;: 0,</span><br><span class=\"line\">        &quot;target_max_objects&quot;: 0,</span><br><span class=\"line\">        &quot;tier_of&quot;: -1,</span><br><span class=\"line\">        &quot;tiers&quot;: [],</span><br><span class=\"line\">        &quot;type&quot;: 1,</span><br><span class=\"line\">        &quot;use_gmt_hitset&quot;: true,</span><br><span class=\"line\">        &quot;write_tier&quot;: -1</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        &quot;application_metadata&quot;: &#123;</span><br><span class=\"line\">            &quot;rgw&quot;: &#123;&#125;</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        &quot;auid&quot;: -1,</span><br><span class=\"line\">        &quot;cache_min_evict_age&quot;: 0,</span><br><span class=\"line\">        &quot;cache_min_flush_age&quot;: 0,</span><br><span class=\"line\">        &quot;cache_mode&quot;: &quot;none&quot;,</span><br><span class=\"line\">        &quot;cache_target_dirty_high_ratio_micro&quot;: 600000,</span><br><span class=\"line\">        &quot;cache_target_dirty_ratio_micro&quot;: 400000,</span><br><span class=\"line\">        &quot;cache_target_full_ratio_micro&quot;: 800000,</span><br><span class=\"line\">        &quot;crash_replay_interval&quot;: 0,</span><br><span class=\"line\">        &quot;crush_rule&quot;: 1,</span><br><span class=\"line\">        &quot;erasure_code_profile&quot;: &quot;&quot;,</span><br><span class=\"line\">        &quot;expected_num_objects&quot;: 0,</span><br><span class=\"line\">        &quot;fast_read&quot;: false,</span><br><span class=\"line\">        &quot;flags&quot;: 1,</span><br><span class=\"line\">        &quot;flags_names&quot;: &quot;hashpspool&quot;,</span><br><span class=\"line\">        &quot;grade_table&quot;: [],</span><br><span class=\"line\">        &quot;hit_set_count&quot;: 0,</span><br><span class=\"line\">        &quot;hit_set_grade_decay_rate&quot;: 0,</span><br><span class=\"line\">        &quot;hit_set_params&quot;: &#123;</span><br><span class=\"line\">            &quot;type&quot;: &quot;none&quot;</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        &quot;hit_set_period&quot;: 0,</span><br><span class=\"line\">        &quot;hit_set_search_last_n&quot;: 0,</span><br><span class=\"line\">        &quot;last_change&quot;: &quot;70&quot;,</span><br><span class=\"line\">        &quot;last_force_op_resend&quot;: &quot;0&quot;,</span><br><span class=\"line\">        &quot;last_force_op_resend_preluminous&quot;: &quot;0&quot;,</span><br><span class=\"line\">        &quot;min_read_recency_for_promote&quot;: 0,</span><br><span class=\"line\">        &quot;min_size&quot;: 2,</span><br><span class=\"line\">        &quot;min_write_recency_for_promote&quot;: 0,</span><br><span class=\"line\">        &quot;object_hash&quot;: 2,</span><br><span class=\"line\">        &quot;options&quot;: &#123;&#125;,</span><br><span class=\"line\">        &quot;pg_num&quot;: 8,</span><br><span class=\"line\">        &quot;pgp_num&quot;: 8,</span><br><span class=\"line\">        &quot;pool&quot;: 4,</span><br><span class=\"line\">        &quot;pool_name&quot;: &quot;default.rgw.log&quot;,</span><br><span class=\"line\">        &quot;pool_snaps&quot;: [],</span><br><span class=\"line\">        &quot;quota_max_bytes&quot;: 0,</span><br><span class=\"line\">        &quot;quota_max_objects&quot;: 0,</span><br><span class=\"line\">        &quot;read_tier&quot;: -1,</span><br><span class=\"line\">        &quot;removed_snaps&quot;: &quot;[]&quot;,</span><br><span class=\"line\">        &quot;size&quot;: 3,</span><br><span class=\"line\">        &quot;snap_epoch&quot;: 0,</span><br><span class=\"line\">        &quot;snap_mode&quot;: &quot;selfmanaged&quot;,</span><br><span class=\"line\">        &quot;snap_seq&quot;: 0,</span><br><span class=\"line\">        &quot;stripe_width&quot;: 0,</span><br><span class=\"line\">        &quot;target_max_bytes&quot;: 0,</span><br><span class=\"line\">        &quot;target_max_objects&quot;: 0,</span><br><span class=\"line\">        &quot;tier_of&quot;: -1,</span><br><span class=\"line\">        &quot;tiers&quot;: [],</span><br><span class=\"line\">        &quot;type&quot;: 1,</span><br><span class=\"line\">        &quot;use_gmt_hitset&quot;: true,</span><br><span class=\"line\">        &quot;write_tier&quot;: -1</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        &quot;application_metadata&quot;: &#123;</span><br><span class=\"line\">            &quot;rgw&quot;: &#123;&#125;</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        &quot;auid&quot;: 0,</span><br><span class=\"line\">        &quot;cache_min_evict_age&quot;: 0,</span><br><span class=\"line\">        &quot;cache_min_flush_age&quot;: 0,</span><br><span class=\"line\">        &quot;cache_mode&quot;: &quot;none&quot;,</span><br><span class=\"line\">        &quot;cache_target_dirty_high_ratio_micro&quot;: 600000,</span><br><span class=\"line\">        &quot;cache_target_dirty_ratio_micro&quot;: 400000,</span><br><span class=\"line\">        &quot;cache_target_full_ratio_micro&quot;: 800000,</span><br><span class=\"line\">        &quot;crash_replay_interval&quot;: 0,</span><br><span class=\"line\">        &quot;crush_rule&quot;: 1,</span><br><span class=\"line\">        &quot;erasure_code_profile&quot;: &quot;rule_rgw&quot;,</span><br><span class=\"line\">        &quot;expected_num_objects&quot;: 0,</span><br><span class=\"line\">        &quot;fast_read&quot;: false,</span><br><span class=\"line\">        &quot;flags&quot;: 1,</span><br><span class=\"line\">        &quot;flags_names&quot;: &quot;hashpspool&quot;,</span><br><span class=\"line\">        &quot;grade_table&quot;: [],</span><br><span class=\"line\">        &quot;hit_set_count&quot;: 0,</span><br><span class=\"line\">        &quot;hit_set_grade_decay_rate&quot;: 0,</span><br><span class=\"line\">        &quot;hit_set_params&quot;: &#123;</span><br><span class=\"line\">            &quot;type&quot;: &quot;none&quot;</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        &quot;hit_set_period&quot;: 0,</span><br><span class=\"line\">        &quot;hit_set_search_last_n&quot;: 0,</span><br><span class=\"line\">        &quot;last_change&quot;: &quot;57&quot;,</span><br><span class=\"line\">        &quot;last_force_op_resend&quot;: &quot;0&quot;,</span><br><span class=\"line\">        &quot;last_force_op_resend_preluminous&quot;: &quot;0&quot;,</span><br><span class=\"line\">        &quot;min_read_recency_for_promote&quot;: 0,</span><br><span class=\"line\">        &quot;min_size&quot;: 2,</span><br><span class=\"line\">        &quot;min_write_recency_for_promote&quot;: 0,</span><br><span class=\"line\">        &quot;object_hash&quot;: 2,</span><br><span class=\"line\">        &quot;options&quot;: &#123;&#125;,</span><br><span class=\"line\">        &quot;pg_num&quot;: 16,</span><br><span class=\"line\">        &quot;pgp_num&quot;: 16,</span><br><span class=\"line\">        &quot;pool&quot;: 5,</span><br><span class=\"line\">        &quot;pool_name&quot;: &quot;default.rgw.buckets.index&quot;,</span><br><span class=\"line\">        &quot;pool_snaps&quot;: [],</span><br><span class=\"line\">        &quot;quota_max_bytes&quot;: 0,</span><br><span class=\"line\">        &quot;quota_max_objects&quot;: 0,</span><br><span class=\"line\">        &quot;read_tier&quot;: -1,</span><br><span class=\"line\">        &quot;removed_snaps&quot;: &quot;[]&quot;,</span><br><span class=\"line\">        &quot;size&quot;: 3,</span><br><span class=\"line\">        &quot;snap_epoch&quot;: 0,</span><br><span class=\"line\">        &quot;snap_mode&quot;: &quot;selfmanaged&quot;,</span><br><span class=\"line\">        &quot;snap_seq&quot;: 0,</span><br><span class=\"line\">        &quot;stripe_width&quot;: 0,</span><br><span class=\"line\">        &quot;target_max_bytes&quot;: 0,</span><br><span class=\"line\">        &quot;target_max_objects&quot;: 0,</span><br><span class=\"line\">        &quot;tier_of&quot;: -1,</span><br><span class=\"line\">        &quot;tiers&quot;: [],</span><br><span class=\"line\">        &quot;type&quot;: 1,</span><br><span class=\"line\">        &quot;use_gmt_hitset&quot;: true,</span><br><span class=\"line\">        &quot;write_tier&quot;: -1</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        &quot;application_metadata&quot;: &#123;</span><br><span class=\"line\">            &quot;rgw&quot;: &#123;&#125;</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        &quot;auid&quot;: 0,</span><br><span class=\"line\">        &quot;cache_min_evict_age&quot;: 0,</span><br><span class=\"line\">        &quot;cache_min_flush_age&quot;: 0,</span><br><span class=\"line\">        &quot;cache_mode&quot;: &quot;none&quot;,</span><br><span class=\"line\">        &quot;cache_target_dirty_high_ratio_micro&quot;: 600000,</span><br><span class=\"line\">        &quot;cache_target_dirty_ratio_micro&quot;: 400000,</span><br><span class=\"line\">        &quot;cache_target_full_ratio_micro&quot;: 800000,</span><br><span class=\"line\">        &quot;crash_replay_interval&quot;: 0,</span><br><span class=\"line\">        &quot;crush_rule&quot;: 1,</span><br><span class=\"line\">        &quot;erasure_code_profile&quot;: &quot;rule_rgw&quot;,</span><br><span class=\"line\">        &quot;expected_num_objects&quot;: 0,</span><br><span class=\"line\">        &quot;fast_read&quot;: false,</span><br><span class=\"line\">        &quot;flags&quot;: 1,</span><br><span class=\"line\">        &quot;flags_names&quot;: &quot;hashpspool&quot;,</span><br><span class=\"line\">        &quot;grade_table&quot;: [],</span><br><span class=\"line\">        &quot;hit_set_count&quot;: 0,</span><br><span class=\"line\">        &quot;hit_set_grade_decay_rate&quot;: 0,</span><br><span class=\"line\">        &quot;hit_set_params&quot;: &#123;</span><br><span class=\"line\">            &quot;type&quot;: &quot;none&quot;</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        &quot;hit_set_period&quot;: 0,</span><br><span class=\"line\">        &quot;hit_set_search_last_n&quot;: 0,</span><br><span class=\"line\">        &quot;last_change&quot;: &quot;790&quot;,</span><br><span class=\"line\">        &quot;last_force_op_resend&quot;: &quot;0&quot;,</span><br><span class=\"line\">        &quot;last_force_op_resend_preluminous&quot;: &quot;788&quot;,</span><br><span class=\"line\">        &quot;min_read_recency_for_promote&quot;: 0,</span><br><span class=\"line\">        &quot;min_size&quot;: 2,</span><br><span class=\"line\">        &quot;min_write_recency_for_promote&quot;: 0,</span><br><span class=\"line\">        &quot;object_hash&quot;: 2,</span><br><span class=\"line\">        &quot;options&quot;: &#123;&#125;,</span><br><span class=\"line\">        &quot;pg_num&quot;: 514,</span><br><span class=\"line\">        &quot;pgp_num&quot;: 514,</span><br><span class=\"line\">        &quot;pool&quot;: 6,</span><br><span class=\"line\">        &quot;pool_name&quot;: &quot;default.rgw.buckets.data&quot;,</span><br><span class=\"line\">        &quot;pool_snaps&quot;: [],</span><br><span class=\"line\">        &quot;quota_max_bytes&quot;: 0,</span><br><span class=\"line\">        &quot;quota_max_objects&quot;: 0,</span><br><span class=\"line\">        &quot;read_tier&quot;: -1,</span><br><span class=\"line\">        &quot;removed_snaps&quot;: &quot;[]&quot;,</span><br><span class=\"line\">        &quot;size&quot;: 3,</span><br><span class=\"line\">        &quot;snap_epoch&quot;: 0,</span><br><span class=\"line\">        &quot;snap_mode&quot;: &quot;selfmanaged&quot;,</span><br><span class=\"line\">        &quot;snap_seq&quot;: 0,</span><br><span class=\"line\">        &quot;stripe_width&quot;: 0,</span><br><span class=\"line\">        &quot;target_max_bytes&quot;: 0,</span><br><span class=\"line\">        &quot;target_max_objects&quot;: 0,</span><br><span class=\"line\">        &quot;tier_of&quot;: -1,</span><br><span class=\"line\">        &quot;tiers&quot;: [],</span><br><span class=\"line\">        &quot;type&quot;: 1,</span><br><span class=\"line\">        &quot;use_gmt_hitset&quot;: true,</span><br><span class=\"line\">        &quot;write_tier&quot;: -1</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        &quot;application_metadata&quot;: &#123;</span><br><span class=\"line\">            &quot;cephfs&quot;: &#123;&#125;</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        &quot;auid&quot;: 0,</span><br><span class=\"line\">        &quot;cache_min_evict_age&quot;: 0,</span><br><span class=\"line\">        &quot;cache_min_flush_age&quot;: 0,</span><br><span class=\"line\">        &quot;cache_mode&quot;: &quot;none&quot;,</span><br><span class=\"line\">        &quot;cache_target_dirty_high_ratio_micro&quot;: 600000,</span><br><span class=\"line\">        &quot;cache_target_dirty_ratio_micro&quot;: 400000,</span><br><span class=\"line\">        &quot;cache_target_full_ratio_micro&quot;: 800000,</span><br><span class=\"line\">        &quot;crash_replay_interval&quot;: 0,</span><br><span class=\"line\">        &quot;crush_rule&quot;: 0,</span><br><span class=\"line\">        &quot;erasure_code_profile&quot;: &quot;&quot;,</span><br><span class=\"line\">        &quot;expected_num_objects&quot;: 0,</span><br><span class=\"line\">        &quot;fast_read&quot;: false,</span><br><span class=\"line\">        &quot;flags&quot;: 1,</span><br><span class=\"line\">        &quot;flags_names&quot;: &quot;hashpspool&quot;,</span><br><span class=\"line\">        &quot;grade_table&quot;: [],</span><br><span class=\"line\">        &quot;hit_set_count&quot;: 0,</span><br><span class=\"line\">        &quot;hit_set_grade_decay_rate&quot;: 0,</span><br><span class=\"line\">        &quot;hit_set_params&quot;: &#123;</span><br><span class=\"line\">            &quot;type&quot;: &quot;none&quot;</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        &quot;hit_set_period&quot;: 0,</span><br><span class=\"line\">        &quot;hit_set_search_last_n&quot;: 0,</span><br><span class=\"line\">        &quot;last_change&quot;: &quot;136&quot;,</span><br><span class=\"line\">        &quot;last_force_op_resend&quot;: &quot;0&quot;,</span><br><span class=\"line\">        &quot;last_force_op_resend_preluminous&quot;: &quot;0&quot;,</span><br><span class=\"line\">        &quot;min_read_recency_for_promote&quot;: 0,</span><br><span class=\"line\">        &quot;min_size&quot;: 2,</span><br><span class=\"line\">        &quot;min_write_recency_for_promote&quot;: 0,</span><br><span class=\"line\">        &quot;object_hash&quot;: 2,</span><br><span class=\"line\">        &quot;options&quot;: &#123;&#125;,</span><br><span class=\"line\">        &quot;pg_num&quot;: 128,</span><br><span class=\"line\">        &quot;pgp_num&quot;: 128,</span><br><span class=\"line\">        &quot;pool&quot;: 7,</span><br><span class=\"line\">        &quot;pool_name&quot;: &quot;fs_data&quot;,</span><br><span class=\"line\">        &quot;pool_snaps&quot;: [],</span><br><span class=\"line\">        &quot;quota_max_bytes&quot;: 0,</span><br><span class=\"line\">        &quot;quota_max_objects&quot;: 0,</span><br><span class=\"line\">        &quot;read_tier&quot;: -1,</span><br><span class=\"line\">        &quot;removed_snaps&quot;: &quot;[]&quot;,</span><br><span class=\"line\">        &quot;size&quot;: 3,</span><br><span class=\"line\">        &quot;snap_epoch&quot;: 0,</span><br><span class=\"line\">        &quot;snap_mode&quot;: &quot;selfmanaged&quot;,</span><br><span class=\"line\">        &quot;snap_seq&quot;: 0,</span><br><span class=\"line\">        &quot;stripe_width&quot;: 0,</span><br><span class=\"line\">        &quot;target_max_bytes&quot;: 0,</span><br><span class=\"line\">        &quot;target_max_objects&quot;: 0,</span><br><span class=\"line\">        &quot;tier_of&quot;: -1,</span><br><span class=\"line\">        &quot;tiers&quot;: [],</span><br><span class=\"line\">        &quot;type&quot;: 1,</span><br><span class=\"line\">        &quot;use_gmt_hitset&quot;: true,</span><br><span class=\"line\">        &quot;write_tier&quot;: -1</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        &quot;application_metadata&quot;: &#123;</span><br><span class=\"line\">            &quot;cephfs&quot;: &#123;&#125;</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        &quot;auid&quot;: 0,</span><br><span class=\"line\">        &quot;cache_min_evict_age&quot;: 0,</span><br><span class=\"line\">        &quot;cache_min_flush_age&quot;: 0,</span><br><span class=\"line\">        &quot;cache_mode&quot;: &quot;none&quot;,</span><br><span class=\"line\">        &quot;cache_target_dirty_high_ratio_micro&quot;: 600000,</span><br><span class=\"line\">        &quot;cache_target_dirty_ratio_micro&quot;: 400000,</span><br><span class=\"line\">        &quot;cache_target_full_ratio_micro&quot;: 800000,</span><br><span class=\"line\">        &quot;crash_replay_interval&quot;: 0,</span><br><span class=\"line\">        &quot;crush_rule&quot;: 0,</span><br><span class=\"line\">        &quot;erasure_code_profile&quot;: &quot;&quot;,</span><br><span class=\"line\">        &quot;expected_num_objects&quot;: 0,</span><br><span class=\"line\">        &quot;fast_read&quot;: false,</span><br><span class=\"line\">        &quot;flags&quot;: 1,</span><br><span class=\"line\">        &quot;flags_names&quot;: &quot;hashpspool&quot;,</span><br><span class=\"line\">        &quot;grade_table&quot;: [],</span><br><span class=\"line\">        &quot;hit_set_count&quot;: 0,</span><br><span class=\"line\">        &quot;hit_set_grade_decay_rate&quot;: 0,</span><br><span class=\"line\">        &quot;hit_set_params&quot;: &#123;</span><br><span class=\"line\">            &quot;type&quot;: &quot;none&quot;</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        &quot;hit_set_period&quot;: 0,</span><br><span class=\"line\">        &quot;hit_set_search_last_n&quot;: 0,</span><br><span class=\"line\">        &quot;last_change&quot;: &quot;136&quot;,</span><br><span class=\"line\">        &quot;last_force_op_resend&quot;: &quot;0&quot;,</span><br><span class=\"line\">        &quot;last_force_op_resend_preluminous&quot;: &quot;0&quot;,</span><br><span class=\"line\">        &quot;min_read_recency_for_promote&quot;: 0,</span><br><span class=\"line\">        &quot;min_size&quot;: 2,</span><br><span class=\"line\">        &quot;min_write_recency_for_promote&quot;: 0,</span><br><span class=\"line\">        &quot;object_hash&quot;: 2,</span><br><span class=\"line\">        &quot;options&quot;: &#123;&#125;,</span><br><span class=\"line\">        &quot;pg_num&quot;: 64,</span><br><span class=\"line\">        &quot;pgp_num&quot;: 64,</span><br><span class=\"line\">        &quot;pool&quot;: 8,</span><br><span class=\"line\">        &quot;pool_name&quot;: &quot;fs_metadata&quot;,</span><br><span class=\"line\">        &quot;pool_snaps&quot;: [],</span><br><span class=\"line\">        &quot;quota_max_bytes&quot;: 0,</span><br><span class=\"line\">        &quot;quota_max_objects&quot;: 0,</span><br><span class=\"line\">        &quot;read_tier&quot;: -1,</span><br><span class=\"line\">        &quot;removed_snaps&quot;: &quot;[]&quot;,</span><br><span class=\"line\">        &quot;size&quot;: 3,</span><br><span class=\"line\">        &quot;snap_epoch&quot;: 0,</span><br><span class=\"line\">        &quot;snap_mode&quot;: &quot;selfmanaged&quot;,</span><br><span class=\"line\">        &quot;snap_seq&quot;: 0,</span><br><span class=\"line\">        &quot;stripe_width&quot;: 0,</span><br><span class=\"line\">        &quot;target_max_bytes&quot;: 0,</span><br><span class=\"line\">        &quot;target_max_objects&quot;: 0,</span><br><span class=\"line\">        &quot;tier_of&quot;: -1,</span><br><span class=\"line\">        &quot;tiers&quot;: [],</span><br><span class=\"line\">        &quot;type&quot;: 1,</span><br><span class=\"line\">        &quot;use_gmt_hitset&quot;: true,</span><br><span class=\"line\">        &quot;write_tier&quot;: -1</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        &quot;application_metadata&quot;: &#123;</span><br><span class=\"line\">            &quot;rgw&quot;: &#123;&#125;</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        &quot;auid&quot;: 0,</span><br><span class=\"line\">        &quot;cache_min_evict_age&quot;: 0,</span><br><span class=\"line\">        &quot;cache_min_flush_age&quot;: 0,</span><br><span class=\"line\">        &quot;cache_mode&quot;: &quot;none&quot;,</span><br><span class=\"line\">        &quot;cache_target_dirty_high_ratio_micro&quot;: 600000,</span><br><span class=\"line\">        &quot;cache_target_dirty_ratio_micro&quot;: 400000,</span><br><span class=\"line\">        &quot;cache_target_full_ratio_micro&quot;: 800000,</span><br><span class=\"line\">        &quot;crash_replay_interval&quot;: 0,</span><br><span class=\"line\">        &quot;crush_rule&quot;: 0,</span><br><span class=\"line\">        &quot;erasure_code_profile&quot;: &quot;&quot;,</span><br><span class=\"line\">        &quot;expected_num_objects&quot;: 0,</span><br><span class=\"line\">        &quot;fast_read&quot;: false,</span><br><span class=\"line\">        &quot;flags&quot;: 1,</span><br><span class=\"line\">        &quot;flags_names&quot;: &quot;hashpspool&quot;,</span><br><span class=\"line\">        &quot;grade_table&quot;: [],</span><br><span class=\"line\">        &quot;hit_set_count&quot;: 0,</span><br><span class=\"line\">        &quot;hit_set_grade_decay_rate&quot;: 0,</span><br><span class=\"line\">        &quot;hit_set_params&quot;: &#123;</span><br><span class=\"line\">            &quot;type&quot;: &quot;none&quot;</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        &quot;hit_set_period&quot;: 0,</span><br><span class=\"line\">        &quot;hit_set_search_last_n&quot;: 0,</span><br><span class=\"line\">        &quot;last_change&quot;: &quot;139&quot;,</span><br><span class=\"line\">        &quot;last_force_op_resend&quot;: &quot;0&quot;,</span><br><span class=\"line\">        &quot;last_force_op_resend_preluminous&quot;: &quot;0&quot;,</span><br><span class=\"line\">        &quot;min_read_recency_for_promote&quot;: 0,</span><br><span class=\"line\">        &quot;min_size&quot;: 2,</span><br><span class=\"line\">        &quot;min_write_recency_for_promote&quot;: 0,</span><br><span class=\"line\">        &quot;object_hash&quot;: 2,</span><br><span class=\"line\">        &quot;options&quot;: &#123;&#125;,</span><br><span class=\"line\">        &quot;pg_num&quot;: 8,</span><br><span class=\"line\">        &quot;pgp_num&quot;: 8,</span><br><span class=\"line\">        &quot;pool&quot;: 9,</span><br><span class=\"line\">        &quot;pool_name&quot;: &quot;default.rgw.buckets.non-ec&quot;,</span><br><span class=\"line\">        &quot;pool_snaps&quot;: [],</span><br><span class=\"line\">        &quot;quota_max_bytes&quot;: 0,</span><br><span class=\"line\">        &quot;quota_max_objects&quot;: 0,</span><br><span class=\"line\">        &quot;read_tier&quot;: -1,</span><br><span class=\"line\">        &quot;removed_snaps&quot;: &quot;[]&quot;,</span><br><span class=\"line\">        &quot;size&quot;: 3,</span><br><span class=\"line\">        &quot;snap_epoch&quot;: 0,</span><br><span class=\"line\">        &quot;snap_mode&quot;: &quot;selfmanaged&quot;,</span><br><span class=\"line\">        &quot;snap_seq&quot;: 0,</span><br><span class=\"line\">        &quot;stripe_width&quot;: 0,</span><br><span class=\"line\">        &quot;target_max_bytes&quot;: 0,</span><br><span class=\"line\">        &quot;target_max_objects&quot;: 0,</span><br><span class=\"line\">        &quot;tier_of&quot;: -1,</span><br><span class=\"line\">        &quot;tiers&quot;: [],</span><br><span class=\"line\">        &quot;type&quot;: 1,</span><br><span class=\"line\">        &quot;use_gmt_hitset&quot;: true,</span><br><span class=\"line\">        &quot;write_tier&quot;: -1</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">]</span><br></pre></td></tr></table></figure>\n<h1 id=\"Python调用\"><a href=\"#Python调用\" class=\"headerlink\" title=\"Python调用\"></a>Python调用</h1><p>可以通过requests来调用ceph mgr restful的接口，下面通过Python来获取全部存储池信息。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#! /usr/bin/env python3</span><br><span class=\"line\"></span><br><span class=\"line\">import requests</span><br><span class=\"line\"></span><br><span class=\"line\">r = requests.get(&apos;https://192.168.180.138:8003/pool&apos;,verify=False, auth=(&apos;admin&apos;,&apos;839df177-560e-421a-95fc-9f6a1c08236e&apos;))</span><br><span class=\"line\">print(r.json())</span><br></pre></td></tr></table></figure>\n<h1 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h1><ul>\n<li><a href=\"https://lnsyyj.github.io/2017/11/27/CEPH-MANAGER-DAEMON-RESTful-plugin/\" target=\"_blank\" rel=\"noopener\">https://lnsyyj.github.io/2017/11/27/CEPH-MANAGER-DAEMON-RESTful-plugin/</a></li>\n</ul>\n"},{"title":"Git patch","date":"2018-03-08T06:01:19.000Z","_content":"git format-patch适用于git的patch，包含diff信息，包含提交人，提交时间等 如果生成的补丁不能打到当前分支，git am会给出提示，并协助你完成打补丁工作\n\n## 对比分支生成patch\n\n例：从master checkout 一个新分支修改然后与master对比生成patch。\n\n```bash\n$ git format-patch -M master   # -M选项表示这个patch要和那个分支比对\n$ git am 001-xxx.patch         # 不必重新commit\n```\n\n## 将commit打包成patch\n\n```bash\n$ git format-patch 1bbe3c8c19 # 从1bbe3c8c19往后的全部commit,不包括1bbe3c8c19\n\ngit format-patch -n 1bbe3c8c19 # 1bbe3c8c19开始n个commit，包含1bbe3c8c19\n\n$ git format-patch HEAD^      # 最近的1次commit的patch\n$ git format-patch HEAD^^     # 最近的2次commit的patch\n$ git format-patch HEAD^^^    # 最近的3次commit的patch\n\n$ git format-patch -1         # 同HEAD^  \n$ git format-patch -2         # 同HEAD^^\n$ git format-patch -3         # 同HEAD^^^\n\n$ git format-patch -1 -4      # -1到-4之间的commit，包括-1和-4\n\n$ git format-patch <ref1>..<ref2>  ## 在两个commit之间，包括ref1和ref2 \n```\n\n## patch合并到一个文件\n\n默认情况下，每一个commit都会产生一个patch文件，下面的操作可以把全部commit合并到一个文件中\n\n```bash\n$ git format-path 1bbe3c8c19 --stdout > xxx.patch\n```\n\n## 应用patch\n\n```bash\n# 检查patch文件\n$ git apply --stat xxx.patch\n\n#查看是否能应用成功\n$ git apply --check xxx.patch\n\n# 应用patch\n$ git am -s < xxx.patch\n```","source":"_posts/git-patch.md","raw":"---\ntitle: Git patch\ndate: 2018-03-08 14:01:19\ntags: git\n---\ngit format-patch适用于git的patch，包含diff信息，包含提交人，提交时间等 如果生成的补丁不能打到当前分支，git am会给出提示，并协助你完成打补丁工作\n\n## 对比分支生成patch\n\n例：从master checkout 一个新分支修改然后与master对比生成patch。\n\n```bash\n$ git format-patch -M master   # -M选项表示这个patch要和那个分支比对\n$ git am 001-xxx.patch         # 不必重新commit\n```\n\n## 将commit打包成patch\n\n```bash\n$ git format-patch 1bbe3c8c19 # 从1bbe3c8c19往后的全部commit,不包括1bbe3c8c19\n\ngit format-patch -n 1bbe3c8c19 # 1bbe3c8c19开始n个commit，包含1bbe3c8c19\n\n$ git format-patch HEAD^      # 最近的1次commit的patch\n$ git format-patch HEAD^^     # 最近的2次commit的patch\n$ git format-patch HEAD^^^    # 最近的3次commit的patch\n\n$ git format-patch -1         # 同HEAD^  \n$ git format-patch -2         # 同HEAD^^\n$ git format-patch -3         # 同HEAD^^^\n\n$ git format-patch -1 -4      # -1到-4之间的commit，包括-1和-4\n\n$ git format-patch <ref1>..<ref2>  ## 在两个commit之间，包括ref1和ref2 \n```\n\n## patch合并到一个文件\n\n默认情况下，每一个commit都会产生一个patch文件，下面的操作可以把全部commit合并到一个文件中\n\n```bash\n$ git format-path 1bbe3c8c19 --stdout > xxx.patch\n```\n\n## 应用patch\n\n```bash\n# 检查patch文件\n$ git apply --stat xxx.patch\n\n#查看是否能应用成功\n$ git apply --check xxx.patch\n\n# 应用patch\n$ git am -s < xxx.patch\n```","slug":"git-patch","published":1,"updated":"2018-03-08T07:04:17.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck1pzbtgo0006tp75lm8823fa","content":"<p>git format-patch适用于git的patch，包含diff信息，包含提交人，提交时间等 如果生成的补丁不能打到当前分支，git am会给出提示，并协助你完成打补丁工作</p>\n<h2 id=\"对比分支生成patch\"><a href=\"#对比分支生成patch\" class=\"headerlink\" title=\"对比分支生成patch\"></a>对比分支生成patch</h2><p>例：从master checkout 一个新分支修改然后与master对比生成patch。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ git format-patch -M master   <span class=\"comment\"># -M选项表示这个patch要和那个分支比对</span></span><br><span class=\"line\">$ git am 001-xxx.patch         <span class=\"comment\"># 不必重新commit</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"将commit打包成patch\"><a href=\"#将commit打包成patch\" class=\"headerlink\" title=\"将commit打包成patch\"></a>将commit打包成patch</h2><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ git format-patch 1bbe3c8c19 <span class=\"comment\"># 从1bbe3c8c19往后的全部commit,不包括1bbe3c8c19</span></span><br><span class=\"line\"></span><br><span class=\"line\">git format-patch -n 1bbe3c8c19 <span class=\"comment\"># 1bbe3c8c19开始n个commit，包含1bbe3c8c19</span></span><br><span class=\"line\"></span><br><span class=\"line\">$ git format-patch HEAD^      <span class=\"comment\"># 最近的1次commit的patch</span></span><br><span class=\"line\">$ git format-patch HEAD^^     <span class=\"comment\"># 最近的2次commit的patch</span></span><br><span class=\"line\">$ git format-patch HEAD^^^    <span class=\"comment\"># 最近的3次commit的patch</span></span><br><span class=\"line\"></span><br><span class=\"line\">$ git format-patch -1         <span class=\"comment\"># 同HEAD^  </span></span><br><span class=\"line\">$ git format-patch -2         <span class=\"comment\"># 同HEAD^^</span></span><br><span class=\"line\">$ git format-patch -3         <span class=\"comment\"># 同HEAD^^^</span></span><br><span class=\"line\"></span><br><span class=\"line\">$ git format-patch -1 -4      <span class=\"comment\"># -1到-4之间的commit，包括-1和-4</span></span><br><span class=\"line\"></span><br><span class=\"line\">$ git format-patch &lt;ref1&gt;..&lt;ref2&gt;  <span class=\"comment\">## 在两个commit之间，包括ref1和ref2</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"patch合并到一个文件\"><a href=\"#patch合并到一个文件\" class=\"headerlink\" title=\"patch合并到一个文件\"></a>patch合并到一个文件</h2><p>默认情况下，每一个commit都会产生一个patch文件，下面的操作可以把全部commit合并到一个文件中</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ git format-path 1bbe3c8c19 --stdout &gt; xxx.patch</span><br></pre></td></tr></table></figure>\n<h2 id=\"应用patch\"><a href=\"#应用patch\" class=\"headerlink\" title=\"应用patch\"></a>应用patch</h2><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 检查patch文件</span></span><br><span class=\"line\">$ git apply --<span class=\"built_in\">stat</span> xxx.patch</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#查看是否能应用成功</span></span><br><span class=\"line\">$ git apply --check xxx.patch</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 应用patch</span></span><br><span class=\"line\">$ git am -s &lt; xxx.patch</span><br></pre></td></tr></table></figure>","site":{"data":{}},"excerpt":"","more":"<p>git format-patch适用于git的patch，包含diff信息，包含提交人，提交时间等 如果生成的补丁不能打到当前分支，git am会给出提示，并协助你完成打补丁工作</p>\n<h2 id=\"对比分支生成patch\"><a href=\"#对比分支生成patch\" class=\"headerlink\" title=\"对比分支生成patch\"></a>对比分支生成patch</h2><p>例：从master checkout 一个新分支修改然后与master对比生成patch。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ git format-patch -M master   <span class=\"comment\"># -M选项表示这个patch要和那个分支比对</span></span><br><span class=\"line\">$ git am 001-xxx.patch         <span class=\"comment\"># 不必重新commit</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"将commit打包成patch\"><a href=\"#将commit打包成patch\" class=\"headerlink\" title=\"将commit打包成patch\"></a>将commit打包成patch</h2><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ git format-patch 1bbe3c8c19 <span class=\"comment\"># 从1bbe3c8c19往后的全部commit,不包括1bbe3c8c19</span></span><br><span class=\"line\"></span><br><span class=\"line\">git format-patch -n 1bbe3c8c19 <span class=\"comment\"># 1bbe3c8c19开始n个commit，包含1bbe3c8c19</span></span><br><span class=\"line\"></span><br><span class=\"line\">$ git format-patch HEAD^      <span class=\"comment\"># 最近的1次commit的patch</span></span><br><span class=\"line\">$ git format-patch HEAD^^     <span class=\"comment\"># 最近的2次commit的patch</span></span><br><span class=\"line\">$ git format-patch HEAD^^^    <span class=\"comment\"># 最近的3次commit的patch</span></span><br><span class=\"line\"></span><br><span class=\"line\">$ git format-patch -1         <span class=\"comment\"># 同HEAD^  </span></span><br><span class=\"line\">$ git format-patch -2         <span class=\"comment\"># 同HEAD^^</span></span><br><span class=\"line\">$ git format-patch -3         <span class=\"comment\"># 同HEAD^^^</span></span><br><span class=\"line\"></span><br><span class=\"line\">$ git format-patch -1 -4      <span class=\"comment\"># -1到-4之间的commit，包括-1和-4</span></span><br><span class=\"line\"></span><br><span class=\"line\">$ git format-patch &lt;ref1&gt;..&lt;ref2&gt;  <span class=\"comment\">## 在两个commit之间，包括ref1和ref2</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"patch合并到一个文件\"><a href=\"#patch合并到一个文件\" class=\"headerlink\" title=\"patch合并到一个文件\"></a>patch合并到一个文件</h2><p>默认情况下，每一个commit都会产生一个patch文件，下面的操作可以把全部commit合并到一个文件中</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ git format-path 1bbe3c8c19 --stdout &gt; xxx.patch</span><br></pre></td></tr></table></figure>\n<h2 id=\"应用patch\"><a href=\"#应用patch\" class=\"headerlink\" title=\"应用patch\"></a>应用patch</h2><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 检查patch文件</span></span><br><span class=\"line\">$ git apply --<span class=\"built_in\">stat</span> xxx.patch</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#查看是否能应用成功</span></span><br><span class=\"line\">$ git apply --check xxx.patch</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 应用patch</span></span><br><span class=\"line\">$ git am -s &lt; xxx.patch</span><br></pre></td></tr></table></figure>"},{"title":"通过kubeadm搭建单节点k8s环境","date":"2018-12-08T07:15:00.000Z","_content":"\n\n本次实验，通过kubeadm来安装一个单节点的k8s环境。\n\n本次实验是在虚拟机上进行，虚拟机的配置如下：\n\n| OS | CPU | 内存 | IP |\n| ----- | ----- | ----- | ----- |\n| CentOS Linux release 7.6.1810 (Core) | 2 vCPU | 2G | 172.16.143.171 |\n\n# 环境准备\n\n安装docker  \n\n```\n[kube@kube ~]$ yum update\n[kube@kube ~]$ yum install docker -y\n[kube@kube ~]$ systemctl start docker\n[kube@kube ~]$ systemctl enable docker\n\n[kube@kube ~]$ docker --version\nDocker version 1.13.1, build 07f3374/1.13.1\n\n```\n\n\n关闭Swap\n\n```\nswapoff -a\n\n```\n\n# 安装k8s\n\n配置kubernetes阿里云源  \n\n```\ncat <<EOF > /etc/yum.repos.d/kubernetes.repo\n[kubernetes]\nname=Kubernetes\nbaseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64\nenabled=1\ngpgcheck=1\nrepo_gpgcheck=1\ngpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg\nexclude=kube*\nEOF\n\n```\n\n关闭selinux  \n\n```\nsetenforce 0\nsed -i 's/^SELINUX=enforcing$/SELINUX=permissive/' /etc/selinux/config\n```\n安装kubeadm, kubelet和kubectl\n\n```\nyum install -y kubelet kubeadm kubectl --disableexcludes=kubernetes\n\nsystemctl enable kubelet && systemctl start kubelet\n```\n\n在centos系统上设置iptables  \n\n```\ncat <<EOF >  /etc/sysctl.d/k8s.conf\nnet.bridge.bridge-nf-call-ip6tables = 1\nnet.bridge.bridge-nf-call-iptables = 1\nEOF\n\nsysctl --system\n```\n\nkubeadm默认会从k8s.gcr.io上下载kube的images，但是在国内环境是访问不了这些镜像的，所以可以从aliyun的registry上下载相应的image，然后修改tag，瞒过kubeadm。  \n\n先通过下面的命令查看当前需要哪些image\n\n```\n[root@kube ~]# kubeadm config images list\nI1208 16:30:01.471171   30018 version.go:94] could not fetch a Kubernetes version from the internet: unable to get URL \"https://dl.k8s.io/release/stable-1.txt\": Get https://storage.googleapis.com/kubernetes-release/release/stable-1.txt: net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)\nI1208 16:30:01.471304   30018 version.go:95] falling back to the local client version: v1.13.0\nk8s.gcr.io/kube-apiserver:v1.13.0\nk8s.gcr.io/kube-controller-manager:v1.13.0\nk8s.gcr.io/kube-scheduler:v1.13.0\nk8s.gcr.io/kube-proxy:v1.13.0\nk8s.gcr.io/pause:3.1\nk8s.gcr.io/etcd:3.2.24\nk8s.gcr.io/coredns:1.2.6\n\n```\n通过下面的方式可以从阿里云的registry上下载镜像并修改tag\n\n```\nimages=(\n    kube-apiserver:v1.13.0\n    kube-controller-manager:v1.13.0\n    kube-scheduler:v1.13.0\n    kube-proxy:v1.13.0\n    pause:3.1\n    etcd:3.2.24\n    coredns:1.2.6\n)\n\nfor imageName in ${images[@]} ; do\n    docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/$imageName\n    docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/$imageName k8s.gcr.io/$imageName\ndone\n```\n\n初始化集群\n\n```\n[root@kube ~]# kubeadm init\nI1208 16:38:21.289892   31021 version.go:94] could not fetch a Kubernetes version from the internet: unable to get URL \"https://dl.k8s.io/release/stable-1.txt\": Get https://storage.googleapis.com/kubernetes-release/release/stable-1.txt: net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)\nI1208 16:38:21.289971   31021 version.go:95] falling back to the local client version: v1.13.0\n[init] Using Kubernetes version: v1.13.0\n[preflight] Running pre-flight checks\n[preflight] Pulling images required for setting up a Kubernetes cluster\n[preflight] This might take a minute or two, depending on the speed of your internet connection\n[preflight] You can also perform this action in beforehand using 'kubeadm config images pull'\n[kubelet-start] Writing kubelet environment file with flags to file \"/var/lib/kubelet/kubeadm-flags.env\"\n[kubelet-start] Writing kubelet configuration to file \"/var/lib/kubelet/config.yaml\"\n[kubelet-start] Activating the kubelet service\n[certs] Using certificateDir folder \"/etc/kubernetes/pki\"\n[certs] Generating \"front-proxy-ca\" certificate and key\n[certs] Generating \"front-proxy-client\" certificate and key\n[certs] Generating \"etcd/ca\" certificate and key\n[certs] Generating \"etcd/peer\" certificate and key\n[certs] etcd/peer serving cert is signed for DNS names [kube localhost] and IPs [172.16.143.171 127.0.0.1 ::1]\n[certs] Generating \"apiserver-etcd-client\" certificate and key\n[certs] Generating \"etcd/healthcheck-client\" certificate and key\n[certs] Generating \"etcd/server\" certificate and key\n[certs] etcd/server serving cert is signed for DNS names [kube localhost] and IPs [172.16.143.171 127.0.0.1 ::1]\n[certs] Generating \"ca\" certificate and key\n[certs] Generating \"apiserver\" certificate and key\n[certs] apiserver serving cert is signed for DNS names [kube kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 172.16.143.171]\n[certs] Generating \"apiserver-kubelet-client\" certificate and key\n[certs] Generating \"sa\" key and public key\n[kubeconfig] Using kubeconfig folder \"/etc/kubernetes\"\n[kubeconfig] Writing \"admin.conf\" kubeconfig file\n[kubeconfig] Writing \"kubelet.conf\" kubeconfig file\n[kubeconfig] Writing \"controller-manager.conf\" kubeconfig file\n[kubeconfig] Writing \"scheduler.conf\" kubeconfig file\n[control-plane] Using manifest folder \"/etc/kubernetes/manifests\"\n[control-plane] Creating static Pod manifest for \"kube-apiserver\"\n[control-plane] Creating static Pod manifest for \"kube-controller-manager\"\n[control-plane] Creating static Pod manifest for \"kube-scheduler\"\n[etcd] Creating static Pod manifest for local etcd in \"/etc/kubernetes/manifests\"\n[wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory \"/etc/kubernetes/manifests\". This can take up to 4m0s\n[apiclient] All control plane components are healthy after 24.003474 seconds\n[uploadconfig] storing the configuration used in ConfigMap \"kubeadm-config\" in the \"kube-system\" Namespace\n[kubelet] Creating a ConfigMap \"kubelet-config-1.13\" in namespace kube-system with the configuration for the kubelets in the cluster\n[patchnode] Uploading the CRI Socket information \"/var/run/dockershim.sock\" to the Node API object \"kube\" as an annotation\n[mark-control-plane] Marking the node kube as control-plane by adding the label \"node-role.kubernetes.io/master=''\"\n[mark-control-plane] Marking the node kube as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule]\n[bootstrap-token] Using token: 7ywghw.pbq0fkwpz3c5jozk\n[bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles\n[bootstraptoken] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials\n[bootstraptoken] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token\n[bootstraptoken] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster\n[bootstraptoken] creating the \"cluster-info\" ConfigMap in the \"kube-public\" namespace\n[addons] Applied essential addon: CoreDNS\n[addons] Applied essential addon: kube-proxy\n\nYour Kubernetes master has initialized successfully!\n\nTo start using your cluster, you need to run the following as a regular user:\n\n  mkdir -p $HOME/.kube\n  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\n  sudo chown $(id -u):$(id -g) $HOME/.kube/config\n\nYou should now deploy a pod network to the cluster.\nRun \"kubectl apply -f [podnetwork].yaml\" with one of the options listed at:\n  https://kubernetes.io/docs/concepts/cluster-administration/addons/\n\nYou can now join any number of machines by running the following on each node\nas root:\n\n  kubeadm join 172.16.143.171:6443 --token 7ywghw.pbq0fkwpz3c5jozk --discovery-token-ca-cert-hash sha256:b30445a8098e1e025ce703e7c1bae82567e0f892039489630d39608e77a41b89\n```\n\n从上面的结果可以看出k8s master已经初始化成功，k8s推进使用非root用户使用集群，所以下面我们创建一个kube的用户，并配置sudo权限。\n\n```\nuseradd kube\npasswd kube\n```\n\n通过visudo给kube用户配置sudo权限  \n```\nkube    ALL=(ALL)       ALL\n```\n\n下面的步骤把k8s的配置拷贝到用户的.kube目录下\n\n```\nmkdir -p $HOME/.kube\nsudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\nsudo chown $(id -u):$(id -g) $HOME/.kube/config\n```\n\n要使用k8s集群，还需要安装网络插件，k8s支持很多网络插件，比如calico，flannel，weave等，下面我们就安装weave网络插件。\n\n配置Weave Net  \n```\nkubectl apply -f \"https://cloud.weave.works/k8s/net?k8s-version=$(kubectl version | base64 | tr -d '\\n')\"\n```\n\n默认情况下，master node是不会运行容器的，由于本次实验只有一个节点，所以需要设置master node运行容器。\n\n允许Master Node 运行容器  \n```\n[kube@kube ~]$ kubectl taint nodes --all node-role.kubernetes.io/master-\nnode/kube untainted\n```\n\n这样一个简单的k8s集群就算搭建完成了，通过下面的命令可以看到当前集群中的节点，当前集群中运行的pod。\n\n```\n[kube@kube ~]$ kubectl get node\nNAME   STATUS   ROLES    AGE   VERSION\nkube   Ready    master   41m   v1.13.0\n[kube@kube ~]$ kubectl get pods --all-namespaces\nNAMESPACE     NAME                           READY   STATUS    RESTARTS   AGE\nkube-system   coredns-86c58d9df4-89xn5       1/1     Running   0          41m\nkube-system   coredns-86c58d9df4-mb96l       1/1     Running   0          41m\nkube-system   etcd-kube                      1/1     Running   2          40m\nkube-system   kube-apiserver-kube            1/1     Running   2          40m\nkube-system   kube-controller-manager-kube   1/1     Running   1          40m\nkube-system   kube-proxy-tgk25               1/1     Running   0          41m\nkube-system   kube-scheduler-kube            1/1     Running   1          40m\nkube-system   weave-net-csgmh                2/2     Running   0          27m\n```\n\n# 参考\n- [https://kubernetes.io/docs/setup/independent/install-kubeadm/](https://kubernetes.io/docs/setup/independent/install-kubeadm/)\n- [https://zhuanlan.zhihu.com/p/46341911](https://zhuanlan.zhihu.com/p/46341911) ","source":"_posts/install-k8s.md","raw":"---\ntitle: 通过kubeadm搭建单节点k8s环境\ndate: 2018-12-08 15:15:00\ntags: k8s\n---\n\n\n本次实验，通过kubeadm来安装一个单节点的k8s环境。\n\n本次实验是在虚拟机上进行，虚拟机的配置如下：\n\n| OS | CPU | 内存 | IP |\n| ----- | ----- | ----- | ----- |\n| CentOS Linux release 7.6.1810 (Core) | 2 vCPU | 2G | 172.16.143.171 |\n\n# 环境准备\n\n安装docker  \n\n```\n[kube@kube ~]$ yum update\n[kube@kube ~]$ yum install docker -y\n[kube@kube ~]$ systemctl start docker\n[kube@kube ~]$ systemctl enable docker\n\n[kube@kube ~]$ docker --version\nDocker version 1.13.1, build 07f3374/1.13.1\n\n```\n\n\n关闭Swap\n\n```\nswapoff -a\n\n```\n\n# 安装k8s\n\n配置kubernetes阿里云源  \n\n```\ncat <<EOF > /etc/yum.repos.d/kubernetes.repo\n[kubernetes]\nname=Kubernetes\nbaseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64\nenabled=1\ngpgcheck=1\nrepo_gpgcheck=1\ngpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg\nexclude=kube*\nEOF\n\n```\n\n关闭selinux  \n\n```\nsetenforce 0\nsed -i 's/^SELINUX=enforcing$/SELINUX=permissive/' /etc/selinux/config\n```\n安装kubeadm, kubelet和kubectl\n\n```\nyum install -y kubelet kubeadm kubectl --disableexcludes=kubernetes\n\nsystemctl enable kubelet && systemctl start kubelet\n```\n\n在centos系统上设置iptables  \n\n```\ncat <<EOF >  /etc/sysctl.d/k8s.conf\nnet.bridge.bridge-nf-call-ip6tables = 1\nnet.bridge.bridge-nf-call-iptables = 1\nEOF\n\nsysctl --system\n```\n\nkubeadm默认会从k8s.gcr.io上下载kube的images，但是在国内环境是访问不了这些镜像的，所以可以从aliyun的registry上下载相应的image，然后修改tag，瞒过kubeadm。  \n\n先通过下面的命令查看当前需要哪些image\n\n```\n[root@kube ~]# kubeadm config images list\nI1208 16:30:01.471171   30018 version.go:94] could not fetch a Kubernetes version from the internet: unable to get URL \"https://dl.k8s.io/release/stable-1.txt\": Get https://storage.googleapis.com/kubernetes-release/release/stable-1.txt: net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)\nI1208 16:30:01.471304   30018 version.go:95] falling back to the local client version: v1.13.0\nk8s.gcr.io/kube-apiserver:v1.13.0\nk8s.gcr.io/kube-controller-manager:v1.13.0\nk8s.gcr.io/kube-scheduler:v1.13.0\nk8s.gcr.io/kube-proxy:v1.13.0\nk8s.gcr.io/pause:3.1\nk8s.gcr.io/etcd:3.2.24\nk8s.gcr.io/coredns:1.2.6\n\n```\n通过下面的方式可以从阿里云的registry上下载镜像并修改tag\n\n```\nimages=(\n    kube-apiserver:v1.13.0\n    kube-controller-manager:v1.13.0\n    kube-scheduler:v1.13.0\n    kube-proxy:v1.13.0\n    pause:3.1\n    etcd:3.2.24\n    coredns:1.2.6\n)\n\nfor imageName in ${images[@]} ; do\n    docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/$imageName\n    docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/$imageName k8s.gcr.io/$imageName\ndone\n```\n\n初始化集群\n\n```\n[root@kube ~]# kubeadm init\nI1208 16:38:21.289892   31021 version.go:94] could not fetch a Kubernetes version from the internet: unable to get URL \"https://dl.k8s.io/release/stable-1.txt\": Get https://storage.googleapis.com/kubernetes-release/release/stable-1.txt: net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)\nI1208 16:38:21.289971   31021 version.go:95] falling back to the local client version: v1.13.0\n[init] Using Kubernetes version: v1.13.0\n[preflight] Running pre-flight checks\n[preflight] Pulling images required for setting up a Kubernetes cluster\n[preflight] This might take a minute or two, depending on the speed of your internet connection\n[preflight] You can also perform this action in beforehand using 'kubeadm config images pull'\n[kubelet-start] Writing kubelet environment file with flags to file \"/var/lib/kubelet/kubeadm-flags.env\"\n[kubelet-start] Writing kubelet configuration to file \"/var/lib/kubelet/config.yaml\"\n[kubelet-start] Activating the kubelet service\n[certs] Using certificateDir folder \"/etc/kubernetes/pki\"\n[certs] Generating \"front-proxy-ca\" certificate and key\n[certs] Generating \"front-proxy-client\" certificate and key\n[certs] Generating \"etcd/ca\" certificate and key\n[certs] Generating \"etcd/peer\" certificate and key\n[certs] etcd/peer serving cert is signed for DNS names [kube localhost] and IPs [172.16.143.171 127.0.0.1 ::1]\n[certs] Generating \"apiserver-etcd-client\" certificate and key\n[certs] Generating \"etcd/healthcheck-client\" certificate and key\n[certs] Generating \"etcd/server\" certificate and key\n[certs] etcd/server serving cert is signed for DNS names [kube localhost] and IPs [172.16.143.171 127.0.0.1 ::1]\n[certs] Generating \"ca\" certificate and key\n[certs] Generating \"apiserver\" certificate and key\n[certs] apiserver serving cert is signed for DNS names [kube kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 172.16.143.171]\n[certs] Generating \"apiserver-kubelet-client\" certificate and key\n[certs] Generating \"sa\" key and public key\n[kubeconfig] Using kubeconfig folder \"/etc/kubernetes\"\n[kubeconfig] Writing \"admin.conf\" kubeconfig file\n[kubeconfig] Writing \"kubelet.conf\" kubeconfig file\n[kubeconfig] Writing \"controller-manager.conf\" kubeconfig file\n[kubeconfig] Writing \"scheduler.conf\" kubeconfig file\n[control-plane] Using manifest folder \"/etc/kubernetes/manifests\"\n[control-plane] Creating static Pod manifest for \"kube-apiserver\"\n[control-plane] Creating static Pod manifest for \"kube-controller-manager\"\n[control-plane] Creating static Pod manifest for \"kube-scheduler\"\n[etcd] Creating static Pod manifest for local etcd in \"/etc/kubernetes/manifests\"\n[wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory \"/etc/kubernetes/manifests\". This can take up to 4m0s\n[apiclient] All control plane components are healthy after 24.003474 seconds\n[uploadconfig] storing the configuration used in ConfigMap \"kubeadm-config\" in the \"kube-system\" Namespace\n[kubelet] Creating a ConfigMap \"kubelet-config-1.13\" in namespace kube-system with the configuration for the kubelets in the cluster\n[patchnode] Uploading the CRI Socket information \"/var/run/dockershim.sock\" to the Node API object \"kube\" as an annotation\n[mark-control-plane] Marking the node kube as control-plane by adding the label \"node-role.kubernetes.io/master=''\"\n[mark-control-plane] Marking the node kube as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule]\n[bootstrap-token] Using token: 7ywghw.pbq0fkwpz3c5jozk\n[bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles\n[bootstraptoken] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials\n[bootstraptoken] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token\n[bootstraptoken] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster\n[bootstraptoken] creating the \"cluster-info\" ConfigMap in the \"kube-public\" namespace\n[addons] Applied essential addon: CoreDNS\n[addons] Applied essential addon: kube-proxy\n\nYour Kubernetes master has initialized successfully!\n\nTo start using your cluster, you need to run the following as a regular user:\n\n  mkdir -p $HOME/.kube\n  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\n  sudo chown $(id -u):$(id -g) $HOME/.kube/config\n\nYou should now deploy a pod network to the cluster.\nRun \"kubectl apply -f [podnetwork].yaml\" with one of the options listed at:\n  https://kubernetes.io/docs/concepts/cluster-administration/addons/\n\nYou can now join any number of machines by running the following on each node\nas root:\n\n  kubeadm join 172.16.143.171:6443 --token 7ywghw.pbq0fkwpz3c5jozk --discovery-token-ca-cert-hash sha256:b30445a8098e1e025ce703e7c1bae82567e0f892039489630d39608e77a41b89\n```\n\n从上面的结果可以看出k8s master已经初始化成功，k8s推进使用非root用户使用集群，所以下面我们创建一个kube的用户，并配置sudo权限。\n\n```\nuseradd kube\npasswd kube\n```\n\n通过visudo给kube用户配置sudo权限  \n```\nkube    ALL=(ALL)       ALL\n```\n\n下面的步骤把k8s的配置拷贝到用户的.kube目录下\n\n```\nmkdir -p $HOME/.kube\nsudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\nsudo chown $(id -u):$(id -g) $HOME/.kube/config\n```\n\n要使用k8s集群，还需要安装网络插件，k8s支持很多网络插件，比如calico，flannel，weave等，下面我们就安装weave网络插件。\n\n配置Weave Net  \n```\nkubectl apply -f \"https://cloud.weave.works/k8s/net?k8s-version=$(kubectl version | base64 | tr -d '\\n')\"\n```\n\n默认情况下，master node是不会运行容器的，由于本次实验只有一个节点，所以需要设置master node运行容器。\n\n允许Master Node 运行容器  \n```\n[kube@kube ~]$ kubectl taint nodes --all node-role.kubernetes.io/master-\nnode/kube untainted\n```\n\n这样一个简单的k8s集群就算搭建完成了，通过下面的命令可以看到当前集群中的节点，当前集群中运行的pod。\n\n```\n[kube@kube ~]$ kubectl get node\nNAME   STATUS   ROLES    AGE   VERSION\nkube   Ready    master   41m   v1.13.0\n[kube@kube ~]$ kubectl get pods --all-namespaces\nNAMESPACE     NAME                           READY   STATUS    RESTARTS   AGE\nkube-system   coredns-86c58d9df4-89xn5       1/1     Running   0          41m\nkube-system   coredns-86c58d9df4-mb96l       1/1     Running   0          41m\nkube-system   etcd-kube                      1/1     Running   2          40m\nkube-system   kube-apiserver-kube            1/1     Running   2          40m\nkube-system   kube-controller-manager-kube   1/1     Running   1          40m\nkube-system   kube-proxy-tgk25               1/1     Running   0          41m\nkube-system   kube-scheduler-kube            1/1     Running   1          40m\nkube-system   weave-net-csgmh                2/2     Running   0          27m\n```\n\n# 参考\n- [https://kubernetes.io/docs/setup/independent/install-kubeadm/](https://kubernetes.io/docs/setup/independent/install-kubeadm/)\n- [https://zhuanlan.zhihu.com/p/46341911](https://zhuanlan.zhihu.com/p/46341911) ","slug":"install-k8s","published":1,"updated":"2018-12-08T12:17:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck1pzbtgr0009tp75od5c3fhr","content":"<p>本次实验，通过kubeadm来安装一个单节点的k8s环境。</p>\n<p>本次实验是在虚拟机上进行，虚拟机的配置如下：</p>\n<table>\n<thead>\n<tr>\n<th>OS</th>\n<th>CPU</th>\n<th>内存</th>\n<th>IP</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>CentOS Linux release 7.6.1810 (Core)</td>\n<td>2 vCPU</td>\n<td>2G</td>\n<td>172.16.143.171</td>\n</tr>\n</tbody>\n</table>\n<h1 id=\"环境准备\"><a href=\"#环境准备\" class=\"headerlink\" title=\"环境准备\"></a>环境准备</h1><p>安装docker  </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[kube@kube ~]$ yum update</span><br><span class=\"line\">[kube@kube ~]$ yum install docker -y</span><br><span class=\"line\">[kube@kube ~]$ systemctl start docker</span><br><span class=\"line\">[kube@kube ~]$ systemctl enable docker</span><br><span class=\"line\"></span><br><span class=\"line\">[kube@kube ~]$ docker --version</span><br><span class=\"line\">Docker version 1.13.1, build 07f3374/1.13.1</span><br></pre></td></tr></table></figure>\n<p>关闭Swap</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">swapoff -a</span><br></pre></td></tr></table></figure>\n<h1 id=\"安装k8s\"><a href=\"#安装k8s\" class=\"headerlink\" title=\"安装k8s\"></a>安装k8s</h1><p>配置kubernetes阿里云源  </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo</span><br><span class=\"line\">[kubernetes]</span><br><span class=\"line\">name=Kubernetes</span><br><span class=\"line\">baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64</span><br><span class=\"line\">enabled=1</span><br><span class=\"line\">gpgcheck=1</span><br><span class=\"line\">repo_gpgcheck=1</span><br><span class=\"line\">gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg</span><br><span class=\"line\">exclude=kube*</span><br><span class=\"line\">EOF</span><br></pre></td></tr></table></figure>\n<p>关闭selinux  </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">setenforce 0</span><br><span class=\"line\">sed -i &apos;s/^SELINUX=enforcing$/SELINUX=permissive/&apos; /etc/selinux/config</span><br></pre></td></tr></table></figure>\n<p>安装kubeadm, kubelet和kubectl</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">yum install -y kubelet kubeadm kubectl --disableexcludes=kubernetes</span><br><span class=\"line\"></span><br><span class=\"line\">systemctl enable kubelet &amp;&amp; systemctl start kubelet</span><br></pre></td></tr></table></figure>\n<p>在centos系统上设置iptables  </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cat &lt;&lt;EOF &gt;  /etc/sysctl.d/k8s.conf</span><br><span class=\"line\">net.bridge.bridge-nf-call-ip6tables = 1</span><br><span class=\"line\">net.bridge.bridge-nf-call-iptables = 1</span><br><span class=\"line\">EOF</span><br><span class=\"line\"></span><br><span class=\"line\">sysctl --system</span><br></pre></td></tr></table></figure>\n<p>kubeadm默认会从k8s.gcr.io上下载kube的images，但是在国内环境是访问不了这些镜像的，所以可以从aliyun的registry上下载相应的image，然后修改tag，瞒过kubeadm。  </p>\n<p>先通过下面的命令查看当前需要哪些image</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@kube ~]# kubeadm config images list</span><br><span class=\"line\">I1208 16:30:01.471171   30018 version.go:94] could not fetch a Kubernetes version from the internet: unable to get URL &quot;https://dl.k8s.io/release/stable-1.txt&quot;: Get https://storage.googleapis.com/kubernetes-release/release/stable-1.txt: net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)</span><br><span class=\"line\">I1208 16:30:01.471304   30018 version.go:95] falling back to the local client version: v1.13.0</span><br><span class=\"line\">k8s.gcr.io/kube-apiserver:v1.13.0</span><br><span class=\"line\">k8s.gcr.io/kube-controller-manager:v1.13.0</span><br><span class=\"line\">k8s.gcr.io/kube-scheduler:v1.13.0</span><br><span class=\"line\">k8s.gcr.io/kube-proxy:v1.13.0</span><br><span class=\"line\">k8s.gcr.io/pause:3.1</span><br><span class=\"line\">k8s.gcr.io/etcd:3.2.24</span><br><span class=\"line\">k8s.gcr.io/coredns:1.2.6</span><br></pre></td></tr></table></figure>\n<p>通过下面的方式可以从阿里云的registry上下载镜像并修改tag</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">images=(</span><br><span class=\"line\">    kube-apiserver:v1.13.0</span><br><span class=\"line\">    kube-controller-manager:v1.13.0</span><br><span class=\"line\">    kube-scheduler:v1.13.0</span><br><span class=\"line\">    kube-proxy:v1.13.0</span><br><span class=\"line\">    pause:3.1</span><br><span class=\"line\">    etcd:3.2.24</span><br><span class=\"line\">    coredns:1.2.6</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\">for imageName in $&#123;images[@]&#125; ; do</span><br><span class=\"line\">    docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/$imageName</span><br><span class=\"line\">    docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/$imageName k8s.gcr.io/$imageName</span><br><span class=\"line\">done</span><br></pre></td></tr></table></figure>\n<p>初始化集群</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@kube ~]# kubeadm init</span><br><span class=\"line\">I1208 16:38:21.289892   31021 version.go:94] could not fetch a Kubernetes version from the internet: unable to get URL &quot;https://dl.k8s.io/release/stable-1.txt&quot;: Get https://storage.googleapis.com/kubernetes-release/release/stable-1.txt: net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)</span><br><span class=\"line\">I1208 16:38:21.289971   31021 version.go:95] falling back to the local client version: v1.13.0</span><br><span class=\"line\">[init] Using Kubernetes version: v1.13.0</span><br><span class=\"line\">[preflight] Running pre-flight checks</span><br><span class=\"line\">[preflight] Pulling images required for setting up a Kubernetes cluster</span><br><span class=\"line\">[preflight] This might take a minute or two, depending on the speed of your internet connection</span><br><span class=\"line\">[preflight] You can also perform this action in beforehand using &apos;kubeadm config images pull&apos;</span><br><span class=\"line\">[kubelet-start] Writing kubelet environment file with flags to file &quot;/var/lib/kubelet/kubeadm-flags.env&quot;</span><br><span class=\"line\">[kubelet-start] Writing kubelet configuration to file &quot;/var/lib/kubelet/config.yaml&quot;</span><br><span class=\"line\">[kubelet-start] Activating the kubelet service</span><br><span class=\"line\">[certs] Using certificateDir folder &quot;/etc/kubernetes/pki&quot;</span><br><span class=\"line\">[certs] Generating &quot;front-proxy-ca&quot; certificate and key</span><br><span class=\"line\">[certs] Generating &quot;front-proxy-client&quot; certificate and key</span><br><span class=\"line\">[certs] Generating &quot;etcd/ca&quot; certificate and key</span><br><span class=\"line\">[certs] Generating &quot;etcd/peer&quot; certificate and key</span><br><span class=\"line\">[certs] etcd/peer serving cert is signed for DNS names [kube localhost] and IPs [172.16.143.171 127.0.0.1 ::1]</span><br><span class=\"line\">[certs] Generating &quot;apiserver-etcd-client&quot; certificate and key</span><br><span class=\"line\">[certs] Generating &quot;etcd/healthcheck-client&quot; certificate and key</span><br><span class=\"line\">[certs] Generating &quot;etcd/server&quot; certificate and key</span><br><span class=\"line\">[certs] etcd/server serving cert is signed for DNS names [kube localhost] and IPs [172.16.143.171 127.0.0.1 ::1]</span><br><span class=\"line\">[certs] Generating &quot;ca&quot; certificate and key</span><br><span class=\"line\">[certs] Generating &quot;apiserver&quot; certificate and key</span><br><span class=\"line\">[certs] apiserver serving cert is signed for DNS names [kube kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 172.16.143.171]</span><br><span class=\"line\">[certs] Generating &quot;apiserver-kubelet-client&quot; certificate and key</span><br><span class=\"line\">[certs] Generating &quot;sa&quot; key and public key</span><br><span class=\"line\">[kubeconfig] Using kubeconfig folder &quot;/etc/kubernetes&quot;</span><br><span class=\"line\">[kubeconfig] Writing &quot;admin.conf&quot; kubeconfig file</span><br><span class=\"line\">[kubeconfig] Writing &quot;kubelet.conf&quot; kubeconfig file</span><br><span class=\"line\">[kubeconfig] Writing &quot;controller-manager.conf&quot; kubeconfig file</span><br><span class=\"line\">[kubeconfig] Writing &quot;scheduler.conf&quot; kubeconfig file</span><br><span class=\"line\">[control-plane] Using manifest folder &quot;/etc/kubernetes/manifests&quot;</span><br><span class=\"line\">[control-plane] Creating static Pod manifest for &quot;kube-apiserver&quot;</span><br><span class=\"line\">[control-plane] Creating static Pod manifest for &quot;kube-controller-manager&quot;</span><br><span class=\"line\">[control-plane] Creating static Pod manifest for &quot;kube-scheduler&quot;</span><br><span class=\"line\">[etcd] Creating static Pod manifest for local etcd in &quot;/etc/kubernetes/manifests&quot;</span><br><span class=\"line\">[wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory &quot;/etc/kubernetes/manifests&quot;. This can take up to 4m0s</span><br><span class=\"line\">[apiclient] All control plane components are healthy after 24.003474 seconds</span><br><span class=\"line\">[uploadconfig] storing the configuration used in ConfigMap &quot;kubeadm-config&quot; in the &quot;kube-system&quot; Namespace</span><br><span class=\"line\">[kubelet] Creating a ConfigMap &quot;kubelet-config-1.13&quot; in namespace kube-system with the configuration for the kubelets in the cluster</span><br><span class=\"line\">[patchnode] Uploading the CRI Socket information &quot;/var/run/dockershim.sock&quot; to the Node API object &quot;kube&quot; as an annotation</span><br><span class=\"line\">[mark-control-plane] Marking the node kube as control-plane by adding the label &quot;node-role.kubernetes.io/master=&apos;&apos;&quot;</span><br><span class=\"line\">[mark-control-plane] Marking the node kube as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule]</span><br><span class=\"line\">[bootstrap-token] Using token: 7ywghw.pbq0fkwpz3c5jozk</span><br><span class=\"line\">[bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles</span><br><span class=\"line\">[bootstraptoken] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials</span><br><span class=\"line\">[bootstraptoken] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token</span><br><span class=\"line\">[bootstraptoken] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster</span><br><span class=\"line\">[bootstraptoken] creating the &quot;cluster-info&quot; ConfigMap in the &quot;kube-public&quot; namespace</span><br><span class=\"line\">[addons] Applied essential addon: CoreDNS</span><br><span class=\"line\">[addons] Applied essential addon: kube-proxy</span><br><span class=\"line\"></span><br><span class=\"line\">Your Kubernetes master has initialized successfully!</span><br><span class=\"line\"></span><br><span class=\"line\">To start using your cluster, you need to run the following as a regular user:</span><br><span class=\"line\"></span><br><span class=\"line\">  mkdir -p $HOME/.kube</span><br><span class=\"line\">  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span><br><span class=\"line\">  sudo chown $(id -u):$(id -g) $HOME/.kube/config</span><br><span class=\"line\"></span><br><span class=\"line\">You should now deploy a pod network to the cluster.</span><br><span class=\"line\">Run &quot;kubectl apply -f [podnetwork].yaml&quot; with one of the options listed at:</span><br><span class=\"line\">  https://kubernetes.io/docs/concepts/cluster-administration/addons/</span><br><span class=\"line\"></span><br><span class=\"line\">You can now join any number of machines by running the following on each node</span><br><span class=\"line\">as root:</span><br><span class=\"line\"></span><br><span class=\"line\">  kubeadm join 172.16.143.171:6443 --token 7ywghw.pbq0fkwpz3c5jozk --discovery-token-ca-cert-hash sha256:b30445a8098e1e025ce703e7c1bae82567e0f892039489630d39608e77a41b89</span><br></pre></td></tr></table></figure>\n<p>从上面的结果可以看出k8s master已经初始化成功，k8s推进使用非root用户使用集群，所以下面我们创建一个kube的用户，并配置sudo权限。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">useradd kube</span><br><span class=\"line\">passwd kube</span><br></pre></td></tr></table></figure>\n<p>通过visudo给kube用户配置sudo权限<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kube    ALL=(ALL)       ALL</span><br></pre></td></tr></table></figure></p>\n<p>下面的步骤把k8s的配置拷贝到用户的.kube目录下</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mkdir -p $HOME/.kube</span><br><span class=\"line\">sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span><br><span class=\"line\">sudo chown $(id -u):$(id -g) $HOME/.kube/config</span><br></pre></td></tr></table></figure>\n<p>要使用k8s集群，还需要安装网络插件，k8s支持很多网络插件，比如calico，flannel，weave等，下面我们就安装weave网络插件。</p>\n<p>配置Weave Net<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kubectl apply -f &quot;https://cloud.weave.works/k8s/net?k8s-version=$(kubectl version | base64 | tr -d &apos;\\n&apos;)&quot;</span><br></pre></td></tr></table></figure></p>\n<p>默认情况下，master node是不会运行容器的，由于本次实验只有一个节点，所以需要设置master node运行容器。</p>\n<p>允许Master Node 运行容器<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[kube@kube ~]$ kubectl taint nodes --all node-role.kubernetes.io/master-</span><br><span class=\"line\">node/kube untainted</span><br></pre></td></tr></table></figure></p>\n<p>这样一个简单的k8s集群就算搭建完成了，通过下面的命令可以看到当前集群中的节点，当前集群中运行的pod。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[kube@kube ~]$ kubectl get node</span><br><span class=\"line\">NAME   STATUS   ROLES    AGE   VERSION</span><br><span class=\"line\">kube   Ready    master   41m   v1.13.0</span><br><span class=\"line\">[kube@kube ~]$ kubectl get pods --all-namespaces</span><br><span class=\"line\">NAMESPACE     NAME                           READY   STATUS    RESTARTS   AGE</span><br><span class=\"line\">kube-system   coredns-86c58d9df4-89xn5       1/1     Running   0          41m</span><br><span class=\"line\">kube-system   coredns-86c58d9df4-mb96l       1/1     Running   0          41m</span><br><span class=\"line\">kube-system   etcd-kube                      1/1     Running   2          40m</span><br><span class=\"line\">kube-system   kube-apiserver-kube            1/1     Running   2          40m</span><br><span class=\"line\">kube-system   kube-controller-manager-kube   1/1     Running   1          40m</span><br><span class=\"line\">kube-system   kube-proxy-tgk25               1/1     Running   0          41m</span><br><span class=\"line\">kube-system   kube-scheduler-kube            1/1     Running   1          40m</span><br><span class=\"line\">kube-system   weave-net-csgmh                2/2     Running   0          27m</span><br></pre></td></tr></table></figure>\n<h1 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h1><ul>\n<li><a href=\"https://kubernetes.io/docs/setup/independent/install-kubeadm/\" target=\"_blank\" rel=\"noopener\">https://kubernetes.io/docs/setup/independent/install-kubeadm/</a></li>\n<li><a href=\"https://zhuanlan.zhihu.com/p/46341911\" target=\"_blank\" rel=\"noopener\">https://zhuanlan.zhihu.com/p/46341911</a> </li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<p>本次实验，通过kubeadm来安装一个单节点的k8s环境。</p>\n<p>本次实验是在虚拟机上进行，虚拟机的配置如下：</p>\n<table>\n<thead>\n<tr>\n<th>OS</th>\n<th>CPU</th>\n<th>内存</th>\n<th>IP</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>CentOS Linux release 7.6.1810 (Core)</td>\n<td>2 vCPU</td>\n<td>2G</td>\n<td>172.16.143.171</td>\n</tr>\n</tbody>\n</table>\n<h1 id=\"环境准备\"><a href=\"#环境准备\" class=\"headerlink\" title=\"环境准备\"></a>环境准备</h1><p>安装docker  </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[kube@kube ~]$ yum update</span><br><span class=\"line\">[kube@kube ~]$ yum install docker -y</span><br><span class=\"line\">[kube@kube ~]$ systemctl start docker</span><br><span class=\"line\">[kube@kube ~]$ systemctl enable docker</span><br><span class=\"line\"></span><br><span class=\"line\">[kube@kube ~]$ docker --version</span><br><span class=\"line\">Docker version 1.13.1, build 07f3374/1.13.1</span><br></pre></td></tr></table></figure>\n<p>关闭Swap</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">swapoff -a</span><br></pre></td></tr></table></figure>\n<h1 id=\"安装k8s\"><a href=\"#安装k8s\" class=\"headerlink\" title=\"安装k8s\"></a>安装k8s</h1><p>配置kubernetes阿里云源  </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo</span><br><span class=\"line\">[kubernetes]</span><br><span class=\"line\">name=Kubernetes</span><br><span class=\"line\">baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64</span><br><span class=\"line\">enabled=1</span><br><span class=\"line\">gpgcheck=1</span><br><span class=\"line\">repo_gpgcheck=1</span><br><span class=\"line\">gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg</span><br><span class=\"line\">exclude=kube*</span><br><span class=\"line\">EOF</span><br></pre></td></tr></table></figure>\n<p>关闭selinux  </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">setenforce 0</span><br><span class=\"line\">sed -i &apos;s/^SELINUX=enforcing$/SELINUX=permissive/&apos; /etc/selinux/config</span><br></pre></td></tr></table></figure>\n<p>安装kubeadm, kubelet和kubectl</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">yum install -y kubelet kubeadm kubectl --disableexcludes=kubernetes</span><br><span class=\"line\"></span><br><span class=\"line\">systemctl enable kubelet &amp;&amp; systemctl start kubelet</span><br></pre></td></tr></table></figure>\n<p>在centos系统上设置iptables  </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cat &lt;&lt;EOF &gt;  /etc/sysctl.d/k8s.conf</span><br><span class=\"line\">net.bridge.bridge-nf-call-ip6tables = 1</span><br><span class=\"line\">net.bridge.bridge-nf-call-iptables = 1</span><br><span class=\"line\">EOF</span><br><span class=\"line\"></span><br><span class=\"line\">sysctl --system</span><br></pre></td></tr></table></figure>\n<p>kubeadm默认会从k8s.gcr.io上下载kube的images，但是在国内环境是访问不了这些镜像的，所以可以从aliyun的registry上下载相应的image，然后修改tag，瞒过kubeadm。  </p>\n<p>先通过下面的命令查看当前需要哪些image</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@kube ~]# kubeadm config images list</span><br><span class=\"line\">I1208 16:30:01.471171   30018 version.go:94] could not fetch a Kubernetes version from the internet: unable to get URL &quot;https://dl.k8s.io/release/stable-1.txt&quot;: Get https://storage.googleapis.com/kubernetes-release/release/stable-1.txt: net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)</span><br><span class=\"line\">I1208 16:30:01.471304   30018 version.go:95] falling back to the local client version: v1.13.0</span><br><span class=\"line\">k8s.gcr.io/kube-apiserver:v1.13.0</span><br><span class=\"line\">k8s.gcr.io/kube-controller-manager:v1.13.0</span><br><span class=\"line\">k8s.gcr.io/kube-scheduler:v1.13.0</span><br><span class=\"line\">k8s.gcr.io/kube-proxy:v1.13.0</span><br><span class=\"line\">k8s.gcr.io/pause:3.1</span><br><span class=\"line\">k8s.gcr.io/etcd:3.2.24</span><br><span class=\"line\">k8s.gcr.io/coredns:1.2.6</span><br></pre></td></tr></table></figure>\n<p>通过下面的方式可以从阿里云的registry上下载镜像并修改tag</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">images=(</span><br><span class=\"line\">    kube-apiserver:v1.13.0</span><br><span class=\"line\">    kube-controller-manager:v1.13.0</span><br><span class=\"line\">    kube-scheduler:v1.13.0</span><br><span class=\"line\">    kube-proxy:v1.13.0</span><br><span class=\"line\">    pause:3.1</span><br><span class=\"line\">    etcd:3.2.24</span><br><span class=\"line\">    coredns:1.2.6</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\">for imageName in $&#123;images[@]&#125; ; do</span><br><span class=\"line\">    docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/$imageName</span><br><span class=\"line\">    docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/$imageName k8s.gcr.io/$imageName</span><br><span class=\"line\">done</span><br></pre></td></tr></table></figure>\n<p>初始化集群</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@kube ~]# kubeadm init</span><br><span class=\"line\">I1208 16:38:21.289892   31021 version.go:94] could not fetch a Kubernetes version from the internet: unable to get URL &quot;https://dl.k8s.io/release/stable-1.txt&quot;: Get https://storage.googleapis.com/kubernetes-release/release/stable-1.txt: net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)</span><br><span class=\"line\">I1208 16:38:21.289971   31021 version.go:95] falling back to the local client version: v1.13.0</span><br><span class=\"line\">[init] Using Kubernetes version: v1.13.0</span><br><span class=\"line\">[preflight] Running pre-flight checks</span><br><span class=\"line\">[preflight] Pulling images required for setting up a Kubernetes cluster</span><br><span class=\"line\">[preflight] This might take a minute or two, depending on the speed of your internet connection</span><br><span class=\"line\">[preflight] You can also perform this action in beforehand using &apos;kubeadm config images pull&apos;</span><br><span class=\"line\">[kubelet-start] Writing kubelet environment file with flags to file &quot;/var/lib/kubelet/kubeadm-flags.env&quot;</span><br><span class=\"line\">[kubelet-start] Writing kubelet configuration to file &quot;/var/lib/kubelet/config.yaml&quot;</span><br><span class=\"line\">[kubelet-start] Activating the kubelet service</span><br><span class=\"line\">[certs] Using certificateDir folder &quot;/etc/kubernetes/pki&quot;</span><br><span class=\"line\">[certs] Generating &quot;front-proxy-ca&quot; certificate and key</span><br><span class=\"line\">[certs] Generating &quot;front-proxy-client&quot; certificate and key</span><br><span class=\"line\">[certs] Generating &quot;etcd/ca&quot; certificate and key</span><br><span class=\"line\">[certs] Generating &quot;etcd/peer&quot; certificate and key</span><br><span class=\"line\">[certs] etcd/peer serving cert is signed for DNS names [kube localhost] and IPs [172.16.143.171 127.0.0.1 ::1]</span><br><span class=\"line\">[certs] Generating &quot;apiserver-etcd-client&quot; certificate and key</span><br><span class=\"line\">[certs] Generating &quot;etcd/healthcheck-client&quot; certificate and key</span><br><span class=\"line\">[certs] Generating &quot;etcd/server&quot; certificate and key</span><br><span class=\"line\">[certs] etcd/server serving cert is signed for DNS names [kube localhost] and IPs [172.16.143.171 127.0.0.1 ::1]</span><br><span class=\"line\">[certs] Generating &quot;ca&quot; certificate and key</span><br><span class=\"line\">[certs] Generating &quot;apiserver&quot; certificate and key</span><br><span class=\"line\">[certs] apiserver serving cert is signed for DNS names [kube kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 172.16.143.171]</span><br><span class=\"line\">[certs] Generating &quot;apiserver-kubelet-client&quot; certificate and key</span><br><span class=\"line\">[certs] Generating &quot;sa&quot; key and public key</span><br><span class=\"line\">[kubeconfig] Using kubeconfig folder &quot;/etc/kubernetes&quot;</span><br><span class=\"line\">[kubeconfig] Writing &quot;admin.conf&quot; kubeconfig file</span><br><span class=\"line\">[kubeconfig] Writing &quot;kubelet.conf&quot; kubeconfig file</span><br><span class=\"line\">[kubeconfig] Writing &quot;controller-manager.conf&quot; kubeconfig file</span><br><span class=\"line\">[kubeconfig] Writing &quot;scheduler.conf&quot; kubeconfig file</span><br><span class=\"line\">[control-plane] Using manifest folder &quot;/etc/kubernetes/manifests&quot;</span><br><span class=\"line\">[control-plane] Creating static Pod manifest for &quot;kube-apiserver&quot;</span><br><span class=\"line\">[control-plane] Creating static Pod manifest for &quot;kube-controller-manager&quot;</span><br><span class=\"line\">[control-plane] Creating static Pod manifest for &quot;kube-scheduler&quot;</span><br><span class=\"line\">[etcd] Creating static Pod manifest for local etcd in &quot;/etc/kubernetes/manifests&quot;</span><br><span class=\"line\">[wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory &quot;/etc/kubernetes/manifests&quot;. This can take up to 4m0s</span><br><span class=\"line\">[apiclient] All control plane components are healthy after 24.003474 seconds</span><br><span class=\"line\">[uploadconfig] storing the configuration used in ConfigMap &quot;kubeadm-config&quot; in the &quot;kube-system&quot; Namespace</span><br><span class=\"line\">[kubelet] Creating a ConfigMap &quot;kubelet-config-1.13&quot; in namespace kube-system with the configuration for the kubelets in the cluster</span><br><span class=\"line\">[patchnode] Uploading the CRI Socket information &quot;/var/run/dockershim.sock&quot; to the Node API object &quot;kube&quot; as an annotation</span><br><span class=\"line\">[mark-control-plane] Marking the node kube as control-plane by adding the label &quot;node-role.kubernetes.io/master=&apos;&apos;&quot;</span><br><span class=\"line\">[mark-control-plane] Marking the node kube as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule]</span><br><span class=\"line\">[bootstrap-token] Using token: 7ywghw.pbq0fkwpz3c5jozk</span><br><span class=\"line\">[bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles</span><br><span class=\"line\">[bootstraptoken] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials</span><br><span class=\"line\">[bootstraptoken] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token</span><br><span class=\"line\">[bootstraptoken] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster</span><br><span class=\"line\">[bootstraptoken] creating the &quot;cluster-info&quot; ConfigMap in the &quot;kube-public&quot; namespace</span><br><span class=\"line\">[addons] Applied essential addon: CoreDNS</span><br><span class=\"line\">[addons] Applied essential addon: kube-proxy</span><br><span class=\"line\"></span><br><span class=\"line\">Your Kubernetes master has initialized successfully!</span><br><span class=\"line\"></span><br><span class=\"line\">To start using your cluster, you need to run the following as a regular user:</span><br><span class=\"line\"></span><br><span class=\"line\">  mkdir -p $HOME/.kube</span><br><span class=\"line\">  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span><br><span class=\"line\">  sudo chown $(id -u):$(id -g) $HOME/.kube/config</span><br><span class=\"line\"></span><br><span class=\"line\">You should now deploy a pod network to the cluster.</span><br><span class=\"line\">Run &quot;kubectl apply -f [podnetwork].yaml&quot; with one of the options listed at:</span><br><span class=\"line\">  https://kubernetes.io/docs/concepts/cluster-administration/addons/</span><br><span class=\"line\"></span><br><span class=\"line\">You can now join any number of machines by running the following on each node</span><br><span class=\"line\">as root:</span><br><span class=\"line\"></span><br><span class=\"line\">  kubeadm join 172.16.143.171:6443 --token 7ywghw.pbq0fkwpz3c5jozk --discovery-token-ca-cert-hash sha256:b30445a8098e1e025ce703e7c1bae82567e0f892039489630d39608e77a41b89</span><br></pre></td></tr></table></figure>\n<p>从上面的结果可以看出k8s master已经初始化成功，k8s推进使用非root用户使用集群，所以下面我们创建一个kube的用户，并配置sudo权限。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">useradd kube</span><br><span class=\"line\">passwd kube</span><br></pre></td></tr></table></figure>\n<p>通过visudo给kube用户配置sudo权限<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kube    ALL=(ALL)       ALL</span><br></pre></td></tr></table></figure></p>\n<p>下面的步骤把k8s的配置拷贝到用户的.kube目录下</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mkdir -p $HOME/.kube</span><br><span class=\"line\">sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span><br><span class=\"line\">sudo chown $(id -u):$(id -g) $HOME/.kube/config</span><br></pre></td></tr></table></figure>\n<p>要使用k8s集群，还需要安装网络插件，k8s支持很多网络插件，比如calico，flannel，weave等，下面我们就安装weave网络插件。</p>\n<p>配置Weave Net<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kubectl apply -f &quot;https://cloud.weave.works/k8s/net?k8s-version=$(kubectl version | base64 | tr -d &apos;\\n&apos;)&quot;</span><br></pre></td></tr></table></figure></p>\n<p>默认情况下，master node是不会运行容器的，由于本次实验只有一个节点，所以需要设置master node运行容器。</p>\n<p>允许Master Node 运行容器<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[kube@kube ~]$ kubectl taint nodes --all node-role.kubernetes.io/master-</span><br><span class=\"line\">node/kube untainted</span><br></pre></td></tr></table></figure></p>\n<p>这样一个简单的k8s集群就算搭建完成了，通过下面的命令可以看到当前集群中的节点，当前集群中运行的pod。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[kube@kube ~]$ kubectl get node</span><br><span class=\"line\">NAME   STATUS   ROLES    AGE   VERSION</span><br><span class=\"line\">kube   Ready    master   41m   v1.13.0</span><br><span class=\"line\">[kube@kube ~]$ kubectl get pods --all-namespaces</span><br><span class=\"line\">NAMESPACE     NAME                           READY   STATUS    RESTARTS   AGE</span><br><span class=\"line\">kube-system   coredns-86c58d9df4-89xn5       1/1     Running   0          41m</span><br><span class=\"line\">kube-system   coredns-86c58d9df4-mb96l       1/1     Running   0          41m</span><br><span class=\"line\">kube-system   etcd-kube                      1/1     Running   2          40m</span><br><span class=\"line\">kube-system   kube-apiserver-kube            1/1     Running   2          40m</span><br><span class=\"line\">kube-system   kube-controller-manager-kube   1/1     Running   1          40m</span><br><span class=\"line\">kube-system   kube-proxy-tgk25               1/1     Running   0          41m</span><br><span class=\"line\">kube-system   kube-scheduler-kube            1/1     Running   1          40m</span><br><span class=\"line\">kube-system   weave-net-csgmh                2/2     Running   0          27m</span><br></pre></td></tr></table></figure>\n<h1 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h1><ul>\n<li><a href=\"https://kubernetes.io/docs/setup/independent/install-kubeadm/\" target=\"_blank\" rel=\"noopener\">https://kubernetes.io/docs/setup/independent/install-kubeadm/</a></li>\n<li><a href=\"https://zhuanlan.zhihu.com/p/46341911\" target=\"_blank\" rel=\"noopener\">https://zhuanlan.zhihu.com/p/46341911</a> </li>\n</ul>\n"},{"title":"logrotate","date":"2017-09-26T07:32:23.000Z","_content":"\n通过logroate，可以对日志文件进行切分，压缩，配置保留多少天等\n\n下面两篇文件对logrotate的配置介绍的很详细\n\n<https://support.rackspace.com/how-to/understanding-logrotate-utility/>\n\n<https://support.rackspace.com/how-to/sample-logrotate-configuration-and-troubleshooting/>\n","source":"_posts/logrotate.md","raw":"---\ntitle: logrotate\ndate: 2017-09-26 15:32:23\ntags:\n---\n\n通过logroate，可以对日志文件进行切分，压缩，配置保留多少天等\n\n下面两篇文件对logrotate的配置介绍的很详细\n\n<https://support.rackspace.com/how-to/understanding-logrotate-utility/>\n\n<https://support.rackspace.com/how-to/sample-logrotate-configuration-and-troubleshooting/>\n","slug":"logrotate","published":1,"updated":"2018-03-07T05:39:30.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck1pzbtgs000btp756u3tl7l2","content":"<p>通过logroate，可以对日志文件进行切分，压缩，配置保留多少天等</p>\n<p>下面两篇文件对logrotate的配置介绍的很详细</p>\n<p><a href=\"https://support.rackspace.com/how-to/understanding-logrotate-utility/\" target=\"_blank\" rel=\"noopener\">https://support.rackspace.com/how-to/understanding-logrotate-utility/</a></p>\n<p><a href=\"https://support.rackspace.com/how-to/sample-logrotate-configuration-and-troubleshooting/\" target=\"_blank\" rel=\"noopener\">https://support.rackspace.com/how-to/sample-logrotate-configuration-and-troubleshooting/</a></p>\n","site":{"data":{}},"excerpt":"","more":"<p>通过logroate，可以对日志文件进行切分，压缩，配置保留多少天等</p>\n<p>下面两篇文件对logrotate的配置介绍的很详细</p>\n<p><a href=\"https://support.rackspace.com/how-to/understanding-logrotate-utility/\" target=\"_blank\" rel=\"noopener\">https://support.rackspace.com/how-to/understanding-logrotate-utility/</a></p>\n<p><a href=\"https://support.rackspace.com/how-to/sample-logrotate-configuration-and-troubleshooting/\" target=\"_blank\" rel=\"noopener\">https://support.rackspace.com/how-to/sample-logrotate-configuration-and-troubleshooting/</a></p>\n"},{"title":"mysql主从复制","date":"2018-03-02T09:23:27.000Z","_content":"\n## 环境\nOS：Centos 7.3\n\nDB version： mysql  Ver 15.1 Distrib 5.5.56-MariaDB, for Linux (x86_64) using readline 5.1\n\nhost1(master): 172.16.143.171\n\nhost2(slave): 172.16.143.172\n\n## 安装\n\n两个节点都执行下面的步骤\n\n```bash\nyum install mariadb-server -y\n\nsystemctl start mariadb\n```\n执行db安全选项\n\n```bash\nmysql_secure_installation\nNOTE: RUNNING ALL PARTS OF THIS SCRIPT IS RECOMMENDED FOR ALL MariaDB\n      SERVERS IN PRODUCTION USE!  PLEASE READ EACH STEP CAREFULLY!\n\nIn order to log into MariaDB to secure it, we'll need the current\npassword for the root user.  If you've just installed MariaDB, and\nyou haven't set the root password yet, the password will be blank,\nso you should just press enter here.\n\nEnter current password for root (enter for none):\nOK, successfully used password, moving on...\n\nSetting the root password ensures that nobody can log into the MariaDB\nroot user without the proper authorisation.\n\nYou already have a root password set, so you can safely answer 'n'.\n\nChange the root password? [Y/n] Y\nNew password:\nRe-enter new password:\nPassword updated successfully!\nReloading privilege tables..\n ... Success!\n\n\nBy default, a MariaDB installation has an anonymous user, allowing anyone\nto log into MariaDB without having to have a user account created for\nthem.  This is intended only for testing, and to make the installation\ngo a bit smoother.  You should remove them before moving into a\nproduction environment.\n\nRemove anonymous users? [Y/n] Y\n ... Success!\n\nNormally, root should only be allowed to connect from 'localhost'.  This\nensures that someone cannot guess at the root password from the network.\n\nDisallow root login remotely? [Y/n] Y\n ... Success!\n\nBy default, MariaDB comes with a database named 'test' that anyone can\naccess.  This is also intended only for testing, and should be removed\nbefore moving into a production environment.\n\nRemove test database and access to it? [Y/n] Y\n - Dropping test database...\n ... Success!\n - Removing privileges on test database...\n ... Success!\n\nReloading the privilege tables will ensure that all changes made so far\nwill take effect immediately.\n\nReload privilege tables now? [Y/n] Y\n ... Success!\n\nCleaning up...\n\nAll done!  If you've completed all of the above steps, your MariaDB\ninstallation should now be secure.\n\nThanks for using MariaDB!\n\n```\n\n### master节点配置\n\n在/etc/my.cnf文件的[mysqld]中添加如下内容\n\n```vim\nserver-id=1\nlog-bin = /var/lib/mysql/mysql-bin\nbinlog-ignore-db=mysql\nbinlog-ignore-db=information_schema\nbinlog-ignore-db=performance_schema\n```\n\n重启db\n\n```bash\nsystemctl restart mariadb\n```\n\n```bash\nmysql -u root -p\n\nGRANT REPLICATION SLAVE ON *.* TO 'replic_user'@'%' IDENTIFIED BY 'password';\n\nFLUSH PRIVILEGES;\n\nSHOW MASTER STATUS;\n\nQUIT;\n```\n\n如果 master 中已经存在需要复制的数据，则需要dump出来，然后在slave上重放\n\n```bash\nmysql -u root -p\n\nmysql> FLUSH TABLES WITH READ LOCK;\n\nmysql> SHOW MASTER STATUS;\n\n```\n\n```bash\nmysqldump -u root -p --databases [database-1] [database-2] ...  > /root/db_dump.sql\n\nmysql -u root -p\nmysql> UNLOCK TABLES;\n\n```\n\n### slave节点配置\n\n如果master节点上dump了数据，则需要执行下面的步骤进行重放。\n\n```bash\nscp root@172.16.143.171:/root/db_dump.sql /root/db_dump.sql\nmysql -u root -p < /root/db_dump.sql\n```\n\n在/etc/my.cnf文件的[mysqld]中添加如下内容\n\n```vim\nserver-id=2\nog-bin = /var/lib/mysql/mysql-bin\nbinlog-ignore-db=mysql\nbinlog-ignore-db=information_schema\nbinlog-ignore-db=performance_schema\n```\n重启db\n\n```bash\nsystemctl restart mariadb\n```\n\n```bash\nmysql -u root -p\n\nmysql> CHANGE MASTER TO MASTER_HOST='172.16.143.171',MASTER_USER='replic_user', MASTER_PASSWORD='password', MASTER_LOG_FILE='mysql-bin.000001', MASTER_LOG_POS=107;\n```\n上面命令中<b>MASTER_LOG_FILE</b> 和 <b>MASTER_LOG_POS</b> 需要根据master节点中```show master status```命令结果调整。\n\n```bash\nSTART SLAVE;\n\nSHOW SLAVE STATUS\\G\n```\n\n## 测试\n在master节点中创建db，也可以在slave节点中看到。\n\n## 双向复制\n上面的配置实现了host1 --> host2 的复制关系，如需要实现双向复制，只需要按照上面的步骤再配置从 host2 --> host1 的复制关机即可。\n\n另外在host1的/ect/my.cnf中添加如下内容\n\n```bash\nauto-increment-increment = 2\nauto-increment-offset = 1\n```\n\n在host2的/ect/my.cnf中添加如下内容\n\n```bash\nauto-increment-increment = 2\nauto-increment-offset = 2\n```\n","source":"_posts/mysql-replication.md","raw":"---\ntitle: mysql主从复制\ndate: 2018-03-02 17:23:27\ntags: ['linux','mysql','ha']\n---\n\n## 环境\nOS：Centos 7.3\n\nDB version： mysql  Ver 15.1 Distrib 5.5.56-MariaDB, for Linux (x86_64) using readline 5.1\n\nhost1(master): 172.16.143.171\n\nhost2(slave): 172.16.143.172\n\n## 安装\n\n两个节点都执行下面的步骤\n\n```bash\nyum install mariadb-server -y\n\nsystemctl start mariadb\n```\n执行db安全选项\n\n```bash\nmysql_secure_installation\nNOTE: RUNNING ALL PARTS OF THIS SCRIPT IS RECOMMENDED FOR ALL MariaDB\n      SERVERS IN PRODUCTION USE!  PLEASE READ EACH STEP CAREFULLY!\n\nIn order to log into MariaDB to secure it, we'll need the current\npassword for the root user.  If you've just installed MariaDB, and\nyou haven't set the root password yet, the password will be blank,\nso you should just press enter here.\n\nEnter current password for root (enter for none):\nOK, successfully used password, moving on...\n\nSetting the root password ensures that nobody can log into the MariaDB\nroot user without the proper authorisation.\n\nYou already have a root password set, so you can safely answer 'n'.\n\nChange the root password? [Y/n] Y\nNew password:\nRe-enter new password:\nPassword updated successfully!\nReloading privilege tables..\n ... Success!\n\n\nBy default, a MariaDB installation has an anonymous user, allowing anyone\nto log into MariaDB without having to have a user account created for\nthem.  This is intended only for testing, and to make the installation\ngo a bit smoother.  You should remove them before moving into a\nproduction environment.\n\nRemove anonymous users? [Y/n] Y\n ... Success!\n\nNormally, root should only be allowed to connect from 'localhost'.  This\nensures that someone cannot guess at the root password from the network.\n\nDisallow root login remotely? [Y/n] Y\n ... Success!\n\nBy default, MariaDB comes with a database named 'test' that anyone can\naccess.  This is also intended only for testing, and should be removed\nbefore moving into a production environment.\n\nRemove test database and access to it? [Y/n] Y\n - Dropping test database...\n ... Success!\n - Removing privileges on test database...\n ... Success!\n\nReloading the privilege tables will ensure that all changes made so far\nwill take effect immediately.\n\nReload privilege tables now? [Y/n] Y\n ... Success!\n\nCleaning up...\n\nAll done!  If you've completed all of the above steps, your MariaDB\ninstallation should now be secure.\n\nThanks for using MariaDB!\n\n```\n\n### master节点配置\n\n在/etc/my.cnf文件的[mysqld]中添加如下内容\n\n```vim\nserver-id=1\nlog-bin = /var/lib/mysql/mysql-bin\nbinlog-ignore-db=mysql\nbinlog-ignore-db=information_schema\nbinlog-ignore-db=performance_schema\n```\n\n重启db\n\n```bash\nsystemctl restart mariadb\n```\n\n```bash\nmysql -u root -p\n\nGRANT REPLICATION SLAVE ON *.* TO 'replic_user'@'%' IDENTIFIED BY 'password';\n\nFLUSH PRIVILEGES;\n\nSHOW MASTER STATUS;\n\nQUIT;\n```\n\n如果 master 中已经存在需要复制的数据，则需要dump出来，然后在slave上重放\n\n```bash\nmysql -u root -p\n\nmysql> FLUSH TABLES WITH READ LOCK;\n\nmysql> SHOW MASTER STATUS;\n\n```\n\n```bash\nmysqldump -u root -p --databases [database-1] [database-2] ...  > /root/db_dump.sql\n\nmysql -u root -p\nmysql> UNLOCK TABLES;\n\n```\n\n### slave节点配置\n\n如果master节点上dump了数据，则需要执行下面的步骤进行重放。\n\n```bash\nscp root@172.16.143.171:/root/db_dump.sql /root/db_dump.sql\nmysql -u root -p < /root/db_dump.sql\n```\n\n在/etc/my.cnf文件的[mysqld]中添加如下内容\n\n```vim\nserver-id=2\nog-bin = /var/lib/mysql/mysql-bin\nbinlog-ignore-db=mysql\nbinlog-ignore-db=information_schema\nbinlog-ignore-db=performance_schema\n```\n重启db\n\n```bash\nsystemctl restart mariadb\n```\n\n```bash\nmysql -u root -p\n\nmysql> CHANGE MASTER TO MASTER_HOST='172.16.143.171',MASTER_USER='replic_user', MASTER_PASSWORD='password', MASTER_LOG_FILE='mysql-bin.000001', MASTER_LOG_POS=107;\n```\n上面命令中<b>MASTER_LOG_FILE</b> 和 <b>MASTER_LOG_POS</b> 需要根据master节点中```show master status```命令结果调整。\n\n```bash\nSTART SLAVE;\n\nSHOW SLAVE STATUS\\G\n```\n\n## 测试\n在master节点中创建db，也可以在slave节点中看到。\n\n## 双向复制\n上面的配置实现了host1 --> host2 的复制关系，如需要实现双向复制，只需要按照上面的步骤再配置从 host2 --> host1 的复制关机即可。\n\n另外在host1的/ect/my.cnf中添加如下内容\n\n```bash\nauto-increment-increment = 2\nauto-increment-offset = 1\n```\n\n在host2的/ect/my.cnf中添加如下内容\n\n```bash\nauto-increment-increment = 2\nauto-increment-offset = 2\n```\n","slug":"mysql-replication","published":1,"updated":"2018-09-26T03:47:52.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck1pzbtgu000etp75r4ztix7f","content":"<h2 id=\"环境\"><a href=\"#环境\" class=\"headerlink\" title=\"环境\"></a>环境</h2><p>OS：Centos 7.3</p>\n<p>DB version： mysql  Ver 15.1 Distrib 5.5.56-MariaDB, for Linux (x86_64) using readline 5.1</p>\n<p>host1(master): 172.16.143.171</p>\n<p>host2(slave): 172.16.143.172</p>\n<h2 id=\"安装\"><a href=\"#安装\" class=\"headerlink\" title=\"安装\"></a>安装</h2><p>两个节点都执行下面的步骤</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">yum install mariadb-server -y</span><br><span class=\"line\"></span><br><span class=\"line\">systemctl start mariadb</span><br></pre></td></tr></table></figure>\n<p>执行db安全选项</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql_secure_installation</span><br><span class=\"line\">NOTE: RUNNING ALL PARTS OF THIS SCRIPT IS RECOMMENDED FOR ALL MariaDB</span><br><span class=\"line\">      SERVERS IN PRODUCTION USE!  PLEASE READ EACH STEP CAREFULLY!</span><br><span class=\"line\"></span><br><span class=\"line\">In order to <span class=\"built_in\">log</span> into MariaDB to secure it, we<span class=\"string\">'ll need the current</span></span><br><span class=\"line\"><span class=\"string\">password for the root user.  If you'</span>ve just installed MariaDB, and</span><br><span class=\"line\">you haven<span class=\"string\">'t set the root password yet, the password will be blank,</span></span><br><span class=\"line\"><span class=\"string\">so you should just press enter here.</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">Enter current password for root (enter for none):</span></span><br><span class=\"line\"><span class=\"string\">OK, successfully used password, moving on...</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">Setting the root password ensures that nobody can log into the MariaDB</span></span><br><span class=\"line\"><span class=\"string\">root user without the proper authorisation.</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">You already have a root password set, so you can safely answer '</span>n<span class=\"string\">'.</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">Change the root password? [Y/n] Y</span></span><br><span class=\"line\"><span class=\"string\">New password:</span></span><br><span class=\"line\"><span class=\"string\">Re-enter new password:</span></span><br><span class=\"line\"><span class=\"string\">Password updated successfully!</span></span><br><span class=\"line\"><span class=\"string\">Reloading privilege tables..</span></span><br><span class=\"line\"><span class=\"string\"> ... Success!</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">By default, a MariaDB installation has an anonymous user, allowing anyone</span></span><br><span class=\"line\"><span class=\"string\">to log into MariaDB without having to have a user account created for</span></span><br><span class=\"line\"><span class=\"string\">them.  This is intended only for testing, and to make the installation</span></span><br><span class=\"line\"><span class=\"string\">go a bit smoother.  You should remove them before moving into a</span></span><br><span class=\"line\"><span class=\"string\">production environment.</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">Remove anonymous users? [Y/n] Y</span></span><br><span class=\"line\"><span class=\"string\"> ... Success!</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">Normally, root should only be allowed to connect from '</span>localhost<span class=\"string\">'.  This</span></span><br><span class=\"line\"><span class=\"string\">ensures that someone cannot guess at the root password from the network.</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">Disallow root login remotely? [Y/n] Y</span></span><br><span class=\"line\"><span class=\"string\"> ... Success!</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">By default, MariaDB comes with a database named '</span><span class=\"built_in\">test</span><span class=\"string\">' that anyone can</span></span><br><span class=\"line\"><span class=\"string\">access.  This is also intended only for testing, and should be removed</span></span><br><span class=\"line\"><span class=\"string\">before moving into a production environment.</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">Remove test database and access to it? [Y/n] Y</span></span><br><span class=\"line\"><span class=\"string\"> - Dropping test database...</span></span><br><span class=\"line\"><span class=\"string\"> ... Success!</span></span><br><span class=\"line\"><span class=\"string\"> - Removing privileges on test database...</span></span><br><span class=\"line\"><span class=\"string\"> ... Success!</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">Reloading the privilege tables will ensure that all changes made so far</span></span><br><span class=\"line\"><span class=\"string\">will take effect immediately.</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">Reload privilege tables now? [Y/n] Y</span></span><br><span class=\"line\"><span class=\"string\"> ... Success!</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">Cleaning up...</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">All done!  If you'</span>ve completed all of the above steps, your MariaDB</span><br><span class=\"line\">installation should now be secure.</span><br><span class=\"line\"></span><br><span class=\"line\">Thanks <span class=\"keyword\">for</span> using MariaDB!</span><br></pre></td></tr></table></figure>\n<h3 id=\"master节点配置\"><a href=\"#master节点配置\" class=\"headerlink\" title=\"master节点配置\"></a>master节点配置</h3><p>在/etc/my.cnf文件的[mysqld]中添加如下内容</p>\n<figure class=\"highlight vim\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">server-id=<span class=\"number\">1</span></span><br><span class=\"line\"><span class=\"built_in\">log</span>-bin = /var/lib/mysql/mysql-bin</span><br><span class=\"line\">binlog-ignore-db=mysql</span><br><span class=\"line\">binlog-ignore-db=information_schema</span><br><span class=\"line\">binlog-ignore-db=performance_schema</span><br></pre></td></tr></table></figure>\n<p>重启db</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">systemctl restart mariadb</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql -u root -p</span><br><span class=\"line\"></span><br><span class=\"line\">GRANT REPLICATION SLAVE ON *.* TO <span class=\"string\">'replic_user'</span>@<span class=\"string\">'%'</span> IDENTIFIED BY <span class=\"string\">'password'</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">FLUSH PRIVILEGES;</span><br><span class=\"line\"></span><br><span class=\"line\">SHOW MASTER STATUS;</span><br><span class=\"line\"></span><br><span class=\"line\">QUIT;</span><br></pre></td></tr></table></figure>\n<p>如果 master 中已经存在需要复制的数据，则需要dump出来，然后在slave上重放</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql -u root -p</span><br><span class=\"line\"></span><br><span class=\"line\">mysql&gt; FLUSH TABLES WITH READ LOCK;</span><br><span class=\"line\"></span><br><span class=\"line\">mysql&gt; SHOW MASTER STATUS;</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysqldump -u root -p --databases [database-1] [database-2] ...  &gt; /root/db_dump.sql</span><br><span class=\"line\"></span><br><span class=\"line\">mysql -u root -p</span><br><span class=\"line\">mysql&gt; UNLOCK TABLES;</span><br></pre></td></tr></table></figure>\n<h3 id=\"slave节点配置\"><a href=\"#slave节点配置\" class=\"headerlink\" title=\"slave节点配置\"></a>slave节点配置</h3><p>如果master节点上dump了数据，则需要执行下面的步骤进行重放。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">scp root@172.16.143.171:/root/db_dump.sql /root/db_dump.sql</span><br><span class=\"line\">mysql -u root -p &lt; /root/db_dump.sql</span><br></pre></td></tr></table></figure>\n<p>在/etc/my.cnf文件的[mysqld]中添加如下内容</p>\n<figure class=\"highlight vim\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">server-id=<span class=\"number\">2</span></span><br><span class=\"line\">og-bin = /var/lib/mysql/mysql-bin</span><br><span class=\"line\">binlog-ignore-db=mysql</span><br><span class=\"line\">binlog-ignore-db=information_schema</span><br><span class=\"line\">binlog-ignore-db=performance_schema</span><br></pre></td></tr></table></figure>\n<p>重启db</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">systemctl restart mariadb</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql -u root -p</span><br><span class=\"line\"></span><br><span class=\"line\">mysql&gt; CHANGE MASTER TO MASTER_HOST=<span class=\"string\">'172.16.143.171'</span>,MASTER_USER=<span class=\"string\">'replic_user'</span>, MASTER_PASSWORD=<span class=\"string\">'password'</span>, MASTER_LOG_FILE=<span class=\"string\">'mysql-bin.000001'</span>, MASTER_LOG_POS=107;</span><br></pre></td></tr></table></figure>\n<p>上面命令中<b>MASTER_LOG_FILE</b> 和 <b>MASTER_LOG_POS</b> 需要根据master节点中<figure class=\"highlight plain\"><figcaption><span>master status```命令结果调整。</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">```bash</span><br><span class=\"line\">START SLAVE;</span><br><span class=\"line\"></span><br><span class=\"line\">SHOW SLAVE STATUS\\G</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"测试\"><a href=\"#测试\" class=\"headerlink\" title=\"测试\"></a>测试</h2><p>在master节点中创建db，也可以在slave节点中看到。</p>\n<h2 id=\"双向复制\"><a href=\"#双向复制\" class=\"headerlink\" title=\"双向复制\"></a>双向复制</h2><p>上面的配置实现了host1 –&gt; host2 的复制关系，如需要实现双向复制，只需要按照上面的步骤再配置从 host2 –&gt; host1 的复制关机即可。</p>\n<p>另外在host1的/ect/my.cnf中添加如下内容</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">auto-increment-increment = 2</span><br><span class=\"line\">auto-increment-offset = 1</span><br></pre></td></tr></table></figure>\n<p>在host2的/ect/my.cnf中添加如下内容</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">auto-increment-increment = 2</span><br><span class=\"line\">auto-increment-offset = 2</span><br></pre></td></tr></table></figure>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"环境\"><a href=\"#环境\" class=\"headerlink\" title=\"环境\"></a>环境</h2><p>OS：Centos 7.3</p>\n<p>DB version： mysql  Ver 15.1 Distrib 5.5.56-MariaDB, for Linux (x86_64) using readline 5.1</p>\n<p>host1(master): 172.16.143.171</p>\n<p>host2(slave): 172.16.143.172</p>\n<h2 id=\"安装\"><a href=\"#安装\" class=\"headerlink\" title=\"安装\"></a>安装</h2><p>两个节点都执行下面的步骤</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">yum install mariadb-server -y</span><br><span class=\"line\"></span><br><span class=\"line\">systemctl start mariadb</span><br></pre></td></tr></table></figure>\n<p>执行db安全选项</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql_secure_installation</span><br><span class=\"line\">NOTE: RUNNING ALL PARTS OF THIS SCRIPT IS RECOMMENDED FOR ALL MariaDB</span><br><span class=\"line\">      SERVERS IN PRODUCTION USE!  PLEASE READ EACH STEP CAREFULLY!</span><br><span class=\"line\"></span><br><span class=\"line\">In order to <span class=\"built_in\">log</span> into MariaDB to secure it, we<span class=\"string\">'ll need the current</span></span><br><span class=\"line\"><span class=\"string\">password for the root user.  If you'</span>ve just installed MariaDB, and</span><br><span class=\"line\">you haven<span class=\"string\">'t set the root password yet, the password will be blank,</span></span><br><span class=\"line\"><span class=\"string\">so you should just press enter here.</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">Enter current password for root (enter for none):</span></span><br><span class=\"line\"><span class=\"string\">OK, successfully used password, moving on...</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">Setting the root password ensures that nobody can log into the MariaDB</span></span><br><span class=\"line\"><span class=\"string\">root user without the proper authorisation.</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">You already have a root password set, so you can safely answer '</span>n<span class=\"string\">'.</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">Change the root password? [Y/n] Y</span></span><br><span class=\"line\"><span class=\"string\">New password:</span></span><br><span class=\"line\"><span class=\"string\">Re-enter new password:</span></span><br><span class=\"line\"><span class=\"string\">Password updated successfully!</span></span><br><span class=\"line\"><span class=\"string\">Reloading privilege tables..</span></span><br><span class=\"line\"><span class=\"string\"> ... Success!</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">By default, a MariaDB installation has an anonymous user, allowing anyone</span></span><br><span class=\"line\"><span class=\"string\">to log into MariaDB without having to have a user account created for</span></span><br><span class=\"line\"><span class=\"string\">them.  This is intended only for testing, and to make the installation</span></span><br><span class=\"line\"><span class=\"string\">go a bit smoother.  You should remove them before moving into a</span></span><br><span class=\"line\"><span class=\"string\">production environment.</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">Remove anonymous users? [Y/n] Y</span></span><br><span class=\"line\"><span class=\"string\"> ... Success!</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">Normally, root should only be allowed to connect from '</span>localhost<span class=\"string\">'.  This</span></span><br><span class=\"line\"><span class=\"string\">ensures that someone cannot guess at the root password from the network.</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">Disallow root login remotely? [Y/n] Y</span></span><br><span class=\"line\"><span class=\"string\"> ... Success!</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">By default, MariaDB comes with a database named '</span><span class=\"built_in\">test</span><span class=\"string\">' that anyone can</span></span><br><span class=\"line\"><span class=\"string\">access.  This is also intended only for testing, and should be removed</span></span><br><span class=\"line\"><span class=\"string\">before moving into a production environment.</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">Remove test database and access to it? [Y/n] Y</span></span><br><span class=\"line\"><span class=\"string\"> - Dropping test database...</span></span><br><span class=\"line\"><span class=\"string\"> ... Success!</span></span><br><span class=\"line\"><span class=\"string\"> - Removing privileges on test database...</span></span><br><span class=\"line\"><span class=\"string\"> ... Success!</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">Reloading the privilege tables will ensure that all changes made so far</span></span><br><span class=\"line\"><span class=\"string\">will take effect immediately.</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">Reload privilege tables now? [Y/n] Y</span></span><br><span class=\"line\"><span class=\"string\"> ... Success!</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">Cleaning up...</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">All done!  If you'</span>ve completed all of the above steps, your MariaDB</span><br><span class=\"line\">installation should now be secure.</span><br><span class=\"line\"></span><br><span class=\"line\">Thanks <span class=\"keyword\">for</span> using MariaDB!</span><br></pre></td></tr></table></figure>\n<h3 id=\"master节点配置\"><a href=\"#master节点配置\" class=\"headerlink\" title=\"master节点配置\"></a>master节点配置</h3><p>在/etc/my.cnf文件的[mysqld]中添加如下内容</p>\n<figure class=\"highlight vim\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">server-id=<span class=\"number\">1</span></span><br><span class=\"line\"><span class=\"built_in\">log</span>-bin = /var/lib/mysql/mysql-bin</span><br><span class=\"line\">binlog-ignore-db=mysql</span><br><span class=\"line\">binlog-ignore-db=information_schema</span><br><span class=\"line\">binlog-ignore-db=performance_schema</span><br></pre></td></tr></table></figure>\n<p>重启db</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">systemctl restart mariadb</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql -u root -p</span><br><span class=\"line\"></span><br><span class=\"line\">GRANT REPLICATION SLAVE ON *.* TO <span class=\"string\">'replic_user'</span>@<span class=\"string\">'%'</span> IDENTIFIED BY <span class=\"string\">'password'</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">FLUSH PRIVILEGES;</span><br><span class=\"line\"></span><br><span class=\"line\">SHOW MASTER STATUS;</span><br><span class=\"line\"></span><br><span class=\"line\">QUIT;</span><br></pre></td></tr></table></figure>\n<p>如果 master 中已经存在需要复制的数据，则需要dump出来，然后在slave上重放</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql -u root -p</span><br><span class=\"line\"></span><br><span class=\"line\">mysql&gt; FLUSH TABLES WITH READ LOCK;</span><br><span class=\"line\"></span><br><span class=\"line\">mysql&gt; SHOW MASTER STATUS;</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysqldump -u root -p --databases [database-1] [database-2] ...  &gt; /root/db_dump.sql</span><br><span class=\"line\"></span><br><span class=\"line\">mysql -u root -p</span><br><span class=\"line\">mysql&gt; UNLOCK TABLES;</span><br></pre></td></tr></table></figure>\n<h3 id=\"slave节点配置\"><a href=\"#slave节点配置\" class=\"headerlink\" title=\"slave节点配置\"></a>slave节点配置</h3><p>如果master节点上dump了数据，则需要执行下面的步骤进行重放。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">scp root@172.16.143.171:/root/db_dump.sql /root/db_dump.sql</span><br><span class=\"line\">mysql -u root -p &lt; /root/db_dump.sql</span><br></pre></td></tr></table></figure>\n<p>在/etc/my.cnf文件的[mysqld]中添加如下内容</p>\n<figure class=\"highlight vim\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">server-id=<span class=\"number\">2</span></span><br><span class=\"line\">og-bin = /var/lib/mysql/mysql-bin</span><br><span class=\"line\">binlog-ignore-db=mysql</span><br><span class=\"line\">binlog-ignore-db=information_schema</span><br><span class=\"line\">binlog-ignore-db=performance_schema</span><br></pre></td></tr></table></figure>\n<p>重启db</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">systemctl restart mariadb</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql -u root -p</span><br><span class=\"line\"></span><br><span class=\"line\">mysql&gt; CHANGE MASTER TO MASTER_HOST=<span class=\"string\">'172.16.143.171'</span>,MASTER_USER=<span class=\"string\">'replic_user'</span>, MASTER_PASSWORD=<span class=\"string\">'password'</span>, MASTER_LOG_FILE=<span class=\"string\">'mysql-bin.000001'</span>, MASTER_LOG_POS=107;</span><br></pre></td></tr></table></figure>\n<p>上面命令中<b>MASTER_LOG_FILE</b> 和 <b>MASTER_LOG_POS</b> 需要根据master节点中<figure class=\"highlight plain\"><figcaption><span>master status```命令结果调整。</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">```bash</span><br><span class=\"line\">START SLAVE;</span><br><span class=\"line\"></span><br><span class=\"line\">SHOW SLAVE STATUS\\G</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"测试\"><a href=\"#测试\" class=\"headerlink\" title=\"测试\"></a>测试</h2><p>在master节点中创建db，也可以在slave节点中看到。</p>\n<h2 id=\"双向复制\"><a href=\"#双向复制\" class=\"headerlink\" title=\"双向复制\"></a>双向复制</h2><p>上面的配置实现了host1 –&gt; host2 的复制关系，如需要实现双向复制，只需要按照上面的步骤再配置从 host2 –&gt; host1 的复制关机即可。</p>\n<p>另外在host1的/ect/my.cnf中添加如下内容</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">auto-increment-increment = 2</span><br><span class=\"line\">auto-increment-offset = 1</span><br></pre></td></tr></table></figure>\n<p>在host2的/ect/my.cnf中添加如下内容</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">auto-increment-increment = 2</span><br><span class=\"line\">auto-increment-offset = 2</span><br></pre></td></tr></table></figure>\n"},{"title":"linux performance tools","date":"2019-10-14T05:24:35.000Z","_content":"\n{% asset_img linux_perf_tools_full.png Linux_perf_tools %}","source":"_posts/linux-performance-tools.md","raw":"---\ntitle: linux performance tools\ndate: 2019-10-14 13:24:35\ntags: ['linux']\n---\n\n{% asset_img linux_perf_tools_full.png Linux_perf_tools %}","slug":"linux-performance-tools","published":1,"updated":"2019-10-14T05:40:46.209Z","_id":"ck1pzbtgw000ftp75ky0txdlr","comments":1,"layout":"post","photos":[],"link":"","content":"<img src=\"/2019/10/14/linux-performance-tools/linux_perf_tools_full.png\" title=\"Linux_perf_tools\">","site":{"data":{}},"excerpt":"","more":"<img src=\"/2019/10/14/linux-performance-tools/linux_perf_tools_full.png\" title=\"Linux_perf_tools\">"},{"title":"nextcloud对接ceph","date":"2017-08-09T06:38:45.000Z","_content":"nextcloud是一个私有网盘解决方案，支持多种后端存储解决方案。\nnextcloud也支持aws的s3, 而ceph的radosgw也是兼容s3协议的，所以nextcloud也可以使用ceph作为后端存储，具体的配置如下\n{% asset_img nextcloud1.png 找到插件 %}\n{% asset_img nextcloud2.png enable插件 %}\n{% asset_img nextcloud3.png 添加ceph rgw %}\n填写ceph rgw的server和port，access_key,secret_key,enable path style\n\n{% asset_img nextcloud4.png 找到对应的文件夹 %}\n{% asset_img nextcloud5.png 上传文件 %}\n{% asset_img nextcloud6.png 在Ceph rgw中查看文件 %}\n","source":"_posts/nextcloud-ceph.md","raw":"---\ntitle: nextcloud对接ceph\ndate: 2017-08-09 14:38:45\ntags:\n---\nnextcloud是一个私有网盘解决方案，支持多种后端存储解决方案。\nnextcloud也支持aws的s3, 而ceph的radosgw也是兼容s3协议的，所以nextcloud也可以使用ceph作为后端存储，具体的配置如下\n{% asset_img nextcloud1.png 找到插件 %}\n{% asset_img nextcloud2.png enable插件 %}\n{% asset_img nextcloud3.png 添加ceph rgw %}\n填写ceph rgw的server和port，access_key,secret_key,enable path style\n\n{% asset_img nextcloud4.png 找到对应的文件夹 %}\n{% asset_img nextcloud5.png 上传文件 %}\n{% asset_img nextcloud6.png 在Ceph rgw中查看文件 %}\n","slug":"nextcloud-ceph","published":1,"updated":"2018-09-26T03:58:13.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck1pzbth0000htp75t7s4kb3x","content":"<p>nextcloud是一个私有网盘解决方案，支持多种后端存储解决方案。<br>nextcloud也支持aws的s3, 而ceph的radosgw也是兼容s3协议的，所以nextcloud也可以使用ceph作为后端存储，具体的配置如下<br><img src=\"/2017/08/09/nextcloud-ceph/nextcloud1.png\" title=\"找到插件\"><br><img src=\"/2017/08/09/nextcloud-ceph/nextcloud2.png\" title=\"enable插件\"><br><img src=\"/2017/08/09/nextcloud-ceph/nextcloud3.png\" title=\"添加ceph rgw\"><br>填写ceph rgw的server和port，access_key,secret_key,enable path style</p>\n<img src=\"/2017/08/09/nextcloud-ceph/nextcloud4.png\" title=\"找到对应的文件夹\">\n<img src=\"/2017/08/09/nextcloud-ceph/nextcloud5.png\" title=\"上传文件\">\n<img src=\"/2017/08/09/nextcloud-ceph/nextcloud6.png\" title=\"在Ceph rgw中查看文件\">\n","site":{"data":{}},"excerpt":"","more":"<p>nextcloud是一个私有网盘解决方案，支持多种后端存储解决方案。<br>nextcloud也支持aws的s3, 而ceph的radosgw也是兼容s3协议的，所以nextcloud也可以使用ceph作为后端存储，具体的配置如下<br><img src=\"/2017/08/09/nextcloud-ceph/nextcloud1.png\" title=\"找到插件\"><br><img src=\"/2017/08/09/nextcloud-ceph/nextcloud2.png\" title=\"enable插件\"><br><img src=\"/2017/08/09/nextcloud-ceph/nextcloud3.png\" title=\"添加ceph rgw\"><br>填写ceph rgw的server和port，access_key,secret_key,enable path style</p>\n<img src=\"/2017/08/09/nextcloud-ceph/nextcloud4.png\" title=\"找到对应的文件夹\">\n<img src=\"/2017/08/09/nextcloud-ceph/nextcloud5.png\" title=\"上传文件\">\n<img src=\"/2017/08/09/nextcloud-ceph/nextcloud6.png\" title=\"在Ceph rgw中查看文件\">\n"},{"title":"通过pacemaker管理mysql","date":"2018-03-05T09:59:24.000Z","_content":"\n在上一篇blog中[mysql-replication](https://yanyixing.github.io/2018/03/02/mysql-replication/)介绍了如何配置mysql(mariadb)主从复制。我们还可以添加从节点到主节点的复制关系，这样就达到了mysql(mariadb)双向复制。\n\n下面的配置通过pacemaker管理一个双向复制的mysql(mariadb)和一个VIP来实现mysql(mariadb)在双节点上的高可用。\n\n## 环境\n\nOS: CentOS Linux release 7.3.1611 (Core)\n\nDB: mysql  Ver 15.1 Distrib 5.5.56-MariaDB, for Linux (x86_64) using readline 5.1\n\nhost1(master): 172.16.143.171\n\nhost2(slave): 172.16.143.172\n\n\n## 安装\n\n\n```bash\nyum install -y mariadb-server\n```\n\n安装完成后可以按照上一篇blog来配置双向复制。\n\n\n```bash\nsystemctl stop mariadb\n\nsystemctl disable mariadb\n```\n\n安装配置pacemaker\n\n```bash\nyum install pcs pacemaker corosync fence-angets-all resource-angets -y\n\nsystemctl start pcsd\n\nsystemctl enable pcsd\n\nsystemctl start pacemaker\n\nsystemctl enable pacemaker\n\nsystemctl start corosync\n\nsystemctl enable corosync\n\npasswd hacluster\n\npcs cluster auth ceph01 ceph02\n\npcs cluster setup --start --name cluster_mysql ceph01 ceph02\n\npcs cluster start --all\n\npcs property set stonith-enabled=false\n\npcs property set no-quorum-policy=ignore\n```\n\n## 配置资源\n\n```bash\npcs resource create virtual_ip ocf:heartbeat:IPaddr2 \\\nip=172.16.143.200 cidr_netmask=24 nic=eth0 op monitor interval=30s on-fail=restart\n\npcs resource create mysql ocf:heartbeat:mysql  \\\nbinary=\"/usr/bin/mysqld_safe\"   config=\"/etc/my.cnf\" \\\n  datadir=\"/var/lib/mysql\"   pid=\"/var/lib/mysql/mysql.pid\" \\\n  socket=\"/var/lib/mysql/mysql.sock\"  \\\n additional_parameters=\"--bind-address=0.0.0.0\"   op start timeout=60s \\\n  op stop timeout=60s   op monitor interval=20s timeout=30s \\\non-fail=standby\n\npcs resource clone mysql clone-max=2 clone-node-max=1\n```\n\n## 结果\n\n```bash\n[root@ceph01 ~]# pcs status\nCluster name: cluster_mysql\nStack: corosync\nCurrent DC: ceph01 (version 1.1.16-12.el7_4.7-94ff4df) - partition with quorum\nLast updated: Mon Mar  5 22:07:52 2018\nLast change: Mon Mar  5 22:06:22 2018 by root via cibadmin on cephlcm\n\n2 nodes configured\n3 resources configured\n\nOnline: [ ceph01 ceph02 ]\n\nFull list of resources:\n\n vip\t(ocf::heartbeat:IPaddr2):\tStarted ceph01\n Clone Set: mysql-clone [mysql]\n     Started: [ ceph01 ceph02 ]\n\nDaemon Status:\n  corosync: active/enabled\n  pacemaker: active/enabled\n  pcsd: active/enabled\n```\n\n","source":"_posts/pacemaker-mysql.md","raw":"---\ntitle: 通过pacemaker管理mysql\ndate: 2018-03-05 17:59:24\ntags: ['linux','mysql','ha']\n---\n\n在上一篇blog中[mysql-replication](https://yanyixing.github.io/2018/03/02/mysql-replication/)介绍了如何配置mysql(mariadb)主从复制。我们还可以添加从节点到主节点的复制关系，这样就达到了mysql(mariadb)双向复制。\n\n下面的配置通过pacemaker管理一个双向复制的mysql(mariadb)和一个VIP来实现mysql(mariadb)在双节点上的高可用。\n\n## 环境\n\nOS: CentOS Linux release 7.3.1611 (Core)\n\nDB: mysql  Ver 15.1 Distrib 5.5.56-MariaDB, for Linux (x86_64) using readline 5.1\n\nhost1(master): 172.16.143.171\n\nhost2(slave): 172.16.143.172\n\n\n## 安装\n\n\n```bash\nyum install -y mariadb-server\n```\n\n安装完成后可以按照上一篇blog来配置双向复制。\n\n\n```bash\nsystemctl stop mariadb\n\nsystemctl disable mariadb\n```\n\n安装配置pacemaker\n\n```bash\nyum install pcs pacemaker corosync fence-angets-all resource-angets -y\n\nsystemctl start pcsd\n\nsystemctl enable pcsd\n\nsystemctl start pacemaker\n\nsystemctl enable pacemaker\n\nsystemctl start corosync\n\nsystemctl enable corosync\n\npasswd hacluster\n\npcs cluster auth ceph01 ceph02\n\npcs cluster setup --start --name cluster_mysql ceph01 ceph02\n\npcs cluster start --all\n\npcs property set stonith-enabled=false\n\npcs property set no-quorum-policy=ignore\n```\n\n## 配置资源\n\n```bash\npcs resource create virtual_ip ocf:heartbeat:IPaddr2 \\\nip=172.16.143.200 cidr_netmask=24 nic=eth0 op monitor interval=30s on-fail=restart\n\npcs resource create mysql ocf:heartbeat:mysql  \\\nbinary=\"/usr/bin/mysqld_safe\"   config=\"/etc/my.cnf\" \\\n  datadir=\"/var/lib/mysql\"   pid=\"/var/lib/mysql/mysql.pid\" \\\n  socket=\"/var/lib/mysql/mysql.sock\"  \\\n additional_parameters=\"--bind-address=0.0.0.0\"   op start timeout=60s \\\n  op stop timeout=60s   op monitor interval=20s timeout=30s \\\non-fail=standby\n\npcs resource clone mysql clone-max=2 clone-node-max=1\n```\n\n## 结果\n\n```bash\n[root@ceph01 ~]# pcs status\nCluster name: cluster_mysql\nStack: corosync\nCurrent DC: ceph01 (version 1.1.16-12.el7_4.7-94ff4df) - partition with quorum\nLast updated: Mon Mar  5 22:07:52 2018\nLast change: Mon Mar  5 22:06:22 2018 by root via cibadmin on cephlcm\n\n2 nodes configured\n3 resources configured\n\nOnline: [ ceph01 ceph02 ]\n\nFull list of resources:\n\n vip\t(ocf::heartbeat:IPaddr2):\tStarted ceph01\n Clone Set: mysql-clone [mysql]\n     Started: [ ceph01 ceph02 ]\n\nDaemon Status:\n  corosync: active/enabled\n  pacemaker: active/enabled\n  pcsd: active/enabled\n```\n\n","slug":"pacemaker-mysql","published":1,"updated":"2018-09-26T03:47:22.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck1pzbth3000jtp75zvhmar6d","content":"<p>在上一篇blog中<a href=\"https://yanyixing.github.io/2018/03/02/mysql-replication/\">mysql-replication</a>介绍了如何配置mysql(mariadb)主从复制。我们还可以添加从节点到主节点的复制关系，这样就达到了mysql(mariadb)双向复制。</p>\n<p>下面的配置通过pacemaker管理一个双向复制的mysql(mariadb)和一个VIP来实现mysql(mariadb)在双节点上的高可用。</p>\n<h2 id=\"环境\"><a href=\"#环境\" class=\"headerlink\" title=\"环境\"></a>环境</h2><p>OS: CentOS Linux release 7.3.1611 (Core)</p>\n<p>DB: mysql  Ver 15.1 Distrib 5.5.56-MariaDB, for Linux (x86_64) using readline 5.1</p>\n<p>host1(master): 172.16.143.171</p>\n<p>host2(slave): 172.16.143.172</p>\n<h2 id=\"安装\"><a href=\"#安装\" class=\"headerlink\" title=\"安装\"></a>安装</h2><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">yum install -y mariadb-server</span><br></pre></td></tr></table></figure>\n<p>安装完成后可以按照上一篇blog来配置双向复制。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">systemctl stop mariadb</span><br><span class=\"line\"></span><br><span class=\"line\">systemctl <span class=\"built_in\">disable</span> mariadb</span><br></pre></td></tr></table></figure>\n<p>安装配置pacemaker</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">yum install pcs pacemaker corosync fence-angets-all resource-angets -y</span><br><span class=\"line\"></span><br><span class=\"line\">systemctl start pcsd</span><br><span class=\"line\"></span><br><span class=\"line\">systemctl <span class=\"built_in\">enable</span> pcsd</span><br><span class=\"line\"></span><br><span class=\"line\">systemctl start pacemaker</span><br><span class=\"line\"></span><br><span class=\"line\">systemctl <span class=\"built_in\">enable</span> pacemaker</span><br><span class=\"line\"></span><br><span class=\"line\">systemctl start corosync</span><br><span class=\"line\"></span><br><span class=\"line\">systemctl <span class=\"built_in\">enable</span> corosync</span><br><span class=\"line\"></span><br><span class=\"line\">passwd hacluster</span><br><span class=\"line\"></span><br><span class=\"line\">pcs cluster auth ceph01 ceph02</span><br><span class=\"line\"></span><br><span class=\"line\">pcs cluster setup --start --name cluster_mysql ceph01 ceph02</span><br><span class=\"line\"></span><br><span class=\"line\">pcs cluster start --all</span><br><span class=\"line\"></span><br><span class=\"line\">pcs property <span class=\"built_in\">set</span> stonith-enabled=<span class=\"literal\">false</span></span><br><span class=\"line\"></span><br><span class=\"line\">pcs property <span class=\"built_in\">set</span> no-quorum-policy=ignore</span><br></pre></td></tr></table></figure>\n<h2 id=\"配置资源\"><a href=\"#配置资源\" class=\"headerlink\" title=\"配置资源\"></a>配置资源</h2><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pcs resource create virtual_ip ocf:heartbeat:IPaddr2 \\</span><br><span class=\"line\">ip=172.16.143.200 cidr_netmask=24 nic=eth0 op monitor interval=30s on-fail=restart</span><br><span class=\"line\"></span><br><span class=\"line\">pcs resource create mysql ocf:heartbeat:mysql  \\</span><br><span class=\"line\">binary=<span class=\"string\">\"/usr/bin/mysqld_safe\"</span>   config=<span class=\"string\">\"/etc/my.cnf\"</span> \\</span><br><span class=\"line\">  datadir=<span class=\"string\">\"/var/lib/mysql\"</span>   pid=<span class=\"string\">\"/var/lib/mysql/mysql.pid\"</span> \\</span><br><span class=\"line\">  socket=<span class=\"string\">\"/var/lib/mysql/mysql.sock\"</span>  \\</span><br><span class=\"line\"> additional_parameters=<span class=\"string\">\"--bind-address=0.0.0.0\"</span>   op start timeout=60s \\</span><br><span class=\"line\">  op stop timeout=60s   op monitor interval=20s timeout=30s \\</span><br><span class=\"line\">on-fail=standby</span><br><span class=\"line\"></span><br><span class=\"line\">pcs resource <span class=\"built_in\">clone</span> mysql <span class=\"built_in\">clone</span>-max=2 <span class=\"built_in\">clone</span>-node-max=1</span><br></pre></td></tr></table></figure>\n<h2 id=\"结果\"><a href=\"#结果\" class=\"headerlink\" title=\"结果\"></a>结果</h2><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@ceph01 ~]<span class=\"comment\"># pcs status</span></span><br><span class=\"line\">Cluster name: cluster_mysql</span><br><span class=\"line\">Stack: corosync</span><br><span class=\"line\">Current DC: ceph01 (version 1.1.16-12.el7_4.7-94ff4df) - partition with quorum</span><br><span class=\"line\">Last updated: Mon Mar  5 22:07:52 2018</span><br><span class=\"line\">Last change: Mon Mar  5 22:06:22 2018 by root via cibadmin on cephlcm</span><br><span class=\"line\"></span><br><span class=\"line\">2 nodes configured</span><br><span class=\"line\">3 resources configured</span><br><span class=\"line\"></span><br><span class=\"line\">Online: [ ceph01 ceph02 ]</span><br><span class=\"line\"></span><br><span class=\"line\">Full list of resources:</span><br><span class=\"line\"></span><br><span class=\"line\"> vip\t(ocf::heartbeat:IPaddr2):\tStarted ceph01</span><br><span class=\"line\"> Clone Set: mysql-clone [mysql]</span><br><span class=\"line\">     Started: [ ceph01 ceph02 ]</span><br><span class=\"line\"></span><br><span class=\"line\">Daemon Status:</span><br><span class=\"line\">  corosync: active/enabled</span><br><span class=\"line\">  pacemaker: active/enabled</span><br><span class=\"line\">  pcsd: active/enabled</span><br></pre></td></tr></table></figure>\n","site":{"data":{}},"excerpt":"","more":"<p>在上一篇blog中<a href=\"https://yanyixing.github.io/2018/03/02/mysql-replication/\">mysql-replication</a>介绍了如何配置mysql(mariadb)主从复制。我们还可以添加从节点到主节点的复制关系，这样就达到了mysql(mariadb)双向复制。</p>\n<p>下面的配置通过pacemaker管理一个双向复制的mysql(mariadb)和一个VIP来实现mysql(mariadb)在双节点上的高可用。</p>\n<h2 id=\"环境\"><a href=\"#环境\" class=\"headerlink\" title=\"环境\"></a>环境</h2><p>OS: CentOS Linux release 7.3.1611 (Core)</p>\n<p>DB: mysql  Ver 15.1 Distrib 5.5.56-MariaDB, for Linux (x86_64) using readline 5.1</p>\n<p>host1(master): 172.16.143.171</p>\n<p>host2(slave): 172.16.143.172</p>\n<h2 id=\"安装\"><a href=\"#安装\" class=\"headerlink\" title=\"安装\"></a>安装</h2><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">yum install -y mariadb-server</span><br></pre></td></tr></table></figure>\n<p>安装完成后可以按照上一篇blog来配置双向复制。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">systemctl stop mariadb</span><br><span class=\"line\"></span><br><span class=\"line\">systemctl <span class=\"built_in\">disable</span> mariadb</span><br></pre></td></tr></table></figure>\n<p>安装配置pacemaker</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">yum install pcs pacemaker corosync fence-angets-all resource-angets -y</span><br><span class=\"line\"></span><br><span class=\"line\">systemctl start pcsd</span><br><span class=\"line\"></span><br><span class=\"line\">systemctl <span class=\"built_in\">enable</span> pcsd</span><br><span class=\"line\"></span><br><span class=\"line\">systemctl start pacemaker</span><br><span class=\"line\"></span><br><span class=\"line\">systemctl <span class=\"built_in\">enable</span> pacemaker</span><br><span class=\"line\"></span><br><span class=\"line\">systemctl start corosync</span><br><span class=\"line\"></span><br><span class=\"line\">systemctl <span class=\"built_in\">enable</span> corosync</span><br><span class=\"line\"></span><br><span class=\"line\">passwd hacluster</span><br><span class=\"line\"></span><br><span class=\"line\">pcs cluster auth ceph01 ceph02</span><br><span class=\"line\"></span><br><span class=\"line\">pcs cluster setup --start --name cluster_mysql ceph01 ceph02</span><br><span class=\"line\"></span><br><span class=\"line\">pcs cluster start --all</span><br><span class=\"line\"></span><br><span class=\"line\">pcs property <span class=\"built_in\">set</span> stonith-enabled=<span class=\"literal\">false</span></span><br><span class=\"line\"></span><br><span class=\"line\">pcs property <span class=\"built_in\">set</span> no-quorum-policy=ignore</span><br></pre></td></tr></table></figure>\n<h2 id=\"配置资源\"><a href=\"#配置资源\" class=\"headerlink\" title=\"配置资源\"></a>配置资源</h2><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pcs resource create virtual_ip ocf:heartbeat:IPaddr2 \\</span><br><span class=\"line\">ip=172.16.143.200 cidr_netmask=24 nic=eth0 op monitor interval=30s on-fail=restart</span><br><span class=\"line\"></span><br><span class=\"line\">pcs resource create mysql ocf:heartbeat:mysql  \\</span><br><span class=\"line\">binary=<span class=\"string\">\"/usr/bin/mysqld_safe\"</span>   config=<span class=\"string\">\"/etc/my.cnf\"</span> \\</span><br><span class=\"line\">  datadir=<span class=\"string\">\"/var/lib/mysql\"</span>   pid=<span class=\"string\">\"/var/lib/mysql/mysql.pid\"</span> \\</span><br><span class=\"line\">  socket=<span class=\"string\">\"/var/lib/mysql/mysql.sock\"</span>  \\</span><br><span class=\"line\"> additional_parameters=<span class=\"string\">\"--bind-address=0.0.0.0\"</span>   op start timeout=60s \\</span><br><span class=\"line\">  op stop timeout=60s   op monitor interval=20s timeout=30s \\</span><br><span class=\"line\">on-fail=standby</span><br><span class=\"line\"></span><br><span class=\"line\">pcs resource <span class=\"built_in\">clone</span> mysql <span class=\"built_in\">clone</span>-max=2 <span class=\"built_in\">clone</span>-node-max=1</span><br></pre></td></tr></table></figure>\n<h2 id=\"结果\"><a href=\"#结果\" class=\"headerlink\" title=\"结果\"></a>结果</h2><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@ceph01 ~]<span class=\"comment\"># pcs status</span></span><br><span class=\"line\">Cluster name: cluster_mysql</span><br><span class=\"line\">Stack: corosync</span><br><span class=\"line\">Current DC: ceph01 (version 1.1.16-12.el7_4.7-94ff4df) - partition with quorum</span><br><span class=\"line\">Last updated: Mon Mar  5 22:07:52 2018</span><br><span class=\"line\">Last change: Mon Mar  5 22:06:22 2018 by root via cibadmin on cephlcm</span><br><span class=\"line\"></span><br><span class=\"line\">2 nodes configured</span><br><span class=\"line\">3 resources configured</span><br><span class=\"line\"></span><br><span class=\"line\">Online: [ ceph01 ceph02 ]</span><br><span class=\"line\"></span><br><span class=\"line\">Full list of resources:</span><br><span class=\"line\"></span><br><span class=\"line\"> vip\t(ocf::heartbeat:IPaddr2):\tStarted ceph01</span><br><span class=\"line\"> Clone Set: mysql-clone [mysql]</span><br><span class=\"line\">     Started: [ ceph01 ceph02 ]</span><br><span class=\"line\"></span><br><span class=\"line\">Daemon Status:</span><br><span class=\"line\">  corosync: active/enabled</span><br><span class=\"line\">  pacemaker: active/enabled</span><br><span class=\"line\">  pcsd: active/enabled</span><br></pre></td></tr></table></figure>\n"},{"title":"Redis持久化","date":"2018-09-23T09:36:22.000Z","_content":"## 概述\nRedis是一种内存型的数据库，一般都是作为缓存使用，数据都是保存在内存中，但为了防止宕机后数据丢失，Redis提供了两种持久化方案，分别是RDB和AOF。接下来介绍一下这两种持久化方案。\n\n## RDB持久化\nRDB持久化可以把当前Redis内存中的状态保存到硬盘上，可以手动触发，也可以通过配置文件自动执行。\n\nRDB持久化后的文件是一个经过压缩的二进制文件，redis可以通过这个文件进行数据还原。\n\nRDB持久化可以通过下面两个命令来触发：\n\n* SAVE: 阻塞Redis进程，知道RDB文件创建完成\n* BGSAVE: fork一个子进程来创建RDB文件，\n\n### RDB持久化优点\n1. 一旦采用该方式，那么你的整个Redis数据库将只包含一个文件，这对于文件备份而言是非常完美的。比如，你可能打算每个小时归档一次最近24小时的数据，同时还要每天归档一次最近30天的数据。通过这样的备份策略，一旦系统出现灾难性故障，我们可以非常容易的进行恢复。\n2. 对于灾难恢复而言，RDB是非常不错的选择。因为我们可以非常轻松的将一个单独的文件压缩后再转移到其它存储介质上。\n3. 性能最大化。对于Redis的服务进程而言，在开始持久化时，它唯一需要做的只是fork出子进程，之后再由子进程完成这些持久化的工作，这样就可以极大的避免服务进程执行IO操作了。\n4. 相比于AOF机制，如果数据集很大，RDB的启动效率会更高。\n\n### RDB持久化缺点\n1. 如果你想保证数据的高可用性，即最大限度的避免数据丢失，那么RDB将不是一个很好的选择。因为系统一旦在定时持久化之前出现宕机现象，此前没有来得及写入磁盘的数据都将丢失。\n2. 由于RDB是通过fork子进程来协助完成数据持久化工作的，因此，如果当数据集较大时，可能会导致整个服务器停止服务几百毫秒，甚至是1秒钟。\n\n## AOF持久化\n\nAOF持久化（Append-Only-File），与RDB持久化不同，AOF持久化是通过保存Redis服务器所执行的写状态来记录数据库的。\n\n具体来说，RDB持久化相当于备份数据库状态，而AOF持久化是备份数据库接收到的命令，所有被写入AOF的命令都是以redis的协议格式来保存的。\n\n在AOF持久化的文件中，数据库会记录下所有变更数据库状态的命令，除了指定数据库的select命令，其他的命令都是来自client的，这些命令会以追加(append)的形式保存到文件中。\n\n服务器配置中有一项appendfsync，这个配置会影响服务器多久完成一次命令的记录：\n\n* always：将缓存区的内容总是即时写到AOF文件中。\n* everysec：将缓存区的内容每隔一秒写入AOF文件中。\n* no ：写入AOF文件中的操作由操作系统决定，一般而言为了提高效率，操作系统会等待缓存区被填满，才会开始同步数据到磁盘。\n\nredis默认实用的是everysec。\n\nredis在载入AOF文件的时候，会创建一个虚拟的client，把AOF中每一条命令都执行一遍，最终还原回数据库的状态，它的载入也是自动的。在RDB和AOF备份文件都有的情况下，redis会优先载入AOF备份文件。\n\nAOF文件可能会随着服务器运行的时间越来越大，可以利用AOF重写的功能，来控制AOF文件的大小。AOF重写功能会首先读取数据库中现有的键值对状态，然后根据类型使用一条命令来替代前的键值对多条命令。\n\nAOF重写功能有大量写入操作，所以redis才用子进程来处理AOF重写。这里带来一个新的问题，由于处理重新的是子进程，这样意味着如果主线程的数据在此时被修改，备份的数据和主库的数据将会有不一致的情况发生。因此redis还设置了一个AOF重写缓冲区，这个缓冲区在子进程被创建开始之后开始使用，这个期间，所有的命令会被存两份，一份在AOF缓存空间，一份在AOF重写缓冲区，当AOF重写完成之后，子进程发送信号给主进程，通知主进程将AOF重写缓冲区的内容添加到AOF文件中。\n\n### AOF的优点\n1. 该机制可以带来更高的数据安全性，即数据持久性。Redis中提供了3中同步策略，即everysec、always和no。事实上，everysec也是异步完成的，其效率也是非常高的，所差的是一旦系统出现宕机现象，那么这一秒钟之内修改的数据将会丢失。而always，我们可以将其视为同步持久化，即每次发生的数据变化都会被立即记录到磁盘中。可以预见，这种方式在效率上是最低的。至于no，无需多言，我想大家都能正确的理解它。\n2. 由于该机制对日志文件的写入操作采用的是append模式，因此在写入过程中即使出现宕机现象，也不会破坏日志文件中已经存在的内容。然而如果我们本次操作只是写入了一半数据就出现了系统崩溃问题，不用担心，在Redis下一次启动之前，我们可以通过redis-check-aof工具来帮助我们解决数据一致性的问题。\n3. 如果日志过大，Redis可以自动启用rewrite机制。即Redis以append模式不断的将修改数据写入到老的磁盘文件中，同时Redis还会创建一个新的文件用于记录此期间有哪些修改命令被执行。因此在进行rewrite切换时可以更好的保证数据安全性。\n4. AOF包含一个格式清晰、易于理解的日志文件用于记录所有的修改操作。事实上，我们也可以通过该文件完成数据的重建。\n\n### AOF的缺点\n1. 对于相同数量的数据集而言，AOF文件通常要大于RDB文件。RDB 在恢复大数据集时的速度比 AOF 的恢复速度要快。\n2. 根据同步策略的不同，AOF在运行效率上往往会慢于RDB。总之，每秒同步策略的效率是比较高的，no策略的效率和RDB一样高效。","source":"_posts/redis-persistence.md","raw":"---\ntitle: Redis持久化\ndate: 2018-09-23 17:36:22\ntags: ['redis']\n---\n## 概述\nRedis是一种内存型的数据库，一般都是作为缓存使用，数据都是保存在内存中，但为了防止宕机后数据丢失，Redis提供了两种持久化方案，分别是RDB和AOF。接下来介绍一下这两种持久化方案。\n\n## RDB持久化\nRDB持久化可以把当前Redis内存中的状态保存到硬盘上，可以手动触发，也可以通过配置文件自动执行。\n\nRDB持久化后的文件是一个经过压缩的二进制文件，redis可以通过这个文件进行数据还原。\n\nRDB持久化可以通过下面两个命令来触发：\n\n* SAVE: 阻塞Redis进程，知道RDB文件创建完成\n* BGSAVE: fork一个子进程来创建RDB文件，\n\n### RDB持久化优点\n1. 一旦采用该方式，那么你的整个Redis数据库将只包含一个文件，这对于文件备份而言是非常完美的。比如，你可能打算每个小时归档一次最近24小时的数据，同时还要每天归档一次最近30天的数据。通过这样的备份策略，一旦系统出现灾难性故障，我们可以非常容易的进行恢复。\n2. 对于灾难恢复而言，RDB是非常不错的选择。因为我们可以非常轻松的将一个单独的文件压缩后再转移到其它存储介质上。\n3. 性能最大化。对于Redis的服务进程而言，在开始持久化时，它唯一需要做的只是fork出子进程，之后再由子进程完成这些持久化的工作，这样就可以极大的避免服务进程执行IO操作了。\n4. 相比于AOF机制，如果数据集很大，RDB的启动效率会更高。\n\n### RDB持久化缺点\n1. 如果你想保证数据的高可用性，即最大限度的避免数据丢失，那么RDB将不是一个很好的选择。因为系统一旦在定时持久化之前出现宕机现象，此前没有来得及写入磁盘的数据都将丢失。\n2. 由于RDB是通过fork子进程来协助完成数据持久化工作的，因此，如果当数据集较大时，可能会导致整个服务器停止服务几百毫秒，甚至是1秒钟。\n\n## AOF持久化\n\nAOF持久化（Append-Only-File），与RDB持久化不同，AOF持久化是通过保存Redis服务器所执行的写状态来记录数据库的。\n\n具体来说，RDB持久化相当于备份数据库状态，而AOF持久化是备份数据库接收到的命令，所有被写入AOF的命令都是以redis的协议格式来保存的。\n\n在AOF持久化的文件中，数据库会记录下所有变更数据库状态的命令，除了指定数据库的select命令，其他的命令都是来自client的，这些命令会以追加(append)的形式保存到文件中。\n\n服务器配置中有一项appendfsync，这个配置会影响服务器多久完成一次命令的记录：\n\n* always：将缓存区的内容总是即时写到AOF文件中。\n* everysec：将缓存区的内容每隔一秒写入AOF文件中。\n* no ：写入AOF文件中的操作由操作系统决定，一般而言为了提高效率，操作系统会等待缓存区被填满，才会开始同步数据到磁盘。\n\nredis默认实用的是everysec。\n\nredis在载入AOF文件的时候，会创建一个虚拟的client，把AOF中每一条命令都执行一遍，最终还原回数据库的状态，它的载入也是自动的。在RDB和AOF备份文件都有的情况下，redis会优先载入AOF备份文件。\n\nAOF文件可能会随着服务器运行的时间越来越大，可以利用AOF重写的功能，来控制AOF文件的大小。AOF重写功能会首先读取数据库中现有的键值对状态，然后根据类型使用一条命令来替代前的键值对多条命令。\n\nAOF重写功能有大量写入操作，所以redis才用子进程来处理AOF重写。这里带来一个新的问题，由于处理重新的是子进程，这样意味着如果主线程的数据在此时被修改，备份的数据和主库的数据将会有不一致的情况发生。因此redis还设置了一个AOF重写缓冲区，这个缓冲区在子进程被创建开始之后开始使用，这个期间，所有的命令会被存两份，一份在AOF缓存空间，一份在AOF重写缓冲区，当AOF重写完成之后，子进程发送信号给主进程，通知主进程将AOF重写缓冲区的内容添加到AOF文件中。\n\n### AOF的优点\n1. 该机制可以带来更高的数据安全性，即数据持久性。Redis中提供了3中同步策略，即everysec、always和no。事实上，everysec也是异步完成的，其效率也是非常高的，所差的是一旦系统出现宕机现象，那么这一秒钟之内修改的数据将会丢失。而always，我们可以将其视为同步持久化，即每次发生的数据变化都会被立即记录到磁盘中。可以预见，这种方式在效率上是最低的。至于no，无需多言，我想大家都能正确的理解它。\n2. 由于该机制对日志文件的写入操作采用的是append模式，因此在写入过程中即使出现宕机现象，也不会破坏日志文件中已经存在的内容。然而如果我们本次操作只是写入了一半数据就出现了系统崩溃问题，不用担心，在Redis下一次启动之前，我们可以通过redis-check-aof工具来帮助我们解决数据一致性的问题。\n3. 如果日志过大，Redis可以自动启用rewrite机制。即Redis以append模式不断的将修改数据写入到老的磁盘文件中，同时Redis还会创建一个新的文件用于记录此期间有哪些修改命令被执行。因此在进行rewrite切换时可以更好的保证数据安全性。\n4. AOF包含一个格式清晰、易于理解的日志文件用于记录所有的修改操作。事实上，我们也可以通过该文件完成数据的重建。\n\n### AOF的缺点\n1. 对于相同数量的数据集而言，AOF文件通常要大于RDB文件。RDB 在恢复大数据集时的速度比 AOF 的恢复速度要快。\n2. 根据同步策略的不同，AOF在运行效率上往往会慢于RDB。总之，每秒同步策略的效率是比较高的，no策略的效率和RDB一样高效。","slug":"redis-persistence","published":1,"updated":"2018-09-23T14:12:44.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck1pzbth4000ltp750lf21v15","content":"<h2 id=\"概述\"><a href=\"#概述\" class=\"headerlink\" title=\"概述\"></a>概述</h2><p>Redis是一种内存型的数据库，一般都是作为缓存使用，数据都是保存在内存中，但为了防止宕机后数据丢失，Redis提供了两种持久化方案，分别是RDB和AOF。接下来介绍一下这两种持久化方案。</p>\n<h2 id=\"RDB持久化\"><a href=\"#RDB持久化\" class=\"headerlink\" title=\"RDB持久化\"></a>RDB持久化</h2><p>RDB持久化可以把当前Redis内存中的状态保存到硬盘上，可以手动触发，也可以通过配置文件自动执行。</p>\n<p>RDB持久化后的文件是一个经过压缩的二进制文件，redis可以通过这个文件进行数据还原。</p>\n<p>RDB持久化可以通过下面两个命令来触发：</p>\n<ul>\n<li>SAVE: 阻塞Redis进程，知道RDB文件创建完成</li>\n<li>BGSAVE: fork一个子进程来创建RDB文件，</li>\n</ul>\n<h3 id=\"RDB持久化优点\"><a href=\"#RDB持久化优点\" class=\"headerlink\" title=\"RDB持久化优点\"></a>RDB持久化优点</h3><ol>\n<li>一旦采用该方式，那么你的整个Redis数据库将只包含一个文件，这对于文件备份而言是非常完美的。比如，你可能打算每个小时归档一次最近24小时的数据，同时还要每天归档一次最近30天的数据。通过这样的备份策略，一旦系统出现灾难性故障，我们可以非常容易的进行恢复。</li>\n<li>对于灾难恢复而言，RDB是非常不错的选择。因为我们可以非常轻松的将一个单独的文件压缩后再转移到其它存储介质上。</li>\n<li>性能最大化。对于Redis的服务进程而言，在开始持久化时，它唯一需要做的只是fork出子进程，之后再由子进程完成这些持久化的工作，这样就可以极大的避免服务进程执行IO操作了。</li>\n<li>相比于AOF机制，如果数据集很大，RDB的启动效率会更高。</li>\n</ol>\n<h3 id=\"RDB持久化缺点\"><a href=\"#RDB持久化缺点\" class=\"headerlink\" title=\"RDB持久化缺点\"></a>RDB持久化缺点</h3><ol>\n<li>如果你想保证数据的高可用性，即最大限度的避免数据丢失，那么RDB将不是一个很好的选择。因为系统一旦在定时持久化之前出现宕机现象，此前没有来得及写入磁盘的数据都将丢失。</li>\n<li>由于RDB是通过fork子进程来协助完成数据持久化工作的，因此，如果当数据集较大时，可能会导致整个服务器停止服务几百毫秒，甚至是1秒钟。</li>\n</ol>\n<h2 id=\"AOF持久化\"><a href=\"#AOF持久化\" class=\"headerlink\" title=\"AOF持久化\"></a>AOF持久化</h2><p>AOF持久化（Append-Only-File），与RDB持久化不同，AOF持久化是通过保存Redis服务器所执行的写状态来记录数据库的。</p>\n<p>具体来说，RDB持久化相当于备份数据库状态，而AOF持久化是备份数据库接收到的命令，所有被写入AOF的命令都是以redis的协议格式来保存的。</p>\n<p>在AOF持久化的文件中，数据库会记录下所有变更数据库状态的命令，除了指定数据库的select命令，其他的命令都是来自client的，这些命令会以追加(append)的形式保存到文件中。</p>\n<p>服务器配置中有一项appendfsync，这个配置会影响服务器多久完成一次命令的记录：</p>\n<ul>\n<li>always：将缓存区的内容总是即时写到AOF文件中。</li>\n<li>everysec：将缓存区的内容每隔一秒写入AOF文件中。</li>\n<li>no ：写入AOF文件中的操作由操作系统决定，一般而言为了提高效率，操作系统会等待缓存区被填满，才会开始同步数据到磁盘。</li>\n</ul>\n<p>redis默认实用的是everysec。</p>\n<p>redis在载入AOF文件的时候，会创建一个虚拟的client，把AOF中每一条命令都执行一遍，最终还原回数据库的状态，它的载入也是自动的。在RDB和AOF备份文件都有的情况下，redis会优先载入AOF备份文件。</p>\n<p>AOF文件可能会随着服务器运行的时间越来越大，可以利用AOF重写的功能，来控制AOF文件的大小。AOF重写功能会首先读取数据库中现有的键值对状态，然后根据类型使用一条命令来替代前的键值对多条命令。</p>\n<p>AOF重写功能有大量写入操作，所以redis才用子进程来处理AOF重写。这里带来一个新的问题，由于处理重新的是子进程，这样意味着如果主线程的数据在此时被修改，备份的数据和主库的数据将会有不一致的情况发生。因此redis还设置了一个AOF重写缓冲区，这个缓冲区在子进程被创建开始之后开始使用，这个期间，所有的命令会被存两份，一份在AOF缓存空间，一份在AOF重写缓冲区，当AOF重写完成之后，子进程发送信号给主进程，通知主进程将AOF重写缓冲区的内容添加到AOF文件中。</p>\n<h3 id=\"AOF的优点\"><a href=\"#AOF的优点\" class=\"headerlink\" title=\"AOF的优点\"></a>AOF的优点</h3><ol>\n<li>该机制可以带来更高的数据安全性，即数据持久性。Redis中提供了3中同步策略，即everysec、always和no。事实上，everysec也是异步完成的，其效率也是非常高的，所差的是一旦系统出现宕机现象，那么这一秒钟之内修改的数据将会丢失。而always，我们可以将其视为同步持久化，即每次发生的数据变化都会被立即记录到磁盘中。可以预见，这种方式在效率上是最低的。至于no，无需多言，我想大家都能正确的理解它。</li>\n<li>由于该机制对日志文件的写入操作采用的是append模式，因此在写入过程中即使出现宕机现象，也不会破坏日志文件中已经存在的内容。然而如果我们本次操作只是写入了一半数据就出现了系统崩溃问题，不用担心，在Redis下一次启动之前，我们可以通过redis-check-aof工具来帮助我们解决数据一致性的问题。</li>\n<li>如果日志过大，Redis可以自动启用rewrite机制。即Redis以append模式不断的将修改数据写入到老的磁盘文件中，同时Redis还会创建一个新的文件用于记录此期间有哪些修改命令被执行。因此在进行rewrite切换时可以更好的保证数据安全性。</li>\n<li>AOF包含一个格式清晰、易于理解的日志文件用于记录所有的修改操作。事实上，我们也可以通过该文件完成数据的重建。</li>\n</ol>\n<h3 id=\"AOF的缺点\"><a href=\"#AOF的缺点\" class=\"headerlink\" title=\"AOF的缺点\"></a>AOF的缺点</h3><ol>\n<li>对于相同数量的数据集而言，AOF文件通常要大于RDB文件。RDB 在恢复大数据集时的速度比 AOF 的恢复速度要快。</li>\n<li>根据同步策略的不同，AOF在运行效率上往往会慢于RDB。总之，每秒同步策略的效率是比较高的，no策略的效率和RDB一样高效。</li>\n</ol>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"概述\"><a href=\"#概述\" class=\"headerlink\" title=\"概述\"></a>概述</h2><p>Redis是一种内存型的数据库，一般都是作为缓存使用，数据都是保存在内存中，但为了防止宕机后数据丢失，Redis提供了两种持久化方案，分别是RDB和AOF。接下来介绍一下这两种持久化方案。</p>\n<h2 id=\"RDB持久化\"><a href=\"#RDB持久化\" class=\"headerlink\" title=\"RDB持久化\"></a>RDB持久化</h2><p>RDB持久化可以把当前Redis内存中的状态保存到硬盘上，可以手动触发，也可以通过配置文件自动执行。</p>\n<p>RDB持久化后的文件是一个经过压缩的二进制文件，redis可以通过这个文件进行数据还原。</p>\n<p>RDB持久化可以通过下面两个命令来触发：</p>\n<ul>\n<li>SAVE: 阻塞Redis进程，知道RDB文件创建完成</li>\n<li>BGSAVE: fork一个子进程来创建RDB文件，</li>\n</ul>\n<h3 id=\"RDB持久化优点\"><a href=\"#RDB持久化优点\" class=\"headerlink\" title=\"RDB持久化优点\"></a>RDB持久化优点</h3><ol>\n<li>一旦采用该方式，那么你的整个Redis数据库将只包含一个文件，这对于文件备份而言是非常完美的。比如，你可能打算每个小时归档一次最近24小时的数据，同时还要每天归档一次最近30天的数据。通过这样的备份策略，一旦系统出现灾难性故障，我们可以非常容易的进行恢复。</li>\n<li>对于灾难恢复而言，RDB是非常不错的选择。因为我们可以非常轻松的将一个单独的文件压缩后再转移到其它存储介质上。</li>\n<li>性能最大化。对于Redis的服务进程而言，在开始持久化时，它唯一需要做的只是fork出子进程，之后再由子进程完成这些持久化的工作，这样就可以极大的避免服务进程执行IO操作了。</li>\n<li>相比于AOF机制，如果数据集很大，RDB的启动效率会更高。</li>\n</ol>\n<h3 id=\"RDB持久化缺点\"><a href=\"#RDB持久化缺点\" class=\"headerlink\" title=\"RDB持久化缺点\"></a>RDB持久化缺点</h3><ol>\n<li>如果你想保证数据的高可用性，即最大限度的避免数据丢失，那么RDB将不是一个很好的选择。因为系统一旦在定时持久化之前出现宕机现象，此前没有来得及写入磁盘的数据都将丢失。</li>\n<li>由于RDB是通过fork子进程来协助完成数据持久化工作的，因此，如果当数据集较大时，可能会导致整个服务器停止服务几百毫秒，甚至是1秒钟。</li>\n</ol>\n<h2 id=\"AOF持久化\"><a href=\"#AOF持久化\" class=\"headerlink\" title=\"AOF持久化\"></a>AOF持久化</h2><p>AOF持久化（Append-Only-File），与RDB持久化不同，AOF持久化是通过保存Redis服务器所执行的写状态来记录数据库的。</p>\n<p>具体来说，RDB持久化相当于备份数据库状态，而AOF持久化是备份数据库接收到的命令，所有被写入AOF的命令都是以redis的协议格式来保存的。</p>\n<p>在AOF持久化的文件中，数据库会记录下所有变更数据库状态的命令，除了指定数据库的select命令，其他的命令都是来自client的，这些命令会以追加(append)的形式保存到文件中。</p>\n<p>服务器配置中有一项appendfsync，这个配置会影响服务器多久完成一次命令的记录：</p>\n<ul>\n<li>always：将缓存区的内容总是即时写到AOF文件中。</li>\n<li>everysec：将缓存区的内容每隔一秒写入AOF文件中。</li>\n<li>no ：写入AOF文件中的操作由操作系统决定，一般而言为了提高效率，操作系统会等待缓存区被填满，才会开始同步数据到磁盘。</li>\n</ul>\n<p>redis默认实用的是everysec。</p>\n<p>redis在载入AOF文件的时候，会创建一个虚拟的client，把AOF中每一条命令都执行一遍，最终还原回数据库的状态，它的载入也是自动的。在RDB和AOF备份文件都有的情况下，redis会优先载入AOF备份文件。</p>\n<p>AOF文件可能会随着服务器运行的时间越来越大，可以利用AOF重写的功能，来控制AOF文件的大小。AOF重写功能会首先读取数据库中现有的键值对状态，然后根据类型使用一条命令来替代前的键值对多条命令。</p>\n<p>AOF重写功能有大量写入操作，所以redis才用子进程来处理AOF重写。这里带来一个新的问题，由于处理重新的是子进程，这样意味着如果主线程的数据在此时被修改，备份的数据和主库的数据将会有不一致的情况发生。因此redis还设置了一个AOF重写缓冲区，这个缓冲区在子进程被创建开始之后开始使用，这个期间，所有的命令会被存两份，一份在AOF缓存空间，一份在AOF重写缓冲区，当AOF重写完成之后，子进程发送信号给主进程，通知主进程将AOF重写缓冲区的内容添加到AOF文件中。</p>\n<h3 id=\"AOF的优点\"><a href=\"#AOF的优点\" class=\"headerlink\" title=\"AOF的优点\"></a>AOF的优点</h3><ol>\n<li>该机制可以带来更高的数据安全性，即数据持久性。Redis中提供了3中同步策略，即everysec、always和no。事实上，everysec也是异步完成的，其效率也是非常高的，所差的是一旦系统出现宕机现象，那么这一秒钟之内修改的数据将会丢失。而always，我们可以将其视为同步持久化，即每次发生的数据变化都会被立即记录到磁盘中。可以预见，这种方式在效率上是最低的。至于no，无需多言，我想大家都能正确的理解它。</li>\n<li>由于该机制对日志文件的写入操作采用的是append模式，因此在写入过程中即使出现宕机现象，也不会破坏日志文件中已经存在的内容。然而如果我们本次操作只是写入了一半数据就出现了系统崩溃问题，不用担心，在Redis下一次启动之前，我们可以通过redis-check-aof工具来帮助我们解决数据一致性的问题。</li>\n<li>如果日志过大，Redis可以自动启用rewrite机制。即Redis以append模式不断的将修改数据写入到老的磁盘文件中，同时Redis还会创建一个新的文件用于记录此期间有哪些修改命令被执行。因此在进行rewrite切换时可以更好的保证数据安全性。</li>\n<li>AOF包含一个格式清晰、易于理解的日志文件用于记录所有的修改操作。事实上，我们也可以通过该文件完成数据的重建。</li>\n</ol>\n<h3 id=\"AOF的缺点\"><a href=\"#AOF的缺点\" class=\"headerlink\" title=\"AOF的缺点\"></a>AOF的缺点</h3><ol>\n<li>对于相同数量的数据集而言，AOF文件通常要大于RDB文件。RDB 在恢复大数据集时的速度比 AOF 的恢复速度要快。</li>\n<li>根据同步策略的不同，AOF在运行效率上往往会慢于RDB。总之，每秒同步策略的效率是比较高的，no策略的效率和RDB一样高效。</li>\n</ol>\n"},{"title":"reposync","date":"2018-06-12T10:40:40.000Z","_content":"\n在某些环境中，是不能上外网的，这就需要搭建一个内部的yum源，供内网的服务器安装软件。\n\n那如何把公网的yum源下载下来能，这可以通过使用yum-utils工具包来完成\n\n`\nyum install yum-utils -y\n`\n\n安装完成之后就可以使用reposync命令来同步yum源了\n\n通过下面的命令可以查看当前配置的yum源\n\n`\nyum repolist\n`\n\n找到需要同步的yum源，通过下面的命令进行同步\n\n`\nreposync --repoid=<$reponame> --download_path=<$path>\n`\n\n这样就把公网的yum源同步到本地磁盘了，以后就可以通过下载下来的内容搭建内网yum源\n","source":"_posts/reposync.md","raw":"---\ntitle: reposync\ndate: 2018-06-12 18:40:40\ntags: ['linux']\n---\n\n在某些环境中，是不能上外网的，这就需要搭建一个内部的yum源，供内网的服务器安装软件。\n\n那如何把公网的yum源下载下来能，这可以通过使用yum-utils工具包来完成\n\n`\nyum install yum-utils -y\n`\n\n安装完成之后就可以使用reposync命令来同步yum源了\n\n通过下面的命令可以查看当前配置的yum源\n\n`\nyum repolist\n`\n\n找到需要同步的yum源，通过下面的命令进行同步\n\n`\nreposync --repoid=<$reponame> --download_path=<$path>\n`\n\n这样就把公网的yum源同步到本地磁盘了，以后就可以通过下载下来的内容搭建内网yum源\n","slug":"reposync","published":1,"updated":"2018-06-23T07:52:08.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck1pzbth5000ntp75gxqxhlwi","content":"<p>在某些环境中，是不能上外网的，这就需要搭建一个内部的yum源，供内网的服务器安装软件。</p>\n<p>那如何把公网的yum源下载下来能，这可以通过使用yum-utils工具包来完成</p>\n<p><code>yum install yum-utils -y</code></p>\n<p>安装完成之后就可以使用reposync命令来同步yum源了</p>\n<p>通过下面的命令可以查看当前配置的yum源</p>\n<p><code>yum repolist</code></p>\n<p>找到需要同步的yum源，通过下面的命令进行同步</p>\n<p><code>reposync --repoid=&lt;$reponame&gt; --download_path=&lt;$path&gt;</code></p>\n<p>这样就把公网的yum源同步到本地磁盘了，以后就可以通过下载下来的内容搭建内网yum源</p>\n","site":{"data":{}},"excerpt":"","more":"<p>在某些环境中，是不能上外网的，这就需要搭建一个内部的yum源，供内网的服务器安装软件。</p>\n<p>那如何把公网的yum源下载下来能，这可以通过使用yum-utils工具包来完成</p>\n<p><code>yum install yum-utils -y</code></p>\n<p>安装完成之后就可以使用reposync命令来同步yum源了</p>\n<p>通过下面的命令可以查看当前配置的yum源</p>\n<p><code>yum repolist</code></p>\n<p>找到需要同步的yum源，通过下面的命令进行同步</p>\n<p><code>reposync --repoid=&lt;$reponame&gt; --download_path=&lt;$path&gt;</code></p>\n<p>这样就把公网的yum源同步到本地磁盘了，以后就可以通过下载下来的内容搭建内网yum源</p>\n"},{"title":"Ceph对象存储使用纠删码存储池","date":"2019-03-13T07:05:34.000Z","_content":"\n# 概述\n本文主要验证ceph对象存储使用纠删码的情况  \n本文中纠删码的配置K+M为 4+2，理论上可以容忍M个osd的故障ceph\n\n\n# 配置\n\n创建erasure-code-profile和crush rule\n\n```\n[root@ceph04 ~]# ceph osd erasure-code-profile set rgw_ec_profile k=4 m=2 crush-root=root_rgw plugin=isa crush-failure-domain=host\n[root@ceph04 ~]# ceph osd erasure-code-profile get rgw_ec_profile\ncrush-device-class=\ncrush-failure-domain=host\ncrush-root=root_rgw\nk=4\nm=2\nplugin=isa\ntechnique=reed_sol_van\n```\n\n```\n[root@ceph04 ~]# ceph osd crush rule create-erasure rgw_ec_rule rgw_ec_profile\ncreated rule rgw_ec_rule at 2\n[root@ceph04 ~]# ceph osd crush rule dump\n[\n    {\n        \"rule_id\": 0,\n        \"rule_name\": \"replicated_rule\",\n        \"ruleset\": 0,\n        \"type\": 1,\n        \"min_size\": 1,\n        \"max_size\": 10,\n        \"steps\": [\n            {\n                \"op\": \"take\",\n                \"item\": -1,\n                \"item_name\": \"default\"\n            },\n            {\n                \"op\": \"chooseleaf_firstn\",\n                \"num\": 0,\n                \"type\": \"host\"\n            },\n            {\n                \"op\": \"emit\"\n            }\n        ]\n    },\n    {\n        \"rule_id\": 1,\n        \"rule_name\": \"rule_rgw\",\n        \"ruleset\": 1,\n        \"type\": 1,\n        \"min_size\": 1,\n        \"max_size\": 10,\n        \"steps\": [\n            {\n                \"op\": \"take\",\n                \"item\": -13,\n                \"item_name\": \"root_rgw\"\n            },\n            {\n                \"op\": \"chooseleaf_firstn\",\n                \"num\": 0,\n                \"type\": \"host\"\n            },\n            {\n                \"op\": \"emit\"\n            }\n        ]\n    },\n    {\n        \"rule_id\": 2,\n        \"rule_name\": \"rgw_ec_rule\",\n        \"ruleset\": 2,\n        \"type\": 3,\n        \"min_size\": 3,\n        \"max_size\": 6,\n        \"steps\": [\n            {\n                \"op\": \"set_chooseleaf_tries\",\n                \"num\": 5\n            },\n            {\n                \"op\": \"set_choose_tries\",\n                \"num\": 100\n            },\n            {\n                \"op\": \"take\",\n                \"item\": -13,\n                \"item_name\": \"root_rgw\"\n            },\n            {\n                \"op\": \"chooseleaf_indep\",\n                \"num\": 0,\n                \"type\": \"host\"\n            },\n            {\n                \"op\": \"emit\"\n            }\n        ]\n    }\n]\n```\n由于实验环境只有3个节点，需要调整crush rule，先选择3个host，再在每个host选择两个osd\n\n```\nceph osd getcrushmap -o crushmap\n\ncrushtool -d crushmap -o crushmap.txt\n```\n\n```\nrule rgw_ec_rule {\n        id 2\n        type erasure\n        min_size 3\n        max_size 6\n        step set_chooseleaf_tries 5\n        step set_choose_tries 100\n        step take root_rgw\n        step choose indep 3 type host\n        step choose indep 2 type osd\n        step emit\n}\n```\n\n```\ncrushtool -c crushmap.txt -o crushmap\nceph osd setcrushmap -i crushmap\n```\n\n由于环境中还没有任何数据，我们先停止rgw，然后把默认的default.rgw.buckets.data存储池删掉，再创建一个纠删码的default.rgw.buckets.data存储池\n\n```\n[root@ceph04 ~]# ceph osd pool create default.rgw.buckets.data 64 64 erasure rgw_ec_profile rgw_ec_rule\npool 'default.rgw.buckets.data' created\n\n[root@ceph04 ~]# ceph osd pool application enable default.rgw.buckets.data rgw\nenabled application 'rgw' on pool 'default.rgw.buckets.data'\n\n[root@ceph04 ~]# ceph -s\n  cluster:\n    id:     57df615e-6dec-4f69-84f0-72a2ba76d4d7\n    health: HEALTH_WARN\n            noout flag(s) set\n            too few PGs per OSD (21 < min 30)\n            clock skew detected on mon.ceph04\n\n  services:\n    mon: 3 daemons, quorum ceph06,ceph05,ceph04\n    mgr: ceph04(active), standbys: ceph06, ceph05\n    osd: 18 osds: 18 up, 18 in\n         flags noout\n\n  data:\n    pools:   1 pools, 64 pgs\n    objects: 0 objects, 0 bytes\n    usage:   19351 MB used, 339 GB / 358 GB avail\n    pgs:     64 active+clean\n\n```\n\n可以看到默认创建的存储池的size是k+m=6, min_size=k-m+1=5, 当存储池的当前size小于min_size的时候，pg会出现incomplete的情况，所以在还需要调整存储池的min_size为4，这样就可以容忍2个osd节点故障。\n\n```\n[root@ceph04 ~]# ceph osd pool ls detail\npool 33 'default.rgw.buckets.data' erasure size 6 min_size 5 crush_rule 2 object_hash rjenkins pg_num 64 pgp_num 64 last_change 466 flags hashpspool stripe_width 16384 application rgw\npool 34 '.rgw.root' replicated size 3 min_size 2 crush_rule 0 object_hash rjenkins pg_num 8 pgp_num 8 last_change 405 flags hashpspool stripe_width 0 application rgw\npool 35 'default.rgw.meta' replicated size 3 min_size 2 crush_rule 0 object_hash rjenkins pg_num 8 pgp_num 8 last_change 407 flags hashpspool stripe_width 0 application rgw\npool 36 'default.rgw.log' replicated size 3 min_size 2 crush_rule 0 object_hash rjenkins pg_num 8 pgp_num 8 last_change 409 flags hashpspool stripe_width 0 application rgw\npool 37 'default.rgw.buckets.index' replicated size 3 min_size 2 crush_rule 0 object_hash rjenkins pg_num 8 pgp_num 8 last_change 412 flags hashpspool stripe_width 0 application rgw\n\n\n[root@ceph04 ~]# ceph osd pool set default.rgw.buckets.data min_size 4\nset pool 33 min_size to 4\n[root@ceph04 ~]# ceph osd pool ls detail\npool 33 'default.rgw.buckets.data' erasure size 6 min_size 4 crush_rule 2 object_hash rjenkins pg_num 64 pgp_num 64 last_change 483 flags hashpspool stripe_width 16384 application rgw\npool 34 '.rgw.root' replicated size 3 min_size 2 crush_rule 0 object_hash rjenkins pg_num 8 pgp_num 8 last_change 405 flags hashpspool stripe_width 0 application rgw\npool 35 'default.rgw.meta' replicated size 3 min_size 2 crush_rule 0 object_hash rjenkins pg_num 8 pgp_num 8 last_change 407 flags hashpspool stripe_width 0 application rgw\npool 36 'default.rgw.log' replicated size 3 min_size 2 crush_rule 0 object_hash rjenkins pg_num 8 pgp_num 8 last_change 409 flags hashpspool stripe_width 0 application rgw\npool 37 'default.rgw.buckets.index' replicated size 3 min_size 2 crush_rule 0 object_hash rjenkins pg_num 8 pgp_num 8 last_change 412 flags hashpspool stripe_width 0 application rgw\n\n```\n\n# 验证\n\n创建对象存储用户，并用s3cmd进行验证\n\n```\n[root@ceph04 ~]# radosgw-admin user create --uid=test --display-name=test\n{\n    \"user_id\": \"test\",\n    \"display_name\": \"test\",\n    \"email\": \"\",\n    \"suspended\": 0,\n    \"max_buckets\": 1000,\n    \"auid\": 0,\n    \"subusers\": [],\n    \"keys\": [\n        {\n            \"user\": \"test\",\n            \"access_key\": \"DE8EBP0W6WSO9SGYGV66\",\n            \"secret_key\": \"AG6ufkpWuO4pUtJLOKKimfZNvVmwVsMkeXZmmBgi\"\n        }\n    ],\n    \"swift_keys\": [],\n    \"caps\": [],\n    \"op_mask\": \"read, write, delete\",\n    \"default_placement\": \"\",\n    \"placement_tags\": [],\n    \"bucket_quota\": {\n        \"enabled\": false,\n        \"check_on_raw\": false,\n        \"max_size\": -1,\n        \"max_size_kb\": 0,\n        \"max_objects\": -1\n    },\n    \"user_quota\": {\n        \"enabled\": false,\n        \"check_on_raw\": false,\n        \"max_size\": -1,\n        \"max_size_kb\": 0,\n        \"max_objects\": -1\n    },\n    \"temp_url_keys\": [],\n    \"type\": \"rgw\"\n}\n```\n\n```\n[root@ceph04 ~]# s3cmd ls s3://\n[root@ceph04 ~]# s3cmd mb s3://test\nBucket 's3://test/' created\n```\n\n停掉2个osd，pg也没有出现incomplete的状态, 通过s3cmd也可以正常上传下载\n\n```\n[root@ceph04 ~]# systemctl stop ceph-osd@0\n[root@ceph04 ~]# systemctl stop ceph-osd@1\n[root@ceph04 ~]# ceph -s\n  cluster:\n    id:     57df615e-6dec-4f69-84f0-72a2ba76d4d7\n    health: HEALTH_WARN\n            noout flag(s) set\n            2 osds down\n            Degraded data redundancy: 471/3570 objects degraded (13.193%), 12 pgs degraded\n            too few PGs per OSD (26 < min 30)\n            clock skew detected on mon.ceph05, mon.ceph04\n\n  services:\n    mon: 3 daemons, quorum ceph06,ceph05,ceph04\n    mgr: ceph04(active), standbys: ceph06, ceph05\n    osd: 18 osds: 16 up, 18 in\n         flags noout\n    rgw: 1 daemon active\n\n  data:\n    pools:   5 pools, 96 pgs\n    objects: 1184 objects, 15056 kB\n    usage:   19554 MB used, 339 GB / 358 GB avail\n    pgs:     471/3570 objects degraded (13.193%)\n             43 active+undersized\n             41 active+clean\n             12 active+undersized+degraded\n\n  io:\n    client:   170 B/s rd, 0 B/s wr, 0 op/s rd, 0 op/s wr\n```\n\n\n# 参考\n* [http://www.zphj1987.com/2018/06/12/ceph-erasure-default-min-size/](http://www.zphj1987.com/2018/06/12/ceph-erasure-default-min-size/)\n","source":"_posts/rgw-with-ec.md","raw":"---\ntitle: Ceph对象存储使用纠删码存储池\ndate: 2019-03-13 15:05:34\ntags: ceph\n---\n\n# 概述\n本文主要验证ceph对象存储使用纠删码的情况  \n本文中纠删码的配置K+M为 4+2，理论上可以容忍M个osd的故障ceph\n\n\n# 配置\n\n创建erasure-code-profile和crush rule\n\n```\n[root@ceph04 ~]# ceph osd erasure-code-profile set rgw_ec_profile k=4 m=2 crush-root=root_rgw plugin=isa crush-failure-domain=host\n[root@ceph04 ~]# ceph osd erasure-code-profile get rgw_ec_profile\ncrush-device-class=\ncrush-failure-domain=host\ncrush-root=root_rgw\nk=4\nm=2\nplugin=isa\ntechnique=reed_sol_van\n```\n\n```\n[root@ceph04 ~]# ceph osd crush rule create-erasure rgw_ec_rule rgw_ec_profile\ncreated rule rgw_ec_rule at 2\n[root@ceph04 ~]# ceph osd crush rule dump\n[\n    {\n        \"rule_id\": 0,\n        \"rule_name\": \"replicated_rule\",\n        \"ruleset\": 0,\n        \"type\": 1,\n        \"min_size\": 1,\n        \"max_size\": 10,\n        \"steps\": [\n            {\n                \"op\": \"take\",\n                \"item\": -1,\n                \"item_name\": \"default\"\n            },\n            {\n                \"op\": \"chooseleaf_firstn\",\n                \"num\": 0,\n                \"type\": \"host\"\n            },\n            {\n                \"op\": \"emit\"\n            }\n        ]\n    },\n    {\n        \"rule_id\": 1,\n        \"rule_name\": \"rule_rgw\",\n        \"ruleset\": 1,\n        \"type\": 1,\n        \"min_size\": 1,\n        \"max_size\": 10,\n        \"steps\": [\n            {\n                \"op\": \"take\",\n                \"item\": -13,\n                \"item_name\": \"root_rgw\"\n            },\n            {\n                \"op\": \"chooseleaf_firstn\",\n                \"num\": 0,\n                \"type\": \"host\"\n            },\n            {\n                \"op\": \"emit\"\n            }\n        ]\n    },\n    {\n        \"rule_id\": 2,\n        \"rule_name\": \"rgw_ec_rule\",\n        \"ruleset\": 2,\n        \"type\": 3,\n        \"min_size\": 3,\n        \"max_size\": 6,\n        \"steps\": [\n            {\n                \"op\": \"set_chooseleaf_tries\",\n                \"num\": 5\n            },\n            {\n                \"op\": \"set_choose_tries\",\n                \"num\": 100\n            },\n            {\n                \"op\": \"take\",\n                \"item\": -13,\n                \"item_name\": \"root_rgw\"\n            },\n            {\n                \"op\": \"chooseleaf_indep\",\n                \"num\": 0,\n                \"type\": \"host\"\n            },\n            {\n                \"op\": \"emit\"\n            }\n        ]\n    }\n]\n```\n由于实验环境只有3个节点，需要调整crush rule，先选择3个host，再在每个host选择两个osd\n\n```\nceph osd getcrushmap -o crushmap\n\ncrushtool -d crushmap -o crushmap.txt\n```\n\n```\nrule rgw_ec_rule {\n        id 2\n        type erasure\n        min_size 3\n        max_size 6\n        step set_chooseleaf_tries 5\n        step set_choose_tries 100\n        step take root_rgw\n        step choose indep 3 type host\n        step choose indep 2 type osd\n        step emit\n}\n```\n\n```\ncrushtool -c crushmap.txt -o crushmap\nceph osd setcrushmap -i crushmap\n```\n\n由于环境中还没有任何数据，我们先停止rgw，然后把默认的default.rgw.buckets.data存储池删掉，再创建一个纠删码的default.rgw.buckets.data存储池\n\n```\n[root@ceph04 ~]# ceph osd pool create default.rgw.buckets.data 64 64 erasure rgw_ec_profile rgw_ec_rule\npool 'default.rgw.buckets.data' created\n\n[root@ceph04 ~]# ceph osd pool application enable default.rgw.buckets.data rgw\nenabled application 'rgw' on pool 'default.rgw.buckets.data'\n\n[root@ceph04 ~]# ceph -s\n  cluster:\n    id:     57df615e-6dec-4f69-84f0-72a2ba76d4d7\n    health: HEALTH_WARN\n            noout flag(s) set\n            too few PGs per OSD (21 < min 30)\n            clock skew detected on mon.ceph04\n\n  services:\n    mon: 3 daemons, quorum ceph06,ceph05,ceph04\n    mgr: ceph04(active), standbys: ceph06, ceph05\n    osd: 18 osds: 18 up, 18 in\n         flags noout\n\n  data:\n    pools:   1 pools, 64 pgs\n    objects: 0 objects, 0 bytes\n    usage:   19351 MB used, 339 GB / 358 GB avail\n    pgs:     64 active+clean\n\n```\n\n可以看到默认创建的存储池的size是k+m=6, min_size=k-m+1=5, 当存储池的当前size小于min_size的时候，pg会出现incomplete的情况，所以在还需要调整存储池的min_size为4，这样就可以容忍2个osd节点故障。\n\n```\n[root@ceph04 ~]# ceph osd pool ls detail\npool 33 'default.rgw.buckets.data' erasure size 6 min_size 5 crush_rule 2 object_hash rjenkins pg_num 64 pgp_num 64 last_change 466 flags hashpspool stripe_width 16384 application rgw\npool 34 '.rgw.root' replicated size 3 min_size 2 crush_rule 0 object_hash rjenkins pg_num 8 pgp_num 8 last_change 405 flags hashpspool stripe_width 0 application rgw\npool 35 'default.rgw.meta' replicated size 3 min_size 2 crush_rule 0 object_hash rjenkins pg_num 8 pgp_num 8 last_change 407 flags hashpspool stripe_width 0 application rgw\npool 36 'default.rgw.log' replicated size 3 min_size 2 crush_rule 0 object_hash rjenkins pg_num 8 pgp_num 8 last_change 409 flags hashpspool stripe_width 0 application rgw\npool 37 'default.rgw.buckets.index' replicated size 3 min_size 2 crush_rule 0 object_hash rjenkins pg_num 8 pgp_num 8 last_change 412 flags hashpspool stripe_width 0 application rgw\n\n\n[root@ceph04 ~]# ceph osd pool set default.rgw.buckets.data min_size 4\nset pool 33 min_size to 4\n[root@ceph04 ~]# ceph osd pool ls detail\npool 33 'default.rgw.buckets.data' erasure size 6 min_size 4 crush_rule 2 object_hash rjenkins pg_num 64 pgp_num 64 last_change 483 flags hashpspool stripe_width 16384 application rgw\npool 34 '.rgw.root' replicated size 3 min_size 2 crush_rule 0 object_hash rjenkins pg_num 8 pgp_num 8 last_change 405 flags hashpspool stripe_width 0 application rgw\npool 35 'default.rgw.meta' replicated size 3 min_size 2 crush_rule 0 object_hash rjenkins pg_num 8 pgp_num 8 last_change 407 flags hashpspool stripe_width 0 application rgw\npool 36 'default.rgw.log' replicated size 3 min_size 2 crush_rule 0 object_hash rjenkins pg_num 8 pgp_num 8 last_change 409 flags hashpspool stripe_width 0 application rgw\npool 37 'default.rgw.buckets.index' replicated size 3 min_size 2 crush_rule 0 object_hash rjenkins pg_num 8 pgp_num 8 last_change 412 flags hashpspool stripe_width 0 application rgw\n\n```\n\n# 验证\n\n创建对象存储用户，并用s3cmd进行验证\n\n```\n[root@ceph04 ~]# radosgw-admin user create --uid=test --display-name=test\n{\n    \"user_id\": \"test\",\n    \"display_name\": \"test\",\n    \"email\": \"\",\n    \"suspended\": 0,\n    \"max_buckets\": 1000,\n    \"auid\": 0,\n    \"subusers\": [],\n    \"keys\": [\n        {\n            \"user\": \"test\",\n            \"access_key\": \"DE8EBP0W6WSO9SGYGV66\",\n            \"secret_key\": \"AG6ufkpWuO4pUtJLOKKimfZNvVmwVsMkeXZmmBgi\"\n        }\n    ],\n    \"swift_keys\": [],\n    \"caps\": [],\n    \"op_mask\": \"read, write, delete\",\n    \"default_placement\": \"\",\n    \"placement_tags\": [],\n    \"bucket_quota\": {\n        \"enabled\": false,\n        \"check_on_raw\": false,\n        \"max_size\": -1,\n        \"max_size_kb\": 0,\n        \"max_objects\": -1\n    },\n    \"user_quota\": {\n        \"enabled\": false,\n        \"check_on_raw\": false,\n        \"max_size\": -1,\n        \"max_size_kb\": 0,\n        \"max_objects\": -1\n    },\n    \"temp_url_keys\": [],\n    \"type\": \"rgw\"\n}\n```\n\n```\n[root@ceph04 ~]# s3cmd ls s3://\n[root@ceph04 ~]# s3cmd mb s3://test\nBucket 's3://test/' created\n```\n\n停掉2个osd，pg也没有出现incomplete的状态, 通过s3cmd也可以正常上传下载\n\n```\n[root@ceph04 ~]# systemctl stop ceph-osd@0\n[root@ceph04 ~]# systemctl stop ceph-osd@1\n[root@ceph04 ~]# ceph -s\n  cluster:\n    id:     57df615e-6dec-4f69-84f0-72a2ba76d4d7\n    health: HEALTH_WARN\n            noout flag(s) set\n            2 osds down\n            Degraded data redundancy: 471/3570 objects degraded (13.193%), 12 pgs degraded\n            too few PGs per OSD (26 < min 30)\n            clock skew detected on mon.ceph05, mon.ceph04\n\n  services:\n    mon: 3 daemons, quorum ceph06,ceph05,ceph04\n    mgr: ceph04(active), standbys: ceph06, ceph05\n    osd: 18 osds: 16 up, 18 in\n         flags noout\n    rgw: 1 daemon active\n\n  data:\n    pools:   5 pools, 96 pgs\n    objects: 1184 objects, 15056 kB\n    usage:   19554 MB used, 339 GB / 358 GB avail\n    pgs:     471/3570 objects degraded (13.193%)\n             43 active+undersized\n             41 active+clean\n             12 active+undersized+degraded\n\n  io:\n    client:   170 B/s rd, 0 B/s wr, 0 op/s rd, 0 op/s wr\n```\n\n\n# 参考\n* [http://www.zphj1987.com/2018/06/12/ceph-erasure-default-min-size/](http://www.zphj1987.com/2018/06/12/ceph-erasure-default-min-size/)\n","slug":"rgw-with-ec","published":1,"updated":"2019-03-14T06:48:08.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck1pzbth6000ptp75kbjr704f","content":"<h1 id=\"概述\"><a href=\"#概述\" class=\"headerlink\" title=\"概述\"></a>概述</h1><p>本文主要验证ceph对象存储使用纠删码的情况<br>本文中纠删码的配置K+M为 4+2，理论上可以容忍M个osd的故障ceph</p>\n<h1 id=\"配置\"><a href=\"#配置\" class=\"headerlink\" title=\"配置\"></a>配置</h1><p>创建erasure-code-profile和crush rule</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@ceph04 ~]# ceph osd erasure-code-profile set rgw_ec_profile k=4 m=2 crush-root=root_rgw plugin=isa crush-failure-domain=host</span><br><span class=\"line\">[root@ceph04 ~]# ceph osd erasure-code-profile get rgw_ec_profile</span><br><span class=\"line\">crush-device-class=</span><br><span class=\"line\">crush-failure-domain=host</span><br><span class=\"line\">crush-root=root_rgw</span><br><span class=\"line\">k=4</span><br><span class=\"line\">m=2</span><br><span class=\"line\">plugin=isa</span><br><span class=\"line\">technique=reed_sol_van</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@ceph04 ~]# ceph osd crush rule create-erasure rgw_ec_rule rgw_ec_profile</span><br><span class=\"line\">created rule rgw_ec_rule at 2</span><br><span class=\"line\">[root@ceph04 ~]# ceph osd crush rule dump</span><br><span class=\"line\">[</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        &quot;rule_id&quot;: 0,</span><br><span class=\"line\">        &quot;rule_name&quot;: &quot;replicated_rule&quot;,</span><br><span class=\"line\">        &quot;ruleset&quot;: 0,</span><br><span class=\"line\">        &quot;type&quot;: 1,</span><br><span class=\"line\">        &quot;min_size&quot;: 1,</span><br><span class=\"line\">        &quot;max_size&quot;: 10,</span><br><span class=\"line\">        &quot;steps&quot;: [</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                &quot;op&quot;: &quot;take&quot;,</span><br><span class=\"line\">                &quot;item&quot;: -1,</span><br><span class=\"line\">                &quot;item_name&quot;: &quot;default&quot;</span><br><span class=\"line\">            &#125;,</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                &quot;op&quot;: &quot;chooseleaf_firstn&quot;,</span><br><span class=\"line\">                &quot;num&quot;: 0,</span><br><span class=\"line\">                &quot;type&quot;: &quot;host&quot;</span><br><span class=\"line\">            &#125;,</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                &quot;op&quot;: &quot;emit&quot;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        ]</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        &quot;rule_id&quot;: 1,</span><br><span class=\"line\">        &quot;rule_name&quot;: &quot;rule_rgw&quot;,</span><br><span class=\"line\">        &quot;ruleset&quot;: 1,</span><br><span class=\"line\">        &quot;type&quot;: 1,</span><br><span class=\"line\">        &quot;min_size&quot;: 1,</span><br><span class=\"line\">        &quot;max_size&quot;: 10,</span><br><span class=\"line\">        &quot;steps&quot;: [</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                &quot;op&quot;: &quot;take&quot;,</span><br><span class=\"line\">                &quot;item&quot;: -13,</span><br><span class=\"line\">                &quot;item_name&quot;: &quot;root_rgw&quot;</span><br><span class=\"line\">            &#125;,</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                &quot;op&quot;: &quot;chooseleaf_firstn&quot;,</span><br><span class=\"line\">                &quot;num&quot;: 0,</span><br><span class=\"line\">                &quot;type&quot;: &quot;host&quot;</span><br><span class=\"line\">            &#125;,</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                &quot;op&quot;: &quot;emit&quot;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        ]</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        &quot;rule_id&quot;: 2,</span><br><span class=\"line\">        &quot;rule_name&quot;: &quot;rgw_ec_rule&quot;,</span><br><span class=\"line\">        &quot;ruleset&quot;: 2,</span><br><span class=\"line\">        &quot;type&quot;: 3,</span><br><span class=\"line\">        &quot;min_size&quot;: 3,</span><br><span class=\"line\">        &quot;max_size&quot;: 6,</span><br><span class=\"line\">        &quot;steps&quot;: [</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                &quot;op&quot;: &quot;set_chooseleaf_tries&quot;,</span><br><span class=\"line\">                &quot;num&quot;: 5</span><br><span class=\"line\">            &#125;,</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                &quot;op&quot;: &quot;set_choose_tries&quot;,</span><br><span class=\"line\">                &quot;num&quot;: 100</span><br><span class=\"line\">            &#125;,</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                &quot;op&quot;: &quot;take&quot;,</span><br><span class=\"line\">                &quot;item&quot;: -13,</span><br><span class=\"line\">                &quot;item_name&quot;: &quot;root_rgw&quot;</span><br><span class=\"line\">            &#125;,</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                &quot;op&quot;: &quot;chooseleaf_indep&quot;,</span><br><span class=\"line\">                &quot;num&quot;: 0,</span><br><span class=\"line\">                &quot;type&quot;: &quot;host&quot;</span><br><span class=\"line\">            &#125;,</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                &quot;op&quot;: &quot;emit&quot;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        ]</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">]</span><br></pre></td></tr></table></figure>\n<p>由于实验环境只有3个节点，需要调整crush rule，先选择3个host，再在每个host选择两个osd</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ceph osd getcrushmap -o crushmap</span><br><span class=\"line\"></span><br><span class=\"line\">crushtool -d crushmap -o crushmap.txt</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">rule rgw_ec_rule &#123;</span><br><span class=\"line\">        id 2</span><br><span class=\"line\">        type erasure</span><br><span class=\"line\">        min_size 3</span><br><span class=\"line\">        max_size 6</span><br><span class=\"line\">        step set_chooseleaf_tries 5</span><br><span class=\"line\">        step set_choose_tries 100</span><br><span class=\"line\">        step take root_rgw</span><br><span class=\"line\">        step choose indep 3 type host</span><br><span class=\"line\">        step choose indep 2 type osd</span><br><span class=\"line\">        step emit</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">crushtool -c crushmap.txt -o crushmap</span><br><span class=\"line\">ceph osd setcrushmap -i crushmap</span><br></pre></td></tr></table></figure>\n<p>由于环境中还没有任何数据，我们先停止rgw，然后把默认的default.rgw.buckets.data存储池删掉，再创建一个纠删码的default.rgw.buckets.data存储池</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@ceph04 ~]# ceph osd pool create default.rgw.buckets.data 64 64 erasure rgw_ec_profile rgw_ec_rule</span><br><span class=\"line\">pool &apos;default.rgw.buckets.data&apos; created</span><br><span class=\"line\"></span><br><span class=\"line\">[root@ceph04 ~]# ceph osd pool application enable default.rgw.buckets.data rgw</span><br><span class=\"line\">enabled application &apos;rgw&apos; on pool &apos;default.rgw.buckets.data&apos;</span><br><span class=\"line\"></span><br><span class=\"line\">[root@ceph04 ~]# ceph -s</span><br><span class=\"line\">  cluster:</span><br><span class=\"line\">    id:     57df615e-6dec-4f69-84f0-72a2ba76d4d7</span><br><span class=\"line\">    health: HEALTH_WARN</span><br><span class=\"line\">            noout flag(s) set</span><br><span class=\"line\">            too few PGs per OSD (21 &lt; min 30)</span><br><span class=\"line\">            clock skew detected on mon.ceph04</span><br><span class=\"line\"></span><br><span class=\"line\">  services:</span><br><span class=\"line\">    mon: 3 daemons, quorum ceph06,ceph05,ceph04</span><br><span class=\"line\">    mgr: ceph04(active), standbys: ceph06, ceph05</span><br><span class=\"line\">    osd: 18 osds: 18 up, 18 in</span><br><span class=\"line\">         flags noout</span><br><span class=\"line\"></span><br><span class=\"line\">  data:</span><br><span class=\"line\">    pools:   1 pools, 64 pgs</span><br><span class=\"line\">    objects: 0 objects, 0 bytes</span><br><span class=\"line\">    usage:   19351 MB used, 339 GB / 358 GB avail</span><br><span class=\"line\">    pgs:     64 active+clean</span><br></pre></td></tr></table></figure>\n<p>可以看到默认创建的存储池的size是k+m=6, min_size=k-m+1=5, 当存储池的当前size小于min_size的时候，pg会出现incomplete的情况，所以在还需要调整存储池的min_size为4，这样就可以容忍2个osd节点故障。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@ceph04 ~]# ceph osd pool ls detail</span><br><span class=\"line\">pool 33 &apos;default.rgw.buckets.data&apos; erasure size 6 min_size 5 crush_rule 2 object_hash rjenkins pg_num 64 pgp_num 64 last_change 466 flags hashpspool stripe_width 16384 application rgw</span><br><span class=\"line\">pool 34 &apos;.rgw.root&apos; replicated size 3 min_size 2 crush_rule 0 object_hash rjenkins pg_num 8 pgp_num 8 last_change 405 flags hashpspool stripe_width 0 application rgw</span><br><span class=\"line\">pool 35 &apos;default.rgw.meta&apos; replicated size 3 min_size 2 crush_rule 0 object_hash rjenkins pg_num 8 pgp_num 8 last_change 407 flags hashpspool stripe_width 0 application rgw</span><br><span class=\"line\">pool 36 &apos;default.rgw.log&apos; replicated size 3 min_size 2 crush_rule 0 object_hash rjenkins pg_num 8 pgp_num 8 last_change 409 flags hashpspool stripe_width 0 application rgw</span><br><span class=\"line\">pool 37 &apos;default.rgw.buckets.index&apos; replicated size 3 min_size 2 crush_rule 0 object_hash rjenkins pg_num 8 pgp_num 8 last_change 412 flags hashpspool stripe_width 0 application rgw</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">[root@ceph04 ~]# ceph osd pool set default.rgw.buckets.data min_size 4</span><br><span class=\"line\">set pool 33 min_size to 4</span><br><span class=\"line\">[root@ceph04 ~]# ceph osd pool ls detail</span><br><span class=\"line\">pool 33 &apos;default.rgw.buckets.data&apos; erasure size 6 min_size 4 crush_rule 2 object_hash rjenkins pg_num 64 pgp_num 64 last_change 483 flags hashpspool stripe_width 16384 application rgw</span><br><span class=\"line\">pool 34 &apos;.rgw.root&apos; replicated size 3 min_size 2 crush_rule 0 object_hash rjenkins pg_num 8 pgp_num 8 last_change 405 flags hashpspool stripe_width 0 application rgw</span><br><span class=\"line\">pool 35 &apos;default.rgw.meta&apos; replicated size 3 min_size 2 crush_rule 0 object_hash rjenkins pg_num 8 pgp_num 8 last_change 407 flags hashpspool stripe_width 0 application rgw</span><br><span class=\"line\">pool 36 &apos;default.rgw.log&apos; replicated size 3 min_size 2 crush_rule 0 object_hash rjenkins pg_num 8 pgp_num 8 last_change 409 flags hashpspool stripe_width 0 application rgw</span><br><span class=\"line\">pool 37 &apos;default.rgw.buckets.index&apos; replicated size 3 min_size 2 crush_rule 0 object_hash rjenkins pg_num 8 pgp_num 8 last_change 412 flags hashpspool stripe_width 0 application rgw</span><br></pre></td></tr></table></figure>\n<h1 id=\"验证\"><a href=\"#验证\" class=\"headerlink\" title=\"验证\"></a>验证</h1><p>创建对象存储用户，并用s3cmd进行验证</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@ceph04 ~]# radosgw-admin user create --uid=test --display-name=test</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    &quot;user_id&quot;: &quot;test&quot;,</span><br><span class=\"line\">    &quot;display_name&quot;: &quot;test&quot;,</span><br><span class=\"line\">    &quot;email&quot;: &quot;&quot;,</span><br><span class=\"line\">    &quot;suspended&quot;: 0,</span><br><span class=\"line\">    &quot;max_buckets&quot;: 1000,</span><br><span class=\"line\">    &quot;auid&quot;: 0,</span><br><span class=\"line\">    &quot;subusers&quot;: [],</span><br><span class=\"line\">    &quot;keys&quot;: [</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            &quot;user&quot;: &quot;test&quot;,</span><br><span class=\"line\">            &quot;access_key&quot;: &quot;DE8EBP0W6WSO9SGYGV66&quot;,</span><br><span class=\"line\">            &quot;secret_key&quot;: &quot;AG6ufkpWuO4pUtJLOKKimfZNvVmwVsMkeXZmmBgi&quot;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    ],</span><br><span class=\"line\">    &quot;swift_keys&quot;: [],</span><br><span class=\"line\">    &quot;caps&quot;: [],</span><br><span class=\"line\">    &quot;op_mask&quot;: &quot;read, write, delete&quot;,</span><br><span class=\"line\">    &quot;default_placement&quot;: &quot;&quot;,</span><br><span class=\"line\">    &quot;placement_tags&quot;: [],</span><br><span class=\"line\">    &quot;bucket_quota&quot;: &#123;</span><br><span class=\"line\">        &quot;enabled&quot;: false,</span><br><span class=\"line\">        &quot;check_on_raw&quot;: false,</span><br><span class=\"line\">        &quot;max_size&quot;: -1,</span><br><span class=\"line\">        &quot;max_size_kb&quot;: 0,</span><br><span class=\"line\">        &quot;max_objects&quot;: -1</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    &quot;user_quota&quot;: &#123;</span><br><span class=\"line\">        &quot;enabled&quot;: false,</span><br><span class=\"line\">        &quot;check_on_raw&quot;: false,</span><br><span class=\"line\">        &quot;max_size&quot;: -1,</span><br><span class=\"line\">        &quot;max_size_kb&quot;: 0,</span><br><span class=\"line\">        &quot;max_objects&quot;: -1</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    &quot;temp_url_keys&quot;: [],</span><br><span class=\"line\">    &quot;type&quot;: &quot;rgw&quot;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@ceph04 ~]# s3cmd ls s3://</span><br><span class=\"line\">[root@ceph04 ~]# s3cmd mb s3://test</span><br><span class=\"line\">Bucket &apos;s3://test/&apos; created</span><br></pre></td></tr></table></figure>\n<p>停掉2个osd，pg也没有出现incomplete的状态, 通过s3cmd也可以正常上传下载</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@ceph04 ~]# systemctl stop ceph-osd@0</span><br><span class=\"line\">[root@ceph04 ~]# systemctl stop ceph-osd@1</span><br><span class=\"line\">[root@ceph04 ~]# ceph -s</span><br><span class=\"line\">  cluster:</span><br><span class=\"line\">    id:     57df615e-6dec-4f69-84f0-72a2ba76d4d7</span><br><span class=\"line\">    health: HEALTH_WARN</span><br><span class=\"line\">            noout flag(s) set</span><br><span class=\"line\">            2 osds down</span><br><span class=\"line\">            Degraded data redundancy: 471/3570 objects degraded (13.193%), 12 pgs degraded</span><br><span class=\"line\">            too few PGs per OSD (26 &lt; min 30)</span><br><span class=\"line\">            clock skew detected on mon.ceph05, mon.ceph04</span><br><span class=\"line\"></span><br><span class=\"line\">  services:</span><br><span class=\"line\">    mon: 3 daemons, quorum ceph06,ceph05,ceph04</span><br><span class=\"line\">    mgr: ceph04(active), standbys: ceph06, ceph05</span><br><span class=\"line\">    osd: 18 osds: 16 up, 18 in</span><br><span class=\"line\">         flags noout</span><br><span class=\"line\">    rgw: 1 daemon active</span><br><span class=\"line\"></span><br><span class=\"line\">  data:</span><br><span class=\"line\">    pools:   5 pools, 96 pgs</span><br><span class=\"line\">    objects: 1184 objects, 15056 kB</span><br><span class=\"line\">    usage:   19554 MB used, 339 GB / 358 GB avail</span><br><span class=\"line\">    pgs:     471/3570 objects degraded (13.193%)</span><br><span class=\"line\">             43 active+undersized</span><br><span class=\"line\">             41 active+clean</span><br><span class=\"line\">             12 active+undersized+degraded</span><br><span class=\"line\"></span><br><span class=\"line\">  io:</span><br><span class=\"line\">    client:   170 B/s rd, 0 B/s wr, 0 op/s rd, 0 op/s wr</span><br></pre></td></tr></table></figure>\n<h1 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h1><ul>\n<li><a href=\"http://www.zphj1987.com/2018/06/12/ceph-erasure-default-min-size/\" target=\"_blank\" rel=\"noopener\">http://www.zphj1987.com/2018/06/12/ceph-erasure-default-min-size/</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"概述\"><a href=\"#概述\" class=\"headerlink\" title=\"概述\"></a>概述</h1><p>本文主要验证ceph对象存储使用纠删码的情况<br>本文中纠删码的配置K+M为 4+2，理论上可以容忍M个osd的故障ceph</p>\n<h1 id=\"配置\"><a href=\"#配置\" class=\"headerlink\" title=\"配置\"></a>配置</h1><p>创建erasure-code-profile和crush rule</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@ceph04 ~]# ceph osd erasure-code-profile set rgw_ec_profile k=4 m=2 crush-root=root_rgw plugin=isa crush-failure-domain=host</span><br><span class=\"line\">[root@ceph04 ~]# ceph osd erasure-code-profile get rgw_ec_profile</span><br><span class=\"line\">crush-device-class=</span><br><span class=\"line\">crush-failure-domain=host</span><br><span class=\"line\">crush-root=root_rgw</span><br><span class=\"line\">k=4</span><br><span class=\"line\">m=2</span><br><span class=\"line\">plugin=isa</span><br><span class=\"line\">technique=reed_sol_van</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@ceph04 ~]# ceph osd crush rule create-erasure rgw_ec_rule rgw_ec_profile</span><br><span class=\"line\">created rule rgw_ec_rule at 2</span><br><span class=\"line\">[root@ceph04 ~]# ceph osd crush rule dump</span><br><span class=\"line\">[</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        &quot;rule_id&quot;: 0,</span><br><span class=\"line\">        &quot;rule_name&quot;: &quot;replicated_rule&quot;,</span><br><span class=\"line\">        &quot;ruleset&quot;: 0,</span><br><span class=\"line\">        &quot;type&quot;: 1,</span><br><span class=\"line\">        &quot;min_size&quot;: 1,</span><br><span class=\"line\">        &quot;max_size&quot;: 10,</span><br><span class=\"line\">        &quot;steps&quot;: [</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                &quot;op&quot;: &quot;take&quot;,</span><br><span class=\"line\">                &quot;item&quot;: -1,</span><br><span class=\"line\">                &quot;item_name&quot;: &quot;default&quot;</span><br><span class=\"line\">            &#125;,</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                &quot;op&quot;: &quot;chooseleaf_firstn&quot;,</span><br><span class=\"line\">                &quot;num&quot;: 0,</span><br><span class=\"line\">                &quot;type&quot;: &quot;host&quot;</span><br><span class=\"line\">            &#125;,</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                &quot;op&quot;: &quot;emit&quot;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        ]</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        &quot;rule_id&quot;: 1,</span><br><span class=\"line\">        &quot;rule_name&quot;: &quot;rule_rgw&quot;,</span><br><span class=\"line\">        &quot;ruleset&quot;: 1,</span><br><span class=\"line\">        &quot;type&quot;: 1,</span><br><span class=\"line\">        &quot;min_size&quot;: 1,</span><br><span class=\"line\">        &quot;max_size&quot;: 10,</span><br><span class=\"line\">        &quot;steps&quot;: [</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                &quot;op&quot;: &quot;take&quot;,</span><br><span class=\"line\">                &quot;item&quot;: -13,</span><br><span class=\"line\">                &quot;item_name&quot;: &quot;root_rgw&quot;</span><br><span class=\"line\">            &#125;,</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                &quot;op&quot;: &quot;chooseleaf_firstn&quot;,</span><br><span class=\"line\">                &quot;num&quot;: 0,</span><br><span class=\"line\">                &quot;type&quot;: &quot;host&quot;</span><br><span class=\"line\">            &#125;,</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                &quot;op&quot;: &quot;emit&quot;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        ]</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        &quot;rule_id&quot;: 2,</span><br><span class=\"line\">        &quot;rule_name&quot;: &quot;rgw_ec_rule&quot;,</span><br><span class=\"line\">        &quot;ruleset&quot;: 2,</span><br><span class=\"line\">        &quot;type&quot;: 3,</span><br><span class=\"line\">        &quot;min_size&quot;: 3,</span><br><span class=\"line\">        &quot;max_size&quot;: 6,</span><br><span class=\"line\">        &quot;steps&quot;: [</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                &quot;op&quot;: &quot;set_chooseleaf_tries&quot;,</span><br><span class=\"line\">                &quot;num&quot;: 5</span><br><span class=\"line\">            &#125;,</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                &quot;op&quot;: &quot;set_choose_tries&quot;,</span><br><span class=\"line\">                &quot;num&quot;: 100</span><br><span class=\"line\">            &#125;,</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                &quot;op&quot;: &quot;take&quot;,</span><br><span class=\"line\">                &quot;item&quot;: -13,</span><br><span class=\"line\">                &quot;item_name&quot;: &quot;root_rgw&quot;</span><br><span class=\"line\">            &#125;,</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                &quot;op&quot;: &quot;chooseleaf_indep&quot;,</span><br><span class=\"line\">                &quot;num&quot;: 0,</span><br><span class=\"line\">                &quot;type&quot;: &quot;host&quot;</span><br><span class=\"line\">            &#125;,</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                &quot;op&quot;: &quot;emit&quot;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        ]</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">]</span><br></pre></td></tr></table></figure>\n<p>由于实验环境只有3个节点，需要调整crush rule，先选择3个host，再在每个host选择两个osd</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ceph osd getcrushmap -o crushmap</span><br><span class=\"line\"></span><br><span class=\"line\">crushtool -d crushmap -o crushmap.txt</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">rule rgw_ec_rule &#123;</span><br><span class=\"line\">        id 2</span><br><span class=\"line\">        type erasure</span><br><span class=\"line\">        min_size 3</span><br><span class=\"line\">        max_size 6</span><br><span class=\"line\">        step set_chooseleaf_tries 5</span><br><span class=\"line\">        step set_choose_tries 100</span><br><span class=\"line\">        step take root_rgw</span><br><span class=\"line\">        step choose indep 3 type host</span><br><span class=\"line\">        step choose indep 2 type osd</span><br><span class=\"line\">        step emit</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">crushtool -c crushmap.txt -o crushmap</span><br><span class=\"line\">ceph osd setcrushmap -i crushmap</span><br></pre></td></tr></table></figure>\n<p>由于环境中还没有任何数据，我们先停止rgw，然后把默认的default.rgw.buckets.data存储池删掉，再创建一个纠删码的default.rgw.buckets.data存储池</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@ceph04 ~]# ceph osd pool create default.rgw.buckets.data 64 64 erasure rgw_ec_profile rgw_ec_rule</span><br><span class=\"line\">pool &apos;default.rgw.buckets.data&apos; created</span><br><span class=\"line\"></span><br><span class=\"line\">[root@ceph04 ~]# ceph osd pool application enable default.rgw.buckets.data rgw</span><br><span class=\"line\">enabled application &apos;rgw&apos; on pool &apos;default.rgw.buckets.data&apos;</span><br><span class=\"line\"></span><br><span class=\"line\">[root@ceph04 ~]# ceph -s</span><br><span class=\"line\">  cluster:</span><br><span class=\"line\">    id:     57df615e-6dec-4f69-84f0-72a2ba76d4d7</span><br><span class=\"line\">    health: HEALTH_WARN</span><br><span class=\"line\">            noout flag(s) set</span><br><span class=\"line\">            too few PGs per OSD (21 &lt; min 30)</span><br><span class=\"line\">            clock skew detected on mon.ceph04</span><br><span class=\"line\"></span><br><span class=\"line\">  services:</span><br><span class=\"line\">    mon: 3 daemons, quorum ceph06,ceph05,ceph04</span><br><span class=\"line\">    mgr: ceph04(active), standbys: ceph06, ceph05</span><br><span class=\"line\">    osd: 18 osds: 18 up, 18 in</span><br><span class=\"line\">         flags noout</span><br><span class=\"line\"></span><br><span class=\"line\">  data:</span><br><span class=\"line\">    pools:   1 pools, 64 pgs</span><br><span class=\"line\">    objects: 0 objects, 0 bytes</span><br><span class=\"line\">    usage:   19351 MB used, 339 GB / 358 GB avail</span><br><span class=\"line\">    pgs:     64 active+clean</span><br></pre></td></tr></table></figure>\n<p>可以看到默认创建的存储池的size是k+m=6, min_size=k-m+1=5, 当存储池的当前size小于min_size的时候，pg会出现incomplete的情况，所以在还需要调整存储池的min_size为4，这样就可以容忍2个osd节点故障。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@ceph04 ~]# ceph osd pool ls detail</span><br><span class=\"line\">pool 33 &apos;default.rgw.buckets.data&apos; erasure size 6 min_size 5 crush_rule 2 object_hash rjenkins pg_num 64 pgp_num 64 last_change 466 flags hashpspool stripe_width 16384 application rgw</span><br><span class=\"line\">pool 34 &apos;.rgw.root&apos; replicated size 3 min_size 2 crush_rule 0 object_hash rjenkins pg_num 8 pgp_num 8 last_change 405 flags hashpspool stripe_width 0 application rgw</span><br><span class=\"line\">pool 35 &apos;default.rgw.meta&apos; replicated size 3 min_size 2 crush_rule 0 object_hash rjenkins pg_num 8 pgp_num 8 last_change 407 flags hashpspool stripe_width 0 application rgw</span><br><span class=\"line\">pool 36 &apos;default.rgw.log&apos; replicated size 3 min_size 2 crush_rule 0 object_hash rjenkins pg_num 8 pgp_num 8 last_change 409 flags hashpspool stripe_width 0 application rgw</span><br><span class=\"line\">pool 37 &apos;default.rgw.buckets.index&apos; replicated size 3 min_size 2 crush_rule 0 object_hash rjenkins pg_num 8 pgp_num 8 last_change 412 flags hashpspool stripe_width 0 application rgw</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">[root@ceph04 ~]# ceph osd pool set default.rgw.buckets.data min_size 4</span><br><span class=\"line\">set pool 33 min_size to 4</span><br><span class=\"line\">[root@ceph04 ~]# ceph osd pool ls detail</span><br><span class=\"line\">pool 33 &apos;default.rgw.buckets.data&apos; erasure size 6 min_size 4 crush_rule 2 object_hash rjenkins pg_num 64 pgp_num 64 last_change 483 flags hashpspool stripe_width 16384 application rgw</span><br><span class=\"line\">pool 34 &apos;.rgw.root&apos; replicated size 3 min_size 2 crush_rule 0 object_hash rjenkins pg_num 8 pgp_num 8 last_change 405 flags hashpspool stripe_width 0 application rgw</span><br><span class=\"line\">pool 35 &apos;default.rgw.meta&apos; replicated size 3 min_size 2 crush_rule 0 object_hash rjenkins pg_num 8 pgp_num 8 last_change 407 flags hashpspool stripe_width 0 application rgw</span><br><span class=\"line\">pool 36 &apos;default.rgw.log&apos; replicated size 3 min_size 2 crush_rule 0 object_hash rjenkins pg_num 8 pgp_num 8 last_change 409 flags hashpspool stripe_width 0 application rgw</span><br><span class=\"line\">pool 37 &apos;default.rgw.buckets.index&apos; replicated size 3 min_size 2 crush_rule 0 object_hash rjenkins pg_num 8 pgp_num 8 last_change 412 flags hashpspool stripe_width 0 application rgw</span><br></pre></td></tr></table></figure>\n<h1 id=\"验证\"><a href=\"#验证\" class=\"headerlink\" title=\"验证\"></a>验证</h1><p>创建对象存储用户，并用s3cmd进行验证</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@ceph04 ~]# radosgw-admin user create --uid=test --display-name=test</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    &quot;user_id&quot;: &quot;test&quot;,</span><br><span class=\"line\">    &quot;display_name&quot;: &quot;test&quot;,</span><br><span class=\"line\">    &quot;email&quot;: &quot;&quot;,</span><br><span class=\"line\">    &quot;suspended&quot;: 0,</span><br><span class=\"line\">    &quot;max_buckets&quot;: 1000,</span><br><span class=\"line\">    &quot;auid&quot;: 0,</span><br><span class=\"line\">    &quot;subusers&quot;: [],</span><br><span class=\"line\">    &quot;keys&quot;: [</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            &quot;user&quot;: &quot;test&quot;,</span><br><span class=\"line\">            &quot;access_key&quot;: &quot;DE8EBP0W6WSO9SGYGV66&quot;,</span><br><span class=\"line\">            &quot;secret_key&quot;: &quot;AG6ufkpWuO4pUtJLOKKimfZNvVmwVsMkeXZmmBgi&quot;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    ],</span><br><span class=\"line\">    &quot;swift_keys&quot;: [],</span><br><span class=\"line\">    &quot;caps&quot;: [],</span><br><span class=\"line\">    &quot;op_mask&quot;: &quot;read, write, delete&quot;,</span><br><span class=\"line\">    &quot;default_placement&quot;: &quot;&quot;,</span><br><span class=\"line\">    &quot;placement_tags&quot;: [],</span><br><span class=\"line\">    &quot;bucket_quota&quot;: &#123;</span><br><span class=\"line\">        &quot;enabled&quot;: false,</span><br><span class=\"line\">        &quot;check_on_raw&quot;: false,</span><br><span class=\"line\">        &quot;max_size&quot;: -1,</span><br><span class=\"line\">        &quot;max_size_kb&quot;: 0,</span><br><span class=\"line\">        &quot;max_objects&quot;: -1</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    &quot;user_quota&quot;: &#123;</span><br><span class=\"line\">        &quot;enabled&quot;: false,</span><br><span class=\"line\">        &quot;check_on_raw&quot;: false,</span><br><span class=\"line\">        &quot;max_size&quot;: -1,</span><br><span class=\"line\">        &quot;max_size_kb&quot;: 0,</span><br><span class=\"line\">        &quot;max_objects&quot;: -1</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    &quot;temp_url_keys&quot;: [],</span><br><span class=\"line\">    &quot;type&quot;: &quot;rgw&quot;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@ceph04 ~]# s3cmd ls s3://</span><br><span class=\"line\">[root@ceph04 ~]# s3cmd mb s3://test</span><br><span class=\"line\">Bucket &apos;s3://test/&apos; created</span><br></pre></td></tr></table></figure>\n<p>停掉2个osd，pg也没有出现incomplete的状态, 通过s3cmd也可以正常上传下载</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@ceph04 ~]# systemctl stop ceph-osd@0</span><br><span class=\"line\">[root@ceph04 ~]# systemctl stop ceph-osd@1</span><br><span class=\"line\">[root@ceph04 ~]# ceph -s</span><br><span class=\"line\">  cluster:</span><br><span class=\"line\">    id:     57df615e-6dec-4f69-84f0-72a2ba76d4d7</span><br><span class=\"line\">    health: HEALTH_WARN</span><br><span class=\"line\">            noout flag(s) set</span><br><span class=\"line\">            2 osds down</span><br><span class=\"line\">            Degraded data redundancy: 471/3570 objects degraded (13.193%), 12 pgs degraded</span><br><span class=\"line\">            too few PGs per OSD (26 &lt; min 30)</span><br><span class=\"line\">            clock skew detected on mon.ceph05, mon.ceph04</span><br><span class=\"line\"></span><br><span class=\"line\">  services:</span><br><span class=\"line\">    mon: 3 daemons, quorum ceph06,ceph05,ceph04</span><br><span class=\"line\">    mgr: ceph04(active), standbys: ceph06, ceph05</span><br><span class=\"line\">    osd: 18 osds: 16 up, 18 in</span><br><span class=\"line\">         flags noout</span><br><span class=\"line\">    rgw: 1 daemon active</span><br><span class=\"line\"></span><br><span class=\"line\">  data:</span><br><span class=\"line\">    pools:   5 pools, 96 pgs</span><br><span class=\"line\">    objects: 1184 objects, 15056 kB</span><br><span class=\"line\">    usage:   19554 MB used, 339 GB / 358 GB avail</span><br><span class=\"line\">    pgs:     471/3570 objects degraded (13.193%)</span><br><span class=\"line\">             43 active+undersized</span><br><span class=\"line\">             41 active+clean</span><br><span class=\"line\">             12 active+undersized+degraded</span><br><span class=\"line\"></span><br><span class=\"line\">  io:</span><br><span class=\"line\">    client:   170 B/s rd, 0 B/s wr, 0 op/s rd, 0 op/s wr</span><br></pre></td></tr></table></figure>\n<h1 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h1><ul>\n<li><a href=\"http://www.zphj1987.com/2018/06/12/ceph-erasure-default-min-size/\" target=\"_blank\" rel=\"noopener\">http://www.zphj1987.com/2018/06/12/ceph-erasure-default-min-size/</a></li>\n</ul>\n"},{"title":"Ceph RGW multi site 配置","date":"2019-03-09T12:04:30.000Z","_content":"\n# 概述\n本文主要介绍如何配置Ceph RGW的异步复制功能，通过这个功能可以实现跨数据中心的灾备功能。  \nRGW多活方式是在同一zonegroup的多个zone之间进行，即同一zonegroup中多个zone之间的数据是完全一致的，用户可以通过任意zone读写同一份数据。 但是，对元数据的操作，比如创建桶、创建用户，仍然只能在master zone进行。对数据的操作，比如创建桶中的对象，访问对象等，可以在任意zone中 处理.\n\n# 环境\n实验环境是两个ceph集群，信息如下：  \n集群ceph101  \n\n```\n[root@ceph101 ~]# ceph -s\n  cluster:\n    id:     d6e42188-9871-471b-9db0-957f47893902\n    health: HEALTH_OK\n\n  services:\n    mon: 1 daemons, quorum ceph101\n    mgr: ceph101(active)\n    osd: 3 osds: 3 up, 3 in\n    rgw: 1 daemon active\n\n  data:\n    pools:   4 pools, 32 pgs\n    objects: 187 objects, 1.09KiB\n    usage:   3.01GiB used, 56.7GiB / 59.7GiB avail\n    pgs:     32 active+clean\n```\n\n\n集群ceph102  \n\n```\n[root@ceph102 ~]# ceph -s\n  cluster:\n    id:     2e80de18-e95f-463f-9eb0-531fd3254f0b\n    health: HEALTH_OK\n\n  services:\n    mon: 1 daemons, quorum ceph102\n    mgr: ceph102(active)\n    osd: 3 osds: 3 up, 3 in\n    rgw: 1 daemon active\n\n  data:\n    pools:   4 pools, 32 pgs\n    objects: 187 objects, 1.09KiB\n    usage:   3.01GiB used, 56.7GiB / 59.7GiB avail\n    pgs:     32 active+clean\n```\n\n这两个ceph集群都一个rgw服务，本次实验就通过这两个ceph集群验证rgw multi site的配置，已经功能的验证。  \n本次实验已第一个集群(ceph101)做为主集群，ceph102作为备集群。\n\n# Multi Site 配置\n\n在主集群创建一个名为realm100的realm\n\n```\n[root@ceph101 ~]# radosgw-admin realm create --rgw-realm=realm100 --default\n{\n    \"id\": \"337cd1c3-1ad0-4975-b220-e021a7f2b3eb\",\n    \"name\": \"realm100\",\n    \"current_period\": \"bd6ecbd6-3a28-46d7-a806-22e9ea001ca3\",\n    \"epoch\": 1\n}\n```\n\n创建master zonegroup\n\n```\n[root@ceph101 ~]# radosgw-admin zonegroup create --rgw-zonegroup=cn --endpoints=http://172.16.143.201:8080 --rgw-realm=realm100 --master --default\n{\n    \"id\": \"2b3f1ea0-73e7-4f17-b4f9-1acf5d5c6033\",\n    \"name\": \"cn\",\n    \"api_name\": \"cn\",\n    \"is_master\": \"true\",\n    \"endpoints\": [\n        \"http://172.16.143.201:8080\"\n    ],\n    \"hostnames\": [],\n    \"hostnames_s3website\": [],\n    \"master_zone\": \"\",\n    \"zones\": [],\n    \"placement_targets\": [],\n    \"default_placement\": \"\",\n    \"realm_id\": \"ba638e8a-8a33-4607-8fe3-13aa69dd1758\"\n}\n```\n\n创建master zone\n\n```\n[root@ceph101 ~]# radosgw-admin zone create --rgw-zonegroup=cn --rgw-zone=shanghai --master --default --endpoints=http://172.16.143.201:8080\n{\n    \"id\": \"9c655173-6346-47e7-9759-5e5d32aa017d\",\n    \"name\": \"shanghai\",\n    \"domain_root\": \"shanghai.rgw.meta:root\",\n    \"control_pool\": \"shanghai.rgw.control\",\n    \"gc_pool\": \"shanghai.rgw.log:gc\",\n    \"lc_pool\": \"shanghai.rgw.log:lc\",\n    \"log_pool\": \"shanghai.rgw.log\",\n    \"intent_log_pool\": \"shanghai.rgw.log:intent\",\n    \"usage_log_pool\": \"shanghai.rgw.log:usage\",\n    \"reshard_pool\": \"shanghai.rgw.log:reshard\",\n    \"user_keys_pool\": \"shanghai.rgw.meta:users.keys\",\n    \"user_email_pool\": \"shanghai.rgw.meta:users.email\",\n    \"user_swift_pool\": \"shanghai.rgw.meta:users.swift\",\n    \"user_uid_pool\": \"shanghai.rgw.meta:users.uid\",\n    \"system_key\": {\n        \"access_key\": \"\",\n        \"secret_key\": \"\"\n    },\n    \"placement_pools\": [\n        {\n            \"key\": \"default-placement\",\n            \"val\": {\n                \"index_pool\": \"shanghai.rgw.buckets.index\",\n                \"data_pool\": \"shanghai.rgw.buckets.data\",\n                \"data_extra_pool\": \"shanghai.rgw.buckets.non-ec\",\n                \"index_type\": 0,\n                \"compression\": \"\"\n            }\n        }\n    ],\n    \"metadata_heap\": \"\",\n    \"tier_config\": [],\n    \"realm_id\": \"ba638e8a-8a33-4607-8fe3-13aa69dd1758\"\n}\n```\n\n更新period\n\n```\n[root@ceph101 ~]# radosgw-admin period update --commit\n{\n    \"id\": \"064c5b5e-eb87-462c-aa37-c420ddd68b23\",\n    \"epoch\": 1,\n    \"predecessor_uuid\": \"1abfe2d0-7453-4c01-881b-3db7f53f15c1\",\n    \"sync_status\": [],\n    \"period_map\": {\n        \"id\": \"064c5b5e-eb87-462c-aa37-c420ddd68b23\",\n        \"zonegroups\": [\n            {\n                \"id\": \"2b3f1ea0-73e7-4f17-b4f9-1acf5d5c6033\",\n                \"name\": \"cn\",\n                \"api_name\": \"cn\",\n                \"is_master\": \"true\",\n                \"endpoints\": [\n                    \"http://172.16.143.201:8080\"\n                ],\n                \"hostnames\": [],\n                \"hostnames_s3website\": [],\n                \"master_zone\": \"9c655173-6346-47e7-9759-5e5d32aa017d\",\n                \"zones\": [\n                    {\n                        \"id\": \"9c655173-6346-47e7-9759-5e5d32aa017d\",\n                        \"name\": \"shanghai\",\n                        \"endpoints\": [\n                            \"http://172.16.143.201:8080\"\n                        ],\n                        \"log_meta\": \"false\",\n                        \"log_data\": \"false\",\n                        \"bucket_index_max_shards\": 0,\n                        \"read_only\": \"false\",\n                        \"tier_type\": \"\",\n                        \"sync_from_all\": \"true\",\n                        \"sync_from\": []\n                    }\n                ],\n                \"placement_targets\": [\n                    {\n                        \"name\": \"default-placement\",\n                        \"tags\": []\n                    }\n                ],\n                \"default_placement\": \"default-placement\",\n                \"realm_id\": \"ba638e8a-8a33-4607-8fe3-13aa69dd1758\"\n            }\n        ],\n        \"short_zone_ids\": [\n            {\n                \"key\": \"9c655173-6346-47e7-9759-5e5d32aa017d\",\n                \"val\": 1556250220\n            }\n        ]\n    },\n    \"master_zonegroup\": \"2b3f1ea0-73e7-4f17-b4f9-1acf5d5c6033\",\n    \"master_zone\": \"9c655173-6346-47e7-9759-5e5d32aa017d\",\n    \"period_config\": {\n        \"bucket_quota\": {\n            \"enabled\": false,\n            \"check_on_raw\": false,\n            \"max_size\": -1,\n            \"max_size_kb\": 0,\n            \"max_objects\": -1\n        },\n        \"user_quota\": {\n            \"enabled\": false,\n            \"check_on_raw\": false,\n            \"max_size\": -1,\n            \"max_size_kb\": 0,\n            \"max_objects\": -1\n        }\n    },\n    \"realm_id\": \"ba638e8a-8a33-4607-8fe3-13aa69dd1758\",\n    \"realm_name\": \"realm100\",\n    \"realm_epoch\": 2\n}\n```\n\n创建同步用户\n\n```\n[root@ceph101 ~]# radosgw-admin user create --uid=\"syncuser\" --display-name=\"Synchronization User\" --system\n{\n    \"user_id\": \"syncuser\",\n    \"display_name\": \"Synchronization User\",\n    \"email\": \"\",\n    \"suspended\": 0,\n    \"max_buckets\": 1000,\n    \"auid\": 0,\n    \"subusers\": [],\n    \"keys\": [\n        {\n            \"user\": \"syncuser\",\n            \"access_key\": \"LPTHGKYO5ULI48Q88AWF\",\n            \"secret_key\": \"jGFoORTVt72frRYsmcnPOpGXnz652Dl3C2IeBLN8\"\n        }\n    ],\n    \"swift_keys\": [],\n    \"caps\": [],\n    \"op_mask\": \"read, write, delete\",\n    \"system\": \"true\",\n    \"default_placement\": \"\",\n    \"placement_tags\": [],\n    \"bucket_quota\": {\n        \"enabled\": false,\n        \"check_on_raw\": false,\n        \"max_size\": -1,\n        \"max_size_kb\": 0,\n        \"max_objects\": -1\n    },\n    \"user_quota\": {\n        \"enabled\": false,\n        \"check_on_raw\": false,\n        \"max_size\": -1,\n        \"max_size_kb\": 0,\n        \"max_objects\": -1\n    },\n    \"temp_url_keys\": [],\n    \"type\": \"rgw\"\n}\n```\n\n修改zone的key，并更新period\n\n```\n[root@ceph101 ~]# radosgw-admin zone modify --rgw-zone=shanghai --access-key=LPTHGKYO5ULI48Q88AWF --secret=jGFoORTVt72frRYsmcnPOpGXnz652Dl3C2IeBLN8\n\n[root@ceph101 ~]# radosgw-admin period update --commit\n{\n    \"id\": \"064c5b5e-eb87-462c-aa37-c420ddd68b23\",\n    \"epoch\": 2,\n    \"predecessor_uuid\": \"1abfe2d0-7453-4c01-881b-3db7f53f15c1\",\n    \"sync_status\": [],\n    \"period_map\": {\n        \"id\": \"064c5b5e-eb87-462c-aa37-c420ddd68b23\",\n        \"zonegroups\": [\n            {\n                \"id\": \"2b3f1ea0-73e7-4f17-b4f9-1acf5d5c6033\",\n                \"name\": \"cn\",\n                \"api_name\": \"cn\",\n                \"is_master\": \"true\",\n                \"endpoints\": [\n                    \"http://172.16.143.201:8080\"\n                ],\n                \"hostnames\": [],\n                \"hostnames_s3website\": [],\n                \"master_zone\": \"9c655173-6346-47e7-9759-5e5d32aa017d\",\n                \"zones\": [\n                    {\n                        \"id\": \"9c655173-6346-47e7-9759-5e5d32aa017d\",\n                        \"name\": \"shanghai\",\n                        \"endpoints\": [\n                            \"http://172.16.143.201:8080\"\n                        ],\n                        \"log_meta\": \"false\",\n                        \"log_data\": \"false\",\n                        \"bucket_index_max_shards\": 0,\n                        \"read_only\": \"false\",\n                        \"tier_type\": \"\",\n                        \"sync_from_all\": \"true\",\n                        \"sync_from\": []\n                    }\n                ],\n                \"placement_targets\": [\n                    {\n                        \"name\": \"default-placement\",\n                        \"tags\": []\n                    }\n                ],\n                \"default_placement\": \"default-placement\",\n                \"realm_id\": \"ba638e8a-8a33-4607-8fe3-13aa69dd1758\"\n            }\n        ],\n        \"short_zone_ids\": [\n            {\n                \"key\": \"9c655173-6346-47e7-9759-5e5d32aa017d\",\n                \"val\": 1556250220\n            }\n        ]\n    },\n    \"master_zonegroup\": \"2b3f1ea0-73e7-4f17-b4f9-1acf5d5c6033\",\n    \"master_zone\": \"9c655173-6346-47e7-9759-5e5d32aa017d\",\n    \"period_config\": {\n        \"bucket_quota\": {\n            \"enabled\": false,\n            \"check_on_raw\": false,\n            \"max_size\": -1,\n            \"max_size_kb\": 0,\n            \"max_objects\": -1\n        },\n        \"user_quota\": {\n            \"enabled\": false,\n            \"check_on_raw\": false,\n            \"max_size\": -1,\n            \"max_size_kb\": 0,\n            \"max_objects\": -1\n        }\n    },\n    \"realm_id\": \"ba638e8a-8a33-4607-8fe3-13aa69dd1758\",\n    \"realm_name\": \"realm100\",\n    \"realm_epoch\": 2\n}\n```\n\n删除默认zone和zonegroup\n\n```\n[root@ceph101 ~]# radosgw-admin zonegroup remove --rgw-zonegroup=default --rgw-zone=default\n[root@ceph101 ~]# radosgw-admin period update --commit\n[root@ceph101 ~]# radosgw-admin zone delete --rgw-zone=default\n[root@ceph101 ~]# radosgw-admin period update --commit\n[root@ceph101 ~]# radosgw-admin zonegroup delete --rgw-zonegroup=default\n[root@ceph101 ~]# radosgw-admin period update --commit\n```\n\n删除默认pool\n\n```\n[root@ceph101 ~]# ceph osd pool delete default.rgw.control default.rgw.control --yes-i-really-really-mean-it\npool 'default.rgw.control' removed\n[root@ceph101 ~]# ceph osd pool delete default.rgw.meta default.rgw.meta --yes-i-really-really-mean-it\npool 'default.rgw.meta' removed\n[root@ceph101 ~]# ceph osd pool delete default.rgw.log default.rgw.log --yes-i-really-really-mean-it\npool 'default.rgw.log' removed\n```\n\n修改rgw配置, 增加rgw_zone = shanghai\n\n```\n[root@ceph101 ~]# vim /etc/ceph/ceph.conf\n\n[global]\nfsid = d6e42188-9871-471b-9db0-957f47893902\n\n\n\nmon initial members = ceph101\nmon host = 172.16.143.201\n\npublic network = 172.16.143.0/24\ncluster network = 172.16.140.0/24\n\n\nmon allow pool delete = true\n\n\n[client.rgw.ceph101]\nhost = ceph101\nkeyring = /var/lib/ceph/radosgw/ceph-rgw.ceph101/keyring\nlog file = /var/log/ceph/ceph-rgw-ceph101.log\nrgw frontends = civetweb port=172.16.143.201:8080 num_threads=100\nrgw_zone = shanghai\n```\n\n\n重启rgw，并查看pool是否创建\n\n```\n[root@ceph101 ~]# systemctl restart ceph-radosgw@rgw.ceph101\n[root@ceph101 ~]# ceph osd pool ls\n.rgw.root\nshanghai.rgw.control\nshanghai.rgw.meta\nshanghai.rgw.log\n```\n\n在secondy zone节点进行如下配置：  \n\n同步realm, 并设置realm100为默认的realm\n\n```\n[root@ceph102 ~]# radosgw-admin realm pull --url=http://172.16.143.201:8080 --access-key=LPTHGKYO5ULI48Q88AWF --secret=jGFoORTVt72frRYsmcnPOpGXnz652Dl3C2IeBLN8\n2019-03-09 21:25:10.377485 7fa55aca2dc0  1 found existing latest_epoch 2 >= given epoch 2, returning r=-17\n{\n    \"id\": \"ba638e8a-8a33-4607-8fe3-13aa69dd1758\",\n    \"name\": \"realm100\",\n    \"current_period\": \"064c5b5e-eb87-462c-aa37-c420ddd68b23\",\n    \"epoch\": 2\n}\n\n[root@ceph102 ~]# radosgw-admin realm default --rgw-realm=realm100\n```\n\n更新period\n\n```\n[root@ceph102 ~]# radosgw-admin period pull --url=http://172.16.143.201:8080 --access-key=LPTHGKYO5ULI48Q88AWF --secret=jGFoORTVt72frRYsmcnPOpGXnz652Dl3C2IeBLN8\n{\n    \"id\": \"064c5b5e-eb87-462c-aa37-c420ddd68b23\",\n    \"epoch\": 2,\n    \"predecessor_uuid\": \"1abfe2d0-7453-4c01-881b-3db7f53f15c1\",\n    \"sync_status\": [],\n    \"period_map\": {\n        \"id\": \"064c5b5e-eb87-462c-aa37-c420ddd68b23\",\n        \"zonegroups\": [\n            {\n                \"id\": \"2b3f1ea0-73e7-4f17-b4f9-1acf5d5c6033\",\n                \"name\": \"cn\",\n                \"api_name\": \"cn\",\n                \"is_master\": \"true\",\n                \"endpoints\": [\n                    \"http://172.16.143.201:8080\"\n                ],\n                \"hostnames\": [],\n                \"hostnames_s3website\": [],\n                \"master_zone\": \"9c655173-6346-47e7-9759-5e5d32aa017d\",\n                \"zones\": [\n                    {\n                        \"id\": \"9c655173-6346-47e7-9759-5e5d32aa017d\",\n                        \"name\": \"shanghai\",\n                        \"endpoints\": [\n                            \"http://172.16.143.201:8080\"\n                        ],\n                        \"log_meta\": \"false\",\n                        \"log_data\": \"false\",\n                        \"bucket_index_max_shards\": 0,\n                        \"read_only\": \"false\",\n                        \"tier_type\": \"\",\n                        \"sync_from_all\": \"true\",\n                        \"sync_from\": []\n                    }\n                ],\n                \"placement_targets\": [\n                    {\n                        \"name\": \"default-placement\",\n                        \"tags\": []\n                    }\n                ],\n                \"default_placement\": \"default-placement\",\n                \"realm_id\": \"ba638e8a-8a33-4607-8fe3-13aa69dd1758\"\n            }\n        ],\n        \"short_zone_ids\": [\n            {\n                \"key\": \"9c655173-6346-47e7-9759-5e5d32aa017d\",\n                \"val\": 1556250220\n            }\n        ]\n    },\n    \"master_zonegroup\": \"2b3f1ea0-73e7-4f17-b4f9-1acf5d5c6033\",\n    \"master_zone\": \"9c655173-6346-47e7-9759-5e5d32aa017d\",\n    \"period_config\": {\n        \"bucket_quota\": {\n            \"enabled\": false,\n            \"check_on_raw\": false,\n            \"max_size\": -1,\n            \"max_size_kb\": 0,\n            \"max_objects\": -1\n        },\n        \"user_quota\": {\n            \"enabled\": false,\n            \"check_on_raw\": false,\n            \"max_size\": -1,\n            \"max_size_kb\": 0,\n            \"max_objects\": -1\n        }\n    },\n    \"realm_id\": \"ba638e8a-8a33-4607-8fe3-13aa69dd1758\",\n    \"realm_name\": \"realm100\",\n    \"realm_epoch\": 2\n}\n```\n\n创建secondy zone\n\n```\n[root@ceph102 ~]# radosgw-admin zone create --rgw-zonegroup=cn --rgw-zone=beijing --endpoints=http://172.16.143.202:8080 --access-key=LPTHGKYO5ULI48Q88AWF --secret=jGFoORTVt72frRYsmcnPOpGXnz652Dl3C2IeBLN8\n2019-03-09 21:30:24.323527 7f2441e45dc0  0 failed reading obj info from .rgw.root:zone_info.9c655173-6346-47e7-9759-5e5d32aa017d: (2) No such file or directory\n2019-03-09 21:30:24.323577 7f2441e45dc0  0 WARNING: could not read zone params for zone id=9c655173-6346-47e7-9759-5e5d32aa017d name=shanghai\n{\n    \"id\": \"bf59d999-1561-4f7e-a874-9de718d4c31b\",\n    \"name\": \"beijing\",\n    \"domain_root\": \"beijing.rgw.meta:root\",\n    \"control_pool\": \"beijing.rgw.control\",\n    \"gc_pool\": \"beijing.rgw.log:gc\",\n    \"lc_pool\": \"beijing.rgw.log:lc\",\n    \"log_pool\": \"beijing.rgw.log\",\n    \"intent_log_pool\": \"beijing.rgw.log:intent\",\n    \"usage_log_pool\": \"beijing.rgw.log:usage\",\n    \"reshard_pool\": \"beijing.rgw.log:reshard\",\n    \"user_keys_pool\": \"beijing.rgw.meta:users.keys\",\n    \"user_email_pool\": \"beijing.rgw.meta:users.email\",\n    \"user_swift_pool\": \"beijing.rgw.meta:users.swift\",\n    \"user_uid_pool\": \"beijing.rgw.meta:users.uid\",\n    \"system_key\": {\n        \"access_key\": \"LPTHGKYO5ULI48Q88AWF\",\n        \"secret_key\": \"jGFoORTVt72frRYsmcnPOpGXnz652Dl3C2IeBLN8\"\n    },\n    \"placement_pools\": [\n        {\n            \"key\": \"default-placement\",\n            \"val\": {\n                \"index_pool\": \"beijing.rgw.buckets.index\",\n                \"data_pool\": \"beijing.rgw.buckets.data\",\n                \"data_extra_pool\": \"beijing.rgw.buckets.non-ec\",\n                \"index_type\": 0,\n                \"compression\": \"\"\n            }\n        }\n    ],\n    \"metadata_heap\": \"\",\n    \"tier_config\": [],\n    \"realm_id\": \"ba638e8a-8a33-4607-8fe3-13aa69dd1758\"\n}\n```\n\n删除默认default zone， defaul zonegroup和 default存储池\n\n```\n[root@ceph102 ~]# radosgw-admin zone delete --rgw-zone=default\n2019-03-09 21:31:23.577581 7f2e6c528dc0  0 zone id ce963a6e-7d58-426d-b07a-a2af2983379a is not a part of zonegroup cn\n[root@ceph102 ~]# radosgw-admin zonegroup list\n{\n    \"default_info\": \"2b3f1ea0-73e7-4f17-b4f9-1acf5d5c6033\",\n    \"zonegroups\": [\n        \"cn\",\n        \"default\"\n    ]\n}\n\n[root@ceph102 ~]# radosgw-admin zonegroup delete --rgw-zonegroup=default\n\n[root@ceph102 ~]# ceph osd pool delete default.rgw.control default.rgw.control --yes-i-really-really-mean-it\npool 'default.rgw.control' removed\n[root@ceph102 ~]# ceph osd pool delete default.rgw.meta default.rgw.meta --yes-i-really-really-mean-it\npool 'default.rgw.meta' removed\n[root@ceph102 ~]# ceph osd pool delete default.rgw.log default.rgw.log --yes-i-really-really-mean-it\npool 'default.rgw.log' removed\n```\n\n修改rgw配置, 增加rgw_zone = beijing\n\n```\n[root@ceph101 ~]# vim /etc/ceph/ceph.conf\n\n[global]\nfsid = d6e42188-9871-471b-9db0-957f47893902\n\n\n\nmon initial members = ceph101\nmon host = 172.16.143.201\n\npublic network = 172.16.143.0/24\ncluster network = 172.16.140.0/24\n\n\nmon allow pool delete = true\n\n\n[client.rgw.ceph101]\nhost = ceph101\nkeyring = /var/lib/ceph/radosgw/ceph-rgw.ceph101/keyring\nlog file = /var/log/ceph/ceph-rgw-ceph101.log\nrgw frontends = civetweb port=172.16.143.201:8080 num_threads=100\nrgw_zone = shanghai\n```\n\n\n重启rgw，并查看pool是否创建\n\n```\n[root@ceph102 ~]# systemctl restart ceph-radosgw@rgw.ceph102\n[root@ceph102 ~]# ceph osd pool ls\n.rgw.root\nbeijing.rgw.control\nbeijing.rgw.meta\nbeijing.rgw.log\n```\n\n更新period\n\n```\n[root@ceph102 ~]# radosgw-admin period update --commit\n2019-03-09 21:36:44.462809 7f23c756bdc0  1 Cannot find zone id=bf59d999-1561-4f7e-a874-9de718d4c31b (name=beijing), switching to local zonegroup configuration\nSending period to new master zone 9c655173-6346-47e7-9759-5e5d32aa017d\n{\n    \"id\": \"064c5b5e-eb87-462c-aa37-c420ddd68b23\",\n    \"epoch\": 3,\n    \"predecessor_uuid\": \"1abfe2d0-7453-4c01-881b-3db7f53f15c1\",\n    \"sync_status\": [],\n    \"period_map\": {\n        \"id\": \"064c5b5e-eb87-462c-aa37-c420ddd68b23\",\n        \"zonegroups\": [\n            {\n                \"id\": \"2b3f1ea0-73e7-4f17-b4f9-1acf5d5c6033\",\n                \"name\": \"cn\",\n                \"api_name\": \"cn\",\n                \"is_master\": \"true\",\n                \"endpoints\": [\n                    \"http://172.16.143.201:8080\"\n                ],\n                \"hostnames\": [],\n                \"hostnames_s3website\": [],\n                \"master_zone\": \"9c655173-6346-47e7-9759-5e5d32aa017d\",\n                \"zones\": [\n                    {\n                        \"id\": \"9c655173-6346-47e7-9759-5e5d32aa017d\",\n                        \"name\": \"shanghai\",\n                        \"endpoints\": [\n                            \"http://172.16.143.201:8080\"\n                        ],\n                        \"log_meta\": \"false\",\n                        \"log_data\": \"true\",\n                        \"bucket_index_max_shards\": 0,\n                        \"read_only\": \"false\",\n                        \"tier_type\": \"\",\n                        \"sync_from_all\": \"true\",\n                        \"sync_from\": []\n                    },\n                    {\n                        \"id\": \"bf59d999-1561-4f7e-a874-9de718d4c31b\",\n                        \"name\": \"beijing\",\n                        \"endpoints\": [],\n                        \"log_meta\": \"false\",\n                        \"log_data\": \"true\",\n                        \"bucket_index_max_shards\": 0,\n                        \"read_only\": \"false\",\n                        \"tier_type\": \"\",\n                        \"sync_from_all\": \"true\",\n                        \"sync_from\": []\n                    }\n                ],\n                \"placement_targets\": [\n                    {\n                        \"name\": \"default-placement\",\n                        \"tags\": []\n                    }\n                ],\n                \"default_placement\": \"default-placement\",\n                \"realm_id\": \"ba638e8a-8a33-4607-8fe3-13aa69dd1758\"\n            }\n        ],\n        \"short_zone_ids\": [\n            {\n                \"key\": \"9c655173-6346-47e7-9759-5e5d32aa017d\",\n                \"val\": 1556250220\n            },\n            {\n                \"key\": \"bf59d999-1561-4f7e-a874-9de718d4c31b\",\n                \"val\": 3557185953\n            }\n        ]\n    },\n    \"master_zonegroup\": \"2b3f1ea0-73e7-4f17-b4f9-1acf5d5c6033\",\n    \"master_zone\": \"9c655173-6346-47e7-9759-5e5d32aa017d\",\n    \"period_config\": {\n        \"bucket_quota\": {\n            \"enabled\": false,\n            \"check_on_raw\": false,\n            \"max_size\": -1,\n            \"max_size_kb\": 0,\n            \"max_objects\": -1\n        },\n        \"user_quota\": {\n            \"enabled\": false,\n            \"check_on_raw\": false,\n            \"max_size\": -1,\n            \"max_size_kb\": 0,\n            \"max_objects\": -1\n        }\n    },\n    \"realm_id\": \"ba638e8a-8a33-4607-8fe3-13aa69dd1758\",\n    \"realm_name\": \"realm100\",\n    \"realm_epoch\": 2\n}\n```\n\n查看同步状态\n\n```\n[root@ceph101 ~]# radosgw-admin sync status\n          realm ba638e8a-8a33-4607-8fe3-13aa69dd1758 (realm100)\n      zonegroup 2b3f1ea0-73e7-4f17-b4f9-1acf5d5c6033 (cn)\n           zone 9c655173-6346-47e7-9759-5e5d32aa017d (shanghai)\n  metadata sync no sync (zone is master)\n      data sync source: 0a2f706f-cc81-44f3-adf6-0d79c3e362ac (beijing)\n                        syncing\n                        full sync: 0/128 shards\n                        incremental sync: 128/128 shards\n                        data is caught up with source\n```\n\n```\n[root@ceph102 ~]# radosgw-admin sync status\n          realm ba638e8a-8a33-4607-8fe3-13aa69dd1758 (realm100)\n      zonegroup 2b3f1ea0-73e7-4f17-b4f9-1acf5d5c6033 (cn)\n           zone 0a2f706f-cc81-44f3-adf6-0d79c3e362ac (beijing)\n  metadata sync syncing\n                full sync: 0/64 shards\n                incremental sync: 64/64 shards\n                metadata is caught up with master\n      data sync source: 9c655173-6346-47e7-9759-5e5d32aa017d (shanghai)\n                        syncing\n                        full sync: 0/128 shards\n                        incremental sync: 128/128 shards\n                        data is caught up with source\n```\n\n# 验证\n在master zone 创建一个test用户，在secondy zone 查看信息\n\n```\n[root@ceph101 ~]# radosgw-admin user create --uid test --display-name=\"test user\"\n2019-03-09 22:16:27.795146 7f022820cdc0  0 WARNING: can't generate connection for zone 0a2f706f-cc81-44f3-adf6-0d79c3e362ac id beijing: no endpoints defined\n{\n    \"user_id\": \"test\",\n    \"display_name\": \"test user\",\n    \"email\": \"\",\n    \"suspended\": 0,\n    \"max_buckets\": 1000,\n    \"auid\": 0,\n    \"subusers\": [],\n    \"keys\": [\n        {\n            \"user\": \"test\",\n            \"access_key\": \"9R9YENBPPDZ88TQGP32D\",\n            \"secret_key\": \"B5wtnLKNloIVxmSDISut6scU8MClv52dfInb3Omh\"\n        }\n    ],\n    \"swift_keys\": [],\n    \"caps\": [],\n    \"op_mask\": \"read, write, delete\",\n    \"default_placement\": \"\",\n    \"placement_tags\": [],\n    \"bucket_quota\": {\n        \"enabled\": false,\n        \"check_on_raw\": false,\n        \"max_size\": -1,\n        \"max_size_kb\": 0,\n        \"max_objects\": -1\n    },\n    \"user_quota\": {\n        \"enabled\": false,\n        \"check_on_raw\": false,\n        \"max_size\": -1,\n        \"max_size_kb\": 0,\n        \"max_objects\": -1\n    },\n    \"temp_url_keys\": [],\n    \"type\": \"rgw\"\n}\n```\n\nsecondy zone 查看用户\n\n```\n[root@ceph102 ~]# radosgw-admin user list\n[\n    \"syncuser\",\n    \"test\"\n]\n```\n\n在secondy zone 创建一个test2用户，在master zone 查看信息\n\n```\n[root@ceph102 ~]# radosgw-admin user create --uid test@2 --display-name=\"test2 user\"\n{\n    \"user_id\": \"test@2\",\n    \"display_name\": \"test2 user\",\n    \"email\": \"\",\n    \"suspended\": 0,\n    \"max_buckets\": 1000,\n    \"auid\": 0,\n    \"subusers\": [],\n    \"keys\": [\n        {\n            \"user\": \"test@2\",\n            \"access_key\": \"9413B8F517W6LTEKN0H6\",\n            \"secret_key\": \"lg9vzVhpS2gYdXDnEOEUv3uCwkz0wkyuuBSnh8dl\"\n        }\n    ],\n    \"swift_keys\": [],\n    \"caps\": [],\n    \"op_mask\": \"read, write, delete\",\n    \"default_placement\": \"\",\n    \"placement_tags\": [],\n    \"bucket_quota\": {\n        \"enabled\": false,\n        \"check_on_raw\": false,\n        \"max_size\": -1,\n        \"max_size_kb\": 0,\n        \"max_objects\": -1\n    },\n    \"user_quota\": {\n        \"enabled\": false,\n        \"check_on_raw\": false,\n        \"max_size\": -1,\n        \"max_size_kb\": 0,\n        \"max_objects\": -1\n    },\n    \"temp_url_keys\": [],\n    \"type\": \"rgw\"\n}\n\n[root@ceph102 ~]# radosgw-admin user list\n[\n    \"syncuser\",\n    \"test@2\",\n    \"test\"\n]\n```\n\n在master zone 查看\n\n```\n[root@ceph101 ~]# radosgw-admin user list\n[\n    \"syncuser\",\n    \"test\"\n]\n```\n\n可以看到在master zone创建的用户，在secondy zone也可以看到  \n而在secondy zone创建的用户，在master zone看不到\n\n\n通过test用户，在master zone 创建名为bucket1的bucket\n\n```\n[root@ceph101 ~]# s3cmd mb s3://bucket1\nBucket 's3://bucket1/' created\n[root@ceph101 ~]# radosgw-admin bucket list\n[\n    \"bucket1\"\n]\n```\n\n在secondy zone查看\n\n```\n[root@ceph102 ~]# radosgw-admin bucket list\n[\n    \"bucket1\"\n]\n```\n\n\n通过test用户，在secondy zone 创建名为bucket2的bucket\n\n```\n[root@ceph102 ~]# s3cmd mb s3://bucket2\nBucket 's3://bucket2/' created\n[root@ceph102 ~]# radosgw-admin bucket list\n[\n    \"bucket1\",\n    \"bucket2\"\n]\n```\n\n在master zone 查看\n\n```\n[root@ceph101 ~]# radosgw-admin bucket list\n[\n    \"bucket1\",\n    \"bucket2\"\n]\n```\n\n在master zone 上传文件\n\n```\n[root@ceph101 ~]# s3cmd put Python-3.4.9.tgz s3://bucket1/python3.4.9.tgz\nupload: 'Python-3.4.9.tgz' -> 's3://bucket1/python3.4.9.tgz'  [part 1 of 2, 15MB] [1 of 1]\n 15728640 of 15728640   100% in    2s     6.26 MB/s  done\nupload: 'Python-3.4.9.tgz' -> 's3://bucket1/python3.4.9.tgz'  [part 2 of 2, 3MB] [1 of 1]\n 3955465 of 3955465   100% in    0s    32.73 MB/s  done\n \n[root@ceph101 ~]# md5sum Python-3.4.9.tgz\nc706902881ef95e27e59f13fabbcdcac  Python-3.4.9.tgz\n```\n\n在secondy zone 查看信息\n\n```\n[root@ceph102 ~]# s3cmd ls s3://bucket1\n2019-03-09 15:34  19684105   s3://bucket1/python3.4.9.tgz\n[root@ceph102 ~]# s3cmd get s3://bucket1/python3.4.9.tgz Python3.4.9.tgz\ndownload: 's3://bucket1/python3.4.9.tgz' -> 'Python3.4.9.tgz'  [1 of 1]\n 19684105 of 19684105   100% in    0s    51.81 MB/s  done\n[root@ceph102 ~]# md5sum Python3.4.9.tgz\nc706902881ef95e27e59f13fabbcdcac  Python3.4.9.tgz\n```\n\n在secondy zone 上传文件\n\n```\n[root@ceph102 ~]# s3cmd put anaconda-ks.cfg s3://bucket2/anaconda-ks.cfg\nupload: 'anaconda-ks.cfg' -> 's3://bucket2/anaconda-ks.cfg'  [1 of 1]\n 1030 of 1030   100% in    0s     8.28 kB/s  done\n[root@ceph102 ~]# md5sum anaconda-ks.cfg\n1627b1ce985ce5befdd0d1cb0e6164ae  anaconda-ks.cfg\n```\n\n在master zone 查看\n\n```\n[root@ceph101 tmp]# s3cmd ls s3://bucket2\n2019-03-09 15:37      1030   s3://bucket2/anaconda-ks.cfg\n[root@ceph101 tmp]# s3cmd get s3://bucket2/anaconda-ks.cfg anaconda-ks.cfg\ndownload: 's3://bucket2/anaconda-ks.cfg' -> 'anaconda-ks.cfg'  [1 of 1]\n 1030 of 1030   100% in    0s    23.32 kB/s  done\n[root@ceph101 tmp]# md5sum anaconda-ks.cfg\n1627b1ce985ce5befdd0d1cb0e6164ae  anaconda-ks.cfg\n```\n\n停止master zone的grup，然后在secondy zone上创建存储桶\n\n```\n[root@ceph101 tmp]# systemctl stop ceph-radosgw@rgw.ceph101\n```\n\n```\n[root@ceph102 ~]# s3cmd mb s3://bucket4\nWARNING: Retrying failed request: / (503 (ServiceUnavailable))\nWARNING: Waiting 3 sec...\nWARNING: Retrying failed request: / (503 (ServiceUnavailable))\nWARNING: Waiting 6 sec...\nWARNING: Retrying failed request: / (503 (ServiceUnavailable))\nWARNING: Waiting 9 sec...\n```\n\n可以看到在secondy zone上并不能创建bucket，之前在secondy zone上创建bucket，也是把请求转到master zone上。\n\n反之，停止secondy zone的rgw，在master zone也是可以创建存储桶\n\n```\n[root@ceph102 ~]# systemctl stop ceph-radosgw@ceph102\n```\n\n```\n[root@ceph101 tmp]# s3cmd mb s3://bucket5\nBucket 's3://bucket5/' created\n```\n\n# 参考\n* http://docs.ceph.com/docs/luminous/radosgw/multisite/\n* https://access.redhat.com/documentation/en-us/red_hat_ceph_storage/2/html/object_gateway_guide_for_red_hat_enterprise_linux/multi_site\n* https://www.jianshu.com/p/31a6f8df9a8f\n* http://stor.51cto.com/art/201807/578337.htm\n","source":"_posts/rgw-multi-site.md","raw":"---\ntitle: Ceph RGW multi site 配置\ndate: 2019-03-09 20:04:30\ntags: ceph\n---\n\n# 概述\n本文主要介绍如何配置Ceph RGW的异步复制功能，通过这个功能可以实现跨数据中心的灾备功能。  \nRGW多活方式是在同一zonegroup的多个zone之间进行，即同一zonegroup中多个zone之间的数据是完全一致的，用户可以通过任意zone读写同一份数据。 但是，对元数据的操作，比如创建桶、创建用户，仍然只能在master zone进行。对数据的操作，比如创建桶中的对象，访问对象等，可以在任意zone中 处理.\n\n# 环境\n实验环境是两个ceph集群，信息如下：  \n集群ceph101  \n\n```\n[root@ceph101 ~]# ceph -s\n  cluster:\n    id:     d6e42188-9871-471b-9db0-957f47893902\n    health: HEALTH_OK\n\n  services:\n    mon: 1 daemons, quorum ceph101\n    mgr: ceph101(active)\n    osd: 3 osds: 3 up, 3 in\n    rgw: 1 daemon active\n\n  data:\n    pools:   4 pools, 32 pgs\n    objects: 187 objects, 1.09KiB\n    usage:   3.01GiB used, 56.7GiB / 59.7GiB avail\n    pgs:     32 active+clean\n```\n\n\n集群ceph102  \n\n```\n[root@ceph102 ~]# ceph -s\n  cluster:\n    id:     2e80de18-e95f-463f-9eb0-531fd3254f0b\n    health: HEALTH_OK\n\n  services:\n    mon: 1 daemons, quorum ceph102\n    mgr: ceph102(active)\n    osd: 3 osds: 3 up, 3 in\n    rgw: 1 daemon active\n\n  data:\n    pools:   4 pools, 32 pgs\n    objects: 187 objects, 1.09KiB\n    usage:   3.01GiB used, 56.7GiB / 59.7GiB avail\n    pgs:     32 active+clean\n```\n\n这两个ceph集群都一个rgw服务，本次实验就通过这两个ceph集群验证rgw multi site的配置，已经功能的验证。  \n本次实验已第一个集群(ceph101)做为主集群，ceph102作为备集群。\n\n# Multi Site 配置\n\n在主集群创建一个名为realm100的realm\n\n```\n[root@ceph101 ~]# radosgw-admin realm create --rgw-realm=realm100 --default\n{\n    \"id\": \"337cd1c3-1ad0-4975-b220-e021a7f2b3eb\",\n    \"name\": \"realm100\",\n    \"current_period\": \"bd6ecbd6-3a28-46d7-a806-22e9ea001ca3\",\n    \"epoch\": 1\n}\n```\n\n创建master zonegroup\n\n```\n[root@ceph101 ~]# radosgw-admin zonegroup create --rgw-zonegroup=cn --endpoints=http://172.16.143.201:8080 --rgw-realm=realm100 --master --default\n{\n    \"id\": \"2b3f1ea0-73e7-4f17-b4f9-1acf5d5c6033\",\n    \"name\": \"cn\",\n    \"api_name\": \"cn\",\n    \"is_master\": \"true\",\n    \"endpoints\": [\n        \"http://172.16.143.201:8080\"\n    ],\n    \"hostnames\": [],\n    \"hostnames_s3website\": [],\n    \"master_zone\": \"\",\n    \"zones\": [],\n    \"placement_targets\": [],\n    \"default_placement\": \"\",\n    \"realm_id\": \"ba638e8a-8a33-4607-8fe3-13aa69dd1758\"\n}\n```\n\n创建master zone\n\n```\n[root@ceph101 ~]# radosgw-admin zone create --rgw-zonegroup=cn --rgw-zone=shanghai --master --default --endpoints=http://172.16.143.201:8080\n{\n    \"id\": \"9c655173-6346-47e7-9759-5e5d32aa017d\",\n    \"name\": \"shanghai\",\n    \"domain_root\": \"shanghai.rgw.meta:root\",\n    \"control_pool\": \"shanghai.rgw.control\",\n    \"gc_pool\": \"shanghai.rgw.log:gc\",\n    \"lc_pool\": \"shanghai.rgw.log:lc\",\n    \"log_pool\": \"shanghai.rgw.log\",\n    \"intent_log_pool\": \"shanghai.rgw.log:intent\",\n    \"usage_log_pool\": \"shanghai.rgw.log:usage\",\n    \"reshard_pool\": \"shanghai.rgw.log:reshard\",\n    \"user_keys_pool\": \"shanghai.rgw.meta:users.keys\",\n    \"user_email_pool\": \"shanghai.rgw.meta:users.email\",\n    \"user_swift_pool\": \"shanghai.rgw.meta:users.swift\",\n    \"user_uid_pool\": \"shanghai.rgw.meta:users.uid\",\n    \"system_key\": {\n        \"access_key\": \"\",\n        \"secret_key\": \"\"\n    },\n    \"placement_pools\": [\n        {\n            \"key\": \"default-placement\",\n            \"val\": {\n                \"index_pool\": \"shanghai.rgw.buckets.index\",\n                \"data_pool\": \"shanghai.rgw.buckets.data\",\n                \"data_extra_pool\": \"shanghai.rgw.buckets.non-ec\",\n                \"index_type\": 0,\n                \"compression\": \"\"\n            }\n        }\n    ],\n    \"metadata_heap\": \"\",\n    \"tier_config\": [],\n    \"realm_id\": \"ba638e8a-8a33-4607-8fe3-13aa69dd1758\"\n}\n```\n\n更新period\n\n```\n[root@ceph101 ~]# radosgw-admin period update --commit\n{\n    \"id\": \"064c5b5e-eb87-462c-aa37-c420ddd68b23\",\n    \"epoch\": 1,\n    \"predecessor_uuid\": \"1abfe2d0-7453-4c01-881b-3db7f53f15c1\",\n    \"sync_status\": [],\n    \"period_map\": {\n        \"id\": \"064c5b5e-eb87-462c-aa37-c420ddd68b23\",\n        \"zonegroups\": [\n            {\n                \"id\": \"2b3f1ea0-73e7-4f17-b4f9-1acf5d5c6033\",\n                \"name\": \"cn\",\n                \"api_name\": \"cn\",\n                \"is_master\": \"true\",\n                \"endpoints\": [\n                    \"http://172.16.143.201:8080\"\n                ],\n                \"hostnames\": [],\n                \"hostnames_s3website\": [],\n                \"master_zone\": \"9c655173-6346-47e7-9759-5e5d32aa017d\",\n                \"zones\": [\n                    {\n                        \"id\": \"9c655173-6346-47e7-9759-5e5d32aa017d\",\n                        \"name\": \"shanghai\",\n                        \"endpoints\": [\n                            \"http://172.16.143.201:8080\"\n                        ],\n                        \"log_meta\": \"false\",\n                        \"log_data\": \"false\",\n                        \"bucket_index_max_shards\": 0,\n                        \"read_only\": \"false\",\n                        \"tier_type\": \"\",\n                        \"sync_from_all\": \"true\",\n                        \"sync_from\": []\n                    }\n                ],\n                \"placement_targets\": [\n                    {\n                        \"name\": \"default-placement\",\n                        \"tags\": []\n                    }\n                ],\n                \"default_placement\": \"default-placement\",\n                \"realm_id\": \"ba638e8a-8a33-4607-8fe3-13aa69dd1758\"\n            }\n        ],\n        \"short_zone_ids\": [\n            {\n                \"key\": \"9c655173-6346-47e7-9759-5e5d32aa017d\",\n                \"val\": 1556250220\n            }\n        ]\n    },\n    \"master_zonegroup\": \"2b3f1ea0-73e7-4f17-b4f9-1acf5d5c6033\",\n    \"master_zone\": \"9c655173-6346-47e7-9759-5e5d32aa017d\",\n    \"period_config\": {\n        \"bucket_quota\": {\n            \"enabled\": false,\n            \"check_on_raw\": false,\n            \"max_size\": -1,\n            \"max_size_kb\": 0,\n            \"max_objects\": -1\n        },\n        \"user_quota\": {\n            \"enabled\": false,\n            \"check_on_raw\": false,\n            \"max_size\": -1,\n            \"max_size_kb\": 0,\n            \"max_objects\": -1\n        }\n    },\n    \"realm_id\": \"ba638e8a-8a33-4607-8fe3-13aa69dd1758\",\n    \"realm_name\": \"realm100\",\n    \"realm_epoch\": 2\n}\n```\n\n创建同步用户\n\n```\n[root@ceph101 ~]# radosgw-admin user create --uid=\"syncuser\" --display-name=\"Synchronization User\" --system\n{\n    \"user_id\": \"syncuser\",\n    \"display_name\": \"Synchronization User\",\n    \"email\": \"\",\n    \"suspended\": 0,\n    \"max_buckets\": 1000,\n    \"auid\": 0,\n    \"subusers\": [],\n    \"keys\": [\n        {\n            \"user\": \"syncuser\",\n            \"access_key\": \"LPTHGKYO5ULI48Q88AWF\",\n            \"secret_key\": \"jGFoORTVt72frRYsmcnPOpGXnz652Dl3C2IeBLN8\"\n        }\n    ],\n    \"swift_keys\": [],\n    \"caps\": [],\n    \"op_mask\": \"read, write, delete\",\n    \"system\": \"true\",\n    \"default_placement\": \"\",\n    \"placement_tags\": [],\n    \"bucket_quota\": {\n        \"enabled\": false,\n        \"check_on_raw\": false,\n        \"max_size\": -1,\n        \"max_size_kb\": 0,\n        \"max_objects\": -1\n    },\n    \"user_quota\": {\n        \"enabled\": false,\n        \"check_on_raw\": false,\n        \"max_size\": -1,\n        \"max_size_kb\": 0,\n        \"max_objects\": -1\n    },\n    \"temp_url_keys\": [],\n    \"type\": \"rgw\"\n}\n```\n\n修改zone的key，并更新period\n\n```\n[root@ceph101 ~]# radosgw-admin zone modify --rgw-zone=shanghai --access-key=LPTHGKYO5ULI48Q88AWF --secret=jGFoORTVt72frRYsmcnPOpGXnz652Dl3C2IeBLN8\n\n[root@ceph101 ~]# radosgw-admin period update --commit\n{\n    \"id\": \"064c5b5e-eb87-462c-aa37-c420ddd68b23\",\n    \"epoch\": 2,\n    \"predecessor_uuid\": \"1abfe2d0-7453-4c01-881b-3db7f53f15c1\",\n    \"sync_status\": [],\n    \"period_map\": {\n        \"id\": \"064c5b5e-eb87-462c-aa37-c420ddd68b23\",\n        \"zonegroups\": [\n            {\n                \"id\": \"2b3f1ea0-73e7-4f17-b4f9-1acf5d5c6033\",\n                \"name\": \"cn\",\n                \"api_name\": \"cn\",\n                \"is_master\": \"true\",\n                \"endpoints\": [\n                    \"http://172.16.143.201:8080\"\n                ],\n                \"hostnames\": [],\n                \"hostnames_s3website\": [],\n                \"master_zone\": \"9c655173-6346-47e7-9759-5e5d32aa017d\",\n                \"zones\": [\n                    {\n                        \"id\": \"9c655173-6346-47e7-9759-5e5d32aa017d\",\n                        \"name\": \"shanghai\",\n                        \"endpoints\": [\n                            \"http://172.16.143.201:8080\"\n                        ],\n                        \"log_meta\": \"false\",\n                        \"log_data\": \"false\",\n                        \"bucket_index_max_shards\": 0,\n                        \"read_only\": \"false\",\n                        \"tier_type\": \"\",\n                        \"sync_from_all\": \"true\",\n                        \"sync_from\": []\n                    }\n                ],\n                \"placement_targets\": [\n                    {\n                        \"name\": \"default-placement\",\n                        \"tags\": []\n                    }\n                ],\n                \"default_placement\": \"default-placement\",\n                \"realm_id\": \"ba638e8a-8a33-4607-8fe3-13aa69dd1758\"\n            }\n        ],\n        \"short_zone_ids\": [\n            {\n                \"key\": \"9c655173-6346-47e7-9759-5e5d32aa017d\",\n                \"val\": 1556250220\n            }\n        ]\n    },\n    \"master_zonegroup\": \"2b3f1ea0-73e7-4f17-b4f9-1acf5d5c6033\",\n    \"master_zone\": \"9c655173-6346-47e7-9759-5e5d32aa017d\",\n    \"period_config\": {\n        \"bucket_quota\": {\n            \"enabled\": false,\n            \"check_on_raw\": false,\n            \"max_size\": -1,\n            \"max_size_kb\": 0,\n            \"max_objects\": -1\n        },\n        \"user_quota\": {\n            \"enabled\": false,\n            \"check_on_raw\": false,\n            \"max_size\": -1,\n            \"max_size_kb\": 0,\n            \"max_objects\": -1\n        }\n    },\n    \"realm_id\": \"ba638e8a-8a33-4607-8fe3-13aa69dd1758\",\n    \"realm_name\": \"realm100\",\n    \"realm_epoch\": 2\n}\n```\n\n删除默认zone和zonegroup\n\n```\n[root@ceph101 ~]# radosgw-admin zonegroup remove --rgw-zonegroup=default --rgw-zone=default\n[root@ceph101 ~]# radosgw-admin period update --commit\n[root@ceph101 ~]# radosgw-admin zone delete --rgw-zone=default\n[root@ceph101 ~]# radosgw-admin period update --commit\n[root@ceph101 ~]# radosgw-admin zonegroup delete --rgw-zonegroup=default\n[root@ceph101 ~]# radosgw-admin period update --commit\n```\n\n删除默认pool\n\n```\n[root@ceph101 ~]# ceph osd pool delete default.rgw.control default.rgw.control --yes-i-really-really-mean-it\npool 'default.rgw.control' removed\n[root@ceph101 ~]# ceph osd pool delete default.rgw.meta default.rgw.meta --yes-i-really-really-mean-it\npool 'default.rgw.meta' removed\n[root@ceph101 ~]# ceph osd pool delete default.rgw.log default.rgw.log --yes-i-really-really-mean-it\npool 'default.rgw.log' removed\n```\n\n修改rgw配置, 增加rgw_zone = shanghai\n\n```\n[root@ceph101 ~]# vim /etc/ceph/ceph.conf\n\n[global]\nfsid = d6e42188-9871-471b-9db0-957f47893902\n\n\n\nmon initial members = ceph101\nmon host = 172.16.143.201\n\npublic network = 172.16.143.0/24\ncluster network = 172.16.140.0/24\n\n\nmon allow pool delete = true\n\n\n[client.rgw.ceph101]\nhost = ceph101\nkeyring = /var/lib/ceph/radosgw/ceph-rgw.ceph101/keyring\nlog file = /var/log/ceph/ceph-rgw-ceph101.log\nrgw frontends = civetweb port=172.16.143.201:8080 num_threads=100\nrgw_zone = shanghai\n```\n\n\n重启rgw，并查看pool是否创建\n\n```\n[root@ceph101 ~]# systemctl restart ceph-radosgw@rgw.ceph101\n[root@ceph101 ~]# ceph osd pool ls\n.rgw.root\nshanghai.rgw.control\nshanghai.rgw.meta\nshanghai.rgw.log\n```\n\n在secondy zone节点进行如下配置：  \n\n同步realm, 并设置realm100为默认的realm\n\n```\n[root@ceph102 ~]# radosgw-admin realm pull --url=http://172.16.143.201:8080 --access-key=LPTHGKYO5ULI48Q88AWF --secret=jGFoORTVt72frRYsmcnPOpGXnz652Dl3C2IeBLN8\n2019-03-09 21:25:10.377485 7fa55aca2dc0  1 found existing latest_epoch 2 >= given epoch 2, returning r=-17\n{\n    \"id\": \"ba638e8a-8a33-4607-8fe3-13aa69dd1758\",\n    \"name\": \"realm100\",\n    \"current_period\": \"064c5b5e-eb87-462c-aa37-c420ddd68b23\",\n    \"epoch\": 2\n}\n\n[root@ceph102 ~]# radosgw-admin realm default --rgw-realm=realm100\n```\n\n更新period\n\n```\n[root@ceph102 ~]# radosgw-admin period pull --url=http://172.16.143.201:8080 --access-key=LPTHGKYO5ULI48Q88AWF --secret=jGFoORTVt72frRYsmcnPOpGXnz652Dl3C2IeBLN8\n{\n    \"id\": \"064c5b5e-eb87-462c-aa37-c420ddd68b23\",\n    \"epoch\": 2,\n    \"predecessor_uuid\": \"1abfe2d0-7453-4c01-881b-3db7f53f15c1\",\n    \"sync_status\": [],\n    \"period_map\": {\n        \"id\": \"064c5b5e-eb87-462c-aa37-c420ddd68b23\",\n        \"zonegroups\": [\n            {\n                \"id\": \"2b3f1ea0-73e7-4f17-b4f9-1acf5d5c6033\",\n                \"name\": \"cn\",\n                \"api_name\": \"cn\",\n                \"is_master\": \"true\",\n                \"endpoints\": [\n                    \"http://172.16.143.201:8080\"\n                ],\n                \"hostnames\": [],\n                \"hostnames_s3website\": [],\n                \"master_zone\": \"9c655173-6346-47e7-9759-5e5d32aa017d\",\n                \"zones\": [\n                    {\n                        \"id\": \"9c655173-6346-47e7-9759-5e5d32aa017d\",\n                        \"name\": \"shanghai\",\n                        \"endpoints\": [\n                            \"http://172.16.143.201:8080\"\n                        ],\n                        \"log_meta\": \"false\",\n                        \"log_data\": \"false\",\n                        \"bucket_index_max_shards\": 0,\n                        \"read_only\": \"false\",\n                        \"tier_type\": \"\",\n                        \"sync_from_all\": \"true\",\n                        \"sync_from\": []\n                    }\n                ],\n                \"placement_targets\": [\n                    {\n                        \"name\": \"default-placement\",\n                        \"tags\": []\n                    }\n                ],\n                \"default_placement\": \"default-placement\",\n                \"realm_id\": \"ba638e8a-8a33-4607-8fe3-13aa69dd1758\"\n            }\n        ],\n        \"short_zone_ids\": [\n            {\n                \"key\": \"9c655173-6346-47e7-9759-5e5d32aa017d\",\n                \"val\": 1556250220\n            }\n        ]\n    },\n    \"master_zonegroup\": \"2b3f1ea0-73e7-4f17-b4f9-1acf5d5c6033\",\n    \"master_zone\": \"9c655173-6346-47e7-9759-5e5d32aa017d\",\n    \"period_config\": {\n        \"bucket_quota\": {\n            \"enabled\": false,\n            \"check_on_raw\": false,\n            \"max_size\": -1,\n            \"max_size_kb\": 0,\n            \"max_objects\": -1\n        },\n        \"user_quota\": {\n            \"enabled\": false,\n            \"check_on_raw\": false,\n            \"max_size\": -1,\n            \"max_size_kb\": 0,\n            \"max_objects\": -1\n        }\n    },\n    \"realm_id\": \"ba638e8a-8a33-4607-8fe3-13aa69dd1758\",\n    \"realm_name\": \"realm100\",\n    \"realm_epoch\": 2\n}\n```\n\n创建secondy zone\n\n```\n[root@ceph102 ~]# radosgw-admin zone create --rgw-zonegroup=cn --rgw-zone=beijing --endpoints=http://172.16.143.202:8080 --access-key=LPTHGKYO5ULI48Q88AWF --secret=jGFoORTVt72frRYsmcnPOpGXnz652Dl3C2IeBLN8\n2019-03-09 21:30:24.323527 7f2441e45dc0  0 failed reading obj info from .rgw.root:zone_info.9c655173-6346-47e7-9759-5e5d32aa017d: (2) No such file or directory\n2019-03-09 21:30:24.323577 7f2441e45dc0  0 WARNING: could not read zone params for zone id=9c655173-6346-47e7-9759-5e5d32aa017d name=shanghai\n{\n    \"id\": \"bf59d999-1561-4f7e-a874-9de718d4c31b\",\n    \"name\": \"beijing\",\n    \"domain_root\": \"beijing.rgw.meta:root\",\n    \"control_pool\": \"beijing.rgw.control\",\n    \"gc_pool\": \"beijing.rgw.log:gc\",\n    \"lc_pool\": \"beijing.rgw.log:lc\",\n    \"log_pool\": \"beijing.rgw.log\",\n    \"intent_log_pool\": \"beijing.rgw.log:intent\",\n    \"usage_log_pool\": \"beijing.rgw.log:usage\",\n    \"reshard_pool\": \"beijing.rgw.log:reshard\",\n    \"user_keys_pool\": \"beijing.rgw.meta:users.keys\",\n    \"user_email_pool\": \"beijing.rgw.meta:users.email\",\n    \"user_swift_pool\": \"beijing.rgw.meta:users.swift\",\n    \"user_uid_pool\": \"beijing.rgw.meta:users.uid\",\n    \"system_key\": {\n        \"access_key\": \"LPTHGKYO5ULI48Q88AWF\",\n        \"secret_key\": \"jGFoORTVt72frRYsmcnPOpGXnz652Dl3C2IeBLN8\"\n    },\n    \"placement_pools\": [\n        {\n            \"key\": \"default-placement\",\n            \"val\": {\n                \"index_pool\": \"beijing.rgw.buckets.index\",\n                \"data_pool\": \"beijing.rgw.buckets.data\",\n                \"data_extra_pool\": \"beijing.rgw.buckets.non-ec\",\n                \"index_type\": 0,\n                \"compression\": \"\"\n            }\n        }\n    ],\n    \"metadata_heap\": \"\",\n    \"tier_config\": [],\n    \"realm_id\": \"ba638e8a-8a33-4607-8fe3-13aa69dd1758\"\n}\n```\n\n删除默认default zone， defaul zonegroup和 default存储池\n\n```\n[root@ceph102 ~]# radosgw-admin zone delete --rgw-zone=default\n2019-03-09 21:31:23.577581 7f2e6c528dc0  0 zone id ce963a6e-7d58-426d-b07a-a2af2983379a is not a part of zonegroup cn\n[root@ceph102 ~]# radosgw-admin zonegroup list\n{\n    \"default_info\": \"2b3f1ea0-73e7-4f17-b4f9-1acf5d5c6033\",\n    \"zonegroups\": [\n        \"cn\",\n        \"default\"\n    ]\n}\n\n[root@ceph102 ~]# radosgw-admin zonegroup delete --rgw-zonegroup=default\n\n[root@ceph102 ~]# ceph osd pool delete default.rgw.control default.rgw.control --yes-i-really-really-mean-it\npool 'default.rgw.control' removed\n[root@ceph102 ~]# ceph osd pool delete default.rgw.meta default.rgw.meta --yes-i-really-really-mean-it\npool 'default.rgw.meta' removed\n[root@ceph102 ~]# ceph osd pool delete default.rgw.log default.rgw.log --yes-i-really-really-mean-it\npool 'default.rgw.log' removed\n```\n\n修改rgw配置, 增加rgw_zone = beijing\n\n```\n[root@ceph101 ~]# vim /etc/ceph/ceph.conf\n\n[global]\nfsid = d6e42188-9871-471b-9db0-957f47893902\n\n\n\nmon initial members = ceph101\nmon host = 172.16.143.201\n\npublic network = 172.16.143.0/24\ncluster network = 172.16.140.0/24\n\n\nmon allow pool delete = true\n\n\n[client.rgw.ceph101]\nhost = ceph101\nkeyring = /var/lib/ceph/radosgw/ceph-rgw.ceph101/keyring\nlog file = /var/log/ceph/ceph-rgw-ceph101.log\nrgw frontends = civetweb port=172.16.143.201:8080 num_threads=100\nrgw_zone = shanghai\n```\n\n\n重启rgw，并查看pool是否创建\n\n```\n[root@ceph102 ~]# systemctl restart ceph-radosgw@rgw.ceph102\n[root@ceph102 ~]# ceph osd pool ls\n.rgw.root\nbeijing.rgw.control\nbeijing.rgw.meta\nbeijing.rgw.log\n```\n\n更新period\n\n```\n[root@ceph102 ~]# radosgw-admin period update --commit\n2019-03-09 21:36:44.462809 7f23c756bdc0  1 Cannot find zone id=bf59d999-1561-4f7e-a874-9de718d4c31b (name=beijing), switching to local zonegroup configuration\nSending period to new master zone 9c655173-6346-47e7-9759-5e5d32aa017d\n{\n    \"id\": \"064c5b5e-eb87-462c-aa37-c420ddd68b23\",\n    \"epoch\": 3,\n    \"predecessor_uuid\": \"1abfe2d0-7453-4c01-881b-3db7f53f15c1\",\n    \"sync_status\": [],\n    \"period_map\": {\n        \"id\": \"064c5b5e-eb87-462c-aa37-c420ddd68b23\",\n        \"zonegroups\": [\n            {\n                \"id\": \"2b3f1ea0-73e7-4f17-b4f9-1acf5d5c6033\",\n                \"name\": \"cn\",\n                \"api_name\": \"cn\",\n                \"is_master\": \"true\",\n                \"endpoints\": [\n                    \"http://172.16.143.201:8080\"\n                ],\n                \"hostnames\": [],\n                \"hostnames_s3website\": [],\n                \"master_zone\": \"9c655173-6346-47e7-9759-5e5d32aa017d\",\n                \"zones\": [\n                    {\n                        \"id\": \"9c655173-6346-47e7-9759-5e5d32aa017d\",\n                        \"name\": \"shanghai\",\n                        \"endpoints\": [\n                            \"http://172.16.143.201:8080\"\n                        ],\n                        \"log_meta\": \"false\",\n                        \"log_data\": \"true\",\n                        \"bucket_index_max_shards\": 0,\n                        \"read_only\": \"false\",\n                        \"tier_type\": \"\",\n                        \"sync_from_all\": \"true\",\n                        \"sync_from\": []\n                    },\n                    {\n                        \"id\": \"bf59d999-1561-4f7e-a874-9de718d4c31b\",\n                        \"name\": \"beijing\",\n                        \"endpoints\": [],\n                        \"log_meta\": \"false\",\n                        \"log_data\": \"true\",\n                        \"bucket_index_max_shards\": 0,\n                        \"read_only\": \"false\",\n                        \"tier_type\": \"\",\n                        \"sync_from_all\": \"true\",\n                        \"sync_from\": []\n                    }\n                ],\n                \"placement_targets\": [\n                    {\n                        \"name\": \"default-placement\",\n                        \"tags\": []\n                    }\n                ],\n                \"default_placement\": \"default-placement\",\n                \"realm_id\": \"ba638e8a-8a33-4607-8fe3-13aa69dd1758\"\n            }\n        ],\n        \"short_zone_ids\": [\n            {\n                \"key\": \"9c655173-6346-47e7-9759-5e5d32aa017d\",\n                \"val\": 1556250220\n            },\n            {\n                \"key\": \"bf59d999-1561-4f7e-a874-9de718d4c31b\",\n                \"val\": 3557185953\n            }\n        ]\n    },\n    \"master_zonegroup\": \"2b3f1ea0-73e7-4f17-b4f9-1acf5d5c6033\",\n    \"master_zone\": \"9c655173-6346-47e7-9759-5e5d32aa017d\",\n    \"period_config\": {\n        \"bucket_quota\": {\n            \"enabled\": false,\n            \"check_on_raw\": false,\n            \"max_size\": -1,\n            \"max_size_kb\": 0,\n            \"max_objects\": -1\n        },\n        \"user_quota\": {\n            \"enabled\": false,\n            \"check_on_raw\": false,\n            \"max_size\": -1,\n            \"max_size_kb\": 0,\n            \"max_objects\": -1\n        }\n    },\n    \"realm_id\": \"ba638e8a-8a33-4607-8fe3-13aa69dd1758\",\n    \"realm_name\": \"realm100\",\n    \"realm_epoch\": 2\n}\n```\n\n查看同步状态\n\n```\n[root@ceph101 ~]# radosgw-admin sync status\n          realm ba638e8a-8a33-4607-8fe3-13aa69dd1758 (realm100)\n      zonegroup 2b3f1ea0-73e7-4f17-b4f9-1acf5d5c6033 (cn)\n           zone 9c655173-6346-47e7-9759-5e5d32aa017d (shanghai)\n  metadata sync no sync (zone is master)\n      data sync source: 0a2f706f-cc81-44f3-adf6-0d79c3e362ac (beijing)\n                        syncing\n                        full sync: 0/128 shards\n                        incremental sync: 128/128 shards\n                        data is caught up with source\n```\n\n```\n[root@ceph102 ~]# radosgw-admin sync status\n          realm ba638e8a-8a33-4607-8fe3-13aa69dd1758 (realm100)\n      zonegroup 2b3f1ea0-73e7-4f17-b4f9-1acf5d5c6033 (cn)\n           zone 0a2f706f-cc81-44f3-adf6-0d79c3e362ac (beijing)\n  metadata sync syncing\n                full sync: 0/64 shards\n                incremental sync: 64/64 shards\n                metadata is caught up with master\n      data sync source: 9c655173-6346-47e7-9759-5e5d32aa017d (shanghai)\n                        syncing\n                        full sync: 0/128 shards\n                        incremental sync: 128/128 shards\n                        data is caught up with source\n```\n\n# 验证\n在master zone 创建一个test用户，在secondy zone 查看信息\n\n```\n[root@ceph101 ~]# radosgw-admin user create --uid test --display-name=\"test user\"\n2019-03-09 22:16:27.795146 7f022820cdc0  0 WARNING: can't generate connection for zone 0a2f706f-cc81-44f3-adf6-0d79c3e362ac id beijing: no endpoints defined\n{\n    \"user_id\": \"test\",\n    \"display_name\": \"test user\",\n    \"email\": \"\",\n    \"suspended\": 0,\n    \"max_buckets\": 1000,\n    \"auid\": 0,\n    \"subusers\": [],\n    \"keys\": [\n        {\n            \"user\": \"test\",\n            \"access_key\": \"9R9YENBPPDZ88TQGP32D\",\n            \"secret_key\": \"B5wtnLKNloIVxmSDISut6scU8MClv52dfInb3Omh\"\n        }\n    ],\n    \"swift_keys\": [],\n    \"caps\": [],\n    \"op_mask\": \"read, write, delete\",\n    \"default_placement\": \"\",\n    \"placement_tags\": [],\n    \"bucket_quota\": {\n        \"enabled\": false,\n        \"check_on_raw\": false,\n        \"max_size\": -1,\n        \"max_size_kb\": 0,\n        \"max_objects\": -1\n    },\n    \"user_quota\": {\n        \"enabled\": false,\n        \"check_on_raw\": false,\n        \"max_size\": -1,\n        \"max_size_kb\": 0,\n        \"max_objects\": -1\n    },\n    \"temp_url_keys\": [],\n    \"type\": \"rgw\"\n}\n```\n\nsecondy zone 查看用户\n\n```\n[root@ceph102 ~]# radosgw-admin user list\n[\n    \"syncuser\",\n    \"test\"\n]\n```\n\n在secondy zone 创建一个test2用户，在master zone 查看信息\n\n```\n[root@ceph102 ~]# radosgw-admin user create --uid test@2 --display-name=\"test2 user\"\n{\n    \"user_id\": \"test@2\",\n    \"display_name\": \"test2 user\",\n    \"email\": \"\",\n    \"suspended\": 0,\n    \"max_buckets\": 1000,\n    \"auid\": 0,\n    \"subusers\": [],\n    \"keys\": [\n        {\n            \"user\": \"test@2\",\n            \"access_key\": \"9413B8F517W6LTEKN0H6\",\n            \"secret_key\": \"lg9vzVhpS2gYdXDnEOEUv3uCwkz0wkyuuBSnh8dl\"\n        }\n    ],\n    \"swift_keys\": [],\n    \"caps\": [],\n    \"op_mask\": \"read, write, delete\",\n    \"default_placement\": \"\",\n    \"placement_tags\": [],\n    \"bucket_quota\": {\n        \"enabled\": false,\n        \"check_on_raw\": false,\n        \"max_size\": -1,\n        \"max_size_kb\": 0,\n        \"max_objects\": -1\n    },\n    \"user_quota\": {\n        \"enabled\": false,\n        \"check_on_raw\": false,\n        \"max_size\": -1,\n        \"max_size_kb\": 0,\n        \"max_objects\": -1\n    },\n    \"temp_url_keys\": [],\n    \"type\": \"rgw\"\n}\n\n[root@ceph102 ~]# radosgw-admin user list\n[\n    \"syncuser\",\n    \"test@2\",\n    \"test\"\n]\n```\n\n在master zone 查看\n\n```\n[root@ceph101 ~]# radosgw-admin user list\n[\n    \"syncuser\",\n    \"test\"\n]\n```\n\n可以看到在master zone创建的用户，在secondy zone也可以看到  \n而在secondy zone创建的用户，在master zone看不到\n\n\n通过test用户，在master zone 创建名为bucket1的bucket\n\n```\n[root@ceph101 ~]# s3cmd mb s3://bucket1\nBucket 's3://bucket1/' created\n[root@ceph101 ~]# radosgw-admin bucket list\n[\n    \"bucket1\"\n]\n```\n\n在secondy zone查看\n\n```\n[root@ceph102 ~]# radosgw-admin bucket list\n[\n    \"bucket1\"\n]\n```\n\n\n通过test用户，在secondy zone 创建名为bucket2的bucket\n\n```\n[root@ceph102 ~]# s3cmd mb s3://bucket2\nBucket 's3://bucket2/' created\n[root@ceph102 ~]# radosgw-admin bucket list\n[\n    \"bucket1\",\n    \"bucket2\"\n]\n```\n\n在master zone 查看\n\n```\n[root@ceph101 ~]# radosgw-admin bucket list\n[\n    \"bucket1\",\n    \"bucket2\"\n]\n```\n\n在master zone 上传文件\n\n```\n[root@ceph101 ~]# s3cmd put Python-3.4.9.tgz s3://bucket1/python3.4.9.tgz\nupload: 'Python-3.4.9.tgz' -> 's3://bucket1/python3.4.9.tgz'  [part 1 of 2, 15MB] [1 of 1]\n 15728640 of 15728640   100% in    2s     6.26 MB/s  done\nupload: 'Python-3.4.9.tgz' -> 's3://bucket1/python3.4.9.tgz'  [part 2 of 2, 3MB] [1 of 1]\n 3955465 of 3955465   100% in    0s    32.73 MB/s  done\n \n[root@ceph101 ~]# md5sum Python-3.4.9.tgz\nc706902881ef95e27e59f13fabbcdcac  Python-3.4.9.tgz\n```\n\n在secondy zone 查看信息\n\n```\n[root@ceph102 ~]# s3cmd ls s3://bucket1\n2019-03-09 15:34  19684105   s3://bucket1/python3.4.9.tgz\n[root@ceph102 ~]# s3cmd get s3://bucket1/python3.4.9.tgz Python3.4.9.tgz\ndownload: 's3://bucket1/python3.4.9.tgz' -> 'Python3.4.9.tgz'  [1 of 1]\n 19684105 of 19684105   100% in    0s    51.81 MB/s  done\n[root@ceph102 ~]# md5sum Python3.4.9.tgz\nc706902881ef95e27e59f13fabbcdcac  Python3.4.9.tgz\n```\n\n在secondy zone 上传文件\n\n```\n[root@ceph102 ~]# s3cmd put anaconda-ks.cfg s3://bucket2/anaconda-ks.cfg\nupload: 'anaconda-ks.cfg' -> 's3://bucket2/anaconda-ks.cfg'  [1 of 1]\n 1030 of 1030   100% in    0s     8.28 kB/s  done\n[root@ceph102 ~]# md5sum anaconda-ks.cfg\n1627b1ce985ce5befdd0d1cb0e6164ae  anaconda-ks.cfg\n```\n\n在master zone 查看\n\n```\n[root@ceph101 tmp]# s3cmd ls s3://bucket2\n2019-03-09 15:37      1030   s3://bucket2/anaconda-ks.cfg\n[root@ceph101 tmp]# s3cmd get s3://bucket2/anaconda-ks.cfg anaconda-ks.cfg\ndownload: 's3://bucket2/anaconda-ks.cfg' -> 'anaconda-ks.cfg'  [1 of 1]\n 1030 of 1030   100% in    0s    23.32 kB/s  done\n[root@ceph101 tmp]# md5sum anaconda-ks.cfg\n1627b1ce985ce5befdd0d1cb0e6164ae  anaconda-ks.cfg\n```\n\n停止master zone的grup，然后在secondy zone上创建存储桶\n\n```\n[root@ceph101 tmp]# systemctl stop ceph-radosgw@rgw.ceph101\n```\n\n```\n[root@ceph102 ~]# s3cmd mb s3://bucket4\nWARNING: Retrying failed request: / (503 (ServiceUnavailable))\nWARNING: Waiting 3 sec...\nWARNING: Retrying failed request: / (503 (ServiceUnavailable))\nWARNING: Waiting 6 sec...\nWARNING: Retrying failed request: / (503 (ServiceUnavailable))\nWARNING: Waiting 9 sec...\n```\n\n可以看到在secondy zone上并不能创建bucket，之前在secondy zone上创建bucket，也是把请求转到master zone上。\n\n反之，停止secondy zone的rgw，在master zone也是可以创建存储桶\n\n```\n[root@ceph102 ~]# systemctl stop ceph-radosgw@ceph102\n```\n\n```\n[root@ceph101 tmp]# s3cmd mb s3://bucket5\nBucket 's3://bucket5/' created\n```\n\n# 参考\n* http://docs.ceph.com/docs/luminous/radosgw/multisite/\n* https://access.redhat.com/documentation/en-us/red_hat_ceph_storage/2/html/object_gateway_guide_for_red_hat_enterprise_linux/multi_site\n* https://www.jianshu.com/p/31a6f8df9a8f\n* http://stor.51cto.com/art/201807/578337.htm\n","slug":"rgw-multi-site","published":1,"updated":"2019-03-10T06:32:20.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck1pzbth7000rtp75r1kg9cse","content":"<h1 id=\"概述\"><a href=\"#概述\" class=\"headerlink\" title=\"概述\"></a>概述</h1><p>本文主要介绍如何配置Ceph RGW的异步复制功能，通过这个功能可以实现跨数据中心的灾备功能。<br>RGW多活方式是在同一zonegroup的多个zone之间进行，即同一zonegroup中多个zone之间的数据是完全一致的，用户可以通过任意zone读写同一份数据。 但是，对元数据的操作，比如创建桶、创建用户，仍然只能在master zone进行。对数据的操作，比如创建桶中的对象，访问对象等，可以在任意zone中 处理.</p>\n<h1 id=\"环境\"><a href=\"#环境\" class=\"headerlink\" title=\"环境\"></a>环境</h1><p>实验环境是两个ceph集群，信息如下：<br>集群ceph101  </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@ceph101 ~]# ceph -s</span><br><span class=\"line\">  cluster:</span><br><span class=\"line\">    id:     d6e42188-9871-471b-9db0-957f47893902</span><br><span class=\"line\">    health: HEALTH_OK</span><br><span class=\"line\"></span><br><span class=\"line\">  services:</span><br><span class=\"line\">    mon: 1 daemons, quorum ceph101</span><br><span class=\"line\">    mgr: ceph101(active)</span><br><span class=\"line\">    osd: 3 osds: 3 up, 3 in</span><br><span class=\"line\">    rgw: 1 daemon active</span><br><span class=\"line\"></span><br><span class=\"line\">  data:</span><br><span class=\"line\">    pools:   4 pools, 32 pgs</span><br><span class=\"line\">    objects: 187 objects, 1.09KiB</span><br><span class=\"line\">    usage:   3.01GiB used, 56.7GiB / 59.7GiB avail</span><br><span class=\"line\">    pgs:     32 active+clean</span><br></pre></td></tr></table></figure>\n<p>集群ceph102  </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@ceph102 ~]# ceph -s</span><br><span class=\"line\">  cluster:</span><br><span class=\"line\">    id:     2e80de18-e95f-463f-9eb0-531fd3254f0b</span><br><span class=\"line\">    health: HEALTH_OK</span><br><span class=\"line\"></span><br><span class=\"line\">  services:</span><br><span class=\"line\">    mon: 1 daemons, quorum ceph102</span><br><span class=\"line\">    mgr: ceph102(active)</span><br><span class=\"line\">    osd: 3 osds: 3 up, 3 in</span><br><span class=\"line\">    rgw: 1 daemon active</span><br><span class=\"line\"></span><br><span class=\"line\">  data:</span><br><span class=\"line\">    pools:   4 pools, 32 pgs</span><br><span class=\"line\">    objects: 187 objects, 1.09KiB</span><br><span class=\"line\">    usage:   3.01GiB used, 56.7GiB / 59.7GiB avail</span><br><span class=\"line\">    pgs:     32 active+clean</span><br></pre></td></tr></table></figure>\n<p>这两个ceph集群都一个rgw服务，本次实验就通过这两个ceph集群验证rgw multi site的配置，已经功能的验证。<br>本次实验已第一个集群(ceph101)做为主集群，ceph102作为备集群。</p>\n<h1 id=\"Multi-Site-配置\"><a href=\"#Multi-Site-配置\" class=\"headerlink\" title=\"Multi Site 配置\"></a>Multi Site 配置</h1><p>在主集群创建一个名为realm100的realm</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@ceph101 ~]# radosgw-admin realm create --rgw-realm=realm100 --default</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    &quot;id&quot;: &quot;337cd1c3-1ad0-4975-b220-e021a7f2b3eb&quot;,</span><br><span class=\"line\">    &quot;name&quot;: &quot;realm100&quot;,</span><br><span class=\"line\">    &quot;current_period&quot;: &quot;bd6ecbd6-3a28-46d7-a806-22e9ea001ca3&quot;,</span><br><span class=\"line\">    &quot;epoch&quot;: 1</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>创建master zonegroup</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@ceph101 ~]# radosgw-admin zonegroup create --rgw-zonegroup=cn --endpoints=http://172.16.143.201:8080 --rgw-realm=realm100 --master --default</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    &quot;id&quot;: &quot;2b3f1ea0-73e7-4f17-b4f9-1acf5d5c6033&quot;,</span><br><span class=\"line\">    &quot;name&quot;: &quot;cn&quot;,</span><br><span class=\"line\">    &quot;api_name&quot;: &quot;cn&quot;,</span><br><span class=\"line\">    &quot;is_master&quot;: &quot;true&quot;,</span><br><span class=\"line\">    &quot;endpoints&quot;: [</span><br><span class=\"line\">        &quot;http://172.16.143.201:8080&quot;</span><br><span class=\"line\">    ],</span><br><span class=\"line\">    &quot;hostnames&quot;: [],</span><br><span class=\"line\">    &quot;hostnames_s3website&quot;: [],</span><br><span class=\"line\">    &quot;master_zone&quot;: &quot;&quot;,</span><br><span class=\"line\">    &quot;zones&quot;: [],</span><br><span class=\"line\">    &quot;placement_targets&quot;: [],</span><br><span class=\"line\">    &quot;default_placement&quot;: &quot;&quot;,</span><br><span class=\"line\">    &quot;realm_id&quot;: &quot;ba638e8a-8a33-4607-8fe3-13aa69dd1758&quot;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>创建master zone</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@ceph101 ~]# radosgw-admin zone create --rgw-zonegroup=cn --rgw-zone=shanghai --master --default --endpoints=http://172.16.143.201:8080</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    &quot;id&quot;: &quot;9c655173-6346-47e7-9759-5e5d32aa017d&quot;,</span><br><span class=\"line\">    &quot;name&quot;: &quot;shanghai&quot;,</span><br><span class=\"line\">    &quot;domain_root&quot;: &quot;shanghai.rgw.meta:root&quot;,</span><br><span class=\"line\">    &quot;control_pool&quot;: &quot;shanghai.rgw.control&quot;,</span><br><span class=\"line\">    &quot;gc_pool&quot;: &quot;shanghai.rgw.log:gc&quot;,</span><br><span class=\"line\">    &quot;lc_pool&quot;: &quot;shanghai.rgw.log:lc&quot;,</span><br><span class=\"line\">    &quot;log_pool&quot;: &quot;shanghai.rgw.log&quot;,</span><br><span class=\"line\">    &quot;intent_log_pool&quot;: &quot;shanghai.rgw.log:intent&quot;,</span><br><span class=\"line\">    &quot;usage_log_pool&quot;: &quot;shanghai.rgw.log:usage&quot;,</span><br><span class=\"line\">    &quot;reshard_pool&quot;: &quot;shanghai.rgw.log:reshard&quot;,</span><br><span class=\"line\">    &quot;user_keys_pool&quot;: &quot;shanghai.rgw.meta:users.keys&quot;,</span><br><span class=\"line\">    &quot;user_email_pool&quot;: &quot;shanghai.rgw.meta:users.email&quot;,</span><br><span class=\"line\">    &quot;user_swift_pool&quot;: &quot;shanghai.rgw.meta:users.swift&quot;,</span><br><span class=\"line\">    &quot;user_uid_pool&quot;: &quot;shanghai.rgw.meta:users.uid&quot;,</span><br><span class=\"line\">    &quot;system_key&quot;: &#123;</span><br><span class=\"line\">        &quot;access_key&quot;: &quot;&quot;,</span><br><span class=\"line\">        &quot;secret_key&quot;: &quot;&quot;</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    &quot;placement_pools&quot;: [</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            &quot;key&quot;: &quot;default-placement&quot;,</span><br><span class=\"line\">            &quot;val&quot;: &#123;</span><br><span class=\"line\">                &quot;index_pool&quot;: &quot;shanghai.rgw.buckets.index&quot;,</span><br><span class=\"line\">                &quot;data_pool&quot;: &quot;shanghai.rgw.buckets.data&quot;,</span><br><span class=\"line\">                &quot;data_extra_pool&quot;: &quot;shanghai.rgw.buckets.non-ec&quot;,</span><br><span class=\"line\">                &quot;index_type&quot;: 0,</span><br><span class=\"line\">                &quot;compression&quot;: &quot;&quot;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    ],</span><br><span class=\"line\">    &quot;metadata_heap&quot;: &quot;&quot;,</span><br><span class=\"line\">    &quot;tier_config&quot;: [],</span><br><span class=\"line\">    &quot;realm_id&quot;: &quot;ba638e8a-8a33-4607-8fe3-13aa69dd1758&quot;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>更新period</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@ceph101 ~]# radosgw-admin period update --commit</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    &quot;id&quot;: &quot;064c5b5e-eb87-462c-aa37-c420ddd68b23&quot;,</span><br><span class=\"line\">    &quot;epoch&quot;: 1,</span><br><span class=\"line\">    &quot;predecessor_uuid&quot;: &quot;1abfe2d0-7453-4c01-881b-3db7f53f15c1&quot;,</span><br><span class=\"line\">    &quot;sync_status&quot;: [],</span><br><span class=\"line\">    &quot;period_map&quot;: &#123;</span><br><span class=\"line\">        &quot;id&quot;: &quot;064c5b5e-eb87-462c-aa37-c420ddd68b23&quot;,</span><br><span class=\"line\">        &quot;zonegroups&quot;: [</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                &quot;id&quot;: &quot;2b3f1ea0-73e7-4f17-b4f9-1acf5d5c6033&quot;,</span><br><span class=\"line\">                &quot;name&quot;: &quot;cn&quot;,</span><br><span class=\"line\">                &quot;api_name&quot;: &quot;cn&quot;,</span><br><span class=\"line\">                &quot;is_master&quot;: &quot;true&quot;,</span><br><span class=\"line\">                &quot;endpoints&quot;: [</span><br><span class=\"line\">                    &quot;http://172.16.143.201:8080&quot;</span><br><span class=\"line\">                ],</span><br><span class=\"line\">                &quot;hostnames&quot;: [],</span><br><span class=\"line\">                &quot;hostnames_s3website&quot;: [],</span><br><span class=\"line\">                &quot;master_zone&quot;: &quot;9c655173-6346-47e7-9759-5e5d32aa017d&quot;,</span><br><span class=\"line\">                &quot;zones&quot;: [</span><br><span class=\"line\">                    &#123;</span><br><span class=\"line\">                        &quot;id&quot;: &quot;9c655173-6346-47e7-9759-5e5d32aa017d&quot;,</span><br><span class=\"line\">                        &quot;name&quot;: &quot;shanghai&quot;,</span><br><span class=\"line\">                        &quot;endpoints&quot;: [</span><br><span class=\"line\">                            &quot;http://172.16.143.201:8080&quot;</span><br><span class=\"line\">                        ],</span><br><span class=\"line\">                        &quot;log_meta&quot;: &quot;false&quot;,</span><br><span class=\"line\">                        &quot;log_data&quot;: &quot;false&quot;,</span><br><span class=\"line\">                        &quot;bucket_index_max_shards&quot;: 0,</span><br><span class=\"line\">                        &quot;read_only&quot;: &quot;false&quot;,</span><br><span class=\"line\">                        &quot;tier_type&quot;: &quot;&quot;,</span><br><span class=\"line\">                        &quot;sync_from_all&quot;: &quot;true&quot;,</span><br><span class=\"line\">                        &quot;sync_from&quot;: []</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\">                ],</span><br><span class=\"line\">                &quot;placement_targets&quot;: [</span><br><span class=\"line\">                    &#123;</span><br><span class=\"line\">                        &quot;name&quot;: &quot;default-placement&quot;,</span><br><span class=\"line\">                        &quot;tags&quot;: []</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\">                ],</span><br><span class=\"line\">                &quot;default_placement&quot;: &quot;default-placement&quot;,</span><br><span class=\"line\">                &quot;realm_id&quot;: &quot;ba638e8a-8a33-4607-8fe3-13aa69dd1758&quot;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        ],</span><br><span class=\"line\">        &quot;short_zone_ids&quot;: [</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                &quot;key&quot;: &quot;9c655173-6346-47e7-9759-5e5d32aa017d&quot;,</span><br><span class=\"line\">                &quot;val&quot;: 1556250220</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        ]</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    &quot;master_zonegroup&quot;: &quot;2b3f1ea0-73e7-4f17-b4f9-1acf5d5c6033&quot;,</span><br><span class=\"line\">    &quot;master_zone&quot;: &quot;9c655173-6346-47e7-9759-5e5d32aa017d&quot;,</span><br><span class=\"line\">    &quot;period_config&quot;: &#123;</span><br><span class=\"line\">        &quot;bucket_quota&quot;: &#123;</span><br><span class=\"line\">            &quot;enabled&quot;: false,</span><br><span class=\"line\">            &quot;check_on_raw&quot;: false,</span><br><span class=\"line\">            &quot;max_size&quot;: -1,</span><br><span class=\"line\">            &quot;max_size_kb&quot;: 0,</span><br><span class=\"line\">            &quot;max_objects&quot;: -1</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        &quot;user_quota&quot;: &#123;</span><br><span class=\"line\">            &quot;enabled&quot;: false,</span><br><span class=\"line\">            &quot;check_on_raw&quot;: false,</span><br><span class=\"line\">            &quot;max_size&quot;: -1,</span><br><span class=\"line\">            &quot;max_size_kb&quot;: 0,</span><br><span class=\"line\">            &quot;max_objects&quot;: -1</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    &quot;realm_id&quot;: &quot;ba638e8a-8a33-4607-8fe3-13aa69dd1758&quot;,</span><br><span class=\"line\">    &quot;realm_name&quot;: &quot;realm100&quot;,</span><br><span class=\"line\">    &quot;realm_epoch&quot;: 2</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>创建同步用户</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@ceph101 ~]# radosgw-admin user create --uid=&quot;syncuser&quot; --display-name=&quot;Synchronization User&quot; --system</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    &quot;user_id&quot;: &quot;syncuser&quot;,</span><br><span class=\"line\">    &quot;display_name&quot;: &quot;Synchronization User&quot;,</span><br><span class=\"line\">    &quot;email&quot;: &quot;&quot;,</span><br><span class=\"line\">    &quot;suspended&quot;: 0,</span><br><span class=\"line\">    &quot;max_buckets&quot;: 1000,</span><br><span class=\"line\">    &quot;auid&quot;: 0,</span><br><span class=\"line\">    &quot;subusers&quot;: [],</span><br><span class=\"line\">    &quot;keys&quot;: [</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            &quot;user&quot;: &quot;syncuser&quot;,</span><br><span class=\"line\">            &quot;access_key&quot;: &quot;LPTHGKYO5ULI48Q88AWF&quot;,</span><br><span class=\"line\">            &quot;secret_key&quot;: &quot;jGFoORTVt72frRYsmcnPOpGXnz652Dl3C2IeBLN8&quot;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    ],</span><br><span class=\"line\">    &quot;swift_keys&quot;: [],</span><br><span class=\"line\">    &quot;caps&quot;: [],</span><br><span class=\"line\">    &quot;op_mask&quot;: &quot;read, write, delete&quot;,</span><br><span class=\"line\">    &quot;system&quot;: &quot;true&quot;,</span><br><span class=\"line\">    &quot;default_placement&quot;: &quot;&quot;,</span><br><span class=\"line\">    &quot;placement_tags&quot;: [],</span><br><span class=\"line\">    &quot;bucket_quota&quot;: &#123;</span><br><span class=\"line\">        &quot;enabled&quot;: false,</span><br><span class=\"line\">        &quot;check_on_raw&quot;: false,</span><br><span class=\"line\">        &quot;max_size&quot;: -1,</span><br><span class=\"line\">        &quot;max_size_kb&quot;: 0,</span><br><span class=\"line\">        &quot;max_objects&quot;: -1</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    &quot;user_quota&quot;: &#123;</span><br><span class=\"line\">        &quot;enabled&quot;: false,</span><br><span class=\"line\">        &quot;check_on_raw&quot;: false,</span><br><span class=\"line\">        &quot;max_size&quot;: -1,</span><br><span class=\"line\">        &quot;max_size_kb&quot;: 0,</span><br><span class=\"line\">        &quot;max_objects&quot;: -1</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    &quot;temp_url_keys&quot;: [],</span><br><span class=\"line\">    &quot;type&quot;: &quot;rgw&quot;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>修改zone的key，并更新period</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@ceph101 ~]# radosgw-admin zone modify --rgw-zone=shanghai --access-key=LPTHGKYO5ULI48Q88AWF --secret=jGFoORTVt72frRYsmcnPOpGXnz652Dl3C2IeBLN8</span><br><span class=\"line\"></span><br><span class=\"line\">[root@ceph101 ~]# radosgw-admin period update --commit</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    &quot;id&quot;: &quot;064c5b5e-eb87-462c-aa37-c420ddd68b23&quot;,</span><br><span class=\"line\">    &quot;epoch&quot;: 2,</span><br><span class=\"line\">    &quot;predecessor_uuid&quot;: &quot;1abfe2d0-7453-4c01-881b-3db7f53f15c1&quot;,</span><br><span class=\"line\">    &quot;sync_status&quot;: [],</span><br><span class=\"line\">    &quot;period_map&quot;: &#123;</span><br><span class=\"line\">        &quot;id&quot;: &quot;064c5b5e-eb87-462c-aa37-c420ddd68b23&quot;,</span><br><span class=\"line\">        &quot;zonegroups&quot;: [</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                &quot;id&quot;: &quot;2b3f1ea0-73e7-4f17-b4f9-1acf5d5c6033&quot;,</span><br><span class=\"line\">                &quot;name&quot;: &quot;cn&quot;,</span><br><span class=\"line\">                &quot;api_name&quot;: &quot;cn&quot;,</span><br><span class=\"line\">                &quot;is_master&quot;: &quot;true&quot;,</span><br><span class=\"line\">                &quot;endpoints&quot;: [</span><br><span class=\"line\">                    &quot;http://172.16.143.201:8080&quot;</span><br><span class=\"line\">                ],</span><br><span class=\"line\">                &quot;hostnames&quot;: [],</span><br><span class=\"line\">                &quot;hostnames_s3website&quot;: [],</span><br><span class=\"line\">                &quot;master_zone&quot;: &quot;9c655173-6346-47e7-9759-5e5d32aa017d&quot;,</span><br><span class=\"line\">                &quot;zones&quot;: [</span><br><span class=\"line\">                    &#123;</span><br><span class=\"line\">                        &quot;id&quot;: &quot;9c655173-6346-47e7-9759-5e5d32aa017d&quot;,</span><br><span class=\"line\">                        &quot;name&quot;: &quot;shanghai&quot;,</span><br><span class=\"line\">                        &quot;endpoints&quot;: [</span><br><span class=\"line\">                            &quot;http://172.16.143.201:8080&quot;</span><br><span class=\"line\">                        ],</span><br><span class=\"line\">                        &quot;log_meta&quot;: &quot;false&quot;,</span><br><span class=\"line\">                        &quot;log_data&quot;: &quot;false&quot;,</span><br><span class=\"line\">                        &quot;bucket_index_max_shards&quot;: 0,</span><br><span class=\"line\">                        &quot;read_only&quot;: &quot;false&quot;,</span><br><span class=\"line\">                        &quot;tier_type&quot;: &quot;&quot;,</span><br><span class=\"line\">                        &quot;sync_from_all&quot;: &quot;true&quot;,</span><br><span class=\"line\">                        &quot;sync_from&quot;: []</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\">                ],</span><br><span class=\"line\">                &quot;placement_targets&quot;: [</span><br><span class=\"line\">                    &#123;</span><br><span class=\"line\">                        &quot;name&quot;: &quot;default-placement&quot;,</span><br><span class=\"line\">                        &quot;tags&quot;: []</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\">                ],</span><br><span class=\"line\">                &quot;default_placement&quot;: &quot;default-placement&quot;,</span><br><span class=\"line\">                &quot;realm_id&quot;: &quot;ba638e8a-8a33-4607-8fe3-13aa69dd1758&quot;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        ],</span><br><span class=\"line\">        &quot;short_zone_ids&quot;: [</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                &quot;key&quot;: &quot;9c655173-6346-47e7-9759-5e5d32aa017d&quot;,</span><br><span class=\"line\">                &quot;val&quot;: 1556250220</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        ]</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    &quot;master_zonegroup&quot;: &quot;2b3f1ea0-73e7-4f17-b4f9-1acf5d5c6033&quot;,</span><br><span class=\"line\">    &quot;master_zone&quot;: &quot;9c655173-6346-47e7-9759-5e5d32aa017d&quot;,</span><br><span class=\"line\">    &quot;period_config&quot;: &#123;</span><br><span class=\"line\">        &quot;bucket_quota&quot;: &#123;</span><br><span class=\"line\">            &quot;enabled&quot;: false,</span><br><span class=\"line\">            &quot;check_on_raw&quot;: false,</span><br><span class=\"line\">            &quot;max_size&quot;: -1,</span><br><span class=\"line\">            &quot;max_size_kb&quot;: 0,</span><br><span class=\"line\">            &quot;max_objects&quot;: -1</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        &quot;user_quota&quot;: &#123;</span><br><span class=\"line\">            &quot;enabled&quot;: false,</span><br><span class=\"line\">            &quot;check_on_raw&quot;: false,</span><br><span class=\"line\">            &quot;max_size&quot;: -1,</span><br><span class=\"line\">            &quot;max_size_kb&quot;: 0,</span><br><span class=\"line\">            &quot;max_objects&quot;: -1</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    &quot;realm_id&quot;: &quot;ba638e8a-8a33-4607-8fe3-13aa69dd1758&quot;,</span><br><span class=\"line\">    &quot;realm_name&quot;: &quot;realm100&quot;,</span><br><span class=\"line\">    &quot;realm_epoch&quot;: 2</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>删除默认zone和zonegroup</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@ceph101 ~]# radosgw-admin zonegroup remove --rgw-zonegroup=default --rgw-zone=default</span><br><span class=\"line\">[root@ceph101 ~]# radosgw-admin period update --commit</span><br><span class=\"line\">[root@ceph101 ~]# radosgw-admin zone delete --rgw-zone=default</span><br><span class=\"line\">[root@ceph101 ~]# radosgw-admin period update --commit</span><br><span class=\"line\">[root@ceph101 ~]# radosgw-admin zonegroup delete --rgw-zonegroup=default</span><br><span class=\"line\">[root@ceph101 ~]# radosgw-admin period update --commit</span><br></pre></td></tr></table></figure>\n<p>删除默认pool</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@ceph101 ~]# ceph osd pool delete default.rgw.control default.rgw.control --yes-i-really-really-mean-it</span><br><span class=\"line\">pool &apos;default.rgw.control&apos; removed</span><br><span class=\"line\">[root@ceph101 ~]# ceph osd pool delete default.rgw.meta default.rgw.meta --yes-i-really-really-mean-it</span><br><span class=\"line\">pool &apos;default.rgw.meta&apos; removed</span><br><span class=\"line\">[root@ceph101 ~]# ceph osd pool delete default.rgw.log default.rgw.log --yes-i-really-really-mean-it</span><br><span class=\"line\">pool &apos;default.rgw.log&apos; removed</span><br></pre></td></tr></table></figure>\n<p>修改rgw配置, 增加rgw_zone = shanghai</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@ceph101 ~]# vim /etc/ceph/ceph.conf</span><br><span class=\"line\"></span><br><span class=\"line\">[global]</span><br><span class=\"line\">fsid = d6e42188-9871-471b-9db0-957f47893902</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">mon initial members = ceph101</span><br><span class=\"line\">mon host = 172.16.143.201</span><br><span class=\"line\"></span><br><span class=\"line\">public network = 172.16.143.0/24</span><br><span class=\"line\">cluster network = 172.16.140.0/24</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">mon allow pool delete = true</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">[client.rgw.ceph101]</span><br><span class=\"line\">host = ceph101</span><br><span class=\"line\">keyring = /var/lib/ceph/radosgw/ceph-rgw.ceph101/keyring</span><br><span class=\"line\">log file = /var/log/ceph/ceph-rgw-ceph101.log</span><br><span class=\"line\">rgw frontends = civetweb port=172.16.143.201:8080 num_threads=100</span><br><span class=\"line\">rgw_zone = shanghai</span><br></pre></td></tr></table></figure>\n<p>重启rgw，并查看pool是否创建</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@ceph101 ~]# systemctl restart ceph-radosgw@rgw.ceph101</span><br><span class=\"line\">[root@ceph101 ~]# ceph osd pool ls</span><br><span class=\"line\">.rgw.root</span><br><span class=\"line\">shanghai.rgw.control</span><br><span class=\"line\">shanghai.rgw.meta</span><br><span class=\"line\">shanghai.rgw.log</span><br></pre></td></tr></table></figure>\n<p>在secondy zone节点进行如下配置：  </p>\n<p>同步realm, 并设置realm100为默认的realm</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@ceph102 ~]# radosgw-admin realm pull --url=http://172.16.143.201:8080 --access-key=LPTHGKYO5ULI48Q88AWF --secret=jGFoORTVt72frRYsmcnPOpGXnz652Dl3C2IeBLN8</span><br><span class=\"line\">2019-03-09 21:25:10.377485 7fa55aca2dc0  1 found existing latest_epoch 2 &gt;= given epoch 2, returning r=-17</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    &quot;id&quot;: &quot;ba638e8a-8a33-4607-8fe3-13aa69dd1758&quot;,</span><br><span class=\"line\">    &quot;name&quot;: &quot;realm100&quot;,</span><br><span class=\"line\">    &quot;current_period&quot;: &quot;064c5b5e-eb87-462c-aa37-c420ddd68b23&quot;,</span><br><span class=\"line\">    &quot;epoch&quot;: 2</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">[root@ceph102 ~]# radosgw-admin realm default --rgw-realm=realm100</span><br></pre></td></tr></table></figure>\n<p>更新period</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@ceph102 ~]# radosgw-admin period pull --url=http://172.16.143.201:8080 --access-key=LPTHGKYO5ULI48Q88AWF --secret=jGFoORTVt72frRYsmcnPOpGXnz652Dl3C2IeBLN8</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    &quot;id&quot;: &quot;064c5b5e-eb87-462c-aa37-c420ddd68b23&quot;,</span><br><span class=\"line\">    &quot;epoch&quot;: 2,</span><br><span class=\"line\">    &quot;predecessor_uuid&quot;: &quot;1abfe2d0-7453-4c01-881b-3db7f53f15c1&quot;,</span><br><span class=\"line\">    &quot;sync_status&quot;: [],</span><br><span class=\"line\">    &quot;period_map&quot;: &#123;</span><br><span class=\"line\">        &quot;id&quot;: &quot;064c5b5e-eb87-462c-aa37-c420ddd68b23&quot;,</span><br><span class=\"line\">        &quot;zonegroups&quot;: [</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                &quot;id&quot;: &quot;2b3f1ea0-73e7-4f17-b4f9-1acf5d5c6033&quot;,</span><br><span class=\"line\">                &quot;name&quot;: &quot;cn&quot;,</span><br><span class=\"line\">                &quot;api_name&quot;: &quot;cn&quot;,</span><br><span class=\"line\">                &quot;is_master&quot;: &quot;true&quot;,</span><br><span class=\"line\">                &quot;endpoints&quot;: [</span><br><span class=\"line\">                    &quot;http://172.16.143.201:8080&quot;</span><br><span class=\"line\">                ],</span><br><span class=\"line\">                &quot;hostnames&quot;: [],</span><br><span class=\"line\">                &quot;hostnames_s3website&quot;: [],</span><br><span class=\"line\">                &quot;master_zone&quot;: &quot;9c655173-6346-47e7-9759-5e5d32aa017d&quot;,</span><br><span class=\"line\">                &quot;zones&quot;: [</span><br><span class=\"line\">                    &#123;</span><br><span class=\"line\">                        &quot;id&quot;: &quot;9c655173-6346-47e7-9759-5e5d32aa017d&quot;,</span><br><span class=\"line\">                        &quot;name&quot;: &quot;shanghai&quot;,</span><br><span class=\"line\">                        &quot;endpoints&quot;: [</span><br><span class=\"line\">                            &quot;http://172.16.143.201:8080&quot;</span><br><span class=\"line\">                        ],</span><br><span class=\"line\">                        &quot;log_meta&quot;: &quot;false&quot;,</span><br><span class=\"line\">                        &quot;log_data&quot;: &quot;false&quot;,</span><br><span class=\"line\">                        &quot;bucket_index_max_shards&quot;: 0,</span><br><span class=\"line\">                        &quot;read_only&quot;: &quot;false&quot;,</span><br><span class=\"line\">                        &quot;tier_type&quot;: &quot;&quot;,</span><br><span class=\"line\">                        &quot;sync_from_all&quot;: &quot;true&quot;,</span><br><span class=\"line\">                        &quot;sync_from&quot;: []</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\">                ],</span><br><span class=\"line\">                &quot;placement_targets&quot;: [</span><br><span class=\"line\">                    &#123;</span><br><span class=\"line\">                        &quot;name&quot;: &quot;default-placement&quot;,</span><br><span class=\"line\">                        &quot;tags&quot;: []</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\">                ],</span><br><span class=\"line\">                &quot;default_placement&quot;: &quot;default-placement&quot;,</span><br><span class=\"line\">                &quot;realm_id&quot;: &quot;ba638e8a-8a33-4607-8fe3-13aa69dd1758&quot;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        ],</span><br><span class=\"line\">        &quot;short_zone_ids&quot;: [</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                &quot;key&quot;: &quot;9c655173-6346-47e7-9759-5e5d32aa017d&quot;,</span><br><span class=\"line\">                &quot;val&quot;: 1556250220</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        ]</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    &quot;master_zonegroup&quot;: &quot;2b3f1ea0-73e7-4f17-b4f9-1acf5d5c6033&quot;,</span><br><span class=\"line\">    &quot;master_zone&quot;: &quot;9c655173-6346-47e7-9759-5e5d32aa017d&quot;,</span><br><span class=\"line\">    &quot;period_config&quot;: &#123;</span><br><span class=\"line\">        &quot;bucket_quota&quot;: &#123;</span><br><span class=\"line\">            &quot;enabled&quot;: false,</span><br><span class=\"line\">            &quot;check_on_raw&quot;: false,</span><br><span class=\"line\">            &quot;max_size&quot;: -1,</span><br><span class=\"line\">            &quot;max_size_kb&quot;: 0,</span><br><span class=\"line\">            &quot;max_objects&quot;: -1</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        &quot;user_quota&quot;: &#123;</span><br><span class=\"line\">            &quot;enabled&quot;: false,</span><br><span class=\"line\">            &quot;check_on_raw&quot;: false,</span><br><span class=\"line\">            &quot;max_size&quot;: -1,</span><br><span class=\"line\">            &quot;max_size_kb&quot;: 0,</span><br><span class=\"line\">            &quot;max_objects&quot;: -1</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    &quot;realm_id&quot;: &quot;ba638e8a-8a33-4607-8fe3-13aa69dd1758&quot;,</span><br><span class=\"line\">    &quot;realm_name&quot;: &quot;realm100&quot;,</span><br><span class=\"line\">    &quot;realm_epoch&quot;: 2</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>创建secondy zone</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@ceph102 ~]# radosgw-admin zone create --rgw-zonegroup=cn --rgw-zone=beijing --endpoints=http://172.16.143.202:8080 --access-key=LPTHGKYO5ULI48Q88AWF --secret=jGFoORTVt72frRYsmcnPOpGXnz652Dl3C2IeBLN8</span><br><span class=\"line\">2019-03-09 21:30:24.323527 7f2441e45dc0  0 failed reading obj info from .rgw.root:zone_info.9c655173-6346-47e7-9759-5e5d32aa017d: (2) No such file or directory</span><br><span class=\"line\">2019-03-09 21:30:24.323577 7f2441e45dc0  0 WARNING: could not read zone params for zone id=9c655173-6346-47e7-9759-5e5d32aa017d name=shanghai</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    &quot;id&quot;: &quot;bf59d999-1561-4f7e-a874-9de718d4c31b&quot;,</span><br><span class=\"line\">    &quot;name&quot;: &quot;beijing&quot;,</span><br><span class=\"line\">    &quot;domain_root&quot;: &quot;beijing.rgw.meta:root&quot;,</span><br><span class=\"line\">    &quot;control_pool&quot;: &quot;beijing.rgw.control&quot;,</span><br><span class=\"line\">    &quot;gc_pool&quot;: &quot;beijing.rgw.log:gc&quot;,</span><br><span class=\"line\">    &quot;lc_pool&quot;: &quot;beijing.rgw.log:lc&quot;,</span><br><span class=\"line\">    &quot;log_pool&quot;: &quot;beijing.rgw.log&quot;,</span><br><span class=\"line\">    &quot;intent_log_pool&quot;: &quot;beijing.rgw.log:intent&quot;,</span><br><span class=\"line\">    &quot;usage_log_pool&quot;: &quot;beijing.rgw.log:usage&quot;,</span><br><span class=\"line\">    &quot;reshard_pool&quot;: &quot;beijing.rgw.log:reshard&quot;,</span><br><span class=\"line\">    &quot;user_keys_pool&quot;: &quot;beijing.rgw.meta:users.keys&quot;,</span><br><span class=\"line\">    &quot;user_email_pool&quot;: &quot;beijing.rgw.meta:users.email&quot;,</span><br><span class=\"line\">    &quot;user_swift_pool&quot;: &quot;beijing.rgw.meta:users.swift&quot;,</span><br><span class=\"line\">    &quot;user_uid_pool&quot;: &quot;beijing.rgw.meta:users.uid&quot;,</span><br><span class=\"line\">    &quot;system_key&quot;: &#123;</span><br><span class=\"line\">        &quot;access_key&quot;: &quot;LPTHGKYO5ULI48Q88AWF&quot;,</span><br><span class=\"line\">        &quot;secret_key&quot;: &quot;jGFoORTVt72frRYsmcnPOpGXnz652Dl3C2IeBLN8&quot;</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    &quot;placement_pools&quot;: [</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            &quot;key&quot;: &quot;default-placement&quot;,</span><br><span class=\"line\">            &quot;val&quot;: &#123;</span><br><span class=\"line\">                &quot;index_pool&quot;: &quot;beijing.rgw.buckets.index&quot;,</span><br><span class=\"line\">                &quot;data_pool&quot;: &quot;beijing.rgw.buckets.data&quot;,</span><br><span class=\"line\">                &quot;data_extra_pool&quot;: &quot;beijing.rgw.buckets.non-ec&quot;,</span><br><span class=\"line\">                &quot;index_type&quot;: 0,</span><br><span class=\"line\">                &quot;compression&quot;: &quot;&quot;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    ],</span><br><span class=\"line\">    &quot;metadata_heap&quot;: &quot;&quot;,</span><br><span class=\"line\">    &quot;tier_config&quot;: [],</span><br><span class=\"line\">    &quot;realm_id&quot;: &quot;ba638e8a-8a33-4607-8fe3-13aa69dd1758&quot;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>删除默认default zone， defaul zonegroup和 default存储池</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@ceph102 ~]# radosgw-admin zone delete --rgw-zone=default</span><br><span class=\"line\">2019-03-09 21:31:23.577581 7f2e6c528dc0  0 zone id ce963a6e-7d58-426d-b07a-a2af2983379a is not a part of zonegroup cn</span><br><span class=\"line\">[root@ceph102 ~]# radosgw-admin zonegroup list</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    &quot;default_info&quot;: &quot;2b3f1ea0-73e7-4f17-b4f9-1acf5d5c6033&quot;,</span><br><span class=\"line\">    &quot;zonegroups&quot;: [</span><br><span class=\"line\">        &quot;cn&quot;,</span><br><span class=\"line\">        &quot;default&quot;</span><br><span class=\"line\">    ]</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">[root@ceph102 ~]# radosgw-admin zonegroup delete --rgw-zonegroup=default</span><br><span class=\"line\"></span><br><span class=\"line\">[root@ceph102 ~]# ceph osd pool delete default.rgw.control default.rgw.control --yes-i-really-really-mean-it</span><br><span class=\"line\">pool &apos;default.rgw.control&apos; removed</span><br><span class=\"line\">[root@ceph102 ~]# ceph osd pool delete default.rgw.meta default.rgw.meta --yes-i-really-really-mean-it</span><br><span class=\"line\">pool &apos;default.rgw.meta&apos; removed</span><br><span class=\"line\">[root@ceph102 ~]# ceph osd pool delete default.rgw.log default.rgw.log --yes-i-really-really-mean-it</span><br><span class=\"line\">pool &apos;default.rgw.log&apos; removed</span><br></pre></td></tr></table></figure>\n<p>修改rgw配置, 增加rgw_zone = beijing</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@ceph101 ~]# vim /etc/ceph/ceph.conf</span><br><span class=\"line\"></span><br><span class=\"line\">[global]</span><br><span class=\"line\">fsid = d6e42188-9871-471b-9db0-957f47893902</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">mon initial members = ceph101</span><br><span class=\"line\">mon host = 172.16.143.201</span><br><span class=\"line\"></span><br><span class=\"line\">public network = 172.16.143.0/24</span><br><span class=\"line\">cluster network = 172.16.140.0/24</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">mon allow pool delete = true</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">[client.rgw.ceph101]</span><br><span class=\"line\">host = ceph101</span><br><span class=\"line\">keyring = /var/lib/ceph/radosgw/ceph-rgw.ceph101/keyring</span><br><span class=\"line\">log file = /var/log/ceph/ceph-rgw-ceph101.log</span><br><span class=\"line\">rgw frontends = civetweb port=172.16.143.201:8080 num_threads=100</span><br><span class=\"line\">rgw_zone = shanghai</span><br></pre></td></tr></table></figure>\n<p>重启rgw，并查看pool是否创建</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@ceph102 ~]# systemctl restart ceph-radosgw@rgw.ceph102</span><br><span class=\"line\">[root@ceph102 ~]# ceph osd pool ls</span><br><span class=\"line\">.rgw.root</span><br><span class=\"line\">beijing.rgw.control</span><br><span class=\"line\">beijing.rgw.meta</span><br><span class=\"line\">beijing.rgw.log</span><br></pre></td></tr></table></figure>\n<p>更新period</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@ceph102 ~]# radosgw-admin period update --commit</span><br><span class=\"line\">2019-03-09 21:36:44.462809 7f23c756bdc0  1 Cannot find zone id=bf59d999-1561-4f7e-a874-9de718d4c31b (name=beijing), switching to local zonegroup configuration</span><br><span class=\"line\">Sending period to new master zone 9c655173-6346-47e7-9759-5e5d32aa017d</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    &quot;id&quot;: &quot;064c5b5e-eb87-462c-aa37-c420ddd68b23&quot;,</span><br><span class=\"line\">    &quot;epoch&quot;: 3,</span><br><span class=\"line\">    &quot;predecessor_uuid&quot;: &quot;1abfe2d0-7453-4c01-881b-3db7f53f15c1&quot;,</span><br><span class=\"line\">    &quot;sync_status&quot;: [],</span><br><span class=\"line\">    &quot;period_map&quot;: &#123;</span><br><span class=\"line\">        &quot;id&quot;: &quot;064c5b5e-eb87-462c-aa37-c420ddd68b23&quot;,</span><br><span class=\"line\">        &quot;zonegroups&quot;: [</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                &quot;id&quot;: &quot;2b3f1ea0-73e7-4f17-b4f9-1acf5d5c6033&quot;,</span><br><span class=\"line\">                &quot;name&quot;: &quot;cn&quot;,</span><br><span class=\"line\">                &quot;api_name&quot;: &quot;cn&quot;,</span><br><span class=\"line\">                &quot;is_master&quot;: &quot;true&quot;,</span><br><span class=\"line\">                &quot;endpoints&quot;: [</span><br><span class=\"line\">                    &quot;http://172.16.143.201:8080&quot;</span><br><span class=\"line\">                ],</span><br><span class=\"line\">                &quot;hostnames&quot;: [],</span><br><span class=\"line\">                &quot;hostnames_s3website&quot;: [],</span><br><span class=\"line\">                &quot;master_zone&quot;: &quot;9c655173-6346-47e7-9759-5e5d32aa017d&quot;,</span><br><span class=\"line\">                &quot;zones&quot;: [</span><br><span class=\"line\">                    &#123;</span><br><span class=\"line\">                        &quot;id&quot;: &quot;9c655173-6346-47e7-9759-5e5d32aa017d&quot;,</span><br><span class=\"line\">                        &quot;name&quot;: &quot;shanghai&quot;,</span><br><span class=\"line\">                        &quot;endpoints&quot;: [</span><br><span class=\"line\">                            &quot;http://172.16.143.201:8080&quot;</span><br><span class=\"line\">                        ],</span><br><span class=\"line\">                        &quot;log_meta&quot;: &quot;false&quot;,</span><br><span class=\"line\">                        &quot;log_data&quot;: &quot;true&quot;,</span><br><span class=\"line\">                        &quot;bucket_index_max_shards&quot;: 0,</span><br><span class=\"line\">                        &quot;read_only&quot;: &quot;false&quot;,</span><br><span class=\"line\">                        &quot;tier_type&quot;: &quot;&quot;,</span><br><span class=\"line\">                        &quot;sync_from_all&quot;: &quot;true&quot;,</span><br><span class=\"line\">                        &quot;sync_from&quot;: []</span><br><span class=\"line\">                    &#125;,</span><br><span class=\"line\">                    &#123;</span><br><span class=\"line\">                        &quot;id&quot;: &quot;bf59d999-1561-4f7e-a874-9de718d4c31b&quot;,</span><br><span class=\"line\">                        &quot;name&quot;: &quot;beijing&quot;,</span><br><span class=\"line\">                        &quot;endpoints&quot;: [],</span><br><span class=\"line\">                        &quot;log_meta&quot;: &quot;false&quot;,</span><br><span class=\"line\">                        &quot;log_data&quot;: &quot;true&quot;,</span><br><span class=\"line\">                        &quot;bucket_index_max_shards&quot;: 0,</span><br><span class=\"line\">                        &quot;read_only&quot;: &quot;false&quot;,</span><br><span class=\"line\">                        &quot;tier_type&quot;: &quot;&quot;,</span><br><span class=\"line\">                        &quot;sync_from_all&quot;: &quot;true&quot;,</span><br><span class=\"line\">                        &quot;sync_from&quot;: []</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\">                ],</span><br><span class=\"line\">                &quot;placement_targets&quot;: [</span><br><span class=\"line\">                    &#123;</span><br><span class=\"line\">                        &quot;name&quot;: &quot;default-placement&quot;,</span><br><span class=\"line\">                        &quot;tags&quot;: []</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\">                ],</span><br><span class=\"line\">                &quot;default_placement&quot;: &quot;default-placement&quot;,</span><br><span class=\"line\">                &quot;realm_id&quot;: &quot;ba638e8a-8a33-4607-8fe3-13aa69dd1758&quot;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        ],</span><br><span class=\"line\">        &quot;short_zone_ids&quot;: [</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                &quot;key&quot;: &quot;9c655173-6346-47e7-9759-5e5d32aa017d&quot;,</span><br><span class=\"line\">                &quot;val&quot;: 1556250220</span><br><span class=\"line\">            &#125;,</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                &quot;key&quot;: &quot;bf59d999-1561-4f7e-a874-9de718d4c31b&quot;,</span><br><span class=\"line\">                &quot;val&quot;: 3557185953</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        ]</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    &quot;master_zonegroup&quot;: &quot;2b3f1ea0-73e7-4f17-b4f9-1acf5d5c6033&quot;,</span><br><span class=\"line\">    &quot;master_zone&quot;: &quot;9c655173-6346-47e7-9759-5e5d32aa017d&quot;,</span><br><span class=\"line\">    &quot;period_config&quot;: &#123;</span><br><span class=\"line\">        &quot;bucket_quota&quot;: &#123;</span><br><span class=\"line\">            &quot;enabled&quot;: false,</span><br><span class=\"line\">            &quot;check_on_raw&quot;: false,</span><br><span class=\"line\">            &quot;max_size&quot;: -1,</span><br><span class=\"line\">            &quot;max_size_kb&quot;: 0,</span><br><span class=\"line\">            &quot;max_objects&quot;: -1</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        &quot;user_quota&quot;: &#123;</span><br><span class=\"line\">            &quot;enabled&quot;: false,</span><br><span class=\"line\">            &quot;check_on_raw&quot;: false,</span><br><span class=\"line\">            &quot;max_size&quot;: -1,</span><br><span class=\"line\">            &quot;max_size_kb&quot;: 0,</span><br><span class=\"line\">            &quot;max_objects&quot;: -1</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    &quot;realm_id&quot;: &quot;ba638e8a-8a33-4607-8fe3-13aa69dd1758&quot;,</span><br><span class=\"line\">    &quot;realm_name&quot;: &quot;realm100&quot;,</span><br><span class=\"line\">    &quot;realm_epoch&quot;: 2</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>查看同步状态</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@ceph101 ~]# radosgw-admin sync status</span><br><span class=\"line\">          realm ba638e8a-8a33-4607-8fe3-13aa69dd1758 (realm100)</span><br><span class=\"line\">      zonegroup 2b3f1ea0-73e7-4f17-b4f9-1acf5d5c6033 (cn)</span><br><span class=\"line\">           zone 9c655173-6346-47e7-9759-5e5d32aa017d (shanghai)</span><br><span class=\"line\">  metadata sync no sync (zone is master)</span><br><span class=\"line\">      data sync source: 0a2f706f-cc81-44f3-adf6-0d79c3e362ac (beijing)</span><br><span class=\"line\">                        syncing</span><br><span class=\"line\">                        full sync: 0/128 shards</span><br><span class=\"line\">                        incremental sync: 128/128 shards</span><br><span class=\"line\">                        data is caught up with source</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@ceph102 ~]# radosgw-admin sync status</span><br><span class=\"line\">          realm ba638e8a-8a33-4607-8fe3-13aa69dd1758 (realm100)</span><br><span class=\"line\">      zonegroup 2b3f1ea0-73e7-4f17-b4f9-1acf5d5c6033 (cn)</span><br><span class=\"line\">           zone 0a2f706f-cc81-44f3-adf6-0d79c3e362ac (beijing)</span><br><span class=\"line\">  metadata sync syncing</span><br><span class=\"line\">                full sync: 0/64 shards</span><br><span class=\"line\">                incremental sync: 64/64 shards</span><br><span class=\"line\">                metadata is caught up with master</span><br><span class=\"line\">      data sync source: 9c655173-6346-47e7-9759-5e5d32aa017d (shanghai)</span><br><span class=\"line\">                        syncing</span><br><span class=\"line\">                        full sync: 0/128 shards</span><br><span class=\"line\">                        incremental sync: 128/128 shards</span><br><span class=\"line\">                        data is caught up with source</span><br></pre></td></tr></table></figure>\n<h1 id=\"验证\"><a href=\"#验证\" class=\"headerlink\" title=\"验证\"></a>验证</h1><p>在master zone 创建一个test用户，在secondy zone 查看信息</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@ceph101 ~]# radosgw-admin user create --uid test --display-name=&quot;test user&quot;</span><br><span class=\"line\">2019-03-09 22:16:27.795146 7f022820cdc0  0 WARNING: can&apos;t generate connection for zone 0a2f706f-cc81-44f3-adf6-0d79c3e362ac id beijing: no endpoints defined</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    &quot;user_id&quot;: &quot;test&quot;,</span><br><span class=\"line\">    &quot;display_name&quot;: &quot;test user&quot;,</span><br><span class=\"line\">    &quot;email&quot;: &quot;&quot;,</span><br><span class=\"line\">    &quot;suspended&quot;: 0,</span><br><span class=\"line\">    &quot;max_buckets&quot;: 1000,</span><br><span class=\"line\">    &quot;auid&quot;: 0,</span><br><span class=\"line\">    &quot;subusers&quot;: [],</span><br><span class=\"line\">    &quot;keys&quot;: [</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            &quot;user&quot;: &quot;test&quot;,</span><br><span class=\"line\">            &quot;access_key&quot;: &quot;9R9YENBPPDZ88TQGP32D&quot;,</span><br><span class=\"line\">            &quot;secret_key&quot;: &quot;B5wtnLKNloIVxmSDISut6scU8MClv52dfInb3Omh&quot;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    ],</span><br><span class=\"line\">    &quot;swift_keys&quot;: [],</span><br><span class=\"line\">    &quot;caps&quot;: [],</span><br><span class=\"line\">    &quot;op_mask&quot;: &quot;read, write, delete&quot;,</span><br><span class=\"line\">    &quot;default_placement&quot;: &quot;&quot;,</span><br><span class=\"line\">    &quot;placement_tags&quot;: [],</span><br><span class=\"line\">    &quot;bucket_quota&quot;: &#123;</span><br><span class=\"line\">        &quot;enabled&quot;: false,</span><br><span class=\"line\">        &quot;check_on_raw&quot;: false,</span><br><span class=\"line\">        &quot;max_size&quot;: -1,</span><br><span class=\"line\">        &quot;max_size_kb&quot;: 0,</span><br><span class=\"line\">        &quot;max_objects&quot;: -1</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    &quot;user_quota&quot;: &#123;</span><br><span class=\"line\">        &quot;enabled&quot;: false,</span><br><span class=\"line\">        &quot;check_on_raw&quot;: false,</span><br><span class=\"line\">        &quot;max_size&quot;: -1,</span><br><span class=\"line\">        &quot;max_size_kb&quot;: 0,</span><br><span class=\"line\">        &quot;max_objects&quot;: -1</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    &quot;temp_url_keys&quot;: [],</span><br><span class=\"line\">    &quot;type&quot;: &quot;rgw&quot;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>secondy zone 查看用户</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@ceph102 ~]# radosgw-admin user list</span><br><span class=\"line\">[</span><br><span class=\"line\">    &quot;syncuser&quot;,</span><br><span class=\"line\">    &quot;test&quot;</span><br><span class=\"line\">]</span><br></pre></td></tr></table></figure>\n<p>在secondy zone 创建一个test2用户，在master zone 查看信息</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@ceph102 ~]# radosgw-admin user create --uid test@2 --display-name=&quot;test2 user&quot;</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    &quot;user_id&quot;: &quot;test@2&quot;,</span><br><span class=\"line\">    &quot;display_name&quot;: &quot;test2 user&quot;,</span><br><span class=\"line\">    &quot;email&quot;: &quot;&quot;,</span><br><span class=\"line\">    &quot;suspended&quot;: 0,</span><br><span class=\"line\">    &quot;max_buckets&quot;: 1000,</span><br><span class=\"line\">    &quot;auid&quot;: 0,</span><br><span class=\"line\">    &quot;subusers&quot;: [],</span><br><span class=\"line\">    &quot;keys&quot;: [</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            &quot;user&quot;: &quot;test@2&quot;,</span><br><span class=\"line\">            &quot;access_key&quot;: &quot;9413B8F517W6LTEKN0H6&quot;,</span><br><span class=\"line\">            &quot;secret_key&quot;: &quot;lg9vzVhpS2gYdXDnEOEUv3uCwkz0wkyuuBSnh8dl&quot;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    ],</span><br><span class=\"line\">    &quot;swift_keys&quot;: [],</span><br><span class=\"line\">    &quot;caps&quot;: [],</span><br><span class=\"line\">    &quot;op_mask&quot;: &quot;read, write, delete&quot;,</span><br><span class=\"line\">    &quot;default_placement&quot;: &quot;&quot;,</span><br><span class=\"line\">    &quot;placement_tags&quot;: [],</span><br><span class=\"line\">    &quot;bucket_quota&quot;: &#123;</span><br><span class=\"line\">        &quot;enabled&quot;: false,</span><br><span class=\"line\">        &quot;check_on_raw&quot;: false,</span><br><span class=\"line\">        &quot;max_size&quot;: -1,</span><br><span class=\"line\">        &quot;max_size_kb&quot;: 0,</span><br><span class=\"line\">        &quot;max_objects&quot;: -1</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    &quot;user_quota&quot;: &#123;</span><br><span class=\"line\">        &quot;enabled&quot;: false,</span><br><span class=\"line\">        &quot;check_on_raw&quot;: false,</span><br><span class=\"line\">        &quot;max_size&quot;: -1,</span><br><span class=\"line\">        &quot;max_size_kb&quot;: 0,</span><br><span class=\"line\">        &quot;max_objects&quot;: -1</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    &quot;temp_url_keys&quot;: [],</span><br><span class=\"line\">    &quot;type&quot;: &quot;rgw&quot;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">[root@ceph102 ~]# radosgw-admin user list</span><br><span class=\"line\">[</span><br><span class=\"line\">    &quot;syncuser&quot;,</span><br><span class=\"line\">    &quot;test@2&quot;,</span><br><span class=\"line\">    &quot;test&quot;</span><br><span class=\"line\">]</span><br></pre></td></tr></table></figure>\n<p>在master zone 查看</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@ceph101 ~]# radosgw-admin user list</span><br><span class=\"line\">[</span><br><span class=\"line\">    &quot;syncuser&quot;,</span><br><span class=\"line\">    &quot;test&quot;</span><br><span class=\"line\">]</span><br></pre></td></tr></table></figure>\n<p>可以看到在master zone创建的用户，在secondy zone也可以看到<br>而在secondy zone创建的用户，在master zone看不到</p>\n<p>通过test用户，在master zone 创建名为bucket1的bucket</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@ceph101 ~]# s3cmd mb s3://bucket1</span><br><span class=\"line\">Bucket &apos;s3://bucket1/&apos; created</span><br><span class=\"line\">[root@ceph101 ~]# radosgw-admin bucket list</span><br><span class=\"line\">[</span><br><span class=\"line\">    &quot;bucket1&quot;</span><br><span class=\"line\">]</span><br></pre></td></tr></table></figure>\n<p>在secondy zone查看</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@ceph102 ~]# radosgw-admin bucket list</span><br><span class=\"line\">[</span><br><span class=\"line\">    &quot;bucket1&quot;</span><br><span class=\"line\">]</span><br></pre></td></tr></table></figure>\n<p>通过test用户，在secondy zone 创建名为bucket2的bucket</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@ceph102 ~]# s3cmd mb s3://bucket2</span><br><span class=\"line\">Bucket &apos;s3://bucket2/&apos; created</span><br><span class=\"line\">[root@ceph102 ~]# radosgw-admin bucket list</span><br><span class=\"line\">[</span><br><span class=\"line\">    &quot;bucket1&quot;,</span><br><span class=\"line\">    &quot;bucket2&quot;</span><br><span class=\"line\">]</span><br></pre></td></tr></table></figure>\n<p>在master zone 查看</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@ceph101 ~]# radosgw-admin bucket list</span><br><span class=\"line\">[</span><br><span class=\"line\">    &quot;bucket1&quot;,</span><br><span class=\"line\">    &quot;bucket2&quot;</span><br><span class=\"line\">]</span><br></pre></td></tr></table></figure>\n<p>在master zone 上传文件</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@ceph101 ~]# s3cmd put Python-3.4.9.tgz s3://bucket1/python3.4.9.tgz</span><br><span class=\"line\">upload: &apos;Python-3.4.9.tgz&apos; -&gt; &apos;s3://bucket1/python3.4.9.tgz&apos;  [part 1 of 2, 15MB] [1 of 1]</span><br><span class=\"line\"> 15728640 of 15728640   100% in    2s     6.26 MB/s  done</span><br><span class=\"line\">upload: &apos;Python-3.4.9.tgz&apos; -&gt; &apos;s3://bucket1/python3.4.9.tgz&apos;  [part 2 of 2, 3MB] [1 of 1]</span><br><span class=\"line\"> 3955465 of 3955465   100% in    0s    32.73 MB/s  done</span><br><span class=\"line\"> </span><br><span class=\"line\">[root@ceph101 ~]# md5sum Python-3.4.9.tgz</span><br><span class=\"line\">c706902881ef95e27e59f13fabbcdcac  Python-3.4.9.tgz</span><br></pre></td></tr></table></figure>\n<p>在secondy zone 查看信息</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@ceph102 ~]# s3cmd ls s3://bucket1</span><br><span class=\"line\">2019-03-09 15:34  19684105   s3://bucket1/python3.4.9.tgz</span><br><span class=\"line\">[root@ceph102 ~]# s3cmd get s3://bucket1/python3.4.9.tgz Python3.4.9.tgz</span><br><span class=\"line\">download: &apos;s3://bucket1/python3.4.9.tgz&apos; -&gt; &apos;Python3.4.9.tgz&apos;  [1 of 1]</span><br><span class=\"line\"> 19684105 of 19684105   100% in    0s    51.81 MB/s  done</span><br><span class=\"line\">[root@ceph102 ~]# md5sum Python3.4.9.tgz</span><br><span class=\"line\">c706902881ef95e27e59f13fabbcdcac  Python3.4.9.tgz</span><br></pre></td></tr></table></figure>\n<p>在secondy zone 上传文件</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@ceph102 ~]# s3cmd put anaconda-ks.cfg s3://bucket2/anaconda-ks.cfg</span><br><span class=\"line\">upload: &apos;anaconda-ks.cfg&apos; -&gt; &apos;s3://bucket2/anaconda-ks.cfg&apos;  [1 of 1]</span><br><span class=\"line\"> 1030 of 1030   100% in    0s     8.28 kB/s  done</span><br><span class=\"line\">[root@ceph102 ~]# md5sum anaconda-ks.cfg</span><br><span class=\"line\">1627b1ce985ce5befdd0d1cb0e6164ae  anaconda-ks.cfg</span><br></pre></td></tr></table></figure>\n<p>在master zone 查看</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@ceph101 tmp]# s3cmd ls s3://bucket2</span><br><span class=\"line\">2019-03-09 15:37      1030   s3://bucket2/anaconda-ks.cfg</span><br><span class=\"line\">[root@ceph101 tmp]# s3cmd get s3://bucket2/anaconda-ks.cfg anaconda-ks.cfg</span><br><span class=\"line\">download: &apos;s3://bucket2/anaconda-ks.cfg&apos; -&gt; &apos;anaconda-ks.cfg&apos;  [1 of 1]</span><br><span class=\"line\"> 1030 of 1030   100% in    0s    23.32 kB/s  done</span><br><span class=\"line\">[root@ceph101 tmp]# md5sum anaconda-ks.cfg</span><br><span class=\"line\">1627b1ce985ce5befdd0d1cb0e6164ae  anaconda-ks.cfg</span><br></pre></td></tr></table></figure>\n<p>停止master zone的grup，然后在secondy zone上创建存储桶</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@ceph101 tmp]# systemctl stop ceph-radosgw@rgw.ceph101</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@ceph102 ~]# s3cmd mb s3://bucket4</span><br><span class=\"line\">WARNING: Retrying failed request: / (503 (ServiceUnavailable))</span><br><span class=\"line\">WARNING: Waiting 3 sec...</span><br><span class=\"line\">WARNING: Retrying failed request: / (503 (ServiceUnavailable))</span><br><span class=\"line\">WARNING: Waiting 6 sec...</span><br><span class=\"line\">WARNING: Retrying failed request: / (503 (ServiceUnavailable))</span><br><span class=\"line\">WARNING: Waiting 9 sec...</span><br></pre></td></tr></table></figure>\n<p>可以看到在secondy zone上并不能创建bucket，之前在secondy zone上创建bucket，也是把请求转到master zone上。</p>\n<p>反之，停止secondy zone的rgw，在master zone也是可以创建存储桶</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@ceph102 ~]# systemctl stop ceph-radosgw@ceph102</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@ceph101 tmp]# s3cmd mb s3://bucket5</span><br><span class=\"line\">Bucket &apos;s3://bucket5/&apos; created</span><br></pre></td></tr></table></figure>\n<h1 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h1><ul>\n<li><a href=\"http://docs.ceph.com/docs/luminous/radosgw/multisite/\" target=\"_blank\" rel=\"noopener\">http://docs.ceph.com/docs/luminous/radosgw/multisite/</a></li>\n<li><a href=\"https://access.redhat.com/documentation/en-us/red_hat_ceph_storage/2/html/object_gateway_guide_for_red_hat_enterprise_linux/multi_site\" target=\"_blank\" rel=\"noopener\">https://access.redhat.com/documentation/en-us/red_hat_ceph_storage/2/html/object_gateway_guide_for_red_hat_enterprise_linux/multi_site</a></li>\n<li><a href=\"https://www.jianshu.com/p/31a6f8df9a8f\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/31a6f8df9a8f</a></li>\n<li><a href=\"http://stor.51cto.com/art/201807/578337.htm\" target=\"_blank\" rel=\"noopener\">http://stor.51cto.com/art/201807/578337.htm</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"概述\"><a href=\"#概述\" class=\"headerlink\" title=\"概述\"></a>概述</h1><p>本文主要介绍如何配置Ceph RGW的异步复制功能，通过这个功能可以实现跨数据中心的灾备功能。<br>RGW多活方式是在同一zonegroup的多个zone之间进行，即同一zonegroup中多个zone之间的数据是完全一致的，用户可以通过任意zone读写同一份数据。 但是，对元数据的操作，比如创建桶、创建用户，仍然只能在master zone进行。对数据的操作，比如创建桶中的对象，访问对象等，可以在任意zone中 处理.</p>\n<h1 id=\"环境\"><a href=\"#环境\" class=\"headerlink\" title=\"环境\"></a>环境</h1><p>实验环境是两个ceph集群，信息如下：<br>集群ceph101  </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@ceph101 ~]# ceph -s</span><br><span class=\"line\">  cluster:</span><br><span class=\"line\">    id:     d6e42188-9871-471b-9db0-957f47893902</span><br><span class=\"line\">    health: HEALTH_OK</span><br><span class=\"line\"></span><br><span class=\"line\">  services:</span><br><span class=\"line\">    mon: 1 daemons, quorum ceph101</span><br><span class=\"line\">    mgr: ceph101(active)</span><br><span class=\"line\">    osd: 3 osds: 3 up, 3 in</span><br><span class=\"line\">    rgw: 1 daemon active</span><br><span class=\"line\"></span><br><span class=\"line\">  data:</span><br><span class=\"line\">    pools:   4 pools, 32 pgs</span><br><span class=\"line\">    objects: 187 objects, 1.09KiB</span><br><span class=\"line\">    usage:   3.01GiB used, 56.7GiB / 59.7GiB avail</span><br><span class=\"line\">    pgs:     32 active+clean</span><br></pre></td></tr></table></figure>\n<p>集群ceph102  </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@ceph102 ~]# ceph -s</span><br><span class=\"line\">  cluster:</span><br><span class=\"line\">    id:     2e80de18-e95f-463f-9eb0-531fd3254f0b</span><br><span class=\"line\">    health: HEALTH_OK</span><br><span class=\"line\"></span><br><span class=\"line\">  services:</span><br><span class=\"line\">    mon: 1 daemons, quorum ceph102</span><br><span class=\"line\">    mgr: ceph102(active)</span><br><span class=\"line\">    osd: 3 osds: 3 up, 3 in</span><br><span class=\"line\">    rgw: 1 daemon active</span><br><span class=\"line\"></span><br><span class=\"line\">  data:</span><br><span class=\"line\">    pools:   4 pools, 32 pgs</span><br><span class=\"line\">    objects: 187 objects, 1.09KiB</span><br><span class=\"line\">    usage:   3.01GiB used, 56.7GiB / 59.7GiB avail</span><br><span class=\"line\">    pgs:     32 active+clean</span><br></pre></td></tr></table></figure>\n<p>这两个ceph集群都一个rgw服务，本次实验就通过这两个ceph集群验证rgw multi site的配置，已经功能的验证。<br>本次实验已第一个集群(ceph101)做为主集群，ceph102作为备集群。</p>\n<h1 id=\"Multi-Site-配置\"><a href=\"#Multi-Site-配置\" class=\"headerlink\" title=\"Multi Site 配置\"></a>Multi Site 配置</h1><p>在主集群创建一个名为realm100的realm</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@ceph101 ~]# radosgw-admin realm create --rgw-realm=realm100 --default</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    &quot;id&quot;: &quot;337cd1c3-1ad0-4975-b220-e021a7f2b3eb&quot;,</span><br><span class=\"line\">    &quot;name&quot;: &quot;realm100&quot;,</span><br><span class=\"line\">    &quot;current_period&quot;: &quot;bd6ecbd6-3a28-46d7-a806-22e9ea001ca3&quot;,</span><br><span class=\"line\">    &quot;epoch&quot;: 1</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>创建master zonegroup</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@ceph101 ~]# radosgw-admin zonegroup create --rgw-zonegroup=cn --endpoints=http://172.16.143.201:8080 --rgw-realm=realm100 --master --default</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    &quot;id&quot;: &quot;2b3f1ea0-73e7-4f17-b4f9-1acf5d5c6033&quot;,</span><br><span class=\"line\">    &quot;name&quot;: &quot;cn&quot;,</span><br><span class=\"line\">    &quot;api_name&quot;: &quot;cn&quot;,</span><br><span class=\"line\">    &quot;is_master&quot;: &quot;true&quot;,</span><br><span class=\"line\">    &quot;endpoints&quot;: [</span><br><span class=\"line\">        &quot;http://172.16.143.201:8080&quot;</span><br><span class=\"line\">    ],</span><br><span class=\"line\">    &quot;hostnames&quot;: [],</span><br><span class=\"line\">    &quot;hostnames_s3website&quot;: [],</span><br><span class=\"line\">    &quot;master_zone&quot;: &quot;&quot;,</span><br><span class=\"line\">    &quot;zones&quot;: [],</span><br><span class=\"line\">    &quot;placement_targets&quot;: [],</span><br><span class=\"line\">    &quot;default_placement&quot;: &quot;&quot;,</span><br><span class=\"line\">    &quot;realm_id&quot;: &quot;ba638e8a-8a33-4607-8fe3-13aa69dd1758&quot;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>创建master zone</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@ceph101 ~]# radosgw-admin zone create --rgw-zonegroup=cn --rgw-zone=shanghai --master --default --endpoints=http://172.16.143.201:8080</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    &quot;id&quot;: &quot;9c655173-6346-47e7-9759-5e5d32aa017d&quot;,</span><br><span class=\"line\">    &quot;name&quot;: &quot;shanghai&quot;,</span><br><span class=\"line\">    &quot;domain_root&quot;: &quot;shanghai.rgw.meta:root&quot;,</span><br><span class=\"line\">    &quot;control_pool&quot;: &quot;shanghai.rgw.control&quot;,</span><br><span class=\"line\">    &quot;gc_pool&quot;: &quot;shanghai.rgw.log:gc&quot;,</span><br><span class=\"line\">    &quot;lc_pool&quot;: &quot;shanghai.rgw.log:lc&quot;,</span><br><span class=\"line\">    &quot;log_pool&quot;: &quot;shanghai.rgw.log&quot;,</span><br><span class=\"line\">    &quot;intent_log_pool&quot;: &quot;shanghai.rgw.log:intent&quot;,</span><br><span class=\"line\">    &quot;usage_log_pool&quot;: &quot;shanghai.rgw.log:usage&quot;,</span><br><span class=\"line\">    &quot;reshard_pool&quot;: &quot;shanghai.rgw.log:reshard&quot;,</span><br><span class=\"line\">    &quot;user_keys_pool&quot;: &quot;shanghai.rgw.meta:users.keys&quot;,</span><br><span class=\"line\">    &quot;user_email_pool&quot;: &quot;shanghai.rgw.meta:users.email&quot;,</span><br><span class=\"line\">    &quot;user_swift_pool&quot;: &quot;shanghai.rgw.meta:users.swift&quot;,</span><br><span class=\"line\">    &quot;user_uid_pool&quot;: &quot;shanghai.rgw.meta:users.uid&quot;,</span><br><span class=\"line\">    &quot;system_key&quot;: &#123;</span><br><span class=\"line\">        &quot;access_key&quot;: &quot;&quot;,</span><br><span class=\"line\">        &quot;secret_key&quot;: &quot;&quot;</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    &quot;placement_pools&quot;: [</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            &quot;key&quot;: &quot;default-placement&quot;,</span><br><span class=\"line\">            &quot;val&quot;: &#123;</span><br><span class=\"line\">                &quot;index_pool&quot;: &quot;shanghai.rgw.buckets.index&quot;,</span><br><span class=\"line\">                &quot;data_pool&quot;: &quot;shanghai.rgw.buckets.data&quot;,</span><br><span class=\"line\">                &quot;data_extra_pool&quot;: &quot;shanghai.rgw.buckets.non-ec&quot;,</span><br><span class=\"line\">                &quot;index_type&quot;: 0,</span><br><span class=\"line\">                &quot;compression&quot;: &quot;&quot;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    ],</span><br><span class=\"line\">    &quot;metadata_heap&quot;: &quot;&quot;,</span><br><span class=\"line\">    &quot;tier_config&quot;: [],</span><br><span class=\"line\">    &quot;realm_id&quot;: &quot;ba638e8a-8a33-4607-8fe3-13aa69dd1758&quot;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>更新period</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@ceph101 ~]# radosgw-admin period update --commit</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    &quot;id&quot;: &quot;064c5b5e-eb87-462c-aa37-c420ddd68b23&quot;,</span><br><span class=\"line\">    &quot;epoch&quot;: 1,</span><br><span class=\"line\">    &quot;predecessor_uuid&quot;: &quot;1abfe2d0-7453-4c01-881b-3db7f53f15c1&quot;,</span><br><span class=\"line\">    &quot;sync_status&quot;: [],</span><br><span class=\"line\">    &quot;period_map&quot;: &#123;</span><br><span class=\"line\">        &quot;id&quot;: &quot;064c5b5e-eb87-462c-aa37-c420ddd68b23&quot;,</span><br><span class=\"line\">        &quot;zonegroups&quot;: [</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                &quot;id&quot;: &quot;2b3f1ea0-73e7-4f17-b4f9-1acf5d5c6033&quot;,</span><br><span class=\"line\">                &quot;name&quot;: &quot;cn&quot;,</span><br><span class=\"line\">                &quot;api_name&quot;: &quot;cn&quot;,</span><br><span class=\"line\">                &quot;is_master&quot;: &quot;true&quot;,</span><br><span class=\"line\">                &quot;endpoints&quot;: [</span><br><span class=\"line\">                    &quot;http://172.16.143.201:8080&quot;</span><br><span class=\"line\">                ],</span><br><span class=\"line\">                &quot;hostnames&quot;: [],</span><br><span class=\"line\">                &quot;hostnames_s3website&quot;: [],</span><br><span class=\"line\">                &quot;master_zone&quot;: &quot;9c655173-6346-47e7-9759-5e5d32aa017d&quot;,</span><br><span class=\"line\">                &quot;zones&quot;: [</span><br><span class=\"line\">                    &#123;</span><br><span class=\"line\">                        &quot;id&quot;: &quot;9c655173-6346-47e7-9759-5e5d32aa017d&quot;,</span><br><span class=\"line\">                        &quot;name&quot;: &quot;shanghai&quot;,</span><br><span class=\"line\">                        &quot;endpoints&quot;: [</span><br><span class=\"line\">                            &quot;http://172.16.143.201:8080&quot;</span><br><span class=\"line\">                        ],</span><br><span class=\"line\">                        &quot;log_meta&quot;: &quot;false&quot;,</span><br><span class=\"line\">                        &quot;log_data&quot;: &quot;false&quot;,</span><br><span class=\"line\">                        &quot;bucket_index_max_shards&quot;: 0,</span><br><span class=\"line\">                        &quot;read_only&quot;: &quot;false&quot;,</span><br><span class=\"line\">                        &quot;tier_type&quot;: &quot;&quot;,</span><br><span class=\"line\">                        &quot;sync_from_all&quot;: &quot;true&quot;,</span><br><span class=\"line\">                        &quot;sync_from&quot;: []</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\">                ],</span><br><span class=\"line\">                &quot;placement_targets&quot;: [</span><br><span class=\"line\">                    &#123;</span><br><span class=\"line\">                        &quot;name&quot;: &quot;default-placement&quot;,</span><br><span class=\"line\">                        &quot;tags&quot;: []</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\">                ],</span><br><span class=\"line\">                &quot;default_placement&quot;: &quot;default-placement&quot;,</span><br><span class=\"line\">                &quot;realm_id&quot;: &quot;ba638e8a-8a33-4607-8fe3-13aa69dd1758&quot;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        ],</span><br><span class=\"line\">        &quot;short_zone_ids&quot;: [</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                &quot;key&quot;: &quot;9c655173-6346-47e7-9759-5e5d32aa017d&quot;,</span><br><span class=\"line\">                &quot;val&quot;: 1556250220</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        ]</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    &quot;master_zonegroup&quot;: &quot;2b3f1ea0-73e7-4f17-b4f9-1acf5d5c6033&quot;,</span><br><span class=\"line\">    &quot;master_zone&quot;: &quot;9c655173-6346-47e7-9759-5e5d32aa017d&quot;,</span><br><span class=\"line\">    &quot;period_config&quot;: &#123;</span><br><span class=\"line\">        &quot;bucket_quota&quot;: &#123;</span><br><span class=\"line\">            &quot;enabled&quot;: false,</span><br><span class=\"line\">            &quot;check_on_raw&quot;: false,</span><br><span class=\"line\">            &quot;max_size&quot;: -1,</span><br><span class=\"line\">            &quot;max_size_kb&quot;: 0,</span><br><span class=\"line\">            &quot;max_objects&quot;: -1</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        &quot;user_quota&quot;: &#123;</span><br><span class=\"line\">            &quot;enabled&quot;: false,</span><br><span class=\"line\">            &quot;check_on_raw&quot;: false,</span><br><span class=\"line\">            &quot;max_size&quot;: -1,</span><br><span class=\"line\">            &quot;max_size_kb&quot;: 0,</span><br><span class=\"line\">            &quot;max_objects&quot;: -1</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    &quot;realm_id&quot;: &quot;ba638e8a-8a33-4607-8fe3-13aa69dd1758&quot;,</span><br><span class=\"line\">    &quot;realm_name&quot;: &quot;realm100&quot;,</span><br><span class=\"line\">    &quot;realm_epoch&quot;: 2</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>创建同步用户</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@ceph101 ~]# radosgw-admin user create --uid=&quot;syncuser&quot; --display-name=&quot;Synchronization User&quot; --system</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    &quot;user_id&quot;: &quot;syncuser&quot;,</span><br><span class=\"line\">    &quot;display_name&quot;: &quot;Synchronization User&quot;,</span><br><span class=\"line\">    &quot;email&quot;: &quot;&quot;,</span><br><span class=\"line\">    &quot;suspended&quot;: 0,</span><br><span class=\"line\">    &quot;max_buckets&quot;: 1000,</span><br><span class=\"line\">    &quot;auid&quot;: 0,</span><br><span class=\"line\">    &quot;subusers&quot;: [],</span><br><span class=\"line\">    &quot;keys&quot;: [</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            &quot;user&quot;: &quot;syncuser&quot;,</span><br><span class=\"line\">            &quot;access_key&quot;: &quot;LPTHGKYO5ULI48Q88AWF&quot;,</span><br><span class=\"line\">            &quot;secret_key&quot;: &quot;jGFoORTVt72frRYsmcnPOpGXnz652Dl3C2IeBLN8&quot;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    ],</span><br><span class=\"line\">    &quot;swift_keys&quot;: [],</span><br><span class=\"line\">    &quot;caps&quot;: [],</span><br><span class=\"line\">    &quot;op_mask&quot;: &quot;read, write, delete&quot;,</span><br><span class=\"line\">    &quot;system&quot;: &quot;true&quot;,</span><br><span class=\"line\">    &quot;default_placement&quot;: &quot;&quot;,</span><br><span class=\"line\">    &quot;placement_tags&quot;: [],</span><br><span class=\"line\">    &quot;bucket_quota&quot;: &#123;</span><br><span class=\"line\">        &quot;enabled&quot;: false,</span><br><span class=\"line\">        &quot;check_on_raw&quot;: false,</span><br><span class=\"line\">        &quot;max_size&quot;: -1,</span><br><span class=\"line\">        &quot;max_size_kb&quot;: 0,</span><br><span class=\"line\">        &quot;max_objects&quot;: -1</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    &quot;user_quota&quot;: &#123;</span><br><span class=\"line\">        &quot;enabled&quot;: false,</span><br><span class=\"line\">        &quot;check_on_raw&quot;: false,</span><br><span class=\"line\">        &quot;max_size&quot;: -1,</span><br><span class=\"line\">        &quot;max_size_kb&quot;: 0,</span><br><span class=\"line\">        &quot;max_objects&quot;: -1</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    &quot;temp_url_keys&quot;: [],</span><br><span class=\"line\">    &quot;type&quot;: &quot;rgw&quot;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>修改zone的key，并更新period</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@ceph101 ~]# radosgw-admin zone modify --rgw-zone=shanghai --access-key=LPTHGKYO5ULI48Q88AWF --secret=jGFoORTVt72frRYsmcnPOpGXnz652Dl3C2IeBLN8</span><br><span class=\"line\"></span><br><span class=\"line\">[root@ceph101 ~]# radosgw-admin period update --commit</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    &quot;id&quot;: &quot;064c5b5e-eb87-462c-aa37-c420ddd68b23&quot;,</span><br><span class=\"line\">    &quot;epoch&quot;: 2,</span><br><span class=\"line\">    &quot;predecessor_uuid&quot;: &quot;1abfe2d0-7453-4c01-881b-3db7f53f15c1&quot;,</span><br><span class=\"line\">    &quot;sync_status&quot;: [],</span><br><span class=\"line\">    &quot;period_map&quot;: &#123;</span><br><span class=\"line\">        &quot;id&quot;: &quot;064c5b5e-eb87-462c-aa37-c420ddd68b23&quot;,</span><br><span class=\"line\">        &quot;zonegroups&quot;: [</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                &quot;id&quot;: &quot;2b3f1ea0-73e7-4f17-b4f9-1acf5d5c6033&quot;,</span><br><span class=\"line\">                &quot;name&quot;: &quot;cn&quot;,</span><br><span class=\"line\">                &quot;api_name&quot;: &quot;cn&quot;,</span><br><span class=\"line\">                &quot;is_master&quot;: &quot;true&quot;,</span><br><span class=\"line\">                &quot;endpoints&quot;: [</span><br><span class=\"line\">                    &quot;http://172.16.143.201:8080&quot;</span><br><span class=\"line\">                ],</span><br><span class=\"line\">                &quot;hostnames&quot;: [],</span><br><span class=\"line\">                &quot;hostnames_s3website&quot;: [],</span><br><span class=\"line\">                &quot;master_zone&quot;: &quot;9c655173-6346-47e7-9759-5e5d32aa017d&quot;,</span><br><span class=\"line\">                &quot;zones&quot;: [</span><br><span class=\"line\">                    &#123;</span><br><span class=\"line\">                        &quot;id&quot;: &quot;9c655173-6346-47e7-9759-5e5d32aa017d&quot;,</span><br><span class=\"line\">                        &quot;name&quot;: &quot;shanghai&quot;,</span><br><span class=\"line\">                        &quot;endpoints&quot;: [</span><br><span class=\"line\">                            &quot;http://172.16.143.201:8080&quot;</span><br><span class=\"line\">                        ],</span><br><span class=\"line\">                        &quot;log_meta&quot;: &quot;false&quot;,</span><br><span class=\"line\">                        &quot;log_data&quot;: &quot;false&quot;,</span><br><span class=\"line\">                        &quot;bucket_index_max_shards&quot;: 0,</span><br><span class=\"line\">                        &quot;read_only&quot;: &quot;false&quot;,</span><br><span class=\"line\">                        &quot;tier_type&quot;: &quot;&quot;,</span><br><span class=\"line\">                        &quot;sync_from_all&quot;: &quot;true&quot;,</span><br><span class=\"line\">                        &quot;sync_from&quot;: []</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\">                ],</span><br><span class=\"line\">                &quot;placement_targets&quot;: [</span><br><span class=\"line\">                    &#123;</span><br><span class=\"line\">                        &quot;name&quot;: &quot;default-placement&quot;,</span><br><span class=\"line\">                        &quot;tags&quot;: []</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\">                ],</span><br><span class=\"line\">                &quot;default_placement&quot;: &quot;default-placement&quot;,</span><br><span class=\"line\">                &quot;realm_id&quot;: &quot;ba638e8a-8a33-4607-8fe3-13aa69dd1758&quot;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        ],</span><br><span class=\"line\">        &quot;short_zone_ids&quot;: [</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                &quot;key&quot;: &quot;9c655173-6346-47e7-9759-5e5d32aa017d&quot;,</span><br><span class=\"line\">                &quot;val&quot;: 1556250220</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        ]</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    &quot;master_zonegroup&quot;: &quot;2b3f1ea0-73e7-4f17-b4f9-1acf5d5c6033&quot;,</span><br><span class=\"line\">    &quot;master_zone&quot;: &quot;9c655173-6346-47e7-9759-5e5d32aa017d&quot;,</span><br><span class=\"line\">    &quot;period_config&quot;: &#123;</span><br><span class=\"line\">        &quot;bucket_quota&quot;: &#123;</span><br><span class=\"line\">            &quot;enabled&quot;: false,</span><br><span class=\"line\">            &quot;check_on_raw&quot;: false,</span><br><span class=\"line\">            &quot;max_size&quot;: -1,</span><br><span class=\"line\">            &quot;max_size_kb&quot;: 0,</span><br><span class=\"line\">            &quot;max_objects&quot;: -1</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        &quot;user_quota&quot;: &#123;</span><br><span class=\"line\">            &quot;enabled&quot;: false,</span><br><span class=\"line\">            &quot;check_on_raw&quot;: false,</span><br><span class=\"line\">            &quot;max_size&quot;: -1,</span><br><span class=\"line\">            &quot;max_size_kb&quot;: 0,</span><br><span class=\"line\">            &quot;max_objects&quot;: -1</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    &quot;realm_id&quot;: &quot;ba638e8a-8a33-4607-8fe3-13aa69dd1758&quot;,</span><br><span class=\"line\">    &quot;realm_name&quot;: &quot;realm100&quot;,</span><br><span class=\"line\">    &quot;realm_epoch&quot;: 2</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>删除默认zone和zonegroup</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@ceph101 ~]# radosgw-admin zonegroup remove --rgw-zonegroup=default --rgw-zone=default</span><br><span class=\"line\">[root@ceph101 ~]# radosgw-admin period update --commit</span><br><span class=\"line\">[root@ceph101 ~]# radosgw-admin zone delete --rgw-zone=default</span><br><span class=\"line\">[root@ceph101 ~]# radosgw-admin period update --commit</span><br><span class=\"line\">[root@ceph101 ~]# radosgw-admin zonegroup delete --rgw-zonegroup=default</span><br><span class=\"line\">[root@ceph101 ~]# radosgw-admin period update --commit</span><br></pre></td></tr></table></figure>\n<p>删除默认pool</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@ceph101 ~]# ceph osd pool delete default.rgw.control default.rgw.control --yes-i-really-really-mean-it</span><br><span class=\"line\">pool &apos;default.rgw.control&apos; removed</span><br><span class=\"line\">[root@ceph101 ~]# ceph osd pool delete default.rgw.meta default.rgw.meta --yes-i-really-really-mean-it</span><br><span class=\"line\">pool &apos;default.rgw.meta&apos; removed</span><br><span class=\"line\">[root@ceph101 ~]# ceph osd pool delete default.rgw.log default.rgw.log --yes-i-really-really-mean-it</span><br><span class=\"line\">pool &apos;default.rgw.log&apos; removed</span><br></pre></td></tr></table></figure>\n<p>修改rgw配置, 增加rgw_zone = shanghai</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@ceph101 ~]# vim /etc/ceph/ceph.conf</span><br><span class=\"line\"></span><br><span class=\"line\">[global]</span><br><span class=\"line\">fsid = d6e42188-9871-471b-9db0-957f47893902</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">mon initial members = ceph101</span><br><span class=\"line\">mon host = 172.16.143.201</span><br><span class=\"line\"></span><br><span class=\"line\">public network = 172.16.143.0/24</span><br><span class=\"line\">cluster network = 172.16.140.0/24</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">mon allow pool delete = true</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">[client.rgw.ceph101]</span><br><span class=\"line\">host = ceph101</span><br><span class=\"line\">keyring = /var/lib/ceph/radosgw/ceph-rgw.ceph101/keyring</span><br><span class=\"line\">log file = /var/log/ceph/ceph-rgw-ceph101.log</span><br><span class=\"line\">rgw frontends = civetweb port=172.16.143.201:8080 num_threads=100</span><br><span class=\"line\">rgw_zone = shanghai</span><br></pre></td></tr></table></figure>\n<p>重启rgw，并查看pool是否创建</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@ceph101 ~]# systemctl restart ceph-radosgw@rgw.ceph101</span><br><span class=\"line\">[root@ceph101 ~]# ceph osd pool ls</span><br><span class=\"line\">.rgw.root</span><br><span class=\"line\">shanghai.rgw.control</span><br><span class=\"line\">shanghai.rgw.meta</span><br><span class=\"line\">shanghai.rgw.log</span><br></pre></td></tr></table></figure>\n<p>在secondy zone节点进行如下配置：  </p>\n<p>同步realm, 并设置realm100为默认的realm</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@ceph102 ~]# radosgw-admin realm pull --url=http://172.16.143.201:8080 --access-key=LPTHGKYO5ULI48Q88AWF --secret=jGFoORTVt72frRYsmcnPOpGXnz652Dl3C2IeBLN8</span><br><span class=\"line\">2019-03-09 21:25:10.377485 7fa55aca2dc0  1 found existing latest_epoch 2 &gt;= given epoch 2, returning r=-17</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    &quot;id&quot;: &quot;ba638e8a-8a33-4607-8fe3-13aa69dd1758&quot;,</span><br><span class=\"line\">    &quot;name&quot;: &quot;realm100&quot;,</span><br><span class=\"line\">    &quot;current_period&quot;: &quot;064c5b5e-eb87-462c-aa37-c420ddd68b23&quot;,</span><br><span class=\"line\">    &quot;epoch&quot;: 2</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">[root@ceph102 ~]# radosgw-admin realm default --rgw-realm=realm100</span><br></pre></td></tr></table></figure>\n<p>更新period</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@ceph102 ~]# radosgw-admin period pull --url=http://172.16.143.201:8080 --access-key=LPTHGKYO5ULI48Q88AWF --secret=jGFoORTVt72frRYsmcnPOpGXnz652Dl3C2IeBLN8</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    &quot;id&quot;: &quot;064c5b5e-eb87-462c-aa37-c420ddd68b23&quot;,</span><br><span class=\"line\">    &quot;epoch&quot;: 2,</span><br><span class=\"line\">    &quot;predecessor_uuid&quot;: &quot;1abfe2d0-7453-4c01-881b-3db7f53f15c1&quot;,</span><br><span class=\"line\">    &quot;sync_status&quot;: [],</span><br><span class=\"line\">    &quot;period_map&quot;: &#123;</span><br><span class=\"line\">        &quot;id&quot;: &quot;064c5b5e-eb87-462c-aa37-c420ddd68b23&quot;,</span><br><span class=\"line\">        &quot;zonegroups&quot;: [</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                &quot;id&quot;: &quot;2b3f1ea0-73e7-4f17-b4f9-1acf5d5c6033&quot;,</span><br><span class=\"line\">                &quot;name&quot;: &quot;cn&quot;,</span><br><span class=\"line\">                &quot;api_name&quot;: &quot;cn&quot;,</span><br><span class=\"line\">                &quot;is_master&quot;: &quot;true&quot;,</span><br><span class=\"line\">                &quot;endpoints&quot;: [</span><br><span class=\"line\">                    &quot;http://172.16.143.201:8080&quot;</span><br><span class=\"line\">                ],</span><br><span class=\"line\">                &quot;hostnames&quot;: [],</span><br><span class=\"line\">                &quot;hostnames_s3website&quot;: [],</span><br><span class=\"line\">                &quot;master_zone&quot;: &quot;9c655173-6346-47e7-9759-5e5d32aa017d&quot;,</span><br><span class=\"line\">                &quot;zones&quot;: [</span><br><span class=\"line\">                    &#123;</span><br><span class=\"line\">                        &quot;id&quot;: &quot;9c655173-6346-47e7-9759-5e5d32aa017d&quot;,</span><br><span class=\"line\">                        &quot;name&quot;: &quot;shanghai&quot;,</span><br><span class=\"line\">                        &quot;endpoints&quot;: [</span><br><span class=\"line\">                            &quot;http://172.16.143.201:8080&quot;</span><br><span class=\"line\">                        ],</span><br><span class=\"line\">                        &quot;log_meta&quot;: &quot;false&quot;,</span><br><span class=\"line\">                        &quot;log_data&quot;: &quot;false&quot;,</span><br><span class=\"line\">                        &quot;bucket_index_max_shards&quot;: 0,</span><br><span class=\"line\">                        &quot;read_only&quot;: &quot;false&quot;,</span><br><span class=\"line\">                        &quot;tier_type&quot;: &quot;&quot;,</span><br><span class=\"line\">                        &quot;sync_from_all&quot;: &quot;true&quot;,</span><br><span class=\"line\">                        &quot;sync_from&quot;: []</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\">                ],</span><br><span class=\"line\">                &quot;placement_targets&quot;: [</span><br><span class=\"line\">                    &#123;</span><br><span class=\"line\">                        &quot;name&quot;: &quot;default-placement&quot;,</span><br><span class=\"line\">                        &quot;tags&quot;: []</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\">                ],</span><br><span class=\"line\">                &quot;default_placement&quot;: &quot;default-placement&quot;,</span><br><span class=\"line\">                &quot;realm_id&quot;: &quot;ba638e8a-8a33-4607-8fe3-13aa69dd1758&quot;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        ],</span><br><span class=\"line\">        &quot;short_zone_ids&quot;: [</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                &quot;key&quot;: &quot;9c655173-6346-47e7-9759-5e5d32aa017d&quot;,</span><br><span class=\"line\">                &quot;val&quot;: 1556250220</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        ]</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    &quot;master_zonegroup&quot;: &quot;2b3f1ea0-73e7-4f17-b4f9-1acf5d5c6033&quot;,</span><br><span class=\"line\">    &quot;master_zone&quot;: &quot;9c655173-6346-47e7-9759-5e5d32aa017d&quot;,</span><br><span class=\"line\">    &quot;period_config&quot;: &#123;</span><br><span class=\"line\">        &quot;bucket_quota&quot;: &#123;</span><br><span class=\"line\">            &quot;enabled&quot;: false,</span><br><span class=\"line\">            &quot;check_on_raw&quot;: false,</span><br><span class=\"line\">            &quot;max_size&quot;: -1,</span><br><span class=\"line\">            &quot;max_size_kb&quot;: 0,</span><br><span class=\"line\">            &quot;max_objects&quot;: -1</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        &quot;user_quota&quot;: &#123;</span><br><span class=\"line\">            &quot;enabled&quot;: false,</span><br><span class=\"line\">            &quot;check_on_raw&quot;: false,</span><br><span class=\"line\">            &quot;max_size&quot;: -1,</span><br><span class=\"line\">            &quot;max_size_kb&quot;: 0,</span><br><span class=\"line\">            &quot;max_objects&quot;: -1</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    &quot;realm_id&quot;: &quot;ba638e8a-8a33-4607-8fe3-13aa69dd1758&quot;,</span><br><span class=\"line\">    &quot;realm_name&quot;: &quot;realm100&quot;,</span><br><span class=\"line\">    &quot;realm_epoch&quot;: 2</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>创建secondy zone</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@ceph102 ~]# radosgw-admin zone create --rgw-zonegroup=cn --rgw-zone=beijing --endpoints=http://172.16.143.202:8080 --access-key=LPTHGKYO5ULI48Q88AWF --secret=jGFoORTVt72frRYsmcnPOpGXnz652Dl3C2IeBLN8</span><br><span class=\"line\">2019-03-09 21:30:24.323527 7f2441e45dc0  0 failed reading obj info from .rgw.root:zone_info.9c655173-6346-47e7-9759-5e5d32aa017d: (2) No such file or directory</span><br><span class=\"line\">2019-03-09 21:30:24.323577 7f2441e45dc0  0 WARNING: could not read zone params for zone id=9c655173-6346-47e7-9759-5e5d32aa017d name=shanghai</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    &quot;id&quot;: &quot;bf59d999-1561-4f7e-a874-9de718d4c31b&quot;,</span><br><span class=\"line\">    &quot;name&quot;: &quot;beijing&quot;,</span><br><span class=\"line\">    &quot;domain_root&quot;: &quot;beijing.rgw.meta:root&quot;,</span><br><span class=\"line\">    &quot;control_pool&quot;: &quot;beijing.rgw.control&quot;,</span><br><span class=\"line\">    &quot;gc_pool&quot;: &quot;beijing.rgw.log:gc&quot;,</span><br><span class=\"line\">    &quot;lc_pool&quot;: &quot;beijing.rgw.log:lc&quot;,</span><br><span class=\"line\">    &quot;log_pool&quot;: &quot;beijing.rgw.log&quot;,</span><br><span class=\"line\">    &quot;intent_log_pool&quot;: &quot;beijing.rgw.log:intent&quot;,</span><br><span class=\"line\">    &quot;usage_log_pool&quot;: &quot;beijing.rgw.log:usage&quot;,</span><br><span class=\"line\">    &quot;reshard_pool&quot;: &quot;beijing.rgw.log:reshard&quot;,</span><br><span class=\"line\">    &quot;user_keys_pool&quot;: &quot;beijing.rgw.meta:users.keys&quot;,</span><br><span class=\"line\">    &quot;user_email_pool&quot;: &quot;beijing.rgw.meta:users.email&quot;,</span><br><span class=\"line\">    &quot;user_swift_pool&quot;: &quot;beijing.rgw.meta:users.swift&quot;,</span><br><span class=\"line\">    &quot;user_uid_pool&quot;: &quot;beijing.rgw.meta:users.uid&quot;,</span><br><span class=\"line\">    &quot;system_key&quot;: &#123;</span><br><span class=\"line\">        &quot;access_key&quot;: &quot;LPTHGKYO5ULI48Q88AWF&quot;,</span><br><span class=\"line\">        &quot;secret_key&quot;: &quot;jGFoORTVt72frRYsmcnPOpGXnz652Dl3C2IeBLN8&quot;</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    &quot;placement_pools&quot;: [</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            &quot;key&quot;: &quot;default-placement&quot;,</span><br><span class=\"line\">            &quot;val&quot;: &#123;</span><br><span class=\"line\">                &quot;index_pool&quot;: &quot;beijing.rgw.buckets.index&quot;,</span><br><span class=\"line\">                &quot;data_pool&quot;: &quot;beijing.rgw.buckets.data&quot;,</span><br><span class=\"line\">                &quot;data_extra_pool&quot;: &quot;beijing.rgw.buckets.non-ec&quot;,</span><br><span class=\"line\">                &quot;index_type&quot;: 0,</span><br><span class=\"line\">                &quot;compression&quot;: &quot;&quot;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    ],</span><br><span class=\"line\">    &quot;metadata_heap&quot;: &quot;&quot;,</span><br><span class=\"line\">    &quot;tier_config&quot;: [],</span><br><span class=\"line\">    &quot;realm_id&quot;: &quot;ba638e8a-8a33-4607-8fe3-13aa69dd1758&quot;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>删除默认default zone， defaul zonegroup和 default存储池</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@ceph102 ~]# radosgw-admin zone delete --rgw-zone=default</span><br><span class=\"line\">2019-03-09 21:31:23.577581 7f2e6c528dc0  0 zone id ce963a6e-7d58-426d-b07a-a2af2983379a is not a part of zonegroup cn</span><br><span class=\"line\">[root@ceph102 ~]# radosgw-admin zonegroup list</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    &quot;default_info&quot;: &quot;2b3f1ea0-73e7-4f17-b4f9-1acf5d5c6033&quot;,</span><br><span class=\"line\">    &quot;zonegroups&quot;: [</span><br><span class=\"line\">        &quot;cn&quot;,</span><br><span class=\"line\">        &quot;default&quot;</span><br><span class=\"line\">    ]</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">[root@ceph102 ~]# radosgw-admin zonegroup delete --rgw-zonegroup=default</span><br><span class=\"line\"></span><br><span class=\"line\">[root@ceph102 ~]# ceph osd pool delete default.rgw.control default.rgw.control --yes-i-really-really-mean-it</span><br><span class=\"line\">pool &apos;default.rgw.control&apos; removed</span><br><span class=\"line\">[root@ceph102 ~]# ceph osd pool delete default.rgw.meta default.rgw.meta --yes-i-really-really-mean-it</span><br><span class=\"line\">pool &apos;default.rgw.meta&apos; removed</span><br><span class=\"line\">[root@ceph102 ~]# ceph osd pool delete default.rgw.log default.rgw.log --yes-i-really-really-mean-it</span><br><span class=\"line\">pool &apos;default.rgw.log&apos; removed</span><br></pre></td></tr></table></figure>\n<p>修改rgw配置, 增加rgw_zone = beijing</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@ceph101 ~]# vim /etc/ceph/ceph.conf</span><br><span class=\"line\"></span><br><span class=\"line\">[global]</span><br><span class=\"line\">fsid = d6e42188-9871-471b-9db0-957f47893902</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">mon initial members = ceph101</span><br><span class=\"line\">mon host = 172.16.143.201</span><br><span class=\"line\"></span><br><span class=\"line\">public network = 172.16.143.0/24</span><br><span class=\"line\">cluster network = 172.16.140.0/24</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">mon allow pool delete = true</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">[client.rgw.ceph101]</span><br><span class=\"line\">host = ceph101</span><br><span class=\"line\">keyring = /var/lib/ceph/radosgw/ceph-rgw.ceph101/keyring</span><br><span class=\"line\">log file = /var/log/ceph/ceph-rgw-ceph101.log</span><br><span class=\"line\">rgw frontends = civetweb port=172.16.143.201:8080 num_threads=100</span><br><span class=\"line\">rgw_zone = shanghai</span><br></pre></td></tr></table></figure>\n<p>重启rgw，并查看pool是否创建</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@ceph102 ~]# systemctl restart ceph-radosgw@rgw.ceph102</span><br><span class=\"line\">[root@ceph102 ~]# ceph osd pool ls</span><br><span class=\"line\">.rgw.root</span><br><span class=\"line\">beijing.rgw.control</span><br><span class=\"line\">beijing.rgw.meta</span><br><span class=\"line\">beijing.rgw.log</span><br></pre></td></tr></table></figure>\n<p>更新period</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@ceph102 ~]# radosgw-admin period update --commit</span><br><span class=\"line\">2019-03-09 21:36:44.462809 7f23c756bdc0  1 Cannot find zone id=bf59d999-1561-4f7e-a874-9de718d4c31b (name=beijing), switching to local zonegroup configuration</span><br><span class=\"line\">Sending period to new master zone 9c655173-6346-47e7-9759-5e5d32aa017d</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    &quot;id&quot;: &quot;064c5b5e-eb87-462c-aa37-c420ddd68b23&quot;,</span><br><span class=\"line\">    &quot;epoch&quot;: 3,</span><br><span class=\"line\">    &quot;predecessor_uuid&quot;: &quot;1abfe2d0-7453-4c01-881b-3db7f53f15c1&quot;,</span><br><span class=\"line\">    &quot;sync_status&quot;: [],</span><br><span class=\"line\">    &quot;period_map&quot;: &#123;</span><br><span class=\"line\">        &quot;id&quot;: &quot;064c5b5e-eb87-462c-aa37-c420ddd68b23&quot;,</span><br><span class=\"line\">        &quot;zonegroups&quot;: [</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                &quot;id&quot;: &quot;2b3f1ea0-73e7-4f17-b4f9-1acf5d5c6033&quot;,</span><br><span class=\"line\">                &quot;name&quot;: &quot;cn&quot;,</span><br><span class=\"line\">                &quot;api_name&quot;: &quot;cn&quot;,</span><br><span class=\"line\">                &quot;is_master&quot;: &quot;true&quot;,</span><br><span class=\"line\">                &quot;endpoints&quot;: [</span><br><span class=\"line\">                    &quot;http://172.16.143.201:8080&quot;</span><br><span class=\"line\">                ],</span><br><span class=\"line\">                &quot;hostnames&quot;: [],</span><br><span class=\"line\">                &quot;hostnames_s3website&quot;: [],</span><br><span class=\"line\">                &quot;master_zone&quot;: &quot;9c655173-6346-47e7-9759-5e5d32aa017d&quot;,</span><br><span class=\"line\">                &quot;zones&quot;: [</span><br><span class=\"line\">                    &#123;</span><br><span class=\"line\">                        &quot;id&quot;: &quot;9c655173-6346-47e7-9759-5e5d32aa017d&quot;,</span><br><span class=\"line\">                        &quot;name&quot;: &quot;shanghai&quot;,</span><br><span class=\"line\">                        &quot;endpoints&quot;: [</span><br><span class=\"line\">                            &quot;http://172.16.143.201:8080&quot;</span><br><span class=\"line\">                        ],</span><br><span class=\"line\">                        &quot;log_meta&quot;: &quot;false&quot;,</span><br><span class=\"line\">                        &quot;log_data&quot;: &quot;true&quot;,</span><br><span class=\"line\">                        &quot;bucket_index_max_shards&quot;: 0,</span><br><span class=\"line\">                        &quot;read_only&quot;: &quot;false&quot;,</span><br><span class=\"line\">                        &quot;tier_type&quot;: &quot;&quot;,</span><br><span class=\"line\">                        &quot;sync_from_all&quot;: &quot;true&quot;,</span><br><span class=\"line\">                        &quot;sync_from&quot;: []</span><br><span class=\"line\">                    &#125;,</span><br><span class=\"line\">                    &#123;</span><br><span class=\"line\">                        &quot;id&quot;: &quot;bf59d999-1561-4f7e-a874-9de718d4c31b&quot;,</span><br><span class=\"line\">                        &quot;name&quot;: &quot;beijing&quot;,</span><br><span class=\"line\">                        &quot;endpoints&quot;: [],</span><br><span class=\"line\">                        &quot;log_meta&quot;: &quot;false&quot;,</span><br><span class=\"line\">                        &quot;log_data&quot;: &quot;true&quot;,</span><br><span class=\"line\">                        &quot;bucket_index_max_shards&quot;: 0,</span><br><span class=\"line\">                        &quot;read_only&quot;: &quot;false&quot;,</span><br><span class=\"line\">                        &quot;tier_type&quot;: &quot;&quot;,</span><br><span class=\"line\">                        &quot;sync_from_all&quot;: &quot;true&quot;,</span><br><span class=\"line\">                        &quot;sync_from&quot;: []</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\">                ],</span><br><span class=\"line\">                &quot;placement_targets&quot;: [</span><br><span class=\"line\">                    &#123;</span><br><span class=\"line\">                        &quot;name&quot;: &quot;default-placement&quot;,</span><br><span class=\"line\">                        &quot;tags&quot;: []</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\">                ],</span><br><span class=\"line\">                &quot;default_placement&quot;: &quot;default-placement&quot;,</span><br><span class=\"line\">                &quot;realm_id&quot;: &quot;ba638e8a-8a33-4607-8fe3-13aa69dd1758&quot;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        ],</span><br><span class=\"line\">        &quot;short_zone_ids&quot;: [</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                &quot;key&quot;: &quot;9c655173-6346-47e7-9759-5e5d32aa017d&quot;,</span><br><span class=\"line\">                &quot;val&quot;: 1556250220</span><br><span class=\"line\">            &#125;,</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                &quot;key&quot;: &quot;bf59d999-1561-4f7e-a874-9de718d4c31b&quot;,</span><br><span class=\"line\">                &quot;val&quot;: 3557185953</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        ]</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    &quot;master_zonegroup&quot;: &quot;2b3f1ea0-73e7-4f17-b4f9-1acf5d5c6033&quot;,</span><br><span class=\"line\">    &quot;master_zone&quot;: &quot;9c655173-6346-47e7-9759-5e5d32aa017d&quot;,</span><br><span class=\"line\">    &quot;period_config&quot;: &#123;</span><br><span class=\"line\">        &quot;bucket_quota&quot;: &#123;</span><br><span class=\"line\">            &quot;enabled&quot;: false,</span><br><span class=\"line\">            &quot;check_on_raw&quot;: false,</span><br><span class=\"line\">            &quot;max_size&quot;: -1,</span><br><span class=\"line\">            &quot;max_size_kb&quot;: 0,</span><br><span class=\"line\">            &quot;max_objects&quot;: -1</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        &quot;user_quota&quot;: &#123;</span><br><span class=\"line\">            &quot;enabled&quot;: false,</span><br><span class=\"line\">            &quot;check_on_raw&quot;: false,</span><br><span class=\"line\">            &quot;max_size&quot;: -1,</span><br><span class=\"line\">            &quot;max_size_kb&quot;: 0,</span><br><span class=\"line\">            &quot;max_objects&quot;: -1</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    &quot;realm_id&quot;: &quot;ba638e8a-8a33-4607-8fe3-13aa69dd1758&quot;,</span><br><span class=\"line\">    &quot;realm_name&quot;: &quot;realm100&quot;,</span><br><span class=\"line\">    &quot;realm_epoch&quot;: 2</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>查看同步状态</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@ceph101 ~]# radosgw-admin sync status</span><br><span class=\"line\">          realm ba638e8a-8a33-4607-8fe3-13aa69dd1758 (realm100)</span><br><span class=\"line\">      zonegroup 2b3f1ea0-73e7-4f17-b4f9-1acf5d5c6033 (cn)</span><br><span class=\"line\">           zone 9c655173-6346-47e7-9759-5e5d32aa017d (shanghai)</span><br><span class=\"line\">  metadata sync no sync (zone is master)</span><br><span class=\"line\">      data sync source: 0a2f706f-cc81-44f3-adf6-0d79c3e362ac (beijing)</span><br><span class=\"line\">                        syncing</span><br><span class=\"line\">                        full sync: 0/128 shards</span><br><span class=\"line\">                        incremental sync: 128/128 shards</span><br><span class=\"line\">                        data is caught up with source</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@ceph102 ~]# radosgw-admin sync status</span><br><span class=\"line\">          realm ba638e8a-8a33-4607-8fe3-13aa69dd1758 (realm100)</span><br><span class=\"line\">      zonegroup 2b3f1ea0-73e7-4f17-b4f9-1acf5d5c6033 (cn)</span><br><span class=\"line\">           zone 0a2f706f-cc81-44f3-adf6-0d79c3e362ac (beijing)</span><br><span class=\"line\">  metadata sync syncing</span><br><span class=\"line\">                full sync: 0/64 shards</span><br><span class=\"line\">                incremental sync: 64/64 shards</span><br><span class=\"line\">                metadata is caught up with master</span><br><span class=\"line\">      data sync source: 9c655173-6346-47e7-9759-5e5d32aa017d (shanghai)</span><br><span class=\"line\">                        syncing</span><br><span class=\"line\">                        full sync: 0/128 shards</span><br><span class=\"line\">                        incremental sync: 128/128 shards</span><br><span class=\"line\">                        data is caught up with source</span><br></pre></td></tr></table></figure>\n<h1 id=\"验证\"><a href=\"#验证\" class=\"headerlink\" title=\"验证\"></a>验证</h1><p>在master zone 创建一个test用户，在secondy zone 查看信息</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@ceph101 ~]# radosgw-admin user create --uid test --display-name=&quot;test user&quot;</span><br><span class=\"line\">2019-03-09 22:16:27.795146 7f022820cdc0  0 WARNING: can&apos;t generate connection for zone 0a2f706f-cc81-44f3-adf6-0d79c3e362ac id beijing: no endpoints defined</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    &quot;user_id&quot;: &quot;test&quot;,</span><br><span class=\"line\">    &quot;display_name&quot;: &quot;test user&quot;,</span><br><span class=\"line\">    &quot;email&quot;: &quot;&quot;,</span><br><span class=\"line\">    &quot;suspended&quot;: 0,</span><br><span class=\"line\">    &quot;max_buckets&quot;: 1000,</span><br><span class=\"line\">    &quot;auid&quot;: 0,</span><br><span class=\"line\">    &quot;subusers&quot;: [],</span><br><span class=\"line\">    &quot;keys&quot;: [</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            &quot;user&quot;: &quot;test&quot;,</span><br><span class=\"line\">            &quot;access_key&quot;: &quot;9R9YENBPPDZ88TQGP32D&quot;,</span><br><span class=\"line\">            &quot;secret_key&quot;: &quot;B5wtnLKNloIVxmSDISut6scU8MClv52dfInb3Omh&quot;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    ],</span><br><span class=\"line\">    &quot;swift_keys&quot;: [],</span><br><span class=\"line\">    &quot;caps&quot;: [],</span><br><span class=\"line\">    &quot;op_mask&quot;: &quot;read, write, delete&quot;,</span><br><span class=\"line\">    &quot;default_placement&quot;: &quot;&quot;,</span><br><span class=\"line\">    &quot;placement_tags&quot;: [],</span><br><span class=\"line\">    &quot;bucket_quota&quot;: &#123;</span><br><span class=\"line\">        &quot;enabled&quot;: false,</span><br><span class=\"line\">        &quot;check_on_raw&quot;: false,</span><br><span class=\"line\">        &quot;max_size&quot;: -1,</span><br><span class=\"line\">        &quot;max_size_kb&quot;: 0,</span><br><span class=\"line\">        &quot;max_objects&quot;: -1</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    &quot;user_quota&quot;: &#123;</span><br><span class=\"line\">        &quot;enabled&quot;: false,</span><br><span class=\"line\">        &quot;check_on_raw&quot;: false,</span><br><span class=\"line\">        &quot;max_size&quot;: -1,</span><br><span class=\"line\">        &quot;max_size_kb&quot;: 0,</span><br><span class=\"line\">        &quot;max_objects&quot;: -1</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    &quot;temp_url_keys&quot;: [],</span><br><span class=\"line\">    &quot;type&quot;: &quot;rgw&quot;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>secondy zone 查看用户</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@ceph102 ~]# radosgw-admin user list</span><br><span class=\"line\">[</span><br><span class=\"line\">    &quot;syncuser&quot;,</span><br><span class=\"line\">    &quot;test&quot;</span><br><span class=\"line\">]</span><br></pre></td></tr></table></figure>\n<p>在secondy zone 创建一个test2用户，在master zone 查看信息</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@ceph102 ~]# radosgw-admin user create --uid test@2 --display-name=&quot;test2 user&quot;</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    &quot;user_id&quot;: &quot;test@2&quot;,</span><br><span class=\"line\">    &quot;display_name&quot;: &quot;test2 user&quot;,</span><br><span class=\"line\">    &quot;email&quot;: &quot;&quot;,</span><br><span class=\"line\">    &quot;suspended&quot;: 0,</span><br><span class=\"line\">    &quot;max_buckets&quot;: 1000,</span><br><span class=\"line\">    &quot;auid&quot;: 0,</span><br><span class=\"line\">    &quot;subusers&quot;: [],</span><br><span class=\"line\">    &quot;keys&quot;: [</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            &quot;user&quot;: &quot;test@2&quot;,</span><br><span class=\"line\">            &quot;access_key&quot;: &quot;9413B8F517W6LTEKN0H6&quot;,</span><br><span class=\"line\">            &quot;secret_key&quot;: &quot;lg9vzVhpS2gYdXDnEOEUv3uCwkz0wkyuuBSnh8dl&quot;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    ],</span><br><span class=\"line\">    &quot;swift_keys&quot;: [],</span><br><span class=\"line\">    &quot;caps&quot;: [],</span><br><span class=\"line\">    &quot;op_mask&quot;: &quot;read, write, delete&quot;,</span><br><span class=\"line\">    &quot;default_placement&quot;: &quot;&quot;,</span><br><span class=\"line\">    &quot;placement_tags&quot;: [],</span><br><span class=\"line\">    &quot;bucket_quota&quot;: &#123;</span><br><span class=\"line\">        &quot;enabled&quot;: false,</span><br><span class=\"line\">        &quot;check_on_raw&quot;: false,</span><br><span class=\"line\">        &quot;max_size&quot;: -1,</span><br><span class=\"line\">        &quot;max_size_kb&quot;: 0,</span><br><span class=\"line\">        &quot;max_objects&quot;: -1</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    &quot;user_quota&quot;: &#123;</span><br><span class=\"line\">        &quot;enabled&quot;: false,</span><br><span class=\"line\">        &quot;check_on_raw&quot;: false,</span><br><span class=\"line\">        &quot;max_size&quot;: -1,</span><br><span class=\"line\">        &quot;max_size_kb&quot;: 0,</span><br><span class=\"line\">        &quot;max_objects&quot;: -1</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    &quot;temp_url_keys&quot;: [],</span><br><span class=\"line\">    &quot;type&quot;: &quot;rgw&quot;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">[root@ceph102 ~]# radosgw-admin user list</span><br><span class=\"line\">[</span><br><span class=\"line\">    &quot;syncuser&quot;,</span><br><span class=\"line\">    &quot;test@2&quot;,</span><br><span class=\"line\">    &quot;test&quot;</span><br><span class=\"line\">]</span><br></pre></td></tr></table></figure>\n<p>在master zone 查看</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@ceph101 ~]# radosgw-admin user list</span><br><span class=\"line\">[</span><br><span class=\"line\">    &quot;syncuser&quot;,</span><br><span class=\"line\">    &quot;test&quot;</span><br><span class=\"line\">]</span><br></pre></td></tr></table></figure>\n<p>可以看到在master zone创建的用户，在secondy zone也可以看到<br>而在secondy zone创建的用户，在master zone看不到</p>\n<p>通过test用户，在master zone 创建名为bucket1的bucket</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@ceph101 ~]# s3cmd mb s3://bucket1</span><br><span class=\"line\">Bucket &apos;s3://bucket1/&apos; created</span><br><span class=\"line\">[root@ceph101 ~]# radosgw-admin bucket list</span><br><span class=\"line\">[</span><br><span class=\"line\">    &quot;bucket1&quot;</span><br><span class=\"line\">]</span><br></pre></td></tr></table></figure>\n<p>在secondy zone查看</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@ceph102 ~]# radosgw-admin bucket list</span><br><span class=\"line\">[</span><br><span class=\"line\">    &quot;bucket1&quot;</span><br><span class=\"line\">]</span><br></pre></td></tr></table></figure>\n<p>通过test用户，在secondy zone 创建名为bucket2的bucket</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@ceph102 ~]# s3cmd mb s3://bucket2</span><br><span class=\"line\">Bucket &apos;s3://bucket2/&apos; created</span><br><span class=\"line\">[root@ceph102 ~]# radosgw-admin bucket list</span><br><span class=\"line\">[</span><br><span class=\"line\">    &quot;bucket1&quot;,</span><br><span class=\"line\">    &quot;bucket2&quot;</span><br><span class=\"line\">]</span><br></pre></td></tr></table></figure>\n<p>在master zone 查看</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@ceph101 ~]# radosgw-admin bucket list</span><br><span class=\"line\">[</span><br><span class=\"line\">    &quot;bucket1&quot;,</span><br><span class=\"line\">    &quot;bucket2&quot;</span><br><span class=\"line\">]</span><br></pre></td></tr></table></figure>\n<p>在master zone 上传文件</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@ceph101 ~]# s3cmd put Python-3.4.9.tgz s3://bucket1/python3.4.9.tgz</span><br><span class=\"line\">upload: &apos;Python-3.4.9.tgz&apos; -&gt; &apos;s3://bucket1/python3.4.9.tgz&apos;  [part 1 of 2, 15MB] [1 of 1]</span><br><span class=\"line\"> 15728640 of 15728640   100% in    2s     6.26 MB/s  done</span><br><span class=\"line\">upload: &apos;Python-3.4.9.tgz&apos; -&gt; &apos;s3://bucket1/python3.4.9.tgz&apos;  [part 2 of 2, 3MB] [1 of 1]</span><br><span class=\"line\"> 3955465 of 3955465   100% in    0s    32.73 MB/s  done</span><br><span class=\"line\"> </span><br><span class=\"line\">[root@ceph101 ~]# md5sum Python-3.4.9.tgz</span><br><span class=\"line\">c706902881ef95e27e59f13fabbcdcac  Python-3.4.9.tgz</span><br></pre></td></tr></table></figure>\n<p>在secondy zone 查看信息</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@ceph102 ~]# s3cmd ls s3://bucket1</span><br><span class=\"line\">2019-03-09 15:34  19684105   s3://bucket1/python3.4.9.tgz</span><br><span class=\"line\">[root@ceph102 ~]# s3cmd get s3://bucket1/python3.4.9.tgz Python3.4.9.tgz</span><br><span class=\"line\">download: &apos;s3://bucket1/python3.4.9.tgz&apos; -&gt; &apos;Python3.4.9.tgz&apos;  [1 of 1]</span><br><span class=\"line\"> 19684105 of 19684105   100% in    0s    51.81 MB/s  done</span><br><span class=\"line\">[root@ceph102 ~]# md5sum Python3.4.9.tgz</span><br><span class=\"line\">c706902881ef95e27e59f13fabbcdcac  Python3.4.9.tgz</span><br></pre></td></tr></table></figure>\n<p>在secondy zone 上传文件</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@ceph102 ~]# s3cmd put anaconda-ks.cfg s3://bucket2/anaconda-ks.cfg</span><br><span class=\"line\">upload: &apos;anaconda-ks.cfg&apos; -&gt; &apos;s3://bucket2/anaconda-ks.cfg&apos;  [1 of 1]</span><br><span class=\"line\"> 1030 of 1030   100% in    0s     8.28 kB/s  done</span><br><span class=\"line\">[root@ceph102 ~]# md5sum anaconda-ks.cfg</span><br><span class=\"line\">1627b1ce985ce5befdd0d1cb0e6164ae  anaconda-ks.cfg</span><br></pre></td></tr></table></figure>\n<p>在master zone 查看</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@ceph101 tmp]# s3cmd ls s3://bucket2</span><br><span class=\"line\">2019-03-09 15:37      1030   s3://bucket2/anaconda-ks.cfg</span><br><span class=\"line\">[root@ceph101 tmp]# s3cmd get s3://bucket2/anaconda-ks.cfg anaconda-ks.cfg</span><br><span class=\"line\">download: &apos;s3://bucket2/anaconda-ks.cfg&apos; -&gt; &apos;anaconda-ks.cfg&apos;  [1 of 1]</span><br><span class=\"line\"> 1030 of 1030   100% in    0s    23.32 kB/s  done</span><br><span class=\"line\">[root@ceph101 tmp]# md5sum anaconda-ks.cfg</span><br><span class=\"line\">1627b1ce985ce5befdd0d1cb0e6164ae  anaconda-ks.cfg</span><br></pre></td></tr></table></figure>\n<p>停止master zone的grup，然后在secondy zone上创建存储桶</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@ceph101 tmp]# systemctl stop ceph-radosgw@rgw.ceph101</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@ceph102 ~]# s3cmd mb s3://bucket4</span><br><span class=\"line\">WARNING: Retrying failed request: / (503 (ServiceUnavailable))</span><br><span class=\"line\">WARNING: Waiting 3 sec...</span><br><span class=\"line\">WARNING: Retrying failed request: / (503 (ServiceUnavailable))</span><br><span class=\"line\">WARNING: Waiting 6 sec...</span><br><span class=\"line\">WARNING: Retrying failed request: / (503 (ServiceUnavailable))</span><br><span class=\"line\">WARNING: Waiting 9 sec...</span><br></pre></td></tr></table></figure>\n<p>可以看到在secondy zone上并不能创建bucket，之前在secondy zone上创建bucket，也是把请求转到master zone上。</p>\n<p>反之，停止secondy zone的rgw，在master zone也是可以创建存储桶</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@ceph102 ~]# systemctl stop ceph-radosgw@ceph102</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@ceph101 tmp]# s3cmd mb s3://bucket5</span><br><span class=\"line\">Bucket &apos;s3://bucket5/&apos; created</span><br></pre></td></tr></table></figure>\n<h1 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h1><ul>\n<li><a href=\"http://docs.ceph.com/docs/luminous/radosgw/multisite/\" target=\"_blank\" rel=\"noopener\">http://docs.ceph.com/docs/luminous/radosgw/multisite/</a></li>\n<li><a href=\"https://access.redhat.com/documentation/en-us/red_hat_ceph_storage/2/html/object_gateway_guide_for_red_hat_enterprise_linux/multi_site\" target=\"_blank\" rel=\"noopener\">https://access.redhat.com/documentation/en-us/red_hat_ceph_storage/2/html/object_gateway_guide_for_red_hat_enterprise_linux/multi_site</a></li>\n<li><a href=\"https://www.jianshu.com/p/31a6f8df9a8f\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/31a6f8df9a8f</a></li>\n<li><a href=\"http://stor.51cto.com/art/201807/578337.htm\" target=\"_blank\" rel=\"noopener\">http://stor.51cto.com/art/201807/578337.htm</a></li>\n</ul>\n"},{"title":"Rook","date":"2019-03-12T06:42:10.000Z","_content":"\n# 概述\n本文主要介绍如何通过rook在k8s上部署一套ceph集群。  \n测试的k8s集群一共三个节点：  \n\n```\n[root@kube01 ~]# kubectl get nodes\nNAME     STATUS   ROLES    AGE    VERSION\nkube01   Ready    master   3h3m   v1.13.4\nkube02   Ready    master   175m   v1.13.4\nkube03   Ready    master   172m   v1.13.4\n\n```\n\n# Rook部署\n\nclone rook代码  \n\n```\ngit clone https://github.com/rook/rook.git\ncd rook/\ngit checkout v0.9.3\n```\n通过kubectl执行rook-ceph的operator\n\n```\n[root@kube01 rook]# kubectl apply -f cluster/examples/kubernetes/ceph/operator.yaml\nnamespace/rook-ceph-system created\ncustomresourcedefinition.apiextensions.k8s.io/cephclusters.ceph.rook.io created\ncustomresourcedefinition.apiextensions.k8s.io/cephfilesystems.ceph.rook.io created\ncustomresourcedefinition.apiextensions.k8s.io/cephobjectstores.ceph.rook.io created\ncustomresourcedefinition.apiextensions.k8s.io/cephobjectstoreusers.ceph.rook.io created\ncustomresourcedefinition.apiextensions.k8s.io/cephblockpools.ceph.rook.io created\ncustomresourcedefinition.apiextensions.k8s.io/volumes.rook.io created\nclusterrole.rbac.authorization.k8s.io/rook-ceph-cluster-mgmt created\nrole.rbac.authorization.k8s.io/rook-ceph-system created\nclusterrole.rbac.authorization.k8s.io/rook-ceph-global created\nclusterrole.rbac.authorization.k8s.io/rook-ceph-mgr-cluster created\nserviceaccount/rook-ceph-system created\nrolebinding.rbac.authorization.k8s.io/rook-ceph-system created\nclusterrolebinding.rbac.authorization.k8s.io/rook-ceph-global created\ndeployment.apps/rook-ceph-operator created\n```\n\n等待全部pod都running状态\n\n```\n[root@kube01 rook]# kubectl get pods -n rook-ceph-system -owide\nNAME                                  READY   STATUS    RESTARTS   AGE     IP               NODE     NOMINATED NODE   READINESS GATES\nrook-ceph-agent-7zgcv                 1/1     Running   0          2m15s   192.168.10.181   kube01   <none>           <none>\nrook-ceph-agent-ww4sk                 1/1     Running   0          2m15s   192.168.10.129   kube02   <none>           <none>\nrook-ceph-agent-xjgm4                 1/1     Running   0          2m15s   192.168.10.44    kube03   <none>           <none>\nrook-ceph-operator-5f4ff4d57d-fm8s5   1/1     Running   0          3m41s   10.244.1.2       kube02   <none>           <none>\nrook-discover-2mwpn                   1/1     Running   0          2m15s   10.244.0.10      kube01   <none>           <none>\nrook-discover-nqhr8                   1/1     Running   0          2m15s   10.244.1.3       kube02   <none>           <none>\nrook-discover-wgpng                   1/1     Running   0          2m15s   10.244.2.2       kube03   <none>           <none>\n```\n\nceph会使用每个节点的vdb作为osd，所以需要修改cluster/examples/kubernetes/ceph/cluster.yaml的内容\n\n```\n  storage: # cluster level storage configuration and selection\n    useAllNodes: true\n    useAllDevices: false\n    deviceFilter: \"^vdb\"\n    location:\n    config:\n      # The default and recommended storeType is dynamically set to bluestore for devices and filestore for directories.\n      # Set the storeType explicitly only if it is required not to use the default.\n      storeType: bluestore\n      #databaseSizeMB: \"1024\" # this value can be removed for environments with normal sized disks (100 GB or larger)\n      #journalSizeMB: \"1024\"  # this value can be removed for environments with normal sized disks (20 GB or larger)\n      osdsPerDevice: \"1\" # this value can be overridden at the node or device level\n```\n\n通过kubectl部署ceph集群\n\n```\n[root@kube01 rook]# kubectl apply -f cluster/examples/kubernetes/ceph/cluster.yaml\nnamespace/rook-ceph created\nserviceaccount/rook-ceph-osd created\nserviceaccount/rook-ceph-mgr created\nrole.rbac.authorization.k8s.io/rook-ceph-osd created\nrole.rbac.authorization.k8s.io/rook-ceph-mgr-system created\nrole.rbac.authorization.k8s.io/rook-ceph-mgr created\nrolebinding.rbac.authorization.k8s.io/rook-ceph-cluster-mgmt created\nrolebinding.rbac.authorization.k8s.io/rook-ceph-osd created\nrolebinding.rbac.authorization.k8s.io/rook-ceph-mgr created\nrolebinding.rbac.authorization.k8s.io/rook-ceph-mgr-system created\nrolebinding.rbac.authorization.k8s.io/rook-ceph-mgr-cluster created\ncephcluster.ceph.rook.io/rook-ceph created\n```\n\n等ceph部署完成，可以看到有三个mon，一个mgr和三个osd\n\n```\n[root@kube01 rook]# kubectl get pods -n rook-ceph\nNAME                                 READY   STATUS      RESTARTS   AGE\nrook-ceph-mgr-a-66db78887f-lmhcf     1/1     Running     0          4m13s\nrook-ceph-mon-a-b6556df54-t7cd4      1/1     Running     0          4m53s\nrook-ceph-mon-b-7f84c6d4b-nhjj6      1/1     Running     0          4m42s\nrook-ceph-mon-c-868c5b476b-ghfqs     1/1     Running     0          4m32s\nrook-ceph-osd-0-6fdf57bcb7-bf6f2     1/1     Running     0          54s\nrook-ceph-osd-1-8c99b7447-h4mfd      1/1     Running     0          39s\nrook-ceph-osd-2-66b76d6944-5df9j     1/1     Running     0          27s\nrook-ceph-osd-prepare-kube01-dfrp2   0/2     Completed   0          3m50s\nrook-ceph-osd-prepare-kube02-pnbsc   0/2     Completed   0          3m49s\nrook-ceph-osd-prepare-kube03-4ztl9   0/2     Completed   0          3m48s\n```\n\n安装ceph-tool，登录到ceph-tools的pod，可以执行ceph相关的命令，查看ceph状态\n\n```\n[root@kube01 rook]# kubectl apply -f cluster/examples/kubernetes/ceph/toolbox.yaml\ndeployment.apps/rook-ceph-tools created\n[root@kube01 rook]# kubectl get pods -n rook-ceph\nNAME                                 READY   STATUS    RESTARTS   AGE\nrook-ceph-mgr-a-66db78887f-lmhcf     1/1     Running   0          5m10s\nrook-ceph-mon-a-b6556df54-t7cd4      1/1     Running   0          5m50s\nrook-ceph-mon-b-7f84c6d4b-nhjj6      1/1     Running   0          5m39s\nrook-ceph-mon-c-868c5b476b-ghfqs     1/1     Running   0          5m29s\nrook-ceph-osd-0-6fdf57bcb7-bf6f2     1/1     Running   0          111s\nrook-ceph-osd-1-8c99b7447-h4mfd      1/1     Running   0          96s\nrook-ceph-osd-2-66b76d6944-5df9j     1/1     Running   0          84s\nrook-ceph-osd-prepare-kube01-d2rrt   1/2     Running   0          49s\nrook-ceph-osd-prepare-kube02-jxl6g   1/2     Running   0          47s\nrook-ceph-osd-prepare-kube03-fz276   1/2     Running   0          45s\nrook-ceph-tools-544fb656d-tddrx      1/1     Running   0          3s\n```\n登录到ceph-tools Pod\n\n```\n[root@kube01 rook]# kubectl exec -it rook-ceph-tools-544fb656d-tddrx bash -n rook-ceph\nbash: warning: setlocale: LC_CTYPE: cannot change locale (en_US.UTF-8): No such file or directory\nbash: warning: setlocale: LC_COLLATE: cannot change locale (en_US.UTF-8): No such file or directory\nbash: warning: setlocale: LC_MESSAGES: cannot change locale (en_US.UTF-8): No such file or directory\nbash: warning: setlocale: LC_NUMERIC: cannot change locale (en_US.UTF-8): No such file or directory\nbash: warning: setlocale: LC_TIME: cannot change locale (en_US.UTF-8): No such file or directory\n[root@kube03 /]# ceph -s\n  cluster:\n    id:     f9609ec9-62c7-4462-a4f2-35c4137c25ef\n    health: HEALTH_OK\n\n  services:\n    mon: 3 daemons, quorum c,a,b\n    mgr: a(active)\n    osd: 3 osds: 3 up, 3 in\n\n  data:\n    pools:   0 pools, 0 pgs\n    objects: 0  objects, 0 B\n    usage:   3.0 GiB used, 57 GiB / 60 GiB avail\n    pgs:\n\n[root@kube03 /]# ceph osd tree\nID CLASS WEIGHT  TYPE NAME       STATUS REWEIGHT PRI-AFF\n-1       0.05846 root default\n-7       0.01949     host kube01\n 2   hdd 0.01949         osd.2       up  1.00000 1.00000\n-3       0.01949     host kube02\n 0   hdd 0.01949         osd.0       up  1.00000 1.00000\n-5       0.01949     host kube03\n 1   hdd 0.01949         osd.1       up  1.00000 1.00000\n \n```\n \n部署好的ceph集群并没有rgw服务，通过下面的方式可以添加rgw服务\n \n```\n[root@kube01 rook]# kubectl apply -f cluster/examples/kubernetes/ceph/object.yaml\ncephobjectstore.ceph.rook.io/my-store created\n\n[root@kube01 rook]# kubectl get pods -n rook-ceph\nNAME                                      READY   STATUS      RESTARTS   AGE\nrook-ceph-mgr-a-66db78887f-lmhcf          1/1     Running     0          11m\nrook-ceph-mon-a-b6556df54-t7cd4           1/1     Running     0          11m\nrook-ceph-mon-b-7f84c6d4b-nhjj6           1/1     Running     0          11m\nrook-ceph-mon-c-868c5b476b-ghfqs          1/1     Running     0          11m\nrook-ceph-osd-0-f986cc57d-6xclh           1/1     Running     0          6m\nrook-ceph-osd-1-765556c558-jwv2n          1/1     Running     0          5m40s\nrook-ceph-osd-2-766db888c7-j7z8f          1/1     Running     0          5m48s\nrook-ceph-osd-prepare-kube01-d2rrt        0/2     Completed   0          6m57s\nrook-ceph-osd-prepare-kube02-jxl6g        0/2     Completed   0          6m55s\nrook-ceph-osd-prepare-kube03-fz276        0/2     Completed   0          6m53s\nrook-ceph-rgw-my-store-5b68744bc6-pc7g7   1/1     Running     0          21s\nrook-ceph-tools-544fb656d-tddrx           1/1     Running     0          6m11s\n\n[root@kube01 rook]# kubectl exec -it rook-ceph-tools-544fb656d-tddrx bash -n rook-ceph\nbash: warning: setlocale: LC_CTYPE: cannot change locale (en_US.UTF-8): No such file or directory\nbash: warning: setlocale: LC_COLLATE: cannot change locale (en_US.UTF-8): No such file or directory\nbash: warning: setlocale: LC_MESSAGES: cannot change locale (en_US.UTF-8): No such file or directory\nbash: warning: setlocale: LC_NUMERIC: cannot change locale (en_US.UTF-8): No such file or directory\nbash: warning: setlocale: LC_TIME: cannot change locale (en_US.UTF-8): No such file or directory\n[root@kube03 /]# ceph -s\n  cluster:\n    id:     f9609ec9-62c7-4462-a4f2-35c4137c25ef\n    health: HEALTH_OK\n\n  services:\n    mon: 3 daemons, quorum c,a,b\n    mgr: a(active)\n    osd: 3 osds: 3 up, 3 in\n    rgw: 1 daemon active\n\n  data:\n    pools:   6 pools, 600 pgs\n    objects: 201  objects, 3.7 KiB\n    usage:   3.0 GiB used, 57 GiB / 60 GiB avail\n    pgs:     600 active+clean\n    \n    \n\n```\n通过下面的方式可以把rgw服务以NodePort的方式对外提供服务\n \n```\n[root@kube01 rook]# kubectl apply -f cluster/examples/kubernetes/ceph/rgw-external.yaml\nservice/rook-ceph-rgw-my-store-external created\n \n[root@kube01 rook]# kubectl get services -n rook-ceph\nNAME                              TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)        AGE\nrook-ceph-mgr                     ClusterIP   172.30.117.80    <none>        9283/TCP       12m\nrook-ceph-mgr-dashboard           ClusterIP   172.30.225.42    <none>        8443/TCP       12m\nrook-ceph-mon-a                   ClusterIP   172.30.82.3      <none>        6790/TCP       13m\nrook-ceph-mon-b                   ClusterIP   172.30.122.28    <none>        6790/TCP       13m\nrook-ceph-mon-c                   ClusterIP   172.30.62.26     <none>        6790/TCP       13m\nrook-ceph-rgw-my-store            ClusterIP   172.30.107.175   <none>        80/TCP         2m47s\nrook-ceph-rgw-my-store-external   NodePort    172.30.131.185   <none>        80:32185/TCP   4m2s\n \n```\n\n下面的部署安装ceph mds \n\n```\n[root@kube01 rook]# kubectl apply -f cluster/examples/kubernetes/ceph/filesystem.yaml\ncephfilesystem.ceph.rook.io/myfs created\n\n[root@kube01 rook]# kubectl get pods -n rook-ceph\nNAME                                      READY   STATUS      RESTARTS   AGE\nrook-ceph-mds-myfs-a-6bbc59cbc8-fp5px     1/1     Running     0          11s\nrook-ceph-mds-myfs-b-658fc8fd66-5cd9g     1/1     Running     0          11s\nrook-ceph-mgr-a-66db78887f-lmhcf          1/1     Running     0          23m\nrook-ceph-mon-a-b6556df54-t7cd4           1/1     Running     0          24m\nrook-ceph-mon-b-7f84c6d4b-nhjj6           1/1     Running     0          24m\nrook-ceph-mon-c-868c5b476b-ghfqs          1/1     Running     0          23m\nrook-ceph-osd-0-f986cc57d-6xclh           1/1     Running     0          18m\nrook-ceph-osd-1-765556c558-jwv2n          1/1     Running     0          17m\nrook-ceph-osd-2-766db888c7-j7z8f          1/1     Running     0          18m\nrook-ceph-osd-prepare-kube01-d2rrt        0/2     Completed   0          19m\nrook-ceph-osd-prepare-kube02-jxl6g        0/2     Completed   0          19m\nrook-ceph-osd-prepare-kube03-fz276        0/2     Completed   0          19m\nrook-ceph-rgw-my-store-5b68744bc6-pc7g7   1/1     Running     0          12m\nrook-ceph-tools-544fb656d-tddrx           1/1     Running     0          18m\n\n[root@kube01 rook]# kubectl exec -it rook-ceph-tools-544fb656d-tddrx bash -n rook-ceph\nbash: warning: setlocale: LC_CTYPE: cannot change locale (en_US.UTF-8): No such file or directory\nbash: warning: setlocale: LC_COLLATE: cannot change locale (en_US.UTF-8): No such file or directory\nbash: warning: setlocale: LC_MESSAGES: cannot change locale (en_US.UTF-8): No such file or directory\nbash: warning: setlocale: LC_NUMERIC: cannot change locale (en_US.UTF-8): No such file or directory\nbash: warning: setlocale: LC_TIME: cannot change locale (en_US.UTF-8): No such file or directory\n[root@kube03 /]# ceph -s\n  cluster:\n    id:     f9609ec9-62c7-4462-a4f2-35c4137c25ef\n    health: HEALTH_OK\n\n  services:\n    mon: 3 daemons, quorum c,a,b\n    mgr: a(active)\n    mds: myfs-1/1/1 up  {0=myfs-b=up:active}, 1 up:standby-replay\n    osd: 3 osds: 3 up, 3 in\n    rgw: 1 daemon active\n\n  data:\n    pools:   8 pools, 800 pgs\n    objects: 224  objects, 5.9 KiB\n    usage:   3.0 GiB used, 57 GiB / 60 GiB avail\n    pgs:     800 active+clean\n\n  io:\n    client:   852 B/s rd, 1 op/s rd, 0 op/s wr\n\n\n```\n\ncluster/examples/kubernetes/ceph/ 目录下还有其他yaml文件，可以对ceph集群进行其他操作，比如启用mgr dashboar，安装prometheus监控等\n\n```\n-rwxr-xr-x 1 root root  8139 Mar 15 15:20 cluster.yaml\n-rw-r--r-- 1 root root   363 Mar 15 14:47 dashboard-external-https.yaml\n-rw-r--r-- 1 root root   362 Mar 15 14:47 dashboard-external-http.yaml\n-rw-r--r-- 1 root root  1487 Mar 15 14:47 ec-filesystem.yaml\n-rw-r--r-- 1 root root  1538 Mar 15 14:47 ec-storageclass.yaml\n-rw-r--r-- 1 root root  1375 Mar 15 14:47 filesystem.yaml\n-rw-r--r-- 1 root root  1923 Mar 15 14:48 kube-registry.yaml\ndrwxr-xr-x 2 root root    85 Mar 15 16:07 monitoring\n-rw-r--r-- 1 root root   160 Mar 15 14:47 object-user.yaml\n-rw-r--r-- 1 root root  1813 Mar 15 14:47 object.yaml\n-rwxr-xr-x 1 root root 12690 Mar 15 14:48 operator.yaml\n-rw-r--r-- 1 root root   742 Mar 15 14:47 pool.yaml\n-rw-r--r-- 1 root root   410 Mar 15 14:47 rgw-external.yaml\n-rw-r--r-- 1 root root  1216 Mar 15 14:47 scc.yaml\n-rw-r--r-- 1 root root   991 Mar 15 14:47 storageclass.yaml\n-rw-r--r-- 1 root root  1544 Mar 15 14:48 toolbox.yaml\n-rw-r--r-- 1 root root  6492 Mar 15 14:47 upgrade-from-v0.8-create.yaml\n-rw-r--r-- 1 root root   874 Mar 15 14:47 upgrade-from-v0.8-replace.yaml\n```\n\n# 参考\n* [http://www.yangguanjun.com/2018/12/22/rook-ceph-practice-part1/](http://www.yangguanjun.com/2018/12/22/rook-ceph-practice-part1/)\n* [http://www.yangguanjun.com/2018/12/28/rook-ceph-practice-part2/](http://www.yangguanjun.com/2018/12/28/rook-ceph-practice-part2/)\n \n","source":"_posts/rook.md","raw":"---\ntitle: Rook\ndate: 2019-03-12 14:42:10\ntags: ['ceph','k8s']\n---\n\n# 概述\n本文主要介绍如何通过rook在k8s上部署一套ceph集群。  \n测试的k8s集群一共三个节点：  \n\n```\n[root@kube01 ~]# kubectl get nodes\nNAME     STATUS   ROLES    AGE    VERSION\nkube01   Ready    master   3h3m   v1.13.4\nkube02   Ready    master   175m   v1.13.4\nkube03   Ready    master   172m   v1.13.4\n\n```\n\n# Rook部署\n\nclone rook代码  \n\n```\ngit clone https://github.com/rook/rook.git\ncd rook/\ngit checkout v0.9.3\n```\n通过kubectl执行rook-ceph的operator\n\n```\n[root@kube01 rook]# kubectl apply -f cluster/examples/kubernetes/ceph/operator.yaml\nnamespace/rook-ceph-system created\ncustomresourcedefinition.apiextensions.k8s.io/cephclusters.ceph.rook.io created\ncustomresourcedefinition.apiextensions.k8s.io/cephfilesystems.ceph.rook.io created\ncustomresourcedefinition.apiextensions.k8s.io/cephobjectstores.ceph.rook.io created\ncustomresourcedefinition.apiextensions.k8s.io/cephobjectstoreusers.ceph.rook.io created\ncustomresourcedefinition.apiextensions.k8s.io/cephblockpools.ceph.rook.io created\ncustomresourcedefinition.apiextensions.k8s.io/volumes.rook.io created\nclusterrole.rbac.authorization.k8s.io/rook-ceph-cluster-mgmt created\nrole.rbac.authorization.k8s.io/rook-ceph-system created\nclusterrole.rbac.authorization.k8s.io/rook-ceph-global created\nclusterrole.rbac.authorization.k8s.io/rook-ceph-mgr-cluster created\nserviceaccount/rook-ceph-system created\nrolebinding.rbac.authorization.k8s.io/rook-ceph-system created\nclusterrolebinding.rbac.authorization.k8s.io/rook-ceph-global created\ndeployment.apps/rook-ceph-operator created\n```\n\n等待全部pod都running状态\n\n```\n[root@kube01 rook]# kubectl get pods -n rook-ceph-system -owide\nNAME                                  READY   STATUS    RESTARTS   AGE     IP               NODE     NOMINATED NODE   READINESS GATES\nrook-ceph-agent-7zgcv                 1/1     Running   0          2m15s   192.168.10.181   kube01   <none>           <none>\nrook-ceph-agent-ww4sk                 1/1     Running   0          2m15s   192.168.10.129   kube02   <none>           <none>\nrook-ceph-agent-xjgm4                 1/1     Running   0          2m15s   192.168.10.44    kube03   <none>           <none>\nrook-ceph-operator-5f4ff4d57d-fm8s5   1/1     Running   0          3m41s   10.244.1.2       kube02   <none>           <none>\nrook-discover-2mwpn                   1/1     Running   0          2m15s   10.244.0.10      kube01   <none>           <none>\nrook-discover-nqhr8                   1/1     Running   0          2m15s   10.244.1.3       kube02   <none>           <none>\nrook-discover-wgpng                   1/1     Running   0          2m15s   10.244.2.2       kube03   <none>           <none>\n```\n\nceph会使用每个节点的vdb作为osd，所以需要修改cluster/examples/kubernetes/ceph/cluster.yaml的内容\n\n```\n  storage: # cluster level storage configuration and selection\n    useAllNodes: true\n    useAllDevices: false\n    deviceFilter: \"^vdb\"\n    location:\n    config:\n      # The default and recommended storeType is dynamically set to bluestore for devices and filestore for directories.\n      # Set the storeType explicitly only if it is required not to use the default.\n      storeType: bluestore\n      #databaseSizeMB: \"1024\" # this value can be removed for environments with normal sized disks (100 GB or larger)\n      #journalSizeMB: \"1024\"  # this value can be removed for environments with normal sized disks (20 GB or larger)\n      osdsPerDevice: \"1\" # this value can be overridden at the node or device level\n```\n\n通过kubectl部署ceph集群\n\n```\n[root@kube01 rook]# kubectl apply -f cluster/examples/kubernetes/ceph/cluster.yaml\nnamespace/rook-ceph created\nserviceaccount/rook-ceph-osd created\nserviceaccount/rook-ceph-mgr created\nrole.rbac.authorization.k8s.io/rook-ceph-osd created\nrole.rbac.authorization.k8s.io/rook-ceph-mgr-system created\nrole.rbac.authorization.k8s.io/rook-ceph-mgr created\nrolebinding.rbac.authorization.k8s.io/rook-ceph-cluster-mgmt created\nrolebinding.rbac.authorization.k8s.io/rook-ceph-osd created\nrolebinding.rbac.authorization.k8s.io/rook-ceph-mgr created\nrolebinding.rbac.authorization.k8s.io/rook-ceph-mgr-system created\nrolebinding.rbac.authorization.k8s.io/rook-ceph-mgr-cluster created\ncephcluster.ceph.rook.io/rook-ceph created\n```\n\n等ceph部署完成，可以看到有三个mon，一个mgr和三个osd\n\n```\n[root@kube01 rook]# kubectl get pods -n rook-ceph\nNAME                                 READY   STATUS      RESTARTS   AGE\nrook-ceph-mgr-a-66db78887f-lmhcf     1/1     Running     0          4m13s\nrook-ceph-mon-a-b6556df54-t7cd4      1/1     Running     0          4m53s\nrook-ceph-mon-b-7f84c6d4b-nhjj6      1/1     Running     0          4m42s\nrook-ceph-mon-c-868c5b476b-ghfqs     1/1     Running     0          4m32s\nrook-ceph-osd-0-6fdf57bcb7-bf6f2     1/1     Running     0          54s\nrook-ceph-osd-1-8c99b7447-h4mfd      1/1     Running     0          39s\nrook-ceph-osd-2-66b76d6944-5df9j     1/1     Running     0          27s\nrook-ceph-osd-prepare-kube01-dfrp2   0/2     Completed   0          3m50s\nrook-ceph-osd-prepare-kube02-pnbsc   0/2     Completed   0          3m49s\nrook-ceph-osd-prepare-kube03-4ztl9   0/2     Completed   0          3m48s\n```\n\n安装ceph-tool，登录到ceph-tools的pod，可以执行ceph相关的命令，查看ceph状态\n\n```\n[root@kube01 rook]# kubectl apply -f cluster/examples/kubernetes/ceph/toolbox.yaml\ndeployment.apps/rook-ceph-tools created\n[root@kube01 rook]# kubectl get pods -n rook-ceph\nNAME                                 READY   STATUS    RESTARTS   AGE\nrook-ceph-mgr-a-66db78887f-lmhcf     1/1     Running   0          5m10s\nrook-ceph-mon-a-b6556df54-t7cd4      1/1     Running   0          5m50s\nrook-ceph-mon-b-7f84c6d4b-nhjj6      1/1     Running   0          5m39s\nrook-ceph-mon-c-868c5b476b-ghfqs     1/1     Running   0          5m29s\nrook-ceph-osd-0-6fdf57bcb7-bf6f2     1/1     Running   0          111s\nrook-ceph-osd-1-8c99b7447-h4mfd      1/1     Running   0          96s\nrook-ceph-osd-2-66b76d6944-5df9j     1/1     Running   0          84s\nrook-ceph-osd-prepare-kube01-d2rrt   1/2     Running   0          49s\nrook-ceph-osd-prepare-kube02-jxl6g   1/2     Running   0          47s\nrook-ceph-osd-prepare-kube03-fz276   1/2     Running   0          45s\nrook-ceph-tools-544fb656d-tddrx      1/1     Running   0          3s\n```\n登录到ceph-tools Pod\n\n```\n[root@kube01 rook]# kubectl exec -it rook-ceph-tools-544fb656d-tddrx bash -n rook-ceph\nbash: warning: setlocale: LC_CTYPE: cannot change locale (en_US.UTF-8): No such file or directory\nbash: warning: setlocale: LC_COLLATE: cannot change locale (en_US.UTF-8): No such file or directory\nbash: warning: setlocale: LC_MESSAGES: cannot change locale (en_US.UTF-8): No such file or directory\nbash: warning: setlocale: LC_NUMERIC: cannot change locale (en_US.UTF-8): No such file or directory\nbash: warning: setlocale: LC_TIME: cannot change locale (en_US.UTF-8): No such file or directory\n[root@kube03 /]# ceph -s\n  cluster:\n    id:     f9609ec9-62c7-4462-a4f2-35c4137c25ef\n    health: HEALTH_OK\n\n  services:\n    mon: 3 daemons, quorum c,a,b\n    mgr: a(active)\n    osd: 3 osds: 3 up, 3 in\n\n  data:\n    pools:   0 pools, 0 pgs\n    objects: 0  objects, 0 B\n    usage:   3.0 GiB used, 57 GiB / 60 GiB avail\n    pgs:\n\n[root@kube03 /]# ceph osd tree\nID CLASS WEIGHT  TYPE NAME       STATUS REWEIGHT PRI-AFF\n-1       0.05846 root default\n-7       0.01949     host kube01\n 2   hdd 0.01949         osd.2       up  1.00000 1.00000\n-3       0.01949     host kube02\n 0   hdd 0.01949         osd.0       up  1.00000 1.00000\n-5       0.01949     host kube03\n 1   hdd 0.01949         osd.1       up  1.00000 1.00000\n \n```\n \n部署好的ceph集群并没有rgw服务，通过下面的方式可以添加rgw服务\n \n```\n[root@kube01 rook]# kubectl apply -f cluster/examples/kubernetes/ceph/object.yaml\ncephobjectstore.ceph.rook.io/my-store created\n\n[root@kube01 rook]# kubectl get pods -n rook-ceph\nNAME                                      READY   STATUS      RESTARTS   AGE\nrook-ceph-mgr-a-66db78887f-lmhcf          1/1     Running     0          11m\nrook-ceph-mon-a-b6556df54-t7cd4           1/1     Running     0          11m\nrook-ceph-mon-b-7f84c6d4b-nhjj6           1/1     Running     0          11m\nrook-ceph-mon-c-868c5b476b-ghfqs          1/1     Running     0          11m\nrook-ceph-osd-0-f986cc57d-6xclh           1/1     Running     0          6m\nrook-ceph-osd-1-765556c558-jwv2n          1/1     Running     0          5m40s\nrook-ceph-osd-2-766db888c7-j7z8f          1/1     Running     0          5m48s\nrook-ceph-osd-prepare-kube01-d2rrt        0/2     Completed   0          6m57s\nrook-ceph-osd-prepare-kube02-jxl6g        0/2     Completed   0          6m55s\nrook-ceph-osd-prepare-kube03-fz276        0/2     Completed   0          6m53s\nrook-ceph-rgw-my-store-5b68744bc6-pc7g7   1/1     Running     0          21s\nrook-ceph-tools-544fb656d-tddrx           1/1     Running     0          6m11s\n\n[root@kube01 rook]# kubectl exec -it rook-ceph-tools-544fb656d-tddrx bash -n rook-ceph\nbash: warning: setlocale: LC_CTYPE: cannot change locale (en_US.UTF-8): No such file or directory\nbash: warning: setlocale: LC_COLLATE: cannot change locale (en_US.UTF-8): No such file or directory\nbash: warning: setlocale: LC_MESSAGES: cannot change locale (en_US.UTF-8): No such file or directory\nbash: warning: setlocale: LC_NUMERIC: cannot change locale (en_US.UTF-8): No such file or directory\nbash: warning: setlocale: LC_TIME: cannot change locale (en_US.UTF-8): No such file or directory\n[root@kube03 /]# ceph -s\n  cluster:\n    id:     f9609ec9-62c7-4462-a4f2-35c4137c25ef\n    health: HEALTH_OK\n\n  services:\n    mon: 3 daemons, quorum c,a,b\n    mgr: a(active)\n    osd: 3 osds: 3 up, 3 in\n    rgw: 1 daemon active\n\n  data:\n    pools:   6 pools, 600 pgs\n    objects: 201  objects, 3.7 KiB\n    usage:   3.0 GiB used, 57 GiB / 60 GiB avail\n    pgs:     600 active+clean\n    \n    \n\n```\n通过下面的方式可以把rgw服务以NodePort的方式对外提供服务\n \n```\n[root@kube01 rook]# kubectl apply -f cluster/examples/kubernetes/ceph/rgw-external.yaml\nservice/rook-ceph-rgw-my-store-external created\n \n[root@kube01 rook]# kubectl get services -n rook-ceph\nNAME                              TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)        AGE\nrook-ceph-mgr                     ClusterIP   172.30.117.80    <none>        9283/TCP       12m\nrook-ceph-mgr-dashboard           ClusterIP   172.30.225.42    <none>        8443/TCP       12m\nrook-ceph-mon-a                   ClusterIP   172.30.82.3      <none>        6790/TCP       13m\nrook-ceph-mon-b                   ClusterIP   172.30.122.28    <none>        6790/TCP       13m\nrook-ceph-mon-c                   ClusterIP   172.30.62.26     <none>        6790/TCP       13m\nrook-ceph-rgw-my-store            ClusterIP   172.30.107.175   <none>        80/TCP         2m47s\nrook-ceph-rgw-my-store-external   NodePort    172.30.131.185   <none>        80:32185/TCP   4m2s\n \n```\n\n下面的部署安装ceph mds \n\n```\n[root@kube01 rook]# kubectl apply -f cluster/examples/kubernetes/ceph/filesystem.yaml\ncephfilesystem.ceph.rook.io/myfs created\n\n[root@kube01 rook]# kubectl get pods -n rook-ceph\nNAME                                      READY   STATUS      RESTARTS   AGE\nrook-ceph-mds-myfs-a-6bbc59cbc8-fp5px     1/1     Running     0          11s\nrook-ceph-mds-myfs-b-658fc8fd66-5cd9g     1/1     Running     0          11s\nrook-ceph-mgr-a-66db78887f-lmhcf          1/1     Running     0          23m\nrook-ceph-mon-a-b6556df54-t7cd4           1/1     Running     0          24m\nrook-ceph-mon-b-7f84c6d4b-nhjj6           1/1     Running     0          24m\nrook-ceph-mon-c-868c5b476b-ghfqs          1/1     Running     0          23m\nrook-ceph-osd-0-f986cc57d-6xclh           1/1     Running     0          18m\nrook-ceph-osd-1-765556c558-jwv2n          1/1     Running     0          17m\nrook-ceph-osd-2-766db888c7-j7z8f          1/1     Running     0          18m\nrook-ceph-osd-prepare-kube01-d2rrt        0/2     Completed   0          19m\nrook-ceph-osd-prepare-kube02-jxl6g        0/2     Completed   0          19m\nrook-ceph-osd-prepare-kube03-fz276        0/2     Completed   0          19m\nrook-ceph-rgw-my-store-5b68744bc6-pc7g7   1/1     Running     0          12m\nrook-ceph-tools-544fb656d-tddrx           1/1     Running     0          18m\n\n[root@kube01 rook]# kubectl exec -it rook-ceph-tools-544fb656d-tddrx bash -n rook-ceph\nbash: warning: setlocale: LC_CTYPE: cannot change locale (en_US.UTF-8): No such file or directory\nbash: warning: setlocale: LC_COLLATE: cannot change locale (en_US.UTF-8): No such file or directory\nbash: warning: setlocale: LC_MESSAGES: cannot change locale (en_US.UTF-8): No such file or directory\nbash: warning: setlocale: LC_NUMERIC: cannot change locale (en_US.UTF-8): No such file or directory\nbash: warning: setlocale: LC_TIME: cannot change locale (en_US.UTF-8): No such file or directory\n[root@kube03 /]# ceph -s\n  cluster:\n    id:     f9609ec9-62c7-4462-a4f2-35c4137c25ef\n    health: HEALTH_OK\n\n  services:\n    mon: 3 daemons, quorum c,a,b\n    mgr: a(active)\n    mds: myfs-1/1/1 up  {0=myfs-b=up:active}, 1 up:standby-replay\n    osd: 3 osds: 3 up, 3 in\n    rgw: 1 daemon active\n\n  data:\n    pools:   8 pools, 800 pgs\n    objects: 224  objects, 5.9 KiB\n    usage:   3.0 GiB used, 57 GiB / 60 GiB avail\n    pgs:     800 active+clean\n\n  io:\n    client:   852 B/s rd, 1 op/s rd, 0 op/s wr\n\n\n```\n\ncluster/examples/kubernetes/ceph/ 目录下还有其他yaml文件，可以对ceph集群进行其他操作，比如启用mgr dashboar，安装prometheus监控等\n\n```\n-rwxr-xr-x 1 root root  8139 Mar 15 15:20 cluster.yaml\n-rw-r--r-- 1 root root   363 Mar 15 14:47 dashboard-external-https.yaml\n-rw-r--r-- 1 root root   362 Mar 15 14:47 dashboard-external-http.yaml\n-rw-r--r-- 1 root root  1487 Mar 15 14:47 ec-filesystem.yaml\n-rw-r--r-- 1 root root  1538 Mar 15 14:47 ec-storageclass.yaml\n-rw-r--r-- 1 root root  1375 Mar 15 14:47 filesystem.yaml\n-rw-r--r-- 1 root root  1923 Mar 15 14:48 kube-registry.yaml\ndrwxr-xr-x 2 root root    85 Mar 15 16:07 monitoring\n-rw-r--r-- 1 root root   160 Mar 15 14:47 object-user.yaml\n-rw-r--r-- 1 root root  1813 Mar 15 14:47 object.yaml\n-rwxr-xr-x 1 root root 12690 Mar 15 14:48 operator.yaml\n-rw-r--r-- 1 root root   742 Mar 15 14:47 pool.yaml\n-rw-r--r-- 1 root root   410 Mar 15 14:47 rgw-external.yaml\n-rw-r--r-- 1 root root  1216 Mar 15 14:47 scc.yaml\n-rw-r--r-- 1 root root   991 Mar 15 14:47 storageclass.yaml\n-rw-r--r-- 1 root root  1544 Mar 15 14:48 toolbox.yaml\n-rw-r--r-- 1 root root  6492 Mar 15 14:47 upgrade-from-v0.8-create.yaml\n-rw-r--r-- 1 root root   874 Mar 15 14:47 upgrade-from-v0.8-replace.yaml\n```\n\n# 参考\n* [http://www.yangguanjun.com/2018/12/22/rook-ceph-practice-part1/](http://www.yangguanjun.com/2018/12/22/rook-ceph-practice-part1/)\n* [http://www.yangguanjun.com/2018/12/28/rook-ceph-practice-part2/](http://www.yangguanjun.com/2018/12/28/rook-ceph-practice-part2/)\n \n","slug":"rook","published":1,"updated":"2019-03-15T15:14:28.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck1pzbth7000ttp75opc1o4xh","content":"<h1 id=\"概述\"><a href=\"#概述\" class=\"headerlink\" title=\"概述\"></a>概述</h1><p>本文主要介绍如何通过rook在k8s上部署一套ceph集群。<br>测试的k8s集群一共三个节点：  </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@kube01 ~]# kubectl get nodes</span><br><span class=\"line\">NAME     STATUS   ROLES    AGE    VERSION</span><br><span class=\"line\">kube01   Ready    master   3h3m   v1.13.4</span><br><span class=\"line\">kube02   Ready    master   175m   v1.13.4</span><br><span class=\"line\">kube03   Ready    master   172m   v1.13.4</span><br></pre></td></tr></table></figure>\n<h1 id=\"Rook部署\"><a href=\"#Rook部署\" class=\"headerlink\" title=\"Rook部署\"></a>Rook部署</h1><p>clone rook代码  </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git clone https://github.com/rook/rook.git</span><br><span class=\"line\">cd rook/</span><br><span class=\"line\">git checkout v0.9.3</span><br></pre></td></tr></table></figure>\n<p>通过kubectl执行rook-ceph的operator</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@kube01 rook]# kubectl apply -f cluster/examples/kubernetes/ceph/operator.yaml</span><br><span class=\"line\">namespace/rook-ceph-system created</span><br><span class=\"line\">customresourcedefinition.apiextensions.k8s.io/cephclusters.ceph.rook.io created</span><br><span class=\"line\">customresourcedefinition.apiextensions.k8s.io/cephfilesystems.ceph.rook.io created</span><br><span class=\"line\">customresourcedefinition.apiextensions.k8s.io/cephobjectstores.ceph.rook.io created</span><br><span class=\"line\">customresourcedefinition.apiextensions.k8s.io/cephobjectstoreusers.ceph.rook.io created</span><br><span class=\"line\">customresourcedefinition.apiextensions.k8s.io/cephblockpools.ceph.rook.io created</span><br><span class=\"line\">customresourcedefinition.apiextensions.k8s.io/volumes.rook.io created</span><br><span class=\"line\">clusterrole.rbac.authorization.k8s.io/rook-ceph-cluster-mgmt created</span><br><span class=\"line\">role.rbac.authorization.k8s.io/rook-ceph-system created</span><br><span class=\"line\">clusterrole.rbac.authorization.k8s.io/rook-ceph-global created</span><br><span class=\"line\">clusterrole.rbac.authorization.k8s.io/rook-ceph-mgr-cluster created</span><br><span class=\"line\">serviceaccount/rook-ceph-system created</span><br><span class=\"line\">rolebinding.rbac.authorization.k8s.io/rook-ceph-system created</span><br><span class=\"line\">clusterrolebinding.rbac.authorization.k8s.io/rook-ceph-global created</span><br><span class=\"line\">deployment.apps/rook-ceph-operator created</span><br></pre></td></tr></table></figure>\n<p>等待全部pod都running状态</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@kube01 rook]# kubectl get pods -n rook-ceph-system -owide</span><br><span class=\"line\">NAME                                  READY   STATUS    RESTARTS   AGE     IP               NODE     NOMINATED NODE   READINESS GATES</span><br><span class=\"line\">rook-ceph-agent-7zgcv                 1/1     Running   0          2m15s   192.168.10.181   kube01   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">rook-ceph-agent-ww4sk                 1/1     Running   0          2m15s   192.168.10.129   kube02   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">rook-ceph-agent-xjgm4                 1/1     Running   0          2m15s   192.168.10.44    kube03   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">rook-ceph-operator-5f4ff4d57d-fm8s5   1/1     Running   0          3m41s   10.244.1.2       kube02   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">rook-discover-2mwpn                   1/1     Running   0          2m15s   10.244.0.10      kube01   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">rook-discover-nqhr8                   1/1     Running   0          2m15s   10.244.1.3       kube02   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">rook-discover-wgpng                   1/1     Running   0          2m15s   10.244.2.2       kube03   &lt;none&gt;           &lt;none&gt;</span><br></pre></td></tr></table></figure>\n<p>ceph会使用每个节点的vdb作为osd，所以需要修改cluster/examples/kubernetes/ceph/cluster.yaml的内容</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">storage: # cluster level storage configuration and selection</span><br><span class=\"line\">  useAllNodes: true</span><br><span class=\"line\">  useAllDevices: false</span><br><span class=\"line\">  deviceFilter: &quot;^vdb&quot;</span><br><span class=\"line\">  location:</span><br><span class=\"line\">  config:</span><br><span class=\"line\">    # The default and recommended storeType is dynamically set to bluestore for devices and filestore for directories.</span><br><span class=\"line\">    # Set the storeType explicitly only if it is required not to use the default.</span><br><span class=\"line\">    storeType: bluestore</span><br><span class=\"line\">    #databaseSizeMB: &quot;1024&quot; # this value can be removed for environments with normal sized disks (100 GB or larger)</span><br><span class=\"line\">    #journalSizeMB: &quot;1024&quot;  # this value can be removed for environments with normal sized disks (20 GB or larger)</span><br><span class=\"line\">    osdsPerDevice: &quot;1&quot; # this value can be overridden at the node or device level</span><br></pre></td></tr></table></figure>\n<p>通过kubectl部署ceph集群</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@kube01 rook]# kubectl apply -f cluster/examples/kubernetes/ceph/cluster.yaml</span><br><span class=\"line\">namespace/rook-ceph created</span><br><span class=\"line\">serviceaccount/rook-ceph-osd created</span><br><span class=\"line\">serviceaccount/rook-ceph-mgr created</span><br><span class=\"line\">role.rbac.authorization.k8s.io/rook-ceph-osd created</span><br><span class=\"line\">role.rbac.authorization.k8s.io/rook-ceph-mgr-system created</span><br><span class=\"line\">role.rbac.authorization.k8s.io/rook-ceph-mgr created</span><br><span class=\"line\">rolebinding.rbac.authorization.k8s.io/rook-ceph-cluster-mgmt created</span><br><span class=\"line\">rolebinding.rbac.authorization.k8s.io/rook-ceph-osd created</span><br><span class=\"line\">rolebinding.rbac.authorization.k8s.io/rook-ceph-mgr created</span><br><span class=\"line\">rolebinding.rbac.authorization.k8s.io/rook-ceph-mgr-system created</span><br><span class=\"line\">rolebinding.rbac.authorization.k8s.io/rook-ceph-mgr-cluster created</span><br><span class=\"line\">cephcluster.ceph.rook.io/rook-ceph created</span><br></pre></td></tr></table></figure>\n<p>等ceph部署完成，可以看到有三个mon，一个mgr和三个osd</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@kube01 rook]# kubectl get pods -n rook-ceph</span><br><span class=\"line\">NAME                                 READY   STATUS      RESTARTS   AGE</span><br><span class=\"line\">rook-ceph-mgr-a-66db78887f-lmhcf     1/1     Running     0          4m13s</span><br><span class=\"line\">rook-ceph-mon-a-b6556df54-t7cd4      1/1     Running     0          4m53s</span><br><span class=\"line\">rook-ceph-mon-b-7f84c6d4b-nhjj6      1/1     Running     0          4m42s</span><br><span class=\"line\">rook-ceph-mon-c-868c5b476b-ghfqs     1/1     Running     0          4m32s</span><br><span class=\"line\">rook-ceph-osd-0-6fdf57bcb7-bf6f2     1/1     Running     0          54s</span><br><span class=\"line\">rook-ceph-osd-1-8c99b7447-h4mfd      1/1     Running     0          39s</span><br><span class=\"line\">rook-ceph-osd-2-66b76d6944-5df9j     1/1     Running     0          27s</span><br><span class=\"line\">rook-ceph-osd-prepare-kube01-dfrp2   0/2     Completed   0          3m50s</span><br><span class=\"line\">rook-ceph-osd-prepare-kube02-pnbsc   0/2     Completed   0          3m49s</span><br><span class=\"line\">rook-ceph-osd-prepare-kube03-4ztl9   0/2     Completed   0          3m48s</span><br></pre></td></tr></table></figure>\n<p>安装ceph-tool，登录到ceph-tools的pod，可以执行ceph相关的命令，查看ceph状态</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@kube01 rook]# kubectl apply -f cluster/examples/kubernetes/ceph/toolbox.yaml</span><br><span class=\"line\">deployment.apps/rook-ceph-tools created</span><br><span class=\"line\">[root@kube01 rook]# kubectl get pods -n rook-ceph</span><br><span class=\"line\">NAME                                 READY   STATUS    RESTARTS   AGE</span><br><span class=\"line\">rook-ceph-mgr-a-66db78887f-lmhcf     1/1     Running   0          5m10s</span><br><span class=\"line\">rook-ceph-mon-a-b6556df54-t7cd4      1/1     Running   0          5m50s</span><br><span class=\"line\">rook-ceph-mon-b-7f84c6d4b-nhjj6      1/1     Running   0          5m39s</span><br><span class=\"line\">rook-ceph-mon-c-868c5b476b-ghfqs     1/1     Running   0          5m29s</span><br><span class=\"line\">rook-ceph-osd-0-6fdf57bcb7-bf6f2     1/1     Running   0          111s</span><br><span class=\"line\">rook-ceph-osd-1-8c99b7447-h4mfd      1/1     Running   0          96s</span><br><span class=\"line\">rook-ceph-osd-2-66b76d6944-5df9j     1/1     Running   0          84s</span><br><span class=\"line\">rook-ceph-osd-prepare-kube01-d2rrt   1/2     Running   0          49s</span><br><span class=\"line\">rook-ceph-osd-prepare-kube02-jxl6g   1/2     Running   0          47s</span><br><span class=\"line\">rook-ceph-osd-prepare-kube03-fz276   1/2     Running   0          45s</span><br><span class=\"line\">rook-ceph-tools-544fb656d-tddrx      1/1     Running   0          3s</span><br></pre></td></tr></table></figure>\n<p>登录到ceph-tools Pod</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@kube01 rook]# kubectl exec -it rook-ceph-tools-544fb656d-tddrx bash -n rook-ceph</span><br><span class=\"line\">bash: warning: setlocale: LC_CTYPE: cannot change locale (en_US.UTF-8): No such file or directory</span><br><span class=\"line\">bash: warning: setlocale: LC_COLLATE: cannot change locale (en_US.UTF-8): No such file or directory</span><br><span class=\"line\">bash: warning: setlocale: LC_MESSAGES: cannot change locale (en_US.UTF-8): No such file or directory</span><br><span class=\"line\">bash: warning: setlocale: LC_NUMERIC: cannot change locale (en_US.UTF-8): No such file or directory</span><br><span class=\"line\">bash: warning: setlocale: LC_TIME: cannot change locale (en_US.UTF-8): No such file or directory</span><br><span class=\"line\">[root@kube03 /]# ceph -s</span><br><span class=\"line\">  cluster:</span><br><span class=\"line\">    id:     f9609ec9-62c7-4462-a4f2-35c4137c25ef</span><br><span class=\"line\">    health: HEALTH_OK</span><br><span class=\"line\"></span><br><span class=\"line\">  services:</span><br><span class=\"line\">    mon: 3 daemons, quorum c,a,b</span><br><span class=\"line\">    mgr: a(active)</span><br><span class=\"line\">    osd: 3 osds: 3 up, 3 in</span><br><span class=\"line\"></span><br><span class=\"line\">  data:</span><br><span class=\"line\">    pools:   0 pools, 0 pgs</span><br><span class=\"line\">    objects: 0  objects, 0 B</span><br><span class=\"line\">    usage:   3.0 GiB used, 57 GiB / 60 GiB avail</span><br><span class=\"line\">    pgs:</span><br><span class=\"line\"></span><br><span class=\"line\">[root@kube03 /]# ceph osd tree</span><br><span class=\"line\">ID CLASS WEIGHT  TYPE NAME       STATUS REWEIGHT PRI-AFF</span><br><span class=\"line\">-1       0.05846 root default</span><br><span class=\"line\">-7       0.01949     host kube01</span><br><span class=\"line\"> 2   hdd 0.01949         osd.2       up  1.00000 1.00000</span><br><span class=\"line\">-3       0.01949     host kube02</span><br><span class=\"line\"> 0   hdd 0.01949         osd.0       up  1.00000 1.00000</span><br><span class=\"line\">-5       0.01949     host kube03</span><br><span class=\"line\"> 1   hdd 0.01949         osd.1       up  1.00000 1.00000</span><br></pre></td></tr></table></figure>\n<p>部署好的ceph集群并没有rgw服务，通过下面的方式可以添加rgw服务</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@kube01 rook]# kubectl apply -f cluster/examples/kubernetes/ceph/object.yaml</span><br><span class=\"line\">cephobjectstore.ceph.rook.io/my-store created</span><br><span class=\"line\"></span><br><span class=\"line\">[root@kube01 rook]# kubectl get pods -n rook-ceph</span><br><span class=\"line\">NAME                                      READY   STATUS      RESTARTS   AGE</span><br><span class=\"line\">rook-ceph-mgr-a-66db78887f-lmhcf          1/1     Running     0          11m</span><br><span class=\"line\">rook-ceph-mon-a-b6556df54-t7cd4           1/1     Running     0          11m</span><br><span class=\"line\">rook-ceph-mon-b-7f84c6d4b-nhjj6           1/1     Running     0          11m</span><br><span class=\"line\">rook-ceph-mon-c-868c5b476b-ghfqs          1/1     Running     0          11m</span><br><span class=\"line\">rook-ceph-osd-0-f986cc57d-6xclh           1/1     Running     0          6m</span><br><span class=\"line\">rook-ceph-osd-1-765556c558-jwv2n          1/1     Running     0          5m40s</span><br><span class=\"line\">rook-ceph-osd-2-766db888c7-j7z8f          1/1     Running     0          5m48s</span><br><span class=\"line\">rook-ceph-osd-prepare-kube01-d2rrt        0/2     Completed   0          6m57s</span><br><span class=\"line\">rook-ceph-osd-prepare-kube02-jxl6g        0/2     Completed   0          6m55s</span><br><span class=\"line\">rook-ceph-osd-prepare-kube03-fz276        0/2     Completed   0          6m53s</span><br><span class=\"line\">rook-ceph-rgw-my-store-5b68744bc6-pc7g7   1/1     Running     0          21s</span><br><span class=\"line\">rook-ceph-tools-544fb656d-tddrx           1/1     Running     0          6m11s</span><br><span class=\"line\"></span><br><span class=\"line\">[root@kube01 rook]# kubectl exec -it rook-ceph-tools-544fb656d-tddrx bash -n rook-ceph</span><br><span class=\"line\">bash: warning: setlocale: LC_CTYPE: cannot change locale (en_US.UTF-8): No such file or directory</span><br><span class=\"line\">bash: warning: setlocale: LC_COLLATE: cannot change locale (en_US.UTF-8): No such file or directory</span><br><span class=\"line\">bash: warning: setlocale: LC_MESSAGES: cannot change locale (en_US.UTF-8): No such file or directory</span><br><span class=\"line\">bash: warning: setlocale: LC_NUMERIC: cannot change locale (en_US.UTF-8): No such file or directory</span><br><span class=\"line\">bash: warning: setlocale: LC_TIME: cannot change locale (en_US.UTF-8): No such file or directory</span><br><span class=\"line\">[root@kube03 /]# ceph -s</span><br><span class=\"line\">  cluster:</span><br><span class=\"line\">    id:     f9609ec9-62c7-4462-a4f2-35c4137c25ef</span><br><span class=\"line\">    health: HEALTH_OK</span><br><span class=\"line\"></span><br><span class=\"line\">  services:</span><br><span class=\"line\">    mon: 3 daemons, quorum c,a,b</span><br><span class=\"line\">    mgr: a(active)</span><br><span class=\"line\">    osd: 3 osds: 3 up, 3 in</span><br><span class=\"line\">    rgw: 1 daemon active</span><br><span class=\"line\"></span><br><span class=\"line\">  data:</span><br><span class=\"line\">    pools:   6 pools, 600 pgs</span><br><span class=\"line\">    objects: 201  objects, 3.7 KiB</span><br><span class=\"line\">    usage:   3.0 GiB used, 57 GiB / 60 GiB avail</span><br><span class=\"line\">    pgs:     600 active+clean</span><br></pre></td></tr></table></figure>\n<p>通过下面的方式可以把rgw服务以NodePort的方式对外提供服务</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@kube01 rook]# kubectl apply -f cluster/examples/kubernetes/ceph/rgw-external.yaml</span><br><span class=\"line\">service/rook-ceph-rgw-my-store-external created</span><br><span class=\"line\"> </span><br><span class=\"line\">[root@kube01 rook]# kubectl get services -n rook-ceph</span><br><span class=\"line\">NAME                              TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)        AGE</span><br><span class=\"line\">rook-ceph-mgr                     ClusterIP   172.30.117.80    &lt;none&gt;        9283/TCP       12m</span><br><span class=\"line\">rook-ceph-mgr-dashboard           ClusterIP   172.30.225.42    &lt;none&gt;        8443/TCP       12m</span><br><span class=\"line\">rook-ceph-mon-a                   ClusterIP   172.30.82.3      &lt;none&gt;        6790/TCP       13m</span><br><span class=\"line\">rook-ceph-mon-b                   ClusterIP   172.30.122.28    &lt;none&gt;        6790/TCP       13m</span><br><span class=\"line\">rook-ceph-mon-c                   ClusterIP   172.30.62.26     &lt;none&gt;        6790/TCP       13m</span><br><span class=\"line\">rook-ceph-rgw-my-store            ClusterIP   172.30.107.175   &lt;none&gt;        80/TCP         2m47s</span><br><span class=\"line\">rook-ceph-rgw-my-store-external   NodePort    172.30.131.185   &lt;none&gt;        80:32185/TCP   4m2s</span><br></pre></td></tr></table></figure>\n<p>下面的部署安装ceph mds </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@kube01 rook]# kubectl apply -f cluster/examples/kubernetes/ceph/filesystem.yaml</span><br><span class=\"line\">cephfilesystem.ceph.rook.io/myfs created</span><br><span class=\"line\"></span><br><span class=\"line\">[root@kube01 rook]# kubectl get pods -n rook-ceph</span><br><span class=\"line\">NAME                                      READY   STATUS      RESTARTS   AGE</span><br><span class=\"line\">rook-ceph-mds-myfs-a-6bbc59cbc8-fp5px     1/1     Running     0          11s</span><br><span class=\"line\">rook-ceph-mds-myfs-b-658fc8fd66-5cd9g     1/1     Running     0          11s</span><br><span class=\"line\">rook-ceph-mgr-a-66db78887f-lmhcf          1/1     Running     0          23m</span><br><span class=\"line\">rook-ceph-mon-a-b6556df54-t7cd4           1/1     Running     0          24m</span><br><span class=\"line\">rook-ceph-mon-b-7f84c6d4b-nhjj6           1/1     Running     0          24m</span><br><span class=\"line\">rook-ceph-mon-c-868c5b476b-ghfqs          1/1     Running     0          23m</span><br><span class=\"line\">rook-ceph-osd-0-f986cc57d-6xclh           1/1     Running     0          18m</span><br><span class=\"line\">rook-ceph-osd-1-765556c558-jwv2n          1/1     Running     0          17m</span><br><span class=\"line\">rook-ceph-osd-2-766db888c7-j7z8f          1/1     Running     0          18m</span><br><span class=\"line\">rook-ceph-osd-prepare-kube01-d2rrt        0/2     Completed   0          19m</span><br><span class=\"line\">rook-ceph-osd-prepare-kube02-jxl6g        0/2     Completed   0          19m</span><br><span class=\"line\">rook-ceph-osd-prepare-kube03-fz276        0/2     Completed   0          19m</span><br><span class=\"line\">rook-ceph-rgw-my-store-5b68744bc6-pc7g7   1/1     Running     0          12m</span><br><span class=\"line\">rook-ceph-tools-544fb656d-tddrx           1/1     Running     0          18m</span><br><span class=\"line\"></span><br><span class=\"line\">[root@kube01 rook]# kubectl exec -it rook-ceph-tools-544fb656d-tddrx bash -n rook-ceph</span><br><span class=\"line\">bash: warning: setlocale: LC_CTYPE: cannot change locale (en_US.UTF-8): No such file or directory</span><br><span class=\"line\">bash: warning: setlocale: LC_COLLATE: cannot change locale (en_US.UTF-8): No such file or directory</span><br><span class=\"line\">bash: warning: setlocale: LC_MESSAGES: cannot change locale (en_US.UTF-8): No such file or directory</span><br><span class=\"line\">bash: warning: setlocale: LC_NUMERIC: cannot change locale (en_US.UTF-8): No such file or directory</span><br><span class=\"line\">bash: warning: setlocale: LC_TIME: cannot change locale (en_US.UTF-8): No such file or directory</span><br><span class=\"line\">[root@kube03 /]# ceph -s</span><br><span class=\"line\">  cluster:</span><br><span class=\"line\">    id:     f9609ec9-62c7-4462-a4f2-35c4137c25ef</span><br><span class=\"line\">    health: HEALTH_OK</span><br><span class=\"line\"></span><br><span class=\"line\">  services:</span><br><span class=\"line\">    mon: 3 daemons, quorum c,a,b</span><br><span class=\"line\">    mgr: a(active)</span><br><span class=\"line\">    mds: myfs-1/1/1 up  &#123;0=myfs-b=up:active&#125;, 1 up:standby-replay</span><br><span class=\"line\">    osd: 3 osds: 3 up, 3 in</span><br><span class=\"line\">    rgw: 1 daemon active</span><br><span class=\"line\"></span><br><span class=\"line\">  data:</span><br><span class=\"line\">    pools:   8 pools, 800 pgs</span><br><span class=\"line\">    objects: 224  objects, 5.9 KiB</span><br><span class=\"line\">    usage:   3.0 GiB used, 57 GiB / 60 GiB avail</span><br><span class=\"line\">    pgs:     800 active+clean</span><br><span class=\"line\"></span><br><span class=\"line\">  io:</span><br><span class=\"line\">    client:   852 B/s rd, 1 op/s rd, 0 op/s wr</span><br></pre></td></tr></table></figure>\n<p>cluster/examples/kubernetes/ceph/ 目录下还有其他yaml文件，可以对ceph集群进行其他操作，比如启用mgr dashboar，安装prometheus监控等</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">-rwxr-xr-x 1 root root  8139 Mar 15 15:20 cluster.yaml</span><br><span class=\"line\">-rw-r--r-- 1 root root   363 Mar 15 14:47 dashboard-external-https.yaml</span><br><span class=\"line\">-rw-r--r-- 1 root root   362 Mar 15 14:47 dashboard-external-http.yaml</span><br><span class=\"line\">-rw-r--r-- 1 root root  1487 Mar 15 14:47 ec-filesystem.yaml</span><br><span class=\"line\">-rw-r--r-- 1 root root  1538 Mar 15 14:47 ec-storageclass.yaml</span><br><span class=\"line\">-rw-r--r-- 1 root root  1375 Mar 15 14:47 filesystem.yaml</span><br><span class=\"line\">-rw-r--r-- 1 root root  1923 Mar 15 14:48 kube-registry.yaml</span><br><span class=\"line\">drwxr-xr-x 2 root root    85 Mar 15 16:07 monitoring</span><br><span class=\"line\">-rw-r--r-- 1 root root   160 Mar 15 14:47 object-user.yaml</span><br><span class=\"line\">-rw-r--r-- 1 root root  1813 Mar 15 14:47 object.yaml</span><br><span class=\"line\">-rwxr-xr-x 1 root root 12690 Mar 15 14:48 operator.yaml</span><br><span class=\"line\">-rw-r--r-- 1 root root   742 Mar 15 14:47 pool.yaml</span><br><span class=\"line\">-rw-r--r-- 1 root root   410 Mar 15 14:47 rgw-external.yaml</span><br><span class=\"line\">-rw-r--r-- 1 root root  1216 Mar 15 14:47 scc.yaml</span><br><span class=\"line\">-rw-r--r-- 1 root root   991 Mar 15 14:47 storageclass.yaml</span><br><span class=\"line\">-rw-r--r-- 1 root root  1544 Mar 15 14:48 toolbox.yaml</span><br><span class=\"line\">-rw-r--r-- 1 root root  6492 Mar 15 14:47 upgrade-from-v0.8-create.yaml</span><br><span class=\"line\">-rw-r--r-- 1 root root   874 Mar 15 14:47 upgrade-from-v0.8-replace.yaml</span><br></pre></td></tr></table></figure>\n<h1 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h1><ul>\n<li><a href=\"http://www.yangguanjun.com/2018/12/22/rook-ceph-practice-part1/\" target=\"_blank\" rel=\"noopener\">http://www.yangguanjun.com/2018/12/22/rook-ceph-practice-part1/</a></li>\n<li><a href=\"http://www.yangguanjun.com/2018/12/28/rook-ceph-practice-part2/\" target=\"_blank\" rel=\"noopener\">http://www.yangguanjun.com/2018/12/28/rook-ceph-practice-part2/</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"概述\"><a href=\"#概述\" class=\"headerlink\" title=\"概述\"></a>概述</h1><p>本文主要介绍如何通过rook在k8s上部署一套ceph集群。<br>测试的k8s集群一共三个节点：  </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@kube01 ~]# kubectl get nodes</span><br><span class=\"line\">NAME     STATUS   ROLES    AGE    VERSION</span><br><span class=\"line\">kube01   Ready    master   3h3m   v1.13.4</span><br><span class=\"line\">kube02   Ready    master   175m   v1.13.4</span><br><span class=\"line\">kube03   Ready    master   172m   v1.13.4</span><br></pre></td></tr></table></figure>\n<h1 id=\"Rook部署\"><a href=\"#Rook部署\" class=\"headerlink\" title=\"Rook部署\"></a>Rook部署</h1><p>clone rook代码  </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git clone https://github.com/rook/rook.git</span><br><span class=\"line\">cd rook/</span><br><span class=\"line\">git checkout v0.9.3</span><br></pre></td></tr></table></figure>\n<p>通过kubectl执行rook-ceph的operator</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@kube01 rook]# kubectl apply -f cluster/examples/kubernetes/ceph/operator.yaml</span><br><span class=\"line\">namespace/rook-ceph-system created</span><br><span class=\"line\">customresourcedefinition.apiextensions.k8s.io/cephclusters.ceph.rook.io created</span><br><span class=\"line\">customresourcedefinition.apiextensions.k8s.io/cephfilesystems.ceph.rook.io created</span><br><span class=\"line\">customresourcedefinition.apiextensions.k8s.io/cephobjectstores.ceph.rook.io created</span><br><span class=\"line\">customresourcedefinition.apiextensions.k8s.io/cephobjectstoreusers.ceph.rook.io created</span><br><span class=\"line\">customresourcedefinition.apiextensions.k8s.io/cephblockpools.ceph.rook.io created</span><br><span class=\"line\">customresourcedefinition.apiextensions.k8s.io/volumes.rook.io created</span><br><span class=\"line\">clusterrole.rbac.authorization.k8s.io/rook-ceph-cluster-mgmt created</span><br><span class=\"line\">role.rbac.authorization.k8s.io/rook-ceph-system created</span><br><span class=\"line\">clusterrole.rbac.authorization.k8s.io/rook-ceph-global created</span><br><span class=\"line\">clusterrole.rbac.authorization.k8s.io/rook-ceph-mgr-cluster created</span><br><span class=\"line\">serviceaccount/rook-ceph-system created</span><br><span class=\"line\">rolebinding.rbac.authorization.k8s.io/rook-ceph-system created</span><br><span class=\"line\">clusterrolebinding.rbac.authorization.k8s.io/rook-ceph-global created</span><br><span class=\"line\">deployment.apps/rook-ceph-operator created</span><br></pre></td></tr></table></figure>\n<p>等待全部pod都running状态</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@kube01 rook]# kubectl get pods -n rook-ceph-system -owide</span><br><span class=\"line\">NAME                                  READY   STATUS    RESTARTS   AGE     IP               NODE     NOMINATED NODE   READINESS GATES</span><br><span class=\"line\">rook-ceph-agent-7zgcv                 1/1     Running   0          2m15s   192.168.10.181   kube01   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">rook-ceph-agent-ww4sk                 1/1     Running   0          2m15s   192.168.10.129   kube02   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">rook-ceph-agent-xjgm4                 1/1     Running   0          2m15s   192.168.10.44    kube03   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">rook-ceph-operator-5f4ff4d57d-fm8s5   1/1     Running   0          3m41s   10.244.1.2       kube02   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">rook-discover-2mwpn                   1/1     Running   0          2m15s   10.244.0.10      kube01   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">rook-discover-nqhr8                   1/1     Running   0          2m15s   10.244.1.3       kube02   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">rook-discover-wgpng                   1/1     Running   0          2m15s   10.244.2.2       kube03   &lt;none&gt;           &lt;none&gt;</span><br></pre></td></tr></table></figure>\n<p>ceph会使用每个节点的vdb作为osd，所以需要修改cluster/examples/kubernetes/ceph/cluster.yaml的内容</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">storage: # cluster level storage configuration and selection</span><br><span class=\"line\">  useAllNodes: true</span><br><span class=\"line\">  useAllDevices: false</span><br><span class=\"line\">  deviceFilter: &quot;^vdb&quot;</span><br><span class=\"line\">  location:</span><br><span class=\"line\">  config:</span><br><span class=\"line\">    # The default and recommended storeType is dynamically set to bluestore for devices and filestore for directories.</span><br><span class=\"line\">    # Set the storeType explicitly only if it is required not to use the default.</span><br><span class=\"line\">    storeType: bluestore</span><br><span class=\"line\">    #databaseSizeMB: &quot;1024&quot; # this value can be removed for environments with normal sized disks (100 GB or larger)</span><br><span class=\"line\">    #journalSizeMB: &quot;1024&quot;  # this value can be removed for environments with normal sized disks (20 GB or larger)</span><br><span class=\"line\">    osdsPerDevice: &quot;1&quot; # this value can be overridden at the node or device level</span><br></pre></td></tr></table></figure>\n<p>通过kubectl部署ceph集群</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@kube01 rook]# kubectl apply -f cluster/examples/kubernetes/ceph/cluster.yaml</span><br><span class=\"line\">namespace/rook-ceph created</span><br><span class=\"line\">serviceaccount/rook-ceph-osd created</span><br><span class=\"line\">serviceaccount/rook-ceph-mgr created</span><br><span class=\"line\">role.rbac.authorization.k8s.io/rook-ceph-osd created</span><br><span class=\"line\">role.rbac.authorization.k8s.io/rook-ceph-mgr-system created</span><br><span class=\"line\">role.rbac.authorization.k8s.io/rook-ceph-mgr created</span><br><span class=\"line\">rolebinding.rbac.authorization.k8s.io/rook-ceph-cluster-mgmt created</span><br><span class=\"line\">rolebinding.rbac.authorization.k8s.io/rook-ceph-osd created</span><br><span class=\"line\">rolebinding.rbac.authorization.k8s.io/rook-ceph-mgr created</span><br><span class=\"line\">rolebinding.rbac.authorization.k8s.io/rook-ceph-mgr-system created</span><br><span class=\"line\">rolebinding.rbac.authorization.k8s.io/rook-ceph-mgr-cluster created</span><br><span class=\"line\">cephcluster.ceph.rook.io/rook-ceph created</span><br></pre></td></tr></table></figure>\n<p>等ceph部署完成，可以看到有三个mon，一个mgr和三个osd</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@kube01 rook]# kubectl get pods -n rook-ceph</span><br><span class=\"line\">NAME                                 READY   STATUS      RESTARTS   AGE</span><br><span class=\"line\">rook-ceph-mgr-a-66db78887f-lmhcf     1/1     Running     0          4m13s</span><br><span class=\"line\">rook-ceph-mon-a-b6556df54-t7cd4      1/1     Running     0          4m53s</span><br><span class=\"line\">rook-ceph-mon-b-7f84c6d4b-nhjj6      1/1     Running     0          4m42s</span><br><span class=\"line\">rook-ceph-mon-c-868c5b476b-ghfqs     1/1     Running     0          4m32s</span><br><span class=\"line\">rook-ceph-osd-0-6fdf57bcb7-bf6f2     1/1     Running     0          54s</span><br><span class=\"line\">rook-ceph-osd-1-8c99b7447-h4mfd      1/1     Running     0          39s</span><br><span class=\"line\">rook-ceph-osd-2-66b76d6944-5df9j     1/1     Running     0          27s</span><br><span class=\"line\">rook-ceph-osd-prepare-kube01-dfrp2   0/2     Completed   0          3m50s</span><br><span class=\"line\">rook-ceph-osd-prepare-kube02-pnbsc   0/2     Completed   0          3m49s</span><br><span class=\"line\">rook-ceph-osd-prepare-kube03-4ztl9   0/2     Completed   0          3m48s</span><br></pre></td></tr></table></figure>\n<p>安装ceph-tool，登录到ceph-tools的pod，可以执行ceph相关的命令，查看ceph状态</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@kube01 rook]# kubectl apply -f cluster/examples/kubernetes/ceph/toolbox.yaml</span><br><span class=\"line\">deployment.apps/rook-ceph-tools created</span><br><span class=\"line\">[root@kube01 rook]# kubectl get pods -n rook-ceph</span><br><span class=\"line\">NAME                                 READY   STATUS    RESTARTS   AGE</span><br><span class=\"line\">rook-ceph-mgr-a-66db78887f-lmhcf     1/1     Running   0          5m10s</span><br><span class=\"line\">rook-ceph-mon-a-b6556df54-t7cd4      1/1     Running   0          5m50s</span><br><span class=\"line\">rook-ceph-mon-b-7f84c6d4b-nhjj6      1/1     Running   0          5m39s</span><br><span class=\"line\">rook-ceph-mon-c-868c5b476b-ghfqs     1/1     Running   0          5m29s</span><br><span class=\"line\">rook-ceph-osd-0-6fdf57bcb7-bf6f2     1/1     Running   0          111s</span><br><span class=\"line\">rook-ceph-osd-1-8c99b7447-h4mfd      1/1     Running   0          96s</span><br><span class=\"line\">rook-ceph-osd-2-66b76d6944-5df9j     1/1     Running   0          84s</span><br><span class=\"line\">rook-ceph-osd-prepare-kube01-d2rrt   1/2     Running   0          49s</span><br><span class=\"line\">rook-ceph-osd-prepare-kube02-jxl6g   1/2     Running   0          47s</span><br><span class=\"line\">rook-ceph-osd-prepare-kube03-fz276   1/2     Running   0          45s</span><br><span class=\"line\">rook-ceph-tools-544fb656d-tddrx      1/1     Running   0          3s</span><br></pre></td></tr></table></figure>\n<p>登录到ceph-tools Pod</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@kube01 rook]# kubectl exec -it rook-ceph-tools-544fb656d-tddrx bash -n rook-ceph</span><br><span class=\"line\">bash: warning: setlocale: LC_CTYPE: cannot change locale (en_US.UTF-8): No such file or directory</span><br><span class=\"line\">bash: warning: setlocale: LC_COLLATE: cannot change locale (en_US.UTF-8): No such file or directory</span><br><span class=\"line\">bash: warning: setlocale: LC_MESSAGES: cannot change locale (en_US.UTF-8): No such file or directory</span><br><span class=\"line\">bash: warning: setlocale: LC_NUMERIC: cannot change locale (en_US.UTF-8): No such file or directory</span><br><span class=\"line\">bash: warning: setlocale: LC_TIME: cannot change locale (en_US.UTF-8): No such file or directory</span><br><span class=\"line\">[root@kube03 /]# ceph -s</span><br><span class=\"line\">  cluster:</span><br><span class=\"line\">    id:     f9609ec9-62c7-4462-a4f2-35c4137c25ef</span><br><span class=\"line\">    health: HEALTH_OK</span><br><span class=\"line\"></span><br><span class=\"line\">  services:</span><br><span class=\"line\">    mon: 3 daemons, quorum c,a,b</span><br><span class=\"line\">    mgr: a(active)</span><br><span class=\"line\">    osd: 3 osds: 3 up, 3 in</span><br><span class=\"line\"></span><br><span class=\"line\">  data:</span><br><span class=\"line\">    pools:   0 pools, 0 pgs</span><br><span class=\"line\">    objects: 0  objects, 0 B</span><br><span class=\"line\">    usage:   3.0 GiB used, 57 GiB / 60 GiB avail</span><br><span class=\"line\">    pgs:</span><br><span class=\"line\"></span><br><span class=\"line\">[root@kube03 /]# ceph osd tree</span><br><span class=\"line\">ID CLASS WEIGHT  TYPE NAME       STATUS REWEIGHT PRI-AFF</span><br><span class=\"line\">-1       0.05846 root default</span><br><span class=\"line\">-7       0.01949     host kube01</span><br><span class=\"line\"> 2   hdd 0.01949         osd.2       up  1.00000 1.00000</span><br><span class=\"line\">-3       0.01949     host kube02</span><br><span class=\"line\"> 0   hdd 0.01949         osd.0       up  1.00000 1.00000</span><br><span class=\"line\">-5       0.01949     host kube03</span><br><span class=\"line\"> 1   hdd 0.01949         osd.1       up  1.00000 1.00000</span><br></pre></td></tr></table></figure>\n<p>部署好的ceph集群并没有rgw服务，通过下面的方式可以添加rgw服务</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@kube01 rook]# kubectl apply -f cluster/examples/kubernetes/ceph/object.yaml</span><br><span class=\"line\">cephobjectstore.ceph.rook.io/my-store created</span><br><span class=\"line\"></span><br><span class=\"line\">[root@kube01 rook]# kubectl get pods -n rook-ceph</span><br><span class=\"line\">NAME                                      READY   STATUS      RESTARTS   AGE</span><br><span class=\"line\">rook-ceph-mgr-a-66db78887f-lmhcf          1/1     Running     0          11m</span><br><span class=\"line\">rook-ceph-mon-a-b6556df54-t7cd4           1/1     Running     0          11m</span><br><span class=\"line\">rook-ceph-mon-b-7f84c6d4b-nhjj6           1/1     Running     0          11m</span><br><span class=\"line\">rook-ceph-mon-c-868c5b476b-ghfqs          1/1     Running     0          11m</span><br><span class=\"line\">rook-ceph-osd-0-f986cc57d-6xclh           1/1     Running     0          6m</span><br><span class=\"line\">rook-ceph-osd-1-765556c558-jwv2n          1/1     Running     0          5m40s</span><br><span class=\"line\">rook-ceph-osd-2-766db888c7-j7z8f          1/1     Running     0          5m48s</span><br><span class=\"line\">rook-ceph-osd-prepare-kube01-d2rrt        0/2     Completed   0          6m57s</span><br><span class=\"line\">rook-ceph-osd-prepare-kube02-jxl6g        0/2     Completed   0          6m55s</span><br><span class=\"line\">rook-ceph-osd-prepare-kube03-fz276        0/2     Completed   0          6m53s</span><br><span class=\"line\">rook-ceph-rgw-my-store-5b68744bc6-pc7g7   1/1     Running     0          21s</span><br><span class=\"line\">rook-ceph-tools-544fb656d-tddrx           1/1     Running     0          6m11s</span><br><span class=\"line\"></span><br><span class=\"line\">[root@kube01 rook]# kubectl exec -it rook-ceph-tools-544fb656d-tddrx bash -n rook-ceph</span><br><span class=\"line\">bash: warning: setlocale: LC_CTYPE: cannot change locale (en_US.UTF-8): No such file or directory</span><br><span class=\"line\">bash: warning: setlocale: LC_COLLATE: cannot change locale (en_US.UTF-8): No such file or directory</span><br><span class=\"line\">bash: warning: setlocale: LC_MESSAGES: cannot change locale (en_US.UTF-8): No such file or directory</span><br><span class=\"line\">bash: warning: setlocale: LC_NUMERIC: cannot change locale (en_US.UTF-8): No such file or directory</span><br><span class=\"line\">bash: warning: setlocale: LC_TIME: cannot change locale (en_US.UTF-8): No such file or directory</span><br><span class=\"line\">[root@kube03 /]# ceph -s</span><br><span class=\"line\">  cluster:</span><br><span class=\"line\">    id:     f9609ec9-62c7-4462-a4f2-35c4137c25ef</span><br><span class=\"line\">    health: HEALTH_OK</span><br><span class=\"line\"></span><br><span class=\"line\">  services:</span><br><span class=\"line\">    mon: 3 daemons, quorum c,a,b</span><br><span class=\"line\">    mgr: a(active)</span><br><span class=\"line\">    osd: 3 osds: 3 up, 3 in</span><br><span class=\"line\">    rgw: 1 daemon active</span><br><span class=\"line\"></span><br><span class=\"line\">  data:</span><br><span class=\"line\">    pools:   6 pools, 600 pgs</span><br><span class=\"line\">    objects: 201  objects, 3.7 KiB</span><br><span class=\"line\">    usage:   3.0 GiB used, 57 GiB / 60 GiB avail</span><br><span class=\"line\">    pgs:     600 active+clean</span><br></pre></td></tr></table></figure>\n<p>通过下面的方式可以把rgw服务以NodePort的方式对外提供服务</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@kube01 rook]# kubectl apply -f cluster/examples/kubernetes/ceph/rgw-external.yaml</span><br><span class=\"line\">service/rook-ceph-rgw-my-store-external created</span><br><span class=\"line\"> </span><br><span class=\"line\">[root@kube01 rook]# kubectl get services -n rook-ceph</span><br><span class=\"line\">NAME                              TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)        AGE</span><br><span class=\"line\">rook-ceph-mgr                     ClusterIP   172.30.117.80    &lt;none&gt;        9283/TCP       12m</span><br><span class=\"line\">rook-ceph-mgr-dashboard           ClusterIP   172.30.225.42    &lt;none&gt;        8443/TCP       12m</span><br><span class=\"line\">rook-ceph-mon-a                   ClusterIP   172.30.82.3      &lt;none&gt;        6790/TCP       13m</span><br><span class=\"line\">rook-ceph-mon-b                   ClusterIP   172.30.122.28    &lt;none&gt;        6790/TCP       13m</span><br><span class=\"line\">rook-ceph-mon-c                   ClusterIP   172.30.62.26     &lt;none&gt;        6790/TCP       13m</span><br><span class=\"line\">rook-ceph-rgw-my-store            ClusterIP   172.30.107.175   &lt;none&gt;        80/TCP         2m47s</span><br><span class=\"line\">rook-ceph-rgw-my-store-external   NodePort    172.30.131.185   &lt;none&gt;        80:32185/TCP   4m2s</span><br></pre></td></tr></table></figure>\n<p>下面的部署安装ceph mds </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@kube01 rook]# kubectl apply -f cluster/examples/kubernetes/ceph/filesystem.yaml</span><br><span class=\"line\">cephfilesystem.ceph.rook.io/myfs created</span><br><span class=\"line\"></span><br><span class=\"line\">[root@kube01 rook]# kubectl get pods -n rook-ceph</span><br><span class=\"line\">NAME                                      READY   STATUS      RESTARTS   AGE</span><br><span class=\"line\">rook-ceph-mds-myfs-a-6bbc59cbc8-fp5px     1/1     Running     0          11s</span><br><span class=\"line\">rook-ceph-mds-myfs-b-658fc8fd66-5cd9g     1/1     Running     0          11s</span><br><span class=\"line\">rook-ceph-mgr-a-66db78887f-lmhcf          1/1     Running     0          23m</span><br><span class=\"line\">rook-ceph-mon-a-b6556df54-t7cd4           1/1     Running     0          24m</span><br><span class=\"line\">rook-ceph-mon-b-7f84c6d4b-nhjj6           1/1     Running     0          24m</span><br><span class=\"line\">rook-ceph-mon-c-868c5b476b-ghfqs          1/1     Running     0          23m</span><br><span class=\"line\">rook-ceph-osd-0-f986cc57d-6xclh           1/1     Running     0          18m</span><br><span class=\"line\">rook-ceph-osd-1-765556c558-jwv2n          1/1     Running     0          17m</span><br><span class=\"line\">rook-ceph-osd-2-766db888c7-j7z8f          1/1     Running     0          18m</span><br><span class=\"line\">rook-ceph-osd-prepare-kube01-d2rrt        0/2     Completed   0          19m</span><br><span class=\"line\">rook-ceph-osd-prepare-kube02-jxl6g        0/2     Completed   0          19m</span><br><span class=\"line\">rook-ceph-osd-prepare-kube03-fz276        0/2     Completed   0          19m</span><br><span class=\"line\">rook-ceph-rgw-my-store-5b68744bc6-pc7g7   1/1     Running     0          12m</span><br><span class=\"line\">rook-ceph-tools-544fb656d-tddrx           1/1     Running     0          18m</span><br><span class=\"line\"></span><br><span class=\"line\">[root@kube01 rook]# kubectl exec -it rook-ceph-tools-544fb656d-tddrx bash -n rook-ceph</span><br><span class=\"line\">bash: warning: setlocale: LC_CTYPE: cannot change locale (en_US.UTF-8): No such file or directory</span><br><span class=\"line\">bash: warning: setlocale: LC_COLLATE: cannot change locale (en_US.UTF-8): No such file or directory</span><br><span class=\"line\">bash: warning: setlocale: LC_MESSAGES: cannot change locale (en_US.UTF-8): No such file or directory</span><br><span class=\"line\">bash: warning: setlocale: LC_NUMERIC: cannot change locale (en_US.UTF-8): No such file or directory</span><br><span class=\"line\">bash: warning: setlocale: LC_TIME: cannot change locale (en_US.UTF-8): No such file or directory</span><br><span class=\"line\">[root@kube03 /]# ceph -s</span><br><span class=\"line\">  cluster:</span><br><span class=\"line\">    id:     f9609ec9-62c7-4462-a4f2-35c4137c25ef</span><br><span class=\"line\">    health: HEALTH_OK</span><br><span class=\"line\"></span><br><span class=\"line\">  services:</span><br><span class=\"line\">    mon: 3 daemons, quorum c,a,b</span><br><span class=\"line\">    mgr: a(active)</span><br><span class=\"line\">    mds: myfs-1/1/1 up  &#123;0=myfs-b=up:active&#125;, 1 up:standby-replay</span><br><span class=\"line\">    osd: 3 osds: 3 up, 3 in</span><br><span class=\"line\">    rgw: 1 daemon active</span><br><span class=\"line\"></span><br><span class=\"line\">  data:</span><br><span class=\"line\">    pools:   8 pools, 800 pgs</span><br><span class=\"line\">    objects: 224  objects, 5.9 KiB</span><br><span class=\"line\">    usage:   3.0 GiB used, 57 GiB / 60 GiB avail</span><br><span class=\"line\">    pgs:     800 active+clean</span><br><span class=\"line\"></span><br><span class=\"line\">  io:</span><br><span class=\"line\">    client:   852 B/s rd, 1 op/s rd, 0 op/s wr</span><br></pre></td></tr></table></figure>\n<p>cluster/examples/kubernetes/ceph/ 目录下还有其他yaml文件，可以对ceph集群进行其他操作，比如启用mgr dashboar，安装prometheus监控等</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">-rwxr-xr-x 1 root root  8139 Mar 15 15:20 cluster.yaml</span><br><span class=\"line\">-rw-r--r-- 1 root root   363 Mar 15 14:47 dashboard-external-https.yaml</span><br><span class=\"line\">-rw-r--r-- 1 root root   362 Mar 15 14:47 dashboard-external-http.yaml</span><br><span class=\"line\">-rw-r--r-- 1 root root  1487 Mar 15 14:47 ec-filesystem.yaml</span><br><span class=\"line\">-rw-r--r-- 1 root root  1538 Mar 15 14:47 ec-storageclass.yaml</span><br><span class=\"line\">-rw-r--r-- 1 root root  1375 Mar 15 14:47 filesystem.yaml</span><br><span class=\"line\">-rw-r--r-- 1 root root  1923 Mar 15 14:48 kube-registry.yaml</span><br><span class=\"line\">drwxr-xr-x 2 root root    85 Mar 15 16:07 monitoring</span><br><span class=\"line\">-rw-r--r-- 1 root root   160 Mar 15 14:47 object-user.yaml</span><br><span class=\"line\">-rw-r--r-- 1 root root  1813 Mar 15 14:47 object.yaml</span><br><span class=\"line\">-rwxr-xr-x 1 root root 12690 Mar 15 14:48 operator.yaml</span><br><span class=\"line\">-rw-r--r-- 1 root root   742 Mar 15 14:47 pool.yaml</span><br><span class=\"line\">-rw-r--r-- 1 root root   410 Mar 15 14:47 rgw-external.yaml</span><br><span class=\"line\">-rw-r--r-- 1 root root  1216 Mar 15 14:47 scc.yaml</span><br><span class=\"line\">-rw-r--r-- 1 root root   991 Mar 15 14:47 storageclass.yaml</span><br><span class=\"line\">-rw-r--r-- 1 root root  1544 Mar 15 14:48 toolbox.yaml</span><br><span class=\"line\">-rw-r--r-- 1 root root  6492 Mar 15 14:47 upgrade-from-v0.8-create.yaml</span><br><span class=\"line\">-rw-r--r-- 1 root root   874 Mar 15 14:47 upgrade-from-v0.8-replace.yaml</span><br></pre></td></tr></table></figure>\n<h1 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h1><ul>\n<li><a href=\"http://www.yangguanjun.com/2018/12/22/rook-ceph-practice-part1/\" target=\"_blank\" rel=\"noopener\">http://www.yangguanjun.com/2018/12/22/rook-ceph-practice-part1/</a></li>\n<li><a href=\"http://www.yangguanjun.com/2018/12/28/rook-ceph-practice-part2/\" target=\"_blank\" rel=\"noopener\">http://www.yangguanjun.com/2018/12/28/rook-ceph-practice-part2/</a></li>\n</ul>\n"},{"title":"通过mock来构建rpm包","date":"2018-09-25T14:50:54.000Z","_content":"\n## 概述\nmock是一个构建rpm包的工具，你可以使用mock来编译不同系统（CentOS,RedHat和Fedora）版本的rpm包。  \n相比通过rpmbuild来构建rpm包，使用mock通过使用chroot技术，可以在一个干净的环境中来构建rpm包。\n\n## 安装mock\n\n\n```\nyum install epel-release -y\n\nyum install mock -y\n```\n\n需要运行mock的用户都需要添加到mock这个组里，可以通过usermod来把用户添加到mock组。\n\n```\nusermod -a -G mock <user>\n```\n\n## 构建准备\n\n使用mock来构建rpm包，需要要有source rpm。  \n如果有一个spec文件，则可以通过rpmbuild来构建source rpm\n\n```\nrpmbuild -bs xxx.spec\n```\n\n当然，你也可以直接下载source rpm，这样就少了上面的这个步骤。\n\n## 构建RPM包\n\n运行mock命令时，你必须要执行一个配置文件，当前系统上可用的配置文件都在/etc/mock目录下。如下面的内容：\n\n```\n-rw-r--r-- 1 root mock  1595 Aug 16 22:42 epel-5-i386.cfg\n-rw-r--r-- 1 root mock  1585 Aug 16 22:42 epel-5-x86_64.cfg\n-rw-r--r-- 1 root mock  1812 Aug 16 22:42 epel-6-i386.cfg\n-rw-r--r-- 1 root mock  1592 Aug 16 22:42 epel-6-ppc64.cfg\n-rw-r--r-- 1 root mock  2250 Aug 16 22:42 epel-6-x86_64.cfg\n-rw-r--r-- 1 root mock  2362 Aug 16 22:42 epel-7-aarch64.cfg\n-rw-r--r-- 1 root mock  2399 Aug 16 22:42 epel-7-ppc64le.cfg\n-rw-r--r-- 1 root mock  2394 Aug 16 22:42 epel-7-x86_64.cfg\n-rw-r--r-- 1 root mock  2022 Aug 16 22:42 fedora-25-aarch64.cfg\n-rw-r--r-- 1 root mock  2016 Aug 16 22:42 fedora-25-armhfp.cfg\n-rw-r--r-- 1 root mock  2033 Aug 16 22:42 fedora-25-i386.cfg\n-rw-r--r-- 1 root mock  2014 Aug 16 22:42 fedora-25-ppc64.cfg\n-rw-r--r-- 1 root mock  2022 Aug 16 22:42 fedora-25-ppc64le.cfg\n-rw-r--r-- 1 root mock  2015 Aug 16 22:42 fedora-25-s390x.cfg\n-rw-r--r-- 1 root mock  2016 Aug 16 22:42 fedora-25-x86_64.cfg\n-rw-r--r-- 1 root mock  2018 Aug 16 22:42 fedora-26-aarch64.cfg\n-rw-r--r-- 1 root mock  2016 Aug 16 22:42 fedora-26-armhfp.cfg\n-rw-r--r-- 1 root mock  2033 Aug 16 22:42 fedora-26-i386.cfg\n-rw-r--r-- 1 root mock  2010 Aug 16 22:42 fedora-26-ppc64.cfg\n-rw-r--r-- 1 root mock  2018 Aug 16 22:42 fedora-26-ppc64le.cfg\n-rw-r--r-- 1 root mock  2015 Aug 16 22:42 fedora-26-s390x.cfg\n-rw-r--r-- 1 root mock  2016 Aug 16 22:42 fedora-26-x86_64.cfg\n-rw-r--r-- 1 root mock  2018 Aug 16 22:42 fedora-27-aarch64.cfg\n-rw-r--r-- 1 root mock  2160 Aug 16 22:42 fedora-27-armhfp.cfg\n-rw-r--r-- 1 root mock  2033 Aug 16 22:42 fedora-27-i386.cfg\n-rw-r--r-- 1 root mock  2010 Aug 16 22:42 fedora-27-ppc64.cfg\n-rw-r--r-- 1 root mock  2018 Aug 16 22:42 fedora-27-ppc64le.cfg\n-rw-r--r-- 1 root mock  2012 Aug 16 22:42 fedora-27-s390x.cfg\n-rw-r--r-- 1 root mock  2016 Aug 16 22:42 fedora-27-x86_64.cfg\n-rw-r--r-- 1 root mock  2018 Aug 16 22:42 fedora-28-aarch64.cfg\n-rw-r--r-- 1 root mock  2160 Aug 16 22:42 fedora-28-armhfp.cfg\n-rw-r--r-- 1 root mock  2033 Aug 16 22:42 fedora-28-i386.cfg\n```\n\n### 初始化和删除mock chroot\n\n你可以先初始化mock使用的chroot，这样就可以减少构建rpm包的时间\n\n```\nmock -r epel-7-x86_64 --init\n```\n\n你可以通过下面的命令来删除chroot\n\n```\nmock -r epel-7-x86_64 --clean\n```\n\n### 执行构建\n\n```\nmock -r epel-7-x86_64 --rebuild xxx.src.rpm\n```\n当构建完成，结构和日志都在/var/lib/mock/epel-7-x86_64/result目录下。你可可以通过添加参数 --resultdir来调整目录\n\n## 结论\n\n通过mock可以构建不同架构不同版本下的rpm包，mock可以保证整个过程不受之前的构建的影响，并且提供了一个简单的接口用于重复构建rpm包。\n","source":"_posts/rpm-mock.md","raw":"---\ntitle: 通过mock来构建rpm包\ndate: 2018-09-25 22:50:54\ntags: ['linux']\n---\n\n## 概述\nmock是一个构建rpm包的工具，你可以使用mock来编译不同系统（CentOS,RedHat和Fedora）版本的rpm包。  \n相比通过rpmbuild来构建rpm包，使用mock通过使用chroot技术，可以在一个干净的环境中来构建rpm包。\n\n## 安装mock\n\n\n```\nyum install epel-release -y\n\nyum install mock -y\n```\n\n需要运行mock的用户都需要添加到mock这个组里，可以通过usermod来把用户添加到mock组。\n\n```\nusermod -a -G mock <user>\n```\n\n## 构建准备\n\n使用mock来构建rpm包，需要要有source rpm。  \n如果有一个spec文件，则可以通过rpmbuild来构建source rpm\n\n```\nrpmbuild -bs xxx.spec\n```\n\n当然，你也可以直接下载source rpm，这样就少了上面的这个步骤。\n\n## 构建RPM包\n\n运行mock命令时，你必须要执行一个配置文件，当前系统上可用的配置文件都在/etc/mock目录下。如下面的内容：\n\n```\n-rw-r--r-- 1 root mock  1595 Aug 16 22:42 epel-5-i386.cfg\n-rw-r--r-- 1 root mock  1585 Aug 16 22:42 epel-5-x86_64.cfg\n-rw-r--r-- 1 root mock  1812 Aug 16 22:42 epel-6-i386.cfg\n-rw-r--r-- 1 root mock  1592 Aug 16 22:42 epel-6-ppc64.cfg\n-rw-r--r-- 1 root mock  2250 Aug 16 22:42 epel-6-x86_64.cfg\n-rw-r--r-- 1 root mock  2362 Aug 16 22:42 epel-7-aarch64.cfg\n-rw-r--r-- 1 root mock  2399 Aug 16 22:42 epel-7-ppc64le.cfg\n-rw-r--r-- 1 root mock  2394 Aug 16 22:42 epel-7-x86_64.cfg\n-rw-r--r-- 1 root mock  2022 Aug 16 22:42 fedora-25-aarch64.cfg\n-rw-r--r-- 1 root mock  2016 Aug 16 22:42 fedora-25-armhfp.cfg\n-rw-r--r-- 1 root mock  2033 Aug 16 22:42 fedora-25-i386.cfg\n-rw-r--r-- 1 root mock  2014 Aug 16 22:42 fedora-25-ppc64.cfg\n-rw-r--r-- 1 root mock  2022 Aug 16 22:42 fedora-25-ppc64le.cfg\n-rw-r--r-- 1 root mock  2015 Aug 16 22:42 fedora-25-s390x.cfg\n-rw-r--r-- 1 root mock  2016 Aug 16 22:42 fedora-25-x86_64.cfg\n-rw-r--r-- 1 root mock  2018 Aug 16 22:42 fedora-26-aarch64.cfg\n-rw-r--r-- 1 root mock  2016 Aug 16 22:42 fedora-26-armhfp.cfg\n-rw-r--r-- 1 root mock  2033 Aug 16 22:42 fedora-26-i386.cfg\n-rw-r--r-- 1 root mock  2010 Aug 16 22:42 fedora-26-ppc64.cfg\n-rw-r--r-- 1 root mock  2018 Aug 16 22:42 fedora-26-ppc64le.cfg\n-rw-r--r-- 1 root mock  2015 Aug 16 22:42 fedora-26-s390x.cfg\n-rw-r--r-- 1 root mock  2016 Aug 16 22:42 fedora-26-x86_64.cfg\n-rw-r--r-- 1 root mock  2018 Aug 16 22:42 fedora-27-aarch64.cfg\n-rw-r--r-- 1 root mock  2160 Aug 16 22:42 fedora-27-armhfp.cfg\n-rw-r--r-- 1 root mock  2033 Aug 16 22:42 fedora-27-i386.cfg\n-rw-r--r-- 1 root mock  2010 Aug 16 22:42 fedora-27-ppc64.cfg\n-rw-r--r-- 1 root mock  2018 Aug 16 22:42 fedora-27-ppc64le.cfg\n-rw-r--r-- 1 root mock  2012 Aug 16 22:42 fedora-27-s390x.cfg\n-rw-r--r-- 1 root mock  2016 Aug 16 22:42 fedora-27-x86_64.cfg\n-rw-r--r-- 1 root mock  2018 Aug 16 22:42 fedora-28-aarch64.cfg\n-rw-r--r-- 1 root mock  2160 Aug 16 22:42 fedora-28-armhfp.cfg\n-rw-r--r-- 1 root mock  2033 Aug 16 22:42 fedora-28-i386.cfg\n```\n\n### 初始化和删除mock chroot\n\n你可以先初始化mock使用的chroot，这样就可以减少构建rpm包的时间\n\n```\nmock -r epel-7-x86_64 --init\n```\n\n你可以通过下面的命令来删除chroot\n\n```\nmock -r epel-7-x86_64 --clean\n```\n\n### 执行构建\n\n```\nmock -r epel-7-x86_64 --rebuild xxx.src.rpm\n```\n当构建完成，结构和日志都在/var/lib/mock/epel-7-x86_64/result目录下。你可可以通过添加参数 --resultdir来调整目录\n\n## 结论\n\n通过mock可以构建不同架构不同版本下的rpm包，mock可以保证整个过程不受之前的构建的影响，并且提供了一个简单的接口用于重复构建rpm包。\n","slug":"rpm-mock","published":1,"updated":"2018-09-26T02:44:22.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck1pzbth8000wtp75vkjz8fzh","content":"<h2 id=\"概述\"><a href=\"#概述\" class=\"headerlink\" title=\"概述\"></a>概述</h2><p>mock是一个构建rpm包的工具，你可以使用mock来编译不同系统（CentOS,RedHat和Fedora）版本的rpm包。<br>相比通过rpmbuild来构建rpm包，使用mock通过使用chroot技术，可以在一个干净的环境中来构建rpm包。</p>\n<h2 id=\"安装mock\"><a href=\"#安装mock\" class=\"headerlink\" title=\"安装mock\"></a>安装mock</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">yum install epel-release -y</span><br><span class=\"line\"></span><br><span class=\"line\">yum install mock -y</span><br></pre></td></tr></table></figure>\n<p>需要运行mock的用户都需要添加到mock这个组里，可以通过usermod来把用户添加到mock组。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">usermod -a -G mock &lt;user&gt;</span><br></pre></td></tr></table></figure>\n<h2 id=\"构建准备\"><a href=\"#构建准备\" class=\"headerlink\" title=\"构建准备\"></a>构建准备</h2><p>使用mock来构建rpm包，需要要有source rpm。<br>如果有一个spec文件，则可以通过rpmbuild来构建source rpm</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">rpmbuild -bs xxx.spec</span><br></pre></td></tr></table></figure>\n<p>当然，你也可以直接下载source rpm，这样就少了上面的这个步骤。</p>\n<h2 id=\"构建RPM包\"><a href=\"#构建RPM包\" class=\"headerlink\" title=\"构建RPM包\"></a>构建RPM包</h2><p>运行mock命令时，你必须要执行一个配置文件，当前系统上可用的配置文件都在/etc/mock目录下。如下面的内容：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">-rw-r--r-- 1 root mock  1595 Aug 16 22:42 epel-5-i386.cfg</span><br><span class=\"line\">-rw-r--r-- 1 root mock  1585 Aug 16 22:42 epel-5-x86_64.cfg</span><br><span class=\"line\">-rw-r--r-- 1 root mock  1812 Aug 16 22:42 epel-6-i386.cfg</span><br><span class=\"line\">-rw-r--r-- 1 root mock  1592 Aug 16 22:42 epel-6-ppc64.cfg</span><br><span class=\"line\">-rw-r--r-- 1 root mock  2250 Aug 16 22:42 epel-6-x86_64.cfg</span><br><span class=\"line\">-rw-r--r-- 1 root mock  2362 Aug 16 22:42 epel-7-aarch64.cfg</span><br><span class=\"line\">-rw-r--r-- 1 root mock  2399 Aug 16 22:42 epel-7-ppc64le.cfg</span><br><span class=\"line\">-rw-r--r-- 1 root mock  2394 Aug 16 22:42 epel-7-x86_64.cfg</span><br><span class=\"line\">-rw-r--r-- 1 root mock  2022 Aug 16 22:42 fedora-25-aarch64.cfg</span><br><span class=\"line\">-rw-r--r-- 1 root mock  2016 Aug 16 22:42 fedora-25-armhfp.cfg</span><br><span class=\"line\">-rw-r--r-- 1 root mock  2033 Aug 16 22:42 fedora-25-i386.cfg</span><br><span class=\"line\">-rw-r--r-- 1 root mock  2014 Aug 16 22:42 fedora-25-ppc64.cfg</span><br><span class=\"line\">-rw-r--r-- 1 root mock  2022 Aug 16 22:42 fedora-25-ppc64le.cfg</span><br><span class=\"line\">-rw-r--r-- 1 root mock  2015 Aug 16 22:42 fedora-25-s390x.cfg</span><br><span class=\"line\">-rw-r--r-- 1 root mock  2016 Aug 16 22:42 fedora-25-x86_64.cfg</span><br><span class=\"line\">-rw-r--r-- 1 root mock  2018 Aug 16 22:42 fedora-26-aarch64.cfg</span><br><span class=\"line\">-rw-r--r-- 1 root mock  2016 Aug 16 22:42 fedora-26-armhfp.cfg</span><br><span class=\"line\">-rw-r--r-- 1 root mock  2033 Aug 16 22:42 fedora-26-i386.cfg</span><br><span class=\"line\">-rw-r--r-- 1 root mock  2010 Aug 16 22:42 fedora-26-ppc64.cfg</span><br><span class=\"line\">-rw-r--r-- 1 root mock  2018 Aug 16 22:42 fedora-26-ppc64le.cfg</span><br><span class=\"line\">-rw-r--r-- 1 root mock  2015 Aug 16 22:42 fedora-26-s390x.cfg</span><br><span class=\"line\">-rw-r--r-- 1 root mock  2016 Aug 16 22:42 fedora-26-x86_64.cfg</span><br><span class=\"line\">-rw-r--r-- 1 root mock  2018 Aug 16 22:42 fedora-27-aarch64.cfg</span><br><span class=\"line\">-rw-r--r-- 1 root mock  2160 Aug 16 22:42 fedora-27-armhfp.cfg</span><br><span class=\"line\">-rw-r--r-- 1 root mock  2033 Aug 16 22:42 fedora-27-i386.cfg</span><br><span class=\"line\">-rw-r--r-- 1 root mock  2010 Aug 16 22:42 fedora-27-ppc64.cfg</span><br><span class=\"line\">-rw-r--r-- 1 root mock  2018 Aug 16 22:42 fedora-27-ppc64le.cfg</span><br><span class=\"line\">-rw-r--r-- 1 root mock  2012 Aug 16 22:42 fedora-27-s390x.cfg</span><br><span class=\"line\">-rw-r--r-- 1 root mock  2016 Aug 16 22:42 fedora-27-x86_64.cfg</span><br><span class=\"line\">-rw-r--r-- 1 root mock  2018 Aug 16 22:42 fedora-28-aarch64.cfg</span><br><span class=\"line\">-rw-r--r-- 1 root mock  2160 Aug 16 22:42 fedora-28-armhfp.cfg</span><br><span class=\"line\">-rw-r--r-- 1 root mock  2033 Aug 16 22:42 fedora-28-i386.cfg</span><br></pre></td></tr></table></figure>\n<h3 id=\"初始化和删除mock-chroot\"><a href=\"#初始化和删除mock-chroot\" class=\"headerlink\" title=\"初始化和删除mock chroot\"></a>初始化和删除mock chroot</h3><p>你可以先初始化mock使用的chroot，这样就可以减少构建rpm包的时间</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mock -r epel-7-x86_64 --init</span><br></pre></td></tr></table></figure>\n<p>你可以通过下面的命令来删除chroot</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mock -r epel-7-x86_64 --clean</span><br></pre></td></tr></table></figure>\n<h3 id=\"执行构建\"><a href=\"#执行构建\" class=\"headerlink\" title=\"执行构建\"></a>执行构建</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mock -r epel-7-x86_64 --rebuild xxx.src.rpm</span><br></pre></td></tr></table></figure>\n<p>当构建完成，结构和日志都在/var/lib/mock/epel-7-x86_64/result目录下。你可可以通过添加参数 –resultdir来调整目录</p>\n<h2 id=\"结论\"><a href=\"#结论\" class=\"headerlink\" title=\"结论\"></a>结论</h2><p>通过mock可以构建不同架构不同版本下的rpm包，mock可以保证整个过程不受之前的构建的影响，并且提供了一个简单的接口用于重复构建rpm包。</p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"概述\"><a href=\"#概述\" class=\"headerlink\" title=\"概述\"></a>概述</h2><p>mock是一个构建rpm包的工具，你可以使用mock来编译不同系统（CentOS,RedHat和Fedora）版本的rpm包。<br>相比通过rpmbuild来构建rpm包，使用mock通过使用chroot技术，可以在一个干净的环境中来构建rpm包。</p>\n<h2 id=\"安装mock\"><a href=\"#安装mock\" class=\"headerlink\" title=\"安装mock\"></a>安装mock</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">yum install epel-release -y</span><br><span class=\"line\"></span><br><span class=\"line\">yum install mock -y</span><br></pre></td></tr></table></figure>\n<p>需要运行mock的用户都需要添加到mock这个组里，可以通过usermod来把用户添加到mock组。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">usermod -a -G mock &lt;user&gt;</span><br></pre></td></tr></table></figure>\n<h2 id=\"构建准备\"><a href=\"#构建准备\" class=\"headerlink\" title=\"构建准备\"></a>构建准备</h2><p>使用mock来构建rpm包，需要要有source rpm。<br>如果有一个spec文件，则可以通过rpmbuild来构建source rpm</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">rpmbuild -bs xxx.spec</span><br></pre></td></tr></table></figure>\n<p>当然，你也可以直接下载source rpm，这样就少了上面的这个步骤。</p>\n<h2 id=\"构建RPM包\"><a href=\"#构建RPM包\" class=\"headerlink\" title=\"构建RPM包\"></a>构建RPM包</h2><p>运行mock命令时，你必须要执行一个配置文件，当前系统上可用的配置文件都在/etc/mock目录下。如下面的内容：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">-rw-r--r-- 1 root mock  1595 Aug 16 22:42 epel-5-i386.cfg</span><br><span class=\"line\">-rw-r--r-- 1 root mock  1585 Aug 16 22:42 epel-5-x86_64.cfg</span><br><span class=\"line\">-rw-r--r-- 1 root mock  1812 Aug 16 22:42 epel-6-i386.cfg</span><br><span class=\"line\">-rw-r--r-- 1 root mock  1592 Aug 16 22:42 epel-6-ppc64.cfg</span><br><span class=\"line\">-rw-r--r-- 1 root mock  2250 Aug 16 22:42 epel-6-x86_64.cfg</span><br><span class=\"line\">-rw-r--r-- 1 root mock  2362 Aug 16 22:42 epel-7-aarch64.cfg</span><br><span class=\"line\">-rw-r--r-- 1 root mock  2399 Aug 16 22:42 epel-7-ppc64le.cfg</span><br><span class=\"line\">-rw-r--r-- 1 root mock  2394 Aug 16 22:42 epel-7-x86_64.cfg</span><br><span class=\"line\">-rw-r--r-- 1 root mock  2022 Aug 16 22:42 fedora-25-aarch64.cfg</span><br><span class=\"line\">-rw-r--r-- 1 root mock  2016 Aug 16 22:42 fedora-25-armhfp.cfg</span><br><span class=\"line\">-rw-r--r-- 1 root mock  2033 Aug 16 22:42 fedora-25-i386.cfg</span><br><span class=\"line\">-rw-r--r-- 1 root mock  2014 Aug 16 22:42 fedora-25-ppc64.cfg</span><br><span class=\"line\">-rw-r--r-- 1 root mock  2022 Aug 16 22:42 fedora-25-ppc64le.cfg</span><br><span class=\"line\">-rw-r--r-- 1 root mock  2015 Aug 16 22:42 fedora-25-s390x.cfg</span><br><span class=\"line\">-rw-r--r-- 1 root mock  2016 Aug 16 22:42 fedora-25-x86_64.cfg</span><br><span class=\"line\">-rw-r--r-- 1 root mock  2018 Aug 16 22:42 fedora-26-aarch64.cfg</span><br><span class=\"line\">-rw-r--r-- 1 root mock  2016 Aug 16 22:42 fedora-26-armhfp.cfg</span><br><span class=\"line\">-rw-r--r-- 1 root mock  2033 Aug 16 22:42 fedora-26-i386.cfg</span><br><span class=\"line\">-rw-r--r-- 1 root mock  2010 Aug 16 22:42 fedora-26-ppc64.cfg</span><br><span class=\"line\">-rw-r--r-- 1 root mock  2018 Aug 16 22:42 fedora-26-ppc64le.cfg</span><br><span class=\"line\">-rw-r--r-- 1 root mock  2015 Aug 16 22:42 fedora-26-s390x.cfg</span><br><span class=\"line\">-rw-r--r-- 1 root mock  2016 Aug 16 22:42 fedora-26-x86_64.cfg</span><br><span class=\"line\">-rw-r--r-- 1 root mock  2018 Aug 16 22:42 fedora-27-aarch64.cfg</span><br><span class=\"line\">-rw-r--r-- 1 root mock  2160 Aug 16 22:42 fedora-27-armhfp.cfg</span><br><span class=\"line\">-rw-r--r-- 1 root mock  2033 Aug 16 22:42 fedora-27-i386.cfg</span><br><span class=\"line\">-rw-r--r-- 1 root mock  2010 Aug 16 22:42 fedora-27-ppc64.cfg</span><br><span class=\"line\">-rw-r--r-- 1 root mock  2018 Aug 16 22:42 fedora-27-ppc64le.cfg</span><br><span class=\"line\">-rw-r--r-- 1 root mock  2012 Aug 16 22:42 fedora-27-s390x.cfg</span><br><span class=\"line\">-rw-r--r-- 1 root mock  2016 Aug 16 22:42 fedora-27-x86_64.cfg</span><br><span class=\"line\">-rw-r--r-- 1 root mock  2018 Aug 16 22:42 fedora-28-aarch64.cfg</span><br><span class=\"line\">-rw-r--r-- 1 root mock  2160 Aug 16 22:42 fedora-28-armhfp.cfg</span><br><span class=\"line\">-rw-r--r-- 1 root mock  2033 Aug 16 22:42 fedora-28-i386.cfg</span><br></pre></td></tr></table></figure>\n<h3 id=\"初始化和删除mock-chroot\"><a href=\"#初始化和删除mock-chroot\" class=\"headerlink\" title=\"初始化和删除mock chroot\"></a>初始化和删除mock chroot</h3><p>你可以先初始化mock使用的chroot，这样就可以减少构建rpm包的时间</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mock -r epel-7-x86_64 --init</span><br></pre></td></tr></table></figure>\n<p>你可以通过下面的命令来删除chroot</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mock -r epel-7-x86_64 --clean</span><br></pre></td></tr></table></figure>\n<h3 id=\"执行构建\"><a href=\"#执行构建\" class=\"headerlink\" title=\"执行构建\"></a>执行构建</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mock -r epel-7-x86_64 --rebuild xxx.src.rpm</span><br></pre></td></tr></table></figure>\n<p>当构建完成，结构和日志都在/var/lib/mock/epel-7-x86_64/result目录下。你可可以通过添加参数 –resultdir来调整目录</p>\n<h2 id=\"结论\"><a href=\"#结论\" class=\"headerlink\" title=\"结论\"></a>结论</h2><p>通过mock可以构建不同架构不同版本下的rpm包，mock可以保证整个过程不受之前的构建的影响，并且提供了一个简单的接口用于重复构建rpm包。</p>\n"},{"title":"s3cmd for radosgw","date":"2017-08-09T05:45:40.000Z","_content":"创建一个默认的Config文件\n```\n[root@ceph03 ~]# s3cmd --configure\n\nEnter new values or accept defaults in brackets with Enter.\nRefer to user manual for detailed description of all options.\n\nAccess key and Secret key are your identifiers for Amazon S3. Leave them empty for using the env variables.\nAccess Key: key\nSecret Key: secret\nDefault Region [US]:\n\nEncryption password is used to protect your files from reading\nby unauthorized persons while in transfer to S3\nEncryption password:\nPath to GPG program [/usr/bin/gpg]:\n\nWhen using secure HTTPS protocol all communication with Amazon S3\nservers is protected from 3rd party eavesdropping. This method is\nslower than plain HTTP, and can only be proxied with Python 2.7 or newer\nUse HTTPS protocol [Yes]: No\n\nOn some networks all internet access must go through a HTTP proxy.\nTry setting it here if you can't connect to S3 directly\nHTTP Proxy server name:\n\nNew settings:\n  Access Key: key\n  Secret Key: secret\n  Default Region: US\n  Encryption password:\n  Path to GPG program: /usr/bin/gpg\n  Use HTTPS protocol: False\n  HTTP Proxy server name:\n  HTTP Proxy server port: 0\n\nTest access with supplied credentials? [Y/n] n\n\nSave settings? [y/N] y\nConfiguration saved to '/root/.s3cfg'\n```\n\n修改config文件中的access_key,secret_key,host_base 和 host_bucket\n\n```\n[default]\naccess_key = O9P5CKAYAB4AHYGQPGT1\naccess_token =\nadd_encoding_exts =\nadd_headers =\nbucket_location = US\nca_certs_file =\ncache_file =\ncheck_ssl_certificate = True\ncheck_ssl_hostname = True\ncloudfront_host = cloudfront.amazonaws.com\ndefault_mime_type = binary/octet-stream\ndelay_updates = False\ndelete_after = False\ndelete_after_fetch = False\ndelete_removed = False\ndry_run = False\nenable_multipart = True\nencoding = UTF-8\nencrypt = False\nexpiry_date =\nexpiry_days =\nexpiry_prefix =\nfollow_symlinks = False\nforce = False\nget_continue = False\ngpg_command = /usr/bin/gpg\ngpg_decrypt = %(gpg_command)s -d --verbose --no-use-agent --batch --yes --passphrase-fd %(passphrase_fd)s -o %(output_file)s %(input_file)s\ngpg_encrypt = %(gpg_command)s -c --verbose --no-use-agent --batch --yes --passphrase-fd %(passphrase_fd)s -o %(output_file)s %(input_file)s\ngpg_passphrase =\nguess_mime_type = True\nhost_base = 172.16.143.171:8080\nhost_bucket = 172.16.143.171:8080\nhuman_readable_sizes = False\ninvalidate_default_index_on_cf = False\ninvalidate_default_index_root_on_cf = True\ninvalidate_on_cf = False\nkms_key =\nlimitrate = 0\nlist_md5 = False\nlog_target_prefix =\nlong_listing = False\nmax_delete = -1\nmime_type =\nmultipart_chunk_size_mb = 15\nmultipart_max_chunks = 10000\npreserve_attrs = True\nprogress_meter = True\nproxy_host =\nproxy_port = 0\nput_continue = False\nrecursive = False\nrecv_chunk = 65536\nreduced_redundancy = False\nrequester_pays = False\nrestore_days = 1\nsecret_key = BWyaFoWn99pN6MnaHs3NCZP6mMELMtFdJUxuONyX\nsend_chunk = 65536\nserver_side_encryption = False\nsignature_v2 = False\nsimpledb_host = sdb.amazonaws.com\nskip_existing = False\nsocket_timeout = 300\nstats = False\nstop_on_error = False\nstorage_class =\nurlencoding_mode = normal\nuse_https = False\nuse_mime_magic = True\nverbosity = WARNING\nwebsite_endpoint = http://%(bucket)s.s3-website-%(location)s.amazonaws.com/\nwebsite_error =\nwebsite_index = index.html\n```\n\n接下来就可以通过s3cmd来进行操作了\n\n\n```\n[root@ceph02 ~]# s3cmd mb s3://test\nBucket 's3://test/' created\n[root@ceph02 ~]# s3cmd put anaconda-ks.cfg s3://test/anaconda\nupload: 'anaconda-ks.cfg' -> 's3://test/anaconda'  [1 of 1]\n 1030 of 1030   100% in    0s    57.69 kB/s  done\n[root@ceph02 ~]# s3cmd ls s3://test\n2017-08-09 06:01      1030   s3://test/anaconda\n```\n\n","source":"_posts/s3cmd.md","raw":"---\ntitle: s3cmd for radosgw\ndate: 2017-08-09 13:45:40\ntags:\n---\n创建一个默认的Config文件\n```\n[root@ceph03 ~]# s3cmd --configure\n\nEnter new values or accept defaults in brackets with Enter.\nRefer to user manual for detailed description of all options.\n\nAccess key and Secret key are your identifiers for Amazon S3. Leave them empty for using the env variables.\nAccess Key: key\nSecret Key: secret\nDefault Region [US]:\n\nEncryption password is used to protect your files from reading\nby unauthorized persons while in transfer to S3\nEncryption password:\nPath to GPG program [/usr/bin/gpg]:\n\nWhen using secure HTTPS protocol all communication with Amazon S3\nservers is protected from 3rd party eavesdropping. This method is\nslower than plain HTTP, and can only be proxied with Python 2.7 or newer\nUse HTTPS protocol [Yes]: No\n\nOn some networks all internet access must go through a HTTP proxy.\nTry setting it here if you can't connect to S3 directly\nHTTP Proxy server name:\n\nNew settings:\n  Access Key: key\n  Secret Key: secret\n  Default Region: US\n  Encryption password:\n  Path to GPG program: /usr/bin/gpg\n  Use HTTPS protocol: False\n  HTTP Proxy server name:\n  HTTP Proxy server port: 0\n\nTest access with supplied credentials? [Y/n] n\n\nSave settings? [y/N] y\nConfiguration saved to '/root/.s3cfg'\n```\n\n修改config文件中的access_key,secret_key,host_base 和 host_bucket\n\n```\n[default]\naccess_key = O9P5CKAYAB4AHYGQPGT1\naccess_token =\nadd_encoding_exts =\nadd_headers =\nbucket_location = US\nca_certs_file =\ncache_file =\ncheck_ssl_certificate = True\ncheck_ssl_hostname = True\ncloudfront_host = cloudfront.amazonaws.com\ndefault_mime_type = binary/octet-stream\ndelay_updates = False\ndelete_after = False\ndelete_after_fetch = False\ndelete_removed = False\ndry_run = False\nenable_multipart = True\nencoding = UTF-8\nencrypt = False\nexpiry_date =\nexpiry_days =\nexpiry_prefix =\nfollow_symlinks = False\nforce = False\nget_continue = False\ngpg_command = /usr/bin/gpg\ngpg_decrypt = %(gpg_command)s -d --verbose --no-use-agent --batch --yes --passphrase-fd %(passphrase_fd)s -o %(output_file)s %(input_file)s\ngpg_encrypt = %(gpg_command)s -c --verbose --no-use-agent --batch --yes --passphrase-fd %(passphrase_fd)s -o %(output_file)s %(input_file)s\ngpg_passphrase =\nguess_mime_type = True\nhost_base = 172.16.143.171:8080\nhost_bucket = 172.16.143.171:8080\nhuman_readable_sizes = False\ninvalidate_default_index_on_cf = False\ninvalidate_default_index_root_on_cf = True\ninvalidate_on_cf = False\nkms_key =\nlimitrate = 0\nlist_md5 = False\nlog_target_prefix =\nlong_listing = False\nmax_delete = -1\nmime_type =\nmultipart_chunk_size_mb = 15\nmultipart_max_chunks = 10000\npreserve_attrs = True\nprogress_meter = True\nproxy_host =\nproxy_port = 0\nput_continue = False\nrecursive = False\nrecv_chunk = 65536\nreduced_redundancy = False\nrequester_pays = False\nrestore_days = 1\nsecret_key = BWyaFoWn99pN6MnaHs3NCZP6mMELMtFdJUxuONyX\nsend_chunk = 65536\nserver_side_encryption = False\nsignature_v2 = False\nsimpledb_host = sdb.amazonaws.com\nskip_existing = False\nsocket_timeout = 300\nstats = False\nstop_on_error = False\nstorage_class =\nurlencoding_mode = normal\nuse_https = False\nuse_mime_magic = True\nverbosity = WARNING\nwebsite_endpoint = http://%(bucket)s.s3-website-%(location)s.amazonaws.com/\nwebsite_error =\nwebsite_index = index.html\n```\n\n接下来就可以通过s3cmd来进行操作了\n\n\n```\n[root@ceph02 ~]# s3cmd mb s3://test\nBucket 's3://test/' created\n[root@ceph02 ~]# s3cmd put anaconda-ks.cfg s3://test/anaconda\nupload: 'anaconda-ks.cfg' -> 's3://test/anaconda'  [1 of 1]\n 1030 of 1030   100% in    0s    57.69 kB/s  done\n[root@ceph02 ~]# s3cmd ls s3://test\n2017-08-09 06:01      1030   s3://test/anaconda\n```\n\n","slug":"s3cmd","published":1,"updated":"2018-03-07T05:39:30.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck1pzbth9000ytp753yegiuel","content":"<p>创建一个默认的Config文件<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@ceph03 ~]# s3cmd --configure</span><br><span class=\"line\"></span><br><span class=\"line\">Enter new values or accept defaults in brackets with Enter.</span><br><span class=\"line\">Refer to user manual for detailed description of all options.</span><br><span class=\"line\"></span><br><span class=\"line\">Access key and Secret key are your identifiers for Amazon S3. Leave them empty for using the env variables.</span><br><span class=\"line\">Access Key: key</span><br><span class=\"line\">Secret Key: secret</span><br><span class=\"line\">Default Region [US]:</span><br><span class=\"line\"></span><br><span class=\"line\">Encryption password is used to protect your files from reading</span><br><span class=\"line\">by unauthorized persons while in transfer to S3</span><br><span class=\"line\">Encryption password:</span><br><span class=\"line\">Path to GPG program [/usr/bin/gpg]:</span><br><span class=\"line\"></span><br><span class=\"line\">When using secure HTTPS protocol all communication with Amazon S3</span><br><span class=\"line\">servers is protected from 3rd party eavesdropping. This method is</span><br><span class=\"line\">slower than plain HTTP, and can only be proxied with Python 2.7 or newer</span><br><span class=\"line\">Use HTTPS protocol [Yes]: No</span><br><span class=\"line\"></span><br><span class=\"line\">On some networks all internet access must go through a HTTP proxy.</span><br><span class=\"line\">Try setting it here if you can&apos;t connect to S3 directly</span><br><span class=\"line\">HTTP Proxy server name:</span><br><span class=\"line\"></span><br><span class=\"line\">New settings:</span><br><span class=\"line\">  Access Key: key</span><br><span class=\"line\">  Secret Key: secret</span><br><span class=\"line\">  Default Region: US</span><br><span class=\"line\">  Encryption password:</span><br><span class=\"line\">  Path to GPG program: /usr/bin/gpg</span><br><span class=\"line\">  Use HTTPS protocol: False</span><br><span class=\"line\">  HTTP Proxy server name:</span><br><span class=\"line\">  HTTP Proxy server port: 0</span><br><span class=\"line\"></span><br><span class=\"line\">Test access with supplied credentials? [Y/n] n</span><br><span class=\"line\"></span><br><span class=\"line\">Save settings? [y/N] y</span><br><span class=\"line\">Configuration saved to &apos;/root/.s3cfg&apos;</span><br></pre></td></tr></table></figure></p>\n<p>修改config文件中的access_key,secret_key,host_base 和 host_bucket</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[default]</span><br><span class=\"line\">access_key = O9P5CKAYAB4AHYGQPGT1</span><br><span class=\"line\">access_token =</span><br><span class=\"line\">add_encoding_exts =</span><br><span class=\"line\">add_headers =</span><br><span class=\"line\">bucket_location = US</span><br><span class=\"line\">ca_certs_file =</span><br><span class=\"line\">cache_file =</span><br><span class=\"line\">check_ssl_certificate = True</span><br><span class=\"line\">check_ssl_hostname = True</span><br><span class=\"line\">cloudfront_host = cloudfront.amazonaws.com</span><br><span class=\"line\">default_mime_type = binary/octet-stream</span><br><span class=\"line\">delay_updates = False</span><br><span class=\"line\">delete_after = False</span><br><span class=\"line\">delete_after_fetch = False</span><br><span class=\"line\">delete_removed = False</span><br><span class=\"line\">dry_run = False</span><br><span class=\"line\">enable_multipart = True</span><br><span class=\"line\">encoding = UTF-8</span><br><span class=\"line\">encrypt = False</span><br><span class=\"line\">expiry_date =</span><br><span class=\"line\">expiry_days =</span><br><span class=\"line\">expiry_prefix =</span><br><span class=\"line\">follow_symlinks = False</span><br><span class=\"line\">force = False</span><br><span class=\"line\">get_continue = False</span><br><span class=\"line\">gpg_command = /usr/bin/gpg</span><br><span class=\"line\">gpg_decrypt = %(gpg_command)s -d --verbose --no-use-agent --batch --yes --passphrase-fd %(passphrase_fd)s -o %(output_file)s %(input_file)s</span><br><span class=\"line\">gpg_encrypt = %(gpg_command)s -c --verbose --no-use-agent --batch --yes --passphrase-fd %(passphrase_fd)s -o %(output_file)s %(input_file)s</span><br><span class=\"line\">gpg_passphrase =</span><br><span class=\"line\">guess_mime_type = True</span><br><span class=\"line\">host_base = 172.16.143.171:8080</span><br><span class=\"line\">host_bucket = 172.16.143.171:8080</span><br><span class=\"line\">human_readable_sizes = False</span><br><span class=\"line\">invalidate_default_index_on_cf = False</span><br><span class=\"line\">invalidate_default_index_root_on_cf = True</span><br><span class=\"line\">invalidate_on_cf = False</span><br><span class=\"line\">kms_key =</span><br><span class=\"line\">limitrate = 0</span><br><span class=\"line\">list_md5 = False</span><br><span class=\"line\">log_target_prefix =</span><br><span class=\"line\">long_listing = False</span><br><span class=\"line\">max_delete = -1</span><br><span class=\"line\">mime_type =</span><br><span class=\"line\">multipart_chunk_size_mb = 15</span><br><span class=\"line\">multipart_max_chunks = 10000</span><br><span class=\"line\">preserve_attrs = True</span><br><span class=\"line\">progress_meter = True</span><br><span class=\"line\">proxy_host =</span><br><span class=\"line\">proxy_port = 0</span><br><span class=\"line\">put_continue = False</span><br><span class=\"line\">recursive = False</span><br><span class=\"line\">recv_chunk = 65536</span><br><span class=\"line\">reduced_redundancy = False</span><br><span class=\"line\">requester_pays = False</span><br><span class=\"line\">restore_days = 1</span><br><span class=\"line\">secret_key = BWyaFoWn99pN6MnaHs3NCZP6mMELMtFdJUxuONyX</span><br><span class=\"line\">send_chunk = 65536</span><br><span class=\"line\">server_side_encryption = False</span><br><span class=\"line\">signature_v2 = False</span><br><span class=\"line\">simpledb_host = sdb.amazonaws.com</span><br><span class=\"line\">skip_existing = False</span><br><span class=\"line\">socket_timeout = 300</span><br><span class=\"line\">stats = False</span><br><span class=\"line\">stop_on_error = False</span><br><span class=\"line\">storage_class =</span><br><span class=\"line\">urlencoding_mode = normal</span><br><span class=\"line\">use_https = False</span><br><span class=\"line\">use_mime_magic = True</span><br><span class=\"line\">verbosity = WARNING</span><br><span class=\"line\">website_endpoint = http://%(bucket)s.s3-website-%(location)s.amazonaws.com/</span><br><span class=\"line\">website_error =</span><br><span class=\"line\">website_index = index.html</span><br></pre></td></tr></table></figure>\n<p>接下来就可以通过s3cmd来进行操作了</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@ceph02 ~]# s3cmd mb s3://test</span><br><span class=\"line\">Bucket &apos;s3://test/&apos; created</span><br><span class=\"line\">[root@ceph02 ~]# s3cmd put anaconda-ks.cfg s3://test/anaconda</span><br><span class=\"line\">upload: &apos;anaconda-ks.cfg&apos; -&gt; &apos;s3://test/anaconda&apos;  [1 of 1]</span><br><span class=\"line\"> 1030 of 1030   100% in    0s    57.69 kB/s  done</span><br><span class=\"line\">[root@ceph02 ~]# s3cmd ls s3://test</span><br><span class=\"line\">2017-08-09 06:01      1030   s3://test/anaconda</span><br></pre></td></tr></table></figure>\n","site":{"data":{}},"excerpt":"","more":"<p>创建一个默认的Config文件<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@ceph03 ~]# s3cmd --configure</span><br><span class=\"line\"></span><br><span class=\"line\">Enter new values or accept defaults in brackets with Enter.</span><br><span class=\"line\">Refer to user manual for detailed description of all options.</span><br><span class=\"line\"></span><br><span class=\"line\">Access key and Secret key are your identifiers for Amazon S3. Leave them empty for using the env variables.</span><br><span class=\"line\">Access Key: key</span><br><span class=\"line\">Secret Key: secret</span><br><span class=\"line\">Default Region [US]:</span><br><span class=\"line\"></span><br><span class=\"line\">Encryption password is used to protect your files from reading</span><br><span class=\"line\">by unauthorized persons while in transfer to S3</span><br><span class=\"line\">Encryption password:</span><br><span class=\"line\">Path to GPG program [/usr/bin/gpg]:</span><br><span class=\"line\"></span><br><span class=\"line\">When using secure HTTPS protocol all communication with Amazon S3</span><br><span class=\"line\">servers is protected from 3rd party eavesdropping. This method is</span><br><span class=\"line\">slower than plain HTTP, and can only be proxied with Python 2.7 or newer</span><br><span class=\"line\">Use HTTPS protocol [Yes]: No</span><br><span class=\"line\"></span><br><span class=\"line\">On some networks all internet access must go through a HTTP proxy.</span><br><span class=\"line\">Try setting it here if you can&apos;t connect to S3 directly</span><br><span class=\"line\">HTTP Proxy server name:</span><br><span class=\"line\"></span><br><span class=\"line\">New settings:</span><br><span class=\"line\">  Access Key: key</span><br><span class=\"line\">  Secret Key: secret</span><br><span class=\"line\">  Default Region: US</span><br><span class=\"line\">  Encryption password:</span><br><span class=\"line\">  Path to GPG program: /usr/bin/gpg</span><br><span class=\"line\">  Use HTTPS protocol: False</span><br><span class=\"line\">  HTTP Proxy server name:</span><br><span class=\"line\">  HTTP Proxy server port: 0</span><br><span class=\"line\"></span><br><span class=\"line\">Test access with supplied credentials? [Y/n] n</span><br><span class=\"line\"></span><br><span class=\"line\">Save settings? [y/N] y</span><br><span class=\"line\">Configuration saved to &apos;/root/.s3cfg&apos;</span><br></pre></td></tr></table></figure></p>\n<p>修改config文件中的access_key,secret_key,host_base 和 host_bucket</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[default]</span><br><span class=\"line\">access_key = O9P5CKAYAB4AHYGQPGT1</span><br><span class=\"line\">access_token =</span><br><span class=\"line\">add_encoding_exts =</span><br><span class=\"line\">add_headers =</span><br><span class=\"line\">bucket_location = US</span><br><span class=\"line\">ca_certs_file =</span><br><span class=\"line\">cache_file =</span><br><span class=\"line\">check_ssl_certificate = True</span><br><span class=\"line\">check_ssl_hostname = True</span><br><span class=\"line\">cloudfront_host = cloudfront.amazonaws.com</span><br><span class=\"line\">default_mime_type = binary/octet-stream</span><br><span class=\"line\">delay_updates = False</span><br><span class=\"line\">delete_after = False</span><br><span class=\"line\">delete_after_fetch = False</span><br><span class=\"line\">delete_removed = False</span><br><span class=\"line\">dry_run = False</span><br><span class=\"line\">enable_multipart = True</span><br><span class=\"line\">encoding = UTF-8</span><br><span class=\"line\">encrypt = False</span><br><span class=\"line\">expiry_date =</span><br><span class=\"line\">expiry_days =</span><br><span class=\"line\">expiry_prefix =</span><br><span class=\"line\">follow_symlinks = False</span><br><span class=\"line\">force = False</span><br><span class=\"line\">get_continue = False</span><br><span class=\"line\">gpg_command = /usr/bin/gpg</span><br><span class=\"line\">gpg_decrypt = %(gpg_command)s -d --verbose --no-use-agent --batch --yes --passphrase-fd %(passphrase_fd)s -o %(output_file)s %(input_file)s</span><br><span class=\"line\">gpg_encrypt = %(gpg_command)s -c --verbose --no-use-agent --batch --yes --passphrase-fd %(passphrase_fd)s -o %(output_file)s %(input_file)s</span><br><span class=\"line\">gpg_passphrase =</span><br><span class=\"line\">guess_mime_type = True</span><br><span class=\"line\">host_base = 172.16.143.171:8080</span><br><span class=\"line\">host_bucket = 172.16.143.171:8080</span><br><span class=\"line\">human_readable_sizes = False</span><br><span class=\"line\">invalidate_default_index_on_cf = False</span><br><span class=\"line\">invalidate_default_index_root_on_cf = True</span><br><span class=\"line\">invalidate_on_cf = False</span><br><span class=\"line\">kms_key =</span><br><span class=\"line\">limitrate = 0</span><br><span class=\"line\">list_md5 = False</span><br><span class=\"line\">log_target_prefix =</span><br><span class=\"line\">long_listing = False</span><br><span class=\"line\">max_delete = -1</span><br><span class=\"line\">mime_type =</span><br><span class=\"line\">multipart_chunk_size_mb = 15</span><br><span class=\"line\">multipart_max_chunks = 10000</span><br><span class=\"line\">preserve_attrs = True</span><br><span class=\"line\">progress_meter = True</span><br><span class=\"line\">proxy_host =</span><br><span class=\"line\">proxy_port = 0</span><br><span class=\"line\">put_continue = False</span><br><span class=\"line\">recursive = False</span><br><span class=\"line\">recv_chunk = 65536</span><br><span class=\"line\">reduced_redundancy = False</span><br><span class=\"line\">requester_pays = False</span><br><span class=\"line\">restore_days = 1</span><br><span class=\"line\">secret_key = BWyaFoWn99pN6MnaHs3NCZP6mMELMtFdJUxuONyX</span><br><span class=\"line\">send_chunk = 65536</span><br><span class=\"line\">server_side_encryption = False</span><br><span class=\"line\">signature_v2 = False</span><br><span class=\"line\">simpledb_host = sdb.amazonaws.com</span><br><span class=\"line\">skip_existing = False</span><br><span class=\"line\">socket_timeout = 300</span><br><span class=\"line\">stats = False</span><br><span class=\"line\">stop_on_error = False</span><br><span class=\"line\">storage_class =</span><br><span class=\"line\">urlencoding_mode = normal</span><br><span class=\"line\">use_https = False</span><br><span class=\"line\">use_mime_magic = True</span><br><span class=\"line\">verbosity = WARNING</span><br><span class=\"line\">website_endpoint = http://%(bucket)s.s3-website-%(location)s.amazonaws.com/</span><br><span class=\"line\">website_error =</span><br><span class=\"line\">website_index = index.html</span><br></pre></td></tr></table></figure>\n<p>接下来就可以通过s3cmd来进行操作了</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@ceph02 ~]# s3cmd mb s3://test</span><br><span class=\"line\">Bucket &apos;s3://test/&apos; created</span><br><span class=\"line\">[root@ceph02 ~]# s3cmd put anaconda-ks.cfg s3://test/anaconda</span><br><span class=\"line\">upload: &apos;anaconda-ks.cfg&apos; -&gt; &apos;s3://test/anaconda&apos;  [1 of 1]</span><br><span class=\"line\"> 1030 of 1030   100% in    0s    57.69 kB/s  done</span><br><span class=\"line\">[root@ceph02 ~]# s3cmd ls s3://test</span><br><span class=\"line\">2017-08-09 06:01      1030   s3://test/anaconda</span><br></pre></td></tr></table></figure>\n"},{"title":"service start too often","date":"2017-12-18T08:15:08.000Z","_content":"\n通过systemd来管理服务，经常会遇到这种错误\"failed because start of the service wasattempted too often\".\n\n遇到这种情况可以到/etc/systemd/system目录下，修改相应的service文件\n\n一般情况下在添加下面的内容即可：\n\n`[Service]\nStartLimitBurst=0`\n\n保存退出后，执行reload\n\n`\nsudo systemctl daemon-reload\n`\n\n再启动相应服务即可。\n","source":"_posts/service-too-quickly.md","raw":"---\ntitle: service start too often\ndate: 2017-12-18 16:15:08\ntags:\n---\n\n通过systemd来管理服务，经常会遇到这种错误\"failed because start of the service wasattempted too often\".\n\n遇到这种情况可以到/etc/systemd/system目录下，修改相应的service文件\n\n一般情况下在添加下面的内容即可：\n\n`[Service]\nStartLimitBurst=0`\n\n保存退出后，执行reload\n\n`\nsudo systemctl daemon-reload\n`\n\n再启动相应服务即可。\n","slug":"service-too-quickly","published":1,"updated":"2018-03-07T05:39:30.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck1pzbtha0011tp7514a3mzwn","content":"<p>通过systemd来管理服务，经常会遇到这种错误”failed because start of the service wasattempted too often”.</p>\n<p>遇到这种情况可以到/etc/systemd/system目录下，修改相应的service文件</p>\n<p>一般情况下在添加下面的内容即可：</p>\n<p><code>[Service]\nStartLimitBurst=0</code></p>\n<p>保存退出后，执行reload</p>\n<p><code>sudo systemctl daemon-reload</code></p>\n<p>再启动相应服务即可。</p>\n","site":{"data":{}},"excerpt":"","more":"<p>通过systemd来管理服务，经常会遇到这种错误”failed because start of the service wasattempted too often”.</p>\n<p>遇到这种情况可以到/etc/systemd/system目录下，修改相应的service文件</p>\n<p>一般情况下在添加下面的内容即可：</p>\n<p><code>[Service]\nStartLimitBurst=0</code></p>\n<p>保存退出后，执行reload</p>\n<p><code>sudo systemctl daemon-reload</code></p>\n<p>再启动相应服务即可。</p>\n"},{"title":"SQL Join","date":"2018-12-09T07:35:21.000Z","_content":"\n现在有两张表，user和class，内容如下：\n\n```\nMariaDB [jointest]> select * from user;\n+------+------+----------+\n| id   | name | class_id |\n+------+------+----------+\n| 1    | aaa  | 1        |\n| 2    | bbb  | 1        |\n| 3    | ccc  | 1        |\n| 4    | ddd  | 2        |\n| 5    | eee  | 2        |\n| 6    | fff  | 3        |\n| 7    | ggg  | 7        |\n| 8    | hhh  | 9        |\n+------+------+----------+\n8 rows in set (0.00 sec)\n\nMariaDB [jointest]> select * from class;\n+------+--------+\n| id   | name   |\n+------+--------+\n| 1    | class1 |\n| 2    | class2 |\n| 3    | class3 |\n| 4    | class4 |\n| 5    | class5 |\n+------+--------+\n5 rows in set (0.00 sec)\n\n```\n\n# inner join\n\n```\nMariaDB [jointest]> select * from user inner join class on user.class_id=class.id;\n+------+------+----------+------+--------+\n| id   | name | class_id | id   | name   |\n+------+------+----------+------+--------+\n| 1    | aaa  | 1        | 1    | class1 |\n| 2    | bbb  | 1        | 1    | class1 |\n| 3    | ccc  | 1        | 1    | class1 |\n| 4    | ddd  | 2        | 2    | class2 |\n| 5    | eee  | 2        | 2    | class2 |\n| 6    | fff  | 3        | 3    | class3 |\n+------+------+----------+------+--------+\n6 rows in set (0.00 sec)\n```\n\n# left join\n\n```\nMariaDB [jointest]> select * from user left join class on user.class_id=class.id;\n+------+------+----------+------+--------+\n| id   | name | class_id | id   | name   |\n+------+------+----------+------+--------+\n| 1    | aaa  | 1        | 1    | class1 |\n| 2    | bbb  | 1        | 1    | class1 |\n| 3    | ccc  | 1        | 1    | class1 |\n| 4    | ddd  | 2        | 2    | class2 |\n| 5    | eee  | 2        | 2    | class2 |\n| 6    | fff  | 3        | 3    | class3 |\n| 7    | ggg  | 7        | NULL | NULL   |\n| 8    | hhh  | 9        | NULL | NULL   |\n+------+------+----------+------+--------+\n8 rows in set (0.00 sec)\n```\n\n# right join\n\n```\nMariaDB [jointest]> select * from user right join class on user.class_id=class.id;\n+------+------+----------+------+--------+\n| id   | name | class_id | id   | name   |\n+------+------+----------+------+--------+\n| 1    | aaa  | 1        | 1    | class1 |\n| 2    | bbb  | 1        | 1    | class1 |\n| 3    | ccc  | 1        | 1    | class1 |\n| 4    | ddd  | 2        | 2    | class2 |\n| 5    | eee  | 2        | 2    | class2 |\n| 6    | fff  | 3        | 3    | class3 |\n| NULL | NULL | NULL     | 4    | class4 |\n| NULL | NULL | NULL     | 5    | class5 |\n+------+------+----------+------+--------+\n8 rows in set (0.00 sec)\n```\n\n# full join\n\nmysql不知吃full join，不过可以通过union 合并left jion和right jion的结果来模拟full jion。\n\n```\nMariaDB [jointest]> select * from user left join class on user.class_id=class.id\n    -> union\n    -> select * from user right join class on user.class_id=class.id;\n+------+------+----------+------+--------+\n| id   | name | class_id | id   | name   |\n+------+------+----------+------+--------+\n| 1    | aaa  | 1        | 1    | class1 |\n| 2    | bbb  | 1        | 1    | class1 |\n| 3    | ccc  | 1        | 1    | class1 |\n| 4    | ddd  | 2        | 2    | class2 |\n| 5    | eee  | 2        | 2    | class2 |\n| 6    | fff  | 3        | 3    | class3 |\n| 7    | ggg  | 7        | NULL | NULL   |\n| 8    | hhh  | 9        | NULL | NULL   |\n| NULL | NULL | NULL     | 4    | class4 |\n| NULL | NULL | NULL     | 5    | class5 |\n+------+------+----------+------+--------+\n10 rows in set (0.00 sec)\n```\n\n# cross join\n\nuser表一共有8条记录，class表一共有5条记录，cross join一同有8*5=40条结果。\n\n```\nMariaDB [jointest]> select * from user cross join class;\n+------+------+----------+------+--------+\n| id   | name | class_id | id   | name   |\n+------+------+----------+------+--------+\n| 1    | aaa  | 1        | 1    | class1 |\n| 1    | aaa  | 1        | 2    | class2 |\n| 1    | aaa  | 1        | 3    | class3 |\n| 1    | aaa  | 1        | 4    | class4 |\n| 1    | aaa  | 1        | 5    | class5 |\n| 2    | bbb  | 1        | 1    | class1 |\n| 2    | bbb  | 1        | 2    | class2 |\n| 2    | bbb  | 1        | 3    | class3 |\n| 2    | bbb  | 1        | 4    | class4 |\n| 2    | bbb  | 1        | 5    | class5 |\n| 3    | ccc  | 1        | 1    | class1 |\n| 3    | ccc  | 1        | 2    | class2 |\n| 3    | ccc  | 1        | 3    | class3 |\n| 3    | ccc  | 1        | 4    | class4 |\n| 3    | ccc  | 1        | 5    | class5 |\n| 4    | ddd  | 2        | 1    | class1 |\n| 4    | ddd  | 2        | 2    | class2 |\n| 4    | ddd  | 2        | 3    | class3 |\n| 4    | ddd  | 2        | 4    | class4 |\n| 4    | ddd  | 2        | 5    | class5 |\n| 5    | eee  | 2        | 1    | class1 |\n| 5    | eee  | 2        | 2    | class2 |\n| 5    | eee  | 2        | 3    | class3 |\n| 5    | eee  | 2        | 4    | class4 |\n| 5    | eee  | 2        | 5    | class5 |\n| 6    | fff  | 3        | 1    | class1 |\n| 6    | fff  | 3        | 2    | class2 |\n| 6    | fff  | 3        | 3    | class3 |\n| 6    | fff  | 3        | 4    | class4 |\n| 6    | fff  | 3        | 5    | class5 |\n| 7    | ggg  | 7        | 1    | class1 |\n| 7    | ggg  | 7        | 2    | class2 |\n| 7    | ggg  | 7        | 3    | class3 |\n| 7    | ggg  | 7        | 4    | class4 |\n| 7    | ggg  | 7        | 5    | class5 |\n| 8    | hhh  | 9        | 1    | class1 |\n| 8    | hhh  | 9        | 2    | class2 |\n| 8    | hhh  | 9        | 3    | class3 |\n| 8    | hhh  | 9        | 4    | class4 |\n| 8    | hhh  | 9        | 5    | class5 |\n+------+------+----------+------+--------+\n40 rows in set (0.01 sec)\n```\n\n\n# mysqldump\n\n```\n-- MySQL dump 10.14  Distrib 5.5.60-MariaDB, for Linux (x86_64)\n--\n-- Host: localhost    Database: jointest\n-- ------------------------------------------------------\n-- Server version       5.5.60-MariaDB\n\n/*!40101 SET @OLD_CHARACTER_SET_CLIENT=@@CHARACTER_SET_CLIENT */;\n/*!40101 SET @OLD_CHARACTER_SET_RESULTS=@@CHARACTER_SET_RESULTS */;\n/*!40101 SET @OLD_COLLATION_CONNECTION=@@COLLATION_CONNECTION */;\n/*!40101 SET NAMES utf8 */;\n/*!40103 SET @OLD_TIME_ZONE=@@TIME_ZONE */;\n/*!40103 SET TIME_ZONE='+00:00' */;\n/*!40014 SET @OLD_UNIQUE_CHECKS=@@UNIQUE_CHECKS, UNIQUE_CHECKS=0 */;\n/*!40014 SET @OLD_FOREIGN_KEY_CHECKS=@@FOREIGN_KEY_CHECKS, FOREIGN_KEY_CHECKS=0 */;\n/*!40101 SET @OLD_SQL_MODE=@@SQL_MODE, SQL_MODE='NO_AUTO_VALUE_ON_ZERO' */;\n/*!40111 SET @OLD_SQL_NOTES=@@SQL_NOTES, SQL_NOTES=0 */;\n\n--\n-- Current Database: `jointest`\n--\n\nCREATE DATABASE /*!32312 IF NOT EXISTS*/ `jointest` /*!40100 DEFAULT CHARACTER SET latin1 */;\n\nUSE `jointest`;\n\n--\n-- Table structure for table `class`\n--\n\nDROP TABLE IF EXISTS `class`;\n/*!40101 SET @saved_cs_client     = @@character_set_client */;\n/*!40101 SET character_set_client = utf8 */;\nCREATE TABLE `class` (\n  `id` varchar(10) DEFAULT NULL,\n  `name` varchar(20) DEFAULT NULL\n) ENGINE=InnoDB DEFAULT CHARSET=latin1;\n/*!40101 SET character_set_client = @saved_cs_client */;\n\n--\n-- Dumping data for table `class`\n--\n\nLOCK TABLES `class` WRITE;\n/*!40000 ALTER TABLE `class` DISABLE KEYS */;\nINSERT INTO `class` VALUES ('1','class1'),('2','class2'),('3','class3'),('4','class4'),('5','class5');\n/*!40000 ALTER TABLE `class` ENABLE KEYS */;\nUNLOCK TABLES;\n\n--\n-- Table structure for table `user`\n--\n\nDROP TABLE IF EXISTS `user`;\n/*!40101 SET @saved_cs_client     = @@character_set_client */;\n/*!40101 SET character_set_client = utf8 */;\nCREATE TABLE `user` (\n  `id` varchar(10) DEFAULT NULL,\n  `name` varchar(20) DEFAULT NULL,\n  `class_id` varchar(10) DEFAULT NULL\n) ENGINE=InnoDB DEFAULT CHARSET=latin1;\n/*!40101 SET character_set_client = @saved_cs_client */;\n\n--\n-- Dumping data for table `user`\n--\n\nLOCK TABLES `user` WRITE;\n/*!40000 ALTER TABLE `user` DISABLE KEYS */;\nINSERT INTO `user` VALUES ('1','aaa','1'),('2','bbb','1'),('3','ccc','1'),('4','ddd','2'),('5','eee','2'),('6','fff','3'),('7','ggg','7'),('8','hhh','9');\n/*!40000 ALTER TABLE `user` ENABLE KEYS */;\nUNLOCK TABLES;\n/*!40103 SET TIME_ZONE=@OLD_TIME_ZONE */;\n\n/*!40101 SET SQL_MODE=@OLD_SQL_MODE */;\n/*!40014 SET FOREIGN_KEY_CHECKS=@OLD_FOREIGN_KEY_CHECKS */;\n/*!40014 SET UNIQUE_CHECKS=@OLD_UNIQUE_CHECKS */;\n/*!40101 SET CHARACTER_SET_CLIENT=@OLD_CHARACTER_SET_CLIENT */;\n/*!40101 SET CHARACTER_SET_RESULTS=@OLD_CHARACTER_SET_RESULTS */;\n/*!40101 SET COLLATION_CONNECTION=@OLD_COLLATION_CONNECTION */;\n/*!40111 SET SQL_NOTES=@OLD_SQL_NOTES */;\n\n-- Dump completed on 2018-12-09 17:54:20\n```\n\n# 参考\n- https://www.oschina.net/translate/mysql-joins-on-vs-using-vs-theta-style\n- https://www.cnblogs.com/BeginMan/p/3754322.html\n- http://blog.bittiger.io/post198/\n","source":"_posts/sql-join.md","raw":"---\ntitle: SQL Join\ndate: 2018-12-09 15:35:21\ntags: sql\n---\n\n现在有两张表，user和class，内容如下：\n\n```\nMariaDB [jointest]> select * from user;\n+------+------+----------+\n| id   | name | class_id |\n+------+------+----------+\n| 1    | aaa  | 1        |\n| 2    | bbb  | 1        |\n| 3    | ccc  | 1        |\n| 4    | ddd  | 2        |\n| 5    | eee  | 2        |\n| 6    | fff  | 3        |\n| 7    | ggg  | 7        |\n| 8    | hhh  | 9        |\n+------+------+----------+\n8 rows in set (0.00 sec)\n\nMariaDB [jointest]> select * from class;\n+------+--------+\n| id   | name   |\n+------+--------+\n| 1    | class1 |\n| 2    | class2 |\n| 3    | class3 |\n| 4    | class4 |\n| 5    | class5 |\n+------+--------+\n5 rows in set (0.00 sec)\n\n```\n\n# inner join\n\n```\nMariaDB [jointest]> select * from user inner join class on user.class_id=class.id;\n+------+------+----------+------+--------+\n| id   | name | class_id | id   | name   |\n+------+------+----------+------+--------+\n| 1    | aaa  | 1        | 1    | class1 |\n| 2    | bbb  | 1        | 1    | class1 |\n| 3    | ccc  | 1        | 1    | class1 |\n| 4    | ddd  | 2        | 2    | class2 |\n| 5    | eee  | 2        | 2    | class2 |\n| 6    | fff  | 3        | 3    | class3 |\n+------+------+----------+------+--------+\n6 rows in set (0.00 sec)\n```\n\n# left join\n\n```\nMariaDB [jointest]> select * from user left join class on user.class_id=class.id;\n+------+------+----------+------+--------+\n| id   | name | class_id | id   | name   |\n+------+------+----------+------+--------+\n| 1    | aaa  | 1        | 1    | class1 |\n| 2    | bbb  | 1        | 1    | class1 |\n| 3    | ccc  | 1        | 1    | class1 |\n| 4    | ddd  | 2        | 2    | class2 |\n| 5    | eee  | 2        | 2    | class2 |\n| 6    | fff  | 3        | 3    | class3 |\n| 7    | ggg  | 7        | NULL | NULL   |\n| 8    | hhh  | 9        | NULL | NULL   |\n+------+------+----------+------+--------+\n8 rows in set (0.00 sec)\n```\n\n# right join\n\n```\nMariaDB [jointest]> select * from user right join class on user.class_id=class.id;\n+------+------+----------+------+--------+\n| id   | name | class_id | id   | name   |\n+------+------+----------+------+--------+\n| 1    | aaa  | 1        | 1    | class1 |\n| 2    | bbb  | 1        | 1    | class1 |\n| 3    | ccc  | 1        | 1    | class1 |\n| 4    | ddd  | 2        | 2    | class2 |\n| 5    | eee  | 2        | 2    | class2 |\n| 6    | fff  | 3        | 3    | class3 |\n| NULL | NULL | NULL     | 4    | class4 |\n| NULL | NULL | NULL     | 5    | class5 |\n+------+------+----------+------+--------+\n8 rows in set (0.00 sec)\n```\n\n# full join\n\nmysql不知吃full join，不过可以通过union 合并left jion和right jion的结果来模拟full jion。\n\n```\nMariaDB [jointest]> select * from user left join class on user.class_id=class.id\n    -> union\n    -> select * from user right join class on user.class_id=class.id;\n+------+------+----------+------+--------+\n| id   | name | class_id | id   | name   |\n+------+------+----------+------+--------+\n| 1    | aaa  | 1        | 1    | class1 |\n| 2    | bbb  | 1        | 1    | class1 |\n| 3    | ccc  | 1        | 1    | class1 |\n| 4    | ddd  | 2        | 2    | class2 |\n| 5    | eee  | 2        | 2    | class2 |\n| 6    | fff  | 3        | 3    | class3 |\n| 7    | ggg  | 7        | NULL | NULL   |\n| 8    | hhh  | 9        | NULL | NULL   |\n| NULL | NULL | NULL     | 4    | class4 |\n| NULL | NULL | NULL     | 5    | class5 |\n+------+------+----------+------+--------+\n10 rows in set (0.00 sec)\n```\n\n# cross join\n\nuser表一共有8条记录，class表一共有5条记录，cross join一同有8*5=40条结果。\n\n```\nMariaDB [jointest]> select * from user cross join class;\n+------+------+----------+------+--------+\n| id   | name | class_id | id   | name   |\n+------+------+----------+------+--------+\n| 1    | aaa  | 1        | 1    | class1 |\n| 1    | aaa  | 1        | 2    | class2 |\n| 1    | aaa  | 1        | 3    | class3 |\n| 1    | aaa  | 1        | 4    | class4 |\n| 1    | aaa  | 1        | 5    | class5 |\n| 2    | bbb  | 1        | 1    | class1 |\n| 2    | bbb  | 1        | 2    | class2 |\n| 2    | bbb  | 1        | 3    | class3 |\n| 2    | bbb  | 1        | 4    | class4 |\n| 2    | bbb  | 1        | 5    | class5 |\n| 3    | ccc  | 1        | 1    | class1 |\n| 3    | ccc  | 1        | 2    | class2 |\n| 3    | ccc  | 1        | 3    | class3 |\n| 3    | ccc  | 1        | 4    | class4 |\n| 3    | ccc  | 1        | 5    | class5 |\n| 4    | ddd  | 2        | 1    | class1 |\n| 4    | ddd  | 2        | 2    | class2 |\n| 4    | ddd  | 2        | 3    | class3 |\n| 4    | ddd  | 2        | 4    | class4 |\n| 4    | ddd  | 2        | 5    | class5 |\n| 5    | eee  | 2        | 1    | class1 |\n| 5    | eee  | 2        | 2    | class2 |\n| 5    | eee  | 2        | 3    | class3 |\n| 5    | eee  | 2        | 4    | class4 |\n| 5    | eee  | 2        | 5    | class5 |\n| 6    | fff  | 3        | 1    | class1 |\n| 6    | fff  | 3        | 2    | class2 |\n| 6    | fff  | 3        | 3    | class3 |\n| 6    | fff  | 3        | 4    | class4 |\n| 6    | fff  | 3        | 5    | class5 |\n| 7    | ggg  | 7        | 1    | class1 |\n| 7    | ggg  | 7        | 2    | class2 |\n| 7    | ggg  | 7        | 3    | class3 |\n| 7    | ggg  | 7        | 4    | class4 |\n| 7    | ggg  | 7        | 5    | class5 |\n| 8    | hhh  | 9        | 1    | class1 |\n| 8    | hhh  | 9        | 2    | class2 |\n| 8    | hhh  | 9        | 3    | class3 |\n| 8    | hhh  | 9        | 4    | class4 |\n| 8    | hhh  | 9        | 5    | class5 |\n+------+------+----------+------+--------+\n40 rows in set (0.01 sec)\n```\n\n\n# mysqldump\n\n```\n-- MySQL dump 10.14  Distrib 5.5.60-MariaDB, for Linux (x86_64)\n--\n-- Host: localhost    Database: jointest\n-- ------------------------------------------------------\n-- Server version       5.5.60-MariaDB\n\n/*!40101 SET @OLD_CHARACTER_SET_CLIENT=@@CHARACTER_SET_CLIENT */;\n/*!40101 SET @OLD_CHARACTER_SET_RESULTS=@@CHARACTER_SET_RESULTS */;\n/*!40101 SET @OLD_COLLATION_CONNECTION=@@COLLATION_CONNECTION */;\n/*!40101 SET NAMES utf8 */;\n/*!40103 SET @OLD_TIME_ZONE=@@TIME_ZONE */;\n/*!40103 SET TIME_ZONE='+00:00' */;\n/*!40014 SET @OLD_UNIQUE_CHECKS=@@UNIQUE_CHECKS, UNIQUE_CHECKS=0 */;\n/*!40014 SET @OLD_FOREIGN_KEY_CHECKS=@@FOREIGN_KEY_CHECKS, FOREIGN_KEY_CHECKS=0 */;\n/*!40101 SET @OLD_SQL_MODE=@@SQL_MODE, SQL_MODE='NO_AUTO_VALUE_ON_ZERO' */;\n/*!40111 SET @OLD_SQL_NOTES=@@SQL_NOTES, SQL_NOTES=0 */;\n\n--\n-- Current Database: `jointest`\n--\n\nCREATE DATABASE /*!32312 IF NOT EXISTS*/ `jointest` /*!40100 DEFAULT CHARACTER SET latin1 */;\n\nUSE `jointest`;\n\n--\n-- Table structure for table `class`\n--\n\nDROP TABLE IF EXISTS `class`;\n/*!40101 SET @saved_cs_client     = @@character_set_client */;\n/*!40101 SET character_set_client = utf8 */;\nCREATE TABLE `class` (\n  `id` varchar(10) DEFAULT NULL,\n  `name` varchar(20) DEFAULT NULL\n) ENGINE=InnoDB DEFAULT CHARSET=latin1;\n/*!40101 SET character_set_client = @saved_cs_client */;\n\n--\n-- Dumping data for table `class`\n--\n\nLOCK TABLES `class` WRITE;\n/*!40000 ALTER TABLE `class` DISABLE KEYS */;\nINSERT INTO `class` VALUES ('1','class1'),('2','class2'),('3','class3'),('4','class4'),('5','class5');\n/*!40000 ALTER TABLE `class` ENABLE KEYS */;\nUNLOCK TABLES;\n\n--\n-- Table structure for table `user`\n--\n\nDROP TABLE IF EXISTS `user`;\n/*!40101 SET @saved_cs_client     = @@character_set_client */;\n/*!40101 SET character_set_client = utf8 */;\nCREATE TABLE `user` (\n  `id` varchar(10) DEFAULT NULL,\n  `name` varchar(20) DEFAULT NULL,\n  `class_id` varchar(10) DEFAULT NULL\n) ENGINE=InnoDB DEFAULT CHARSET=latin1;\n/*!40101 SET character_set_client = @saved_cs_client */;\n\n--\n-- Dumping data for table `user`\n--\n\nLOCK TABLES `user` WRITE;\n/*!40000 ALTER TABLE `user` DISABLE KEYS */;\nINSERT INTO `user` VALUES ('1','aaa','1'),('2','bbb','1'),('3','ccc','1'),('4','ddd','2'),('5','eee','2'),('6','fff','3'),('7','ggg','7'),('8','hhh','9');\n/*!40000 ALTER TABLE `user` ENABLE KEYS */;\nUNLOCK TABLES;\n/*!40103 SET TIME_ZONE=@OLD_TIME_ZONE */;\n\n/*!40101 SET SQL_MODE=@OLD_SQL_MODE */;\n/*!40014 SET FOREIGN_KEY_CHECKS=@OLD_FOREIGN_KEY_CHECKS */;\n/*!40014 SET UNIQUE_CHECKS=@OLD_UNIQUE_CHECKS */;\n/*!40101 SET CHARACTER_SET_CLIENT=@OLD_CHARACTER_SET_CLIENT */;\n/*!40101 SET CHARACTER_SET_RESULTS=@OLD_CHARACTER_SET_RESULTS */;\n/*!40101 SET COLLATION_CONNECTION=@OLD_COLLATION_CONNECTION */;\n/*!40111 SET SQL_NOTES=@OLD_SQL_NOTES */;\n\n-- Dump completed on 2018-12-09 17:54:20\n```\n\n# 参考\n- https://www.oschina.net/translate/mysql-joins-on-vs-using-vs-theta-style\n- https://www.cnblogs.com/BeginMan/p/3754322.html\n- http://blog.bittiger.io/post198/\n","slug":"sql-join","published":1,"updated":"2018-12-09T14:49:12.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck1pzbthb0013tp75wetcdil3","content":"<p>现在有两张表，user和class，内容如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">MariaDB [jointest]&gt; select * from user;</span><br><span class=\"line\">+------+------+----------+</span><br><span class=\"line\">| id   | name | class_id |</span><br><span class=\"line\">+------+------+----------+</span><br><span class=\"line\">| 1    | aaa  | 1        |</span><br><span class=\"line\">| 2    | bbb  | 1        |</span><br><span class=\"line\">| 3    | ccc  | 1        |</span><br><span class=\"line\">| 4    | ddd  | 2        |</span><br><span class=\"line\">| 5    | eee  | 2        |</span><br><span class=\"line\">| 6    | fff  | 3        |</span><br><span class=\"line\">| 7    | ggg  | 7        |</span><br><span class=\"line\">| 8    | hhh  | 9        |</span><br><span class=\"line\">+------+------+----------+</span><br><span class=\"line\">8 rows in set (0.00 sec)</span><br><span class=\"line\"></span><br><span class=\"line\">MariaDB [jointest]&gt; select * from class;</span><br><span class=\"line\">+------+--------+</span><br><span class=\"line\">| id   | name   |</span><br><span class=\"line\">+------+--------+</span><br><span class=\"line\">| 1    | class1 |</span><br><span class=\"line\">| 2    | class2 |</span><br><span class=\"line\">| 3    | class3 |</span><br><span class=\"line\">| 4    | class4 |</span><br><span class=\"line\">| 5    | class5 |</span><br><span class=\"line\">+------+--------+</span><br><span class=\"line\">5 rows in set (0.00 sec)</span><br></pre></td></tr></table></figure>\n<h1 id=\"inner-join\"><a href=\"#inner-join\" class=\"headerlink\" title=\"inner join\"></a>inner join</h1><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">MariaDB [jointest]&gt; select * from user inner join class on user.class_id=class.id;</span><br><span class=\"line\">+------+------+----------+------+--------+</span><br><span class=\"line\">| id   | name | class_id | id   | name   |</span><br><span class=\"line\">+------+------+----------+------+--------+</span><br><span class=\"line\">| 1    | aaa  | 1        | 1    | class1 |</span><br><span class=\"line\">| 2    | bbb  | 1        | 1    | class1 |</span><br><span class=\"line\">| 3    | ccc  | 1        | 1    | class1 |</span><br><span class=\"line\">| 4    | ddd  | 2        | 2    | class2 |</span><br><span class=\"line\">| 5    | eee  | 2        | 2    | class2 |</span><br><span class=\"line\">| 6    | fff  | 3        | 3    | class3 |</span><br><span class=\"line\">+------+------+----------+------+--------+</span><br><span class=\"line\">6 rows in set (0.00 sec)</span><br></pre></td></tr></table></figure>\n<h1 id=\"left-join\"><a href=\"#left-join\" class=\"headerlink\" title=\"left join\"></a>left join</h1><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">MariaDB [jointest]&gt; select * from user left join class on user.class_id=class.id;</span><br><span class=\"line\">+------+------+----------+------+--------+</span><br><span class=\"line\">| id   | name | class_id | id   | name   |</span><br><span class=\"line\">+------+------+----------+------+--------+</span><br><span class=\"line\">| 1    | aaa  | 1        | 1    | class1 |</span><br><span class=\"line\">| 2    | bbb  | 1        | 1    | class1 |</span><br><span class=\"line\">| 3    | ccc  | 1        | 1    | class1 |</span><br><span class=\"line\">| 4    | ddd  | 2        | 2    | class2 |</span><br><span class=\"line\">| 5    | eee  | 2        | 2    | class2 |</span><br><span class=\"line\">| 6    | fff  | 3        | 3    | class3 |</span><br><span class=\"line\">| 7    | ggg  | 7        | NULL | NULL   |</span><br><span class=\"line\">| 8    | hhh  | 9        | NULL | NULL   |</span><br><span class=\"line\">+------+------+----------+------+--------+</span><br><span class=\"line\">8 rows in set (0.00 sec)</span><br></pre></td></tr></table></figure>\n<h1 id=\"right-join\"><a href=\"#right-join\" class=\"headerlink\" title=\"right join\"></a>right join</h1><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">MariaDB [jointest]&gt; select * from user right join class on user.class_id=class.id;</span><br><span class=\"line\">+------+------+----------+------+--------+</span><br><span class=\"line\">| id   | name | class_id | id   | name   |</span><br><span class=\"line\">+------+------+----------+------+--------+</span><br><span class=\"line\">| 1    | aaa  | 1        | 1    | class1 |</span><br><span class=\"line\">| 2    | bbb  | 1        | 1    | class1 |</span><br><span class=\"line\">| 3    | ccc  | 1        | 1    | class1 |</span><br><span class=\"line\">| 4    | ddd  | 2        | 2    | class2 |</span><br><span class=\"line\">| 5    | eee  | 2        | 2    | class2 |</span><br><span class=\"line\">| 6    | fff  | 3        | 3    | class3 |</span><br><span class=\"line\">| NULL | NULL | NULL     | 4    | class4 |</span><br><span class=\"line\">| NULL | NULL | NULL     | 5    | class5 |</span><br><span class=\"line\">+------+------+----------+------+--------+</span><br><span class=\"line\">8 rows in set (0.00 sec)</span><br></pre></td></tr></table></figure>\n<h1 id=\"full-join\"><a href=\"#full-join\" class=\"headerlink\" title=\"full join\"></a>full join</h1><p>mysql不知吃full join，不过可以通过union 合并left jion和right jion的结果来模拟full jion。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">MariaDB [jointest]&gt; select * from user left join class on user.class_id=class.id</span><br><span class=\"line\">    -&gt; union</span><br><span class=\"line\">    -&gt; select * from user right join class on user.class_id=class.id;</span><br><span class=\"line\">+------+------+----------+------+--------+</span><br><span class=\"line\">| id   | name | class_id | id   | name   |</span><br><span class=\"line\">+------+------+----------+------+--------+</span><br><span class=\"line\">| 1    | aaa  | 1        | 1    | class1 |</span><br><span class=\"line\">| 2    | bbb  | 1        | 1    | class1 |</span><br><span class=\"line\">| 3    | ccc  | 1        | 1    | class1 |</span><br><span class=\"line\">| 4    | ddd  | 2        | 2    | class2 |</span><br><span class=\"line\">| 5    | eee  | 2        | 2    | class2 |</span><br><span class=\"line\">| 6    | fff  | 3        | 3    | class3 |</span><br><span class=\"line\">| 7    | ggg  | 7        | NULL | NULL   |</span><br><span class=\"line\">| 8    | hhh  | 9        | NULL | NULL   |</span><br><span class=\"line\">| NULL | NULL | NULL     | 4    | class4 |</span><br><span class=\"line\">| NULL | NULL | NULL     | 5    | class5 |</span><br><span class=\"line\">+------+------+----------+------+--------+</span><br><span class=\"line\">10 rows in set (0.00 sec)</span><br></pre></td></tr></table></figure>\n<h1 id=\"cross-join\"><a href=\"#cross-join\" class=\"headerlink\" title=\"cross join\"></a>cross join</h1><p>user表一共有8条记录，class表一共有5条记录，cross join一同有8*5=40条结果。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">MariaDB [jointest]&gt; select * from user cross join class;</span><br><span class=\"line\">+------+------+----------+------+--------+</span><br><span class=\"line\">| id   | name | class_id | id   | name   |</span><br><span class=\"line\">+------+------+----------+------+--------+</span><br><span class=\"line\">| 1    | aaa  | 1        | 1    | class1 |</span><br><span class=\"line\">| 1    | aaa  | 1        | 2    | class2 |</span><br><span class=\"line\">| 1    | aaa  | 1        | 3    | class3 |</span><br><span class=\"line\">| 1    | aaa  | 1        | 4    | class4 |</span><br><span class=\"line\">| 1    | aaa  | 1        | 5    | class5 |</span><br><span class=\"line\">| 2    | bbb  | 1        | 1    | class1 |</span><br><span class=\"line\">| 2    | bbb  | 1        | 2    | class2 |</span><br><span class=\"line\">| 2    | bbb  | 1        | 3    | class3 |</span><br><span class=\"line\">| 2    | bbb  | 1        | 4    | class4 |</span><br><span class=\"line\">| 2    | bbb  | 1        | 5    | class5 |</span><br><span class=\"line\">| 3    | ccc  | 1        | 1    | class1 |</span><br><span class=\"line\">| 3    | ccc  | 1        | 2    | class2 |</span><br><span class=\"line\">| 3    | ccc  | 1        | 3    | class3 |</span><br><span class=\"line\">| 3    | ccc  | 1        | 4    | class4 |</span><br><span class=\"line\">| 3    | ccc  | 1        | 5    | class5 |</span><br><span class=\"line\">| 4    | ddd  | 2        | 1    | class1 |</span><br><span class=\"line\">| 4    | ddd  | 2        | 2    | class2 |</span><br><span class=\"line\">| 4    | ddd  | 2        | 3    | class3 |</span><br><span class=\"line\">| 4    | ddd  | 2        | 4    | class4 |</span><br><span class=\"line\">| 4    | ddd  | 2        | 5    | class5 |</span><br><span class=\"line\">| 5    | eee  | 2        | 1    | class1 |</span><br><span class=\"line\">| 5    | eee  | 2        | 2    | class2 |</span><br><span class=\"line\">| 5    | eee  | 2        | 3    | class3 |</span><br><span class=\"line\">| 5    | eee  | 2        | 4    | class4 |</span><br><span class=\"line\">| 5    | eee  | 2        | 5    | class5 |</span><br><span class=\"line\">| 6    | fff  | 3        | 1    | class1 |</span><br><span class=\"line\">| 6    | fff  | 3        | 2    | class2 |</span><br><span class=\"line\">| 6    | fff  | 3        | 3    | class3 |</span><br><span class=\"line\">| 6    | fff  | 3        | 4    | class4 |</span><br><span class=\"line\">| 6    | fff  | 3        | 5    | class5 |</span><br><span class=\"line\">| 7    | ggg  | 7        | 1    | class1 |</span><br><span class=\"line\">| 7    | ggg  | 7        | 2    | class2 |</span><br><span class=\"line\">| 7    | ggg  | 7        | 3    | class3 |</span><br><span class=\"line\">| 7    | ggg  | 7        | 4    | class4 |</span><br><span class=\"line\">| 7    | ggg  | 7        | 5    | class5 |</span><br><span class=\"line\">| 8    | hhh  | 9        | 1    | class1 |</span><br><span class=\"line\">| 8    | hhh  | 9        | 2    | class2 |</span><br><span class=\"line\">| 8    | hhh  | 9        | 3    | class3 |</span><br><span class=\"line\">| 8    | hhh  | 9        | 4    | class4 |</span><br><span class=\"line\">| 8    | hhh  | 9        | 5    | class5 |</span><br><span class=\"line\">+------+------+----------+------+--------+</span><br><span class=\"line\">40 rows in set (0.01 sec)</span><br></pre></td></tr></table></figure>\n<h1 id=\"mysqldump\"><a href=\"#mysqldump\" class=\"headerlink\" title=\"mysqldump\"></a>mysqldump</h1><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">-- MySQL dump 10.14  Distrib 5.5.60-MariaDB, for Linux (x86_64)</span><br><span class=\"line\">--</span><br><span class=\"line\">-- Host: localhost    Database: jointest</span><br><span class=\"line\">-- ------------------------------------------------------</span><br><span class=\"line\">-- Server version       5.5.60-MariaDB</span><br><span class=\"line\"></span><br><span class=\"line\">/*!40101 SET @OLD_CHARACTER_SET_CLIENT=@@CHARACTER_SET_CLIENT */;</span><br><span class=\"line\">/*!40101 SET @OLD_CHARACTER_SET_RESULTS=@@CHARACTER_SET_RESULTS */;</span><br><span class=\"line\">/*!40101 SET @OLD_COLLATION_CONNECTION=@@COLLATION_CONNECTION */;</span><br><span class=\"line\">/*!40101 SET NAMES utf8 */;</span><br><span class=\"line\">/*!40103 SET @OLD_TIME_ZONE=@@TIME_ZONE */;</span><br><span class=\"line\">/*!40103 SET TIME_ZONE=&apos;+00:00&apos; */;</span><br><span class=\"line\">/*!40014 SET @OLD_UNIQUE_CHECKS=@@UNIQUE_CHECKS, UNIQUE_CHECKS=0 */;</span><br><span class=\"line\">/*!40014 SET @OLD_FOREIGN_KEY_CHECKS=@@FOREIGN_KEY_CHECKS, FOREIGN_KEY_CHECKS=0 */;</span><br><span class=\"line\">/*!40101 SET @OLD_SQL_MODE=@@SQL_MODE, SQL_MODE=&apos;NO_AUTO_VALUE_ON_ZERO&apos; */;</span><br><span class=\"line\">/*!40111 SET @OLD_SQL_NOTES=@@SQL_NOTES, SQL_NOTES=0 */;</span><br><span class=\"line\"></span><br><span class=\"line\">--</span><br><span class=\"line\">-- Current Database: `jointest`</span><br><span class=\"line\">--</span><br><span class=\"line\"></span><br><span class=\"line\">CREATE DATABASE /*!32312 IF NOT EXISTS*/ `jointest` /*!40100 DEFAULT CHARACTER SET latin1 */;</span><br><span class=\"line\"></span><br><span class=\"line\">USE `jointest`;</span><br><span class=\"line\"></span><br><span class=\"line\">--</span><br><span class=\"line\">-- Table structure for table `class`</span><br><span class=\"line\">--</span><br><span class=\"line\"></span><br><span class=\"line\">DROP TABLE IF EXISTS `class`;</span><br><span class=\"line\">/*!40101 SET @saved_cs_client     = @@character_set_client */;</span><br><span class=\"line\">/*!40101 SET character_set_client = utf8 */;</span><br><span class=\"line\">CREATE TABLE `class` (</span><br><span class=\"line\">  `id` varchar(10) DEFAULT NULL,</span><br><span class=\"line\">  `name` varchar(20) DEFAULT NULL</span><br><span class=\"line\">) ENGINE=InnoDB DEFAULT CHARSET=latin1;</span><br><span class=\"line\">/*!40101 SET character_set_client = @saved_cs_client */;</span><br><span class=\"line\"></span><br><span class=\"line\">--</span><br><span class=\"line\">-- Dumping data for table `class`</span><br><span class=\"line\">--</span><br><span class=\"line\"></span><br><span class=\"line\">LOCK TABLES `class` WRITE;</span><br><span class=\"line\">/*!40000 ALTER TABLE `class` DISABLE KEYS */;</span><br><span class=\"line\">INSERT INTO `class` VALUES (&apos;1&apos;,&apos;class1&apos;),(&apos;2&apos;,&apos;class2&apos;),(&apos;3&apos;,&apos;class3&apos;),(&apos;4&apos;,&apos;class4&apos;),(&apos;5&apos;,&apos;class5&apos;);</span><br><span class=\"line\">/*!40000 ALTER TABLE `class` ENABLE KEYS */;</span><br><span class=\"line\">UNLOCK TABLES;</span><br><span class=\"line\"></span><br><span class=\"line\">--</span><br><span class=\"line\">-- Table structure for table `user`</span><br><span class=\"line\">--</span><br><span class=\"line\"></span><br><span class=\"line\">DROP TABLE IF EXISTS `user`;</span><br><span class=\"line\">/*!40101 SET @saved_cs_client     = @@character_set_client */;</span><br><span class=\"line\">/*!40101 SET character_set_client = utf8 */;</span><br><span class=\"line\">CREATE TABLE `user` (</span><br><span class=\"line\">  `id` varchar(10) DEFAULT NULL,</span><br><span class=\"line\">  `name` varchar(20) DEFAULT NULL,</span><br><span class=\"line\">  `class_id` varchar(10) DEFAULT NULL</span><br><span class=\"line\">) ENGINE=InnoDB DEFAULT CHARSET=latin1;</span><br><span class=\"line\">/*!40101 SET character_set_client = @saved_cs_client */;</span><br><span class=\"line\"></span><br><span class=\"line\">--</span><br><span class=\"line\">-- Dumping data for table `user`</span><br><span class=\"line\">--</span><br><span class=\"line\"></span><br><span class=\"line\">LOCK TABLES `user` WRITE;</span><br><span class=\"line\">/*!40000 ALTER TABLE `user` DISABLE KEYS */;</span><br><span class=\"line\">INSERT INTO `user` VALUES (&apos;1&apos;,&apos;aaa&apos;,&apos;1&apos;),(&apos;2&apos;,&apos;bbb&apos;,&apos;1&apos;),(&apos;3&apos;,&apos;ccc&apos;,&apos;1&apos;),(&apos;4&apos;,&apos;ddd&apos;,&apos;2&apos;),(&apos;5&apos;,&apos;eee&apos;,&apos;2&apos;),(&apos;6&apos;,&apos;fff&apos;,&apos;3&apos;),(&apos;7&apos;,&apos;ggg&apos;,&apos;7&apos;),(&apos;8&apos;,&apos;hhh&apos;,&apos;9&apos;);</span><br><span class=\"line\">/*!40000 ALTER TABLE `user` ENABLE KEYS */;</span><br><span class=\"line\">UNLOCK TABLES;</span><br><span class=\"line\">/*!40103 SET TIME_ZONE=@OLD_TIME_ZONE */;</span><br><span class=\"line\"></span><br><span class=\"line\">/*!40101 SET SQL_MODE=@OLD_SQL_MODE */;</span><br><span class=\"line\">/*!40014 SET FOREIGN_KEY_CHECKS=@OLD_FOREIGN_KEY_CHECKS */;</span><br><span class=\"line\">/*!40014 SET UNIQUE_CHECKS=@OLD_UNIQUE_CHECKS */;</span><br><span class=\"line\">/*!40101 SET CHARACTER_SET_CLIENT=@OLD_CHARACTER_SET_CLIENT */;</span><br><span class=\"line\">/*!40101 SET CHARACTER_SET_RESULTS=@OLD_CHARACTER_SET_RESULTS */;</span><br><span class=\"line\">/*!40101 SET COLLATION_CONNECTION=@OLD_COLLATION_CONNECTION */;</span><br><span class=\"line\">/*!40111 SET SQL_NOTES=@OLD_SQL_NOTES */;</span><br><span class=\"line\"></span><br><span class=\"line\">-- Dump completed on 2018-12-09 17:54:20</span><br></pre></td></tr></table></figure>\n<h1 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h1><ul>\n<li><a href=\"https://www.oschina.net/translate/mysql-joins-on-vs-using-vs-theta-style\" target=\"_blank\" rel=\"noopener\">https://www.oschina.net/translate/mysql-joins-on-vs-using-vs-theta-style</a></li>\n<li><a href=\"https://www.cnblogs.com/BeginMan/p/3754322.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/BeginMan/p/3754322.html</a></li>\n<li><a href=\"http://blog.bittiger.io/post198/\" target=\"_blank\" rel=\"noopener\">http://blog.bittiger.io/post198/</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<p>现在有两张表，user和class，内容如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">MariaDB [jointest]&gt; select * from user;</span><br><span class=\"line\">+------+------+----------+</span><br><span class=\"line\">| id   | name | class_id |</span><br><span class=\"line\">+------+------+----------+</span><br><span class=\"line\">| 1    | aaa  | 1        |</span><br><span class=\"line\">| 2    | bbb  | 1        |</span><br><span class=\"line\">| 3    | ccc  | 1        |</span><br><span class=\"line\">| 4    | ddd  | 2        |</span><br><span class=\"line\">| 5    | eee  | 2        |</span><br><span class=\"line\">| 6    | fff  | 3        |</span><br><span class=\"line\">| 7    | ggg  | 7        |</span><br><span class=\"line\">| 8    | hhh  | 9        |</span><br><span class=\"line\">+------+------+----------+</span><br><span class=\"line\">8 rows in set (0.00 sec)</span><br><span class=\"line\"></span><br><span class=\"line\">MariaDB [jointest]&gt; select * from class;</span><br><span class=\"line\">+------+--------+</span><br><span class=\"line\">| id   | name   |</span><br><span class=\"line\">+------+--------+</span><br><span class=\"line\">| 1    | class1 |</span><br><span class=\"line\">| 2    | class2 |</span><br><span class=\"line\">| 3    | class3 |</span><br><span class=\"line\">| 4    | class4 |</span><br><span class=\"line\">| 5    | class5 |</span><br><span class=\"line\">+------+--------+</span><br><span class=\"line\">5 rows in set (0.00 sec)</span><br></pre></td></tr></table></figure>\n<h1 id=\"inner-join\"><a href=\"#inner-join\" class=\"headerlink\" title=\"inner join\"></a>inner join</h1><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">MariaDB [jointest]&gt; select * from user inner join class on user.class_id=class.id;</span><br><span class=\"line\">+------+------+----------+------+--------+</span><br><span class=\"line\">| id   | name | class_id | id   | name   |</span><br><span class=\"line\">+------+------+----------+------+--------+</span><br><span class=\"line\">| 1    | aaa  | 1        | 1    | class1 |</span><br><span class=\"line\">| 2    | bbb  | 1        | 1    | class1 |</span><br><span class=\"line\">| 3    | ccc  | 1        | 1    | class1 |</span><br><span class=\"line\">| 4    | ddd  | 2        | 2    | class2 |</span><br><span class=\"line\">| 5    | eee  | 2        | 2    | class2 |</span><br><span class=\"line\">| 6    | fff  | 3        | 3    | class3 |</span><br><span class=\"line\">+------+------+----------+------+--------+</span><br><span class=\"line\">6 rows in set (0.00 sec)</span><br></pre></td></tr></table></figure>\n<h1 id=\"left-join\"><a href=\"#left-join\" class=\"headerlink\" title=\"left join\"></a>left join</h1><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">MariaDB [jointest]&gt; select * from user left join class on user.class_id=class.id;</span><br><span class=\"line\">+------+------+----------+------+--------+</span><br><span class=\"line\">| id   | name | class_id | id   | name   |</span><br><span class=\"line\">+------+------+----------+------+--------+</span><br><span class=\"line\">| 1    | aaa  | 1        | 1    | class1 |</span><br><span class=\"line\">| 2    | bbb  | 1        | 1    | class1 |</span><br><span class=\"line\">| 3    | ccc  | 1        | 1    | class1 |</span><br><span class=\"line\">| 4    | ddd  | 2        | 2    | class2 |</span><br><span class=\"line\">| 5    | eee  | 2        | 2    | class2 |</span><br><span class=\"line\">| 6    | fff  | 3        | 3    | class3 |</span><br><span class=\"line\">| 7    | ggg  | 7        | NULL | NULL   |</span><br><span class=\"line\">| 8    | hhh  | 9        | NULL | NULL   |</span><br><span class=\"line\">+------+------+----------+------+--------+</span><br><span class=\"line\">8 rows in set (0.00 sec)</span><br></pre></td></tr></table></figure>\n<h1 id=\"right-join\"><a href=\"#right-join\" class=\"headerlink\" title=\"right join\"></a>right join</h1><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">MariaDB [jointest]&gt; select * from user right join class on user.class_id=class.id;</span><br><span class=\"line\">+------+------+----------+------+--------+</span><br><span class=\"line\">| id   | name | class_id | id   | name   |</span><br><span class=\"line\">+------+------+----------+------+--------+</span><br><span class=\"line\">| 1    | aaa  | 1        | 1    | class1 |</span><br><span class=\"line\">| 2    | bbb  | 1        | 1    | class1 |</span><br><span class=\"line\">| 3    | ccc  | 1        | 1    | class1 |</span><br><span class=\"line\">| 4    | ddd  | 2        | 2    | class2 |</span><br><span class=\"line\">| 5    | eee  | 2        | 2    | class2 |</span><br><span class=\"line\">| 6    | fff  | 3        | 3    | class3 |</span><br><span class=\"line\">| NULL | NULL | NULL     | 4    | class4 |</span><br><span class=\"line\">| NULL | NULL | NULL     | 5    | class5 |</span><br><span class=\"line\">+------+------+----------+------+--------+</span><br><span class=\"line\">8 rows in set (0.00 sec)</span><br></pre></td></tr></table></figure>\n<h1 id=\"full-join\"><a href=\"#full-join\" class=\"headerlink\" title=\"full join\"></a>full join</h1><p>mysql不知吃full join，不过可以通过union 合并left jion和right jion的结果来模拟full jion。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">MariaDB [jointest]&gt; select * from user left join class on user.class_id=class.id</span><br><span class=\"line\">    -&gt; union</span><br><span class=\"line\">    -&gt; select * from user right join class on user.class_id=class.id;</span><br><span class=\"line\">+------+------+----------+------+--------+</span><br><span class=\"line\">| id   | name | class_id | id   | name   |</span><br><span class=\"line\">+------+------+----------+------+--------+</span><br><span class=\"line\">| 1    | aaa  | 1        | 1    | class1 |</span><br><span class=\"line\">| 2    | bbb  | 1        | 1    | class1 |</span><br><span class=\"line\">| 3    | ccc  | 1        | 1    | class1 |</span><br><span class=\"line\">| 4    | ddd  | 2        | 2    | class2 |</span><br><span class=\"line\">| 5    | eee  | 2        | 2    | class2 |</span><br><span class=\"line\">| 6    | fff  | 3        | 3    | class3 |</span><br><span class=\"line\">| 7    | ggg  | 7        | NULL | NULL   |</span><br><span class=\"line\">| 8    | hhh  | 9        | NULL | NULL   |</span><br><span class=\"line\">| NULL | NULL | NULL     | 4    | class4 |</span><br><span class=\"line\">| NULL | NULL | NULL     | 5    | class5 |</span><br><span class=\"line\">+------+------+----------+------+--------+</span><br><span class=\"line\">10 rows in set (0.00 sec)</span><br></pre></td></tr></table></figure>\n<h1 id=\"cross-join\"><a href=\"#cross-join\" class=\"headerlink\" title=\"cross join\"></a>cross join</h1><p>user表一共有8条记录，class表一共有5条记录，cross join一同有8*5=40条结果。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">MariaDB [jointest]&gt; select * from user cross join class;</span><br><span class=\"line\">+------+------+----------+------+--------+</span><br><span class=\"line\">| id   | name | class_id | id   | name   |</span><br><span class=\"line\">+------+------+----------+------+--------+</span><br><span class=\"line\">| 1    | aaa  | 1        | 1    | class1 |</span><br><span class=\"line\">| 1    | aaa  | 1        | 2    | class2 |</span><br><span class=\"line\">| 1    | aaa  | 1        | 3    | class3 |</span><br><span class=\"line\">| 1    | aaa  | 1        | 4    | class4 |</span><br><span class=\"line\">| 1    | aaa  | 1        | 5    | class5 |</span><br><span class=\"line\">| 2    | bbb  | 1        | 1    | class1 |</span><br><span class=\"line\">| 2    | bbb  | 1        | 2    | class2 |</span><br><span class=\"line\">| 2    | bbb  | 1        | 3    | class3 |</span><br><span class=\"line\">| 2    | bbb  | 1        | 4    | class4 |</span><br><span class=\"line\">| 2    | bbb  | 1        | 5    | class5 |</span><br><span class=\"line\">| 3    | ccc  | 1        | 1    | class1 |</span><br><span class=\"line\">| 3    | ccc  | 1        | 2    | class2 |</span><br><span class=\"line\">| 3    | ccc  | 1        | 3    | class3 |</span><br><span class=\"line\">| 3    | ccc  | 1        | 4    | class4 |</span><br><span class=\"line\">| 3    | ccc  | 1        | 5    | class5 |</span><br><span class=\"line\">| 4    | ddd  | 2        | 1    | class1 |</span><br><span class=\"line\">| 4    | ddd  | 2        | 2    | class2 |</span><br><span class=\"line\">| 4    | ddd  | 2        | 3    | class3 |</span><br><span class=\"line\">| 4    | ddd  | 2        | 4    | class4 |</span><br><span class=\"line\">| 4    | ddd  | 2        | 5    | class5 |</span><br><span class=\"line\">| 5    | eee  | 2        | 1    | class1 |</span><br><span class=\"line\">| 5    | eee  | 2        | 2    | class2 |</span><br><span class=\"line\">| 5    | eee  | 2        | 3    | class3 |</span><br><span class=\"line\">| 5    | eee  | 2        | 4    | class4 |</span><br><span class=\"line\">| 5    | eee  | 2        | 5    | class5 |</span><br><span class=\"line\">| 6    | fff  | 3        | 1    | class1 |</span><br><span class=\"line\">| 6    | fff  | 3        | 2    | class2 |</span><br><span class=\"line\">| 6    | fff  | 3        | 3    | class3 |</span><br><span class=\"line\">| 6    | fff  | 3        | 4    | class4 |</span><br><span class=\"line\">| 6    | fff  | 3        | 5    | class5 |</span><br><span class=\"line\">| 7    | ggg  | 7        | 1    | class1 |</span><br><span class=\"line\">| 7    | ggg  | 7        | 2    | class2 |</span><br><span class=\"line\">| 7    | ggg  | 7        | 3    | class3 |</span><br><span class=\"line\">| 7    | ggg  | 7        | 4    | class4 |</span><br><span class=\"line\">| 7    | ggg  | 7        | 5    | class5 |</span><br><span class=\"line\">| 8    | hhh  | 9        | 1    | class1 |</span><br><span class=\"line\">| 8    | hhh  | 9        | 2    | class2 |</span><br><span class=\"line\">| 8    | hhh  | 9        | 3    | class3 |</span><br><span class=\"line\">| 8    | hhh  | 9        | 4    | class4 |</span><br><span class=\"line\">| 8    | hhh  | 9        | 5    | class5 |</span><br><span class=\"line\">+------+------+----------+------+--------+</span><br><span class=\"line\">40 rows in set (0.01 sec)</span><br></pre></td></tr></table></figure>\n<h1 id=\"mysqldump\"><a href=\"#mysqldump\" class=\"headerlink\" title=\"mysqldump\"></a>mysqldump</h1><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">-- MySQL dump 10.14  Distrib 5.5.60-MariaDB, for Linux (x86_64)</span><br><span class=\"line\">--</span><br><span class=\"line\">-- Host: localhost    Database: jointest</span><br><span class=\"line\">-- ------------------------------------------------------</span><br><span class=\"line\">-- Server version       5.5.60-MariaDB</span><br><span class=\"line\"></span><br><span class=\"line\">/*!40101 SET @OLD_CHARACTER_SET_CLIENT=@@CHARACTER_SET_CLIENT */;</span><br><span class=\"line\">/*!40101 SET @OLD_CHARACTER_SET_RESULTS=@@CHARACTER_SET_RESULTS */;</span><br><span class=\"line\">/*!40101 SET @OLD_COLLATION_CONNECTION=@@COLLATION_CONNECTION */;</span><br><span class=\"line\">/*!40101 SET NAMES utf8 */;</span><br><span class=\"line\">/*!40103 SET @OLD_TIME_ZONE=@@TIME_ZONE */;</span><br><span class=\"line\">/*!40103 SET TIME_ZONE=&apos;+00:00&apos; */;</span><br><span class=\"line\">/*!40014 SET @OLD_UNIQUE_CHECKS=@@UNIQUE_CHECKS, UNIQUE_CHECKS=0 */;</span><br><span class=\"line\">/*!40014 SET @OLD_FOREIGN_KEY_CHECKS=@@FOREIGN_KEY_CHECKS, FOREIGN_KEY_CHECKS=0 */;</span><br><span class=\"line\">/*!40101 SET @OLD_SQL_MODE=@@SQL_MODE, SQL_MODE=&apos;NO_AUTO_VALUE_ON_ZERO&apos; */;</span><br><span class=\"line\">/*!40111 SET @OLD_SQL_NOTES=@@SQL_NOTES, SQL_NOTES=0 */;</span><br><span class=\"line\"></span><br><span class=\"line\">--</span><br><span class=\"line\">-- Current Database: `jointest`</span><br><span class=\"line\">--</span><br><span class=\"line\"></span><br><span class=\"line\">CREATE DATABASE /*!32312 IF NOT EXISTS*/ `jointest` /*!40100 DEFAULT CHARACTER SET latin1 */;</span><br><span class=\"line\"></span><br><span class=\"line\">USE `jointest`;</span><br><span class=\"line\"></span><br><span class=\"line\">--</span><br><span class=\"line\">-- Table structure for table `class`</span><br><span class=\"line\">--</span><br><span class=\"line\"></span><br><span class=\"line\">DROP TABLE IF EXISTS `class`;</span><br><span class=\"line\">/*!40101 SET @saved_cs_client     = @@character_set_client */;</span><br><span class=\"line\">/*!40101 SET character_set_client = utf8 */;</span><br><span class=\"line\">CREATE TABLE `class` (</span><br><span class=\"line\">  `id` varchar(10) DEFAULT NULL,</span><br><span class=\"line\">  `name` varchar(20) DEFAULT NULL</span><br><span class=\"line\">) ENGINE=InnoDB DEFAULT CHARSET=latin1;</span><br><span class=\"line\">/*!40101 SET character_set_client = @saved_cs_client */;</span><br><span class=\"line\"></span><br><span class=\"line\">--</span><br><span class=\"line\">-- Dumping data for table `class`</span><br><span class=\"line\">--</span><br><span class=\"line\"></span><br><span class=\"line\">LOCK TABLES `class` WRITE;</span><br><span class=\"line\">/*!40000 ALTER TABLE `class` DISABLE KEYS */;</span><br><span class=\"line\">INSERT INTO `class` VALUES (&apos;1&apos;,&apos;class1&apos;),(&apos;2&apos;,&apos;class2&apos;),(&apos;3&apos;,&apos;class3&apos;),(&apos;4&apos;,&apos;class4&apos;),(&apos;5&apos;,&apos;class5&apos;);</span><br><span class=\"line\">/*!40000 ALTER TABLE `class` ENABLE KEYS */;</span><br><span class=\"line\">UNLOCK TABLES;</span><br><span class=\"line\"></span><br><span class=\"line\">--</span><br><span class=\"line\">-- Table structure for table `user`</span><br><span class=\"line\">--</span><br><span class=\"line\"></span><br><span class=\"line\">DROP TABLE IF EXISTS `user`;</span><br><span class=\"line\">/*!40101 SET @saved_cs_client     = @@character_set_client */;</span><br><span class=\"line\">/*!40101 SET character_set_client = utf8 */;</span><br><span class=\"line\">CREATE TABLE `user` (</span><br><span class=\"line\">  `id` varchar(10) DEFAULT NULL,</span><br><span class=\"line\">  `name` varchar(20) DEFAULT NULL,</span><br><span class=\"line\">  `class_id` varchar(10) DEFAULT NULL</span><br><span class=\"line\">) ENGINE=InnoDB DEFAULT CHARSET=latin1;</span><br><span class=\"line\">/*!40101 SET character_set_client = @saved_cs_client */;</span><br><span class=\"line\"></span><br><span class=\"line\">--</span><br><span class=\"line\">-- Dumping data for table `user`</span><br><span class=\"line\">--</span><br><span class=\"line\"></span><br><span class=\"line\">LOCK TABLES `user` WRITE;</span><br><span class=\"line\">/*!40000 ALTER TABLE `user` DISABLE KEYS */;</span><br><span class=\"line\">INSERT INTO `user` VALUES (&apos;1&apos;,&apos;aaa&apos;,&apos;1&apos;),(&apos;2&apos;,&apos;bbb&apos;,&apos;1&apos;),(&apos;3&apos;,&apos;ccc&apos;,&apos;1&apos;),(&apos;4&apos;,&apos;ddd&apos;,&apos;2&apos;),(&apos;5&apos;,&apos;eee&apos;,&apos;2&apos;),(&apos;6&apos;,&apos;fff&apos;,&apos;3&apos;),(&apos;7&apos;,&apos;ggg&apos;,&apos;7&apos;),(&apos;8&apos;,&apos;hhh&apos;,&apos;9&apos;);</span><br><span class=\"line\">/*!40000 ALTER TABLE `user` ENABLE KEYS */;</span><br><span class=\"line\">UNLOCK TABLES;</span><br><span class=\"line\">/*!40103 SET TIME_ZONE=@OLD_TIME_ZONE */;</span><br><span class=\"line\"></span><br><span class=\"line\">/*!40101 SET SQL_MODE=@OLD_SQL_MODE */;</span><br><span class=\"line\">/*!40014 SET FOREIGN_KEY_CHECKS=@OLD_FOREIGN_KEY_CHECKS */;</span><br><span class=\"line\">/*!40014 SET UNIQUE_CHECKS=@OLD_UNIQUE_CHECKS */;</span><br><span class=\"line\">/*!40101 SET CHARACTER_SET_CLIENT=@OLD_CHARACTER_SET_CLIENT */;</span><br><span class=\"line\">/*!40101 SET CHARACTER_SET_RESULTS=@OLD_CHARACTER_SET_RESULTS */;</span><br><span class=\"line\">/*!40101 SET COLLATION_CONNECTION=@OLD_COLLATION_CONNECTION */;</span><br><span class=\"line\">/*!40111 SET SQL_NOTES=@OLD_SQL_NOTES */;</span><br><span class=\"line\"></span><br><span class=\"line\">-- Dump completed on 2018-12-09 17:54:20</span><br></pre></td></tr></table></figure>\n<h1 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h1><ul>\n<li><a href=\"https://www.oschina.net/translate/mysql-joins-on-vs-using-vs-theta-style\" target=\"_blank\" rel=\"noopener\">https://www.oschina.net/translate/mysql-joins-on-vs-using-vs-theta-style</a></li>\n<li><a href=\"https://www.cnblogs.com/BeginMan/p/3754322.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/BeginMan/p/3754322.html</a></li>\n<li><a href=\"http://blog.bittiger.io/post198/\" target=\"_blank\" rel=\"noopener\">http://blog.bittiger.io/post198/</a></li>\n</ul>\n"},{"title":"String Join","date":"2017-07-07T10:01:39.000Z","_content":"### 简单字符串\n直接使用\"+\"，\n例如：\n```\nfull_name = prefix + name\n```\n### 复杂字符串\n有格式化需求时，使用\"%\"进行格式化连接，\n例如：\n```\nresult = \"result is %s:%d\" % (name, score)\n```\n\n### 大量字符串拼接\n发生在循环体里时，使用\"str.join\"进行连接，\n例如：\n```\nresult = ''.join(names_tuple)\n```\n\n## 总结\n前两条出于代码美观考虑，后一条出于性能考虑\n","source":"_posts/string-join.md","raw":"---\ntitle: String Join\ndate: 2017-07-07 18:01:39\ntags: python\n---\n### 简单字符串\n直接使用\"+\"，\n例如：\n```\nfull_name = prefix + name\n```\n### 复杂字符串\n有格式化需求时，使用\"%\"进行格式化连接，\n例如：\n```\nresult = \"result is %s:%d\" % (name, score)\n```\n\n### 大量字符串拼接\n发生在循环体里时，使用\"str.join\"进行连接，\n例如：\n```\nresult = ''.join(names_tuple)\n```\n\n## 总结\n前两条出于代码美观考虑，后一条出于性能考虑\n","slug":"string-join","published":1,"updated":"2018-03-07T05:39:30.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck1pzbtlb001ltp7523pqp5kx","content":"<h3 id=\"简单字符串\"><a href=\"#简单字符串\" class=\"headerlink\" title=\"简单字符串\"></a>简单字符串</h3><p>直接使用”+”，<br>例如：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">full_name = prefix + name</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"复杂字符串\"><a href=\"#复杂字符串\" class=\"headerlink\" title=\"复杂字符串\"></a>复杂字符串</h3><p>有格式化需求时，使用”%”进行格式化连接，<br>例如：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">result = &quot;result is %s:%d&quot; % (name, score)</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"大量字符串拼接\"><a href=\"#大量字符串拼接\" class=\"headerlink\" title=\"大量字符串拼接\"></a>大量字符串拼接</h3><p>发生在循环体里时，使用”str.join”进行连接，<br>例如：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">result = &apos;&apos;.join(names_tuple)</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><p>前两条出于代码美观考虑，后一条出于性能考虑</p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"简单字符串\"><a href=\"#简单字符串\" class=\"headerlink\" title=\"简单字符串\"></a>简单字符串</h3><p>直接使用”+”，<br>例如：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">full_name = prefix + name</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"复杂字符串\"><a href=\"#复杂字符串\" class=\"headerlink\" title=\"复杂字符串\"></a>复杂字符串</h3><p>有格式化需求时，使用”%”进行格式化连接，<br>例如：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">result = &quot;result is %s:%d&quot; % (name, score)</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"大量字符串拼接\"><a href=\"#大量字符串拼接\" class=\"headerlink\" title=\"大量字符串拼接\"></a>大量字符串拼接</h3><p>发生在循环体里时，使用”str.join”进行连接，<br>例如：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">result = &apos;&apos;.join(names_tuple)</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><p>前两条出于代码美观考虑，后一条出于性能考虑</p>\n"},{"title":"timedatectl","date":"2017-09-12T10:00:19.000Z","_content":"CentOS 7 设置日期和时间\n\n在CentOS 6版本，时间设置有date、hwclock命令，从CentOS 7开始，使用了一个新的命令timedatectl。\n\n一、基本概念\n\n1.1 GMT、UTC、CST、DST 时间\n\n(1) UTC\n\n整个地球分为二十四时区，每个时区都有自己的本地时间。在国际无线电通信场合，为了统一起见，使用一个统一的时间，称为通用协调时(UTC, Universal Time Coordinated)。\n\n(2) GMT\n\n格林威治标准时间 (Greenwich Mean Time)指位于英国伦敦郊区的皇家格林尼治天文台的标准时间，因为本初子午线被定义在通过那里的经线。(UTC与GMT时间基本相同，本文中不做区分)\n\n(3) CST\n\n中国标准时间 (China Standard Time)\n\n1\nGMT + 8 = UTC + 8 = CST\n(4) DST\n\n夏令时(Daylight Saving Time) 指在夏天太阳升起的比较早时，将时钟拨快一小时，以提早日光的使用。（中国不使用）\n\n1.2 硬件时钟和系统时钟\n\n(1) 硬件时钟\n\nRTC(Real-Time Clock)或CMOS时钟，一般在主板上靠电池供电，服务器断电后也会继续运行。仅保存日期时间数值，无法保存时区和夏令时设置。\n\n(2) 系统时钟\n\n一般在服务器启动时复制RTC时间，之后独立运行，保存了时间、时区和夏令时设置。\n\n二、timedatectl 命令\n\n2.1 读取时间\n\n```\ntimedatectl //等同于 timedatectl status\n```\n2.2 设置时间\n\n```\ntimedatectl set-time \"YYYY-MM-DD HH:MM:SS\"\n```\n\n2.3 列出所有时区\n\n```\ntimedatectl list-timezones\n```\n\n2.4 设置时区\n\n```\ntimedatectl set-timezone Asia/Shanghai\n```\n\n2.5 是否NTP服务器同步\n\n```\ntimedatectl set-ntp yes //yes或者no\n```\n\n2.6 将硬件时钟调整为与本地时钟一致\n\n```\ntimedatectl set-local-rtc 1\nhwclock --systohc --localtime //与上面命令效果一致\n```\n注意 硬件时钟默认使用UTC时间，因为硬件时钟不能保存时区和夏令时调整，修改后就无法从硬件时钟中读取出准确标准时间，因此不建议修改。修改后系统会出现警告。\n\n2.6 硬件时间设置成 UTC：\n\n```\ntimedatectl set-local-rtc 1\nhwclock --systohc --utc //与上面命令效果一致\n```\n\n三、设置系统时间为中国时区并启用NTP同步\n\n```\nyum install ntp //安装ntp服务\nsystemctl enable ntpd //开机启动服务\nsystemctl start ntpd //启动服务\ntimedatectl set-timezone Asia/Shanghai //更改时区\ntimedatectl set-ntp yes //启用ntp同步\nntpq -p //同步时间\n```\n如需更改时间服务器, 修改 /etc/ntp.conf 文件中的服务器地址 server 即可.","source":"_posts/timedatectl.md","raw":"---\ntitle: timedatectl\ndate: 2017-09-12 18:00:19\ntags:\n---\nCentOS 7 设置日期和时间\n\n在CentOS 6版本，时间设置有date、hwclock命令，从CentOS 7开始，使用了一个新的命令timedatectl。\n\n一、基本概念\n\n1.1 GMT、UTC、CST、DST 时间\n\n(1) UTC\n\n整个地球分为二十四时区，每个时区都有自己的本地时间。在国际无线电通信场合，为了统一起见，使用一个统一的时间，称为通用协调时(UTC, Universal Time Coordinated)。\n\n(2) GMT\n\n格林威治标准时间 (Greenwich Mean Time)指位于英国伦敦郊区的皇家格林尼治天文台的标准时间，因为本初子午线被定义在通过那里的经线。(UTC与GMT时间基本相同，本文中不做区分)\n\n(3) CST\n\n中国标准时间 (China Standard Time)\n\n1\nGMT + 8 = UTC + 8 = CST\n(4) DST\n\n夏令时(Daylight Saving Time) 指在夏天太阳升起的比较早时，将时钟拨快一小时，以提早日光的使用。（中国不使用）\n\n1.2 硬件时钟和系统时钟\n\n(1) 硬件时钟\n\nRTC(Real-Time Clock)或CMOS时钟，一般在主板上靠电池供电，服务器断电后也会继续运行。仅保存日期时间数值，无法保存时区和夏令时设置。\n\n(2) 系统时钟\n\n一般在服务器启动时复制RTC时间，之后独立运行，保存了时间、时区和夏令时设置。\n\n二、timedatectl 命令\n\n2.1 读取时间\n\n```\ntimedatectl //等同于 timedatectl status\n```\n2.2 设置时间\n\n```\ntimedatectl set-time \"YYYY-MM-DD HH:MM:SS\"\n```\n\n2.3 列出所有时区\n\n```\ntimedatectl list-timezones\n```\n\n2.4 设置时区\n\n```\ntimedatectl set-timezone Asia/Shanghai\n```\n\n2.5 是否NTP服务器同步\n\n```\ntimedatectl set-ntp yes //yes或者no\n```\n\n2.6 将硬件时钟调整为与本地时钟一致\n\n```\ntimedatectl set-local-rtc 1\nhwclock --systohc --localtime //与上面命令效果一致\n```\n注意 硬件时钟默认使用UTC时间，因为硬件时钟不能保存时区和夏令时调整，修改后就无法从硬件时钟中读取出准确标准时间，因此不建议修改。修改后系统会出现警告。\n\n2.6 硬件时间设置成 UTC：\n\n```\ntimedatectl set-local-rtc 1\nhwclock --systohc --utc //与上面命令效果一致\n```\n\n三、设置系统时间为中国时区并启用NTP同步\n\n```\nyum install ntp //安装ntp服务\nsystemctl enable ntpd //开机启动服务\nsystemctl start ntpd //启动服务\ntimedatectl set-timezone Asia/Shanghai //更改时区\ntimedatectl set-ntp yes //启用ntp同步\nntpq -p //同步时间\n```\n如需更改时间服务器, 修改 /etc/ntp.conf 文件中的服务器地址 server 即可.","slug":"timedatectl","published":1,"updated":"2018-03-07T05:39:30.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck1pzbtle001ntp75rbgnr2uv","content":"<p>CentOS 7 设置日期和时间</p>\n<p>在CentOS 6版本，时间设置有date、hwclock命令，从CentOS 7开始，使用了一个新的命令timedatectl。</p>\n<p>一、基本概念</p>\n<p>1.1 GMT、UTC、CST、DST 时间</p>\n<p>(1) UTC</p>\n<p>整个地球分为二十四时区，每个时区都有自己的本地时间。在国际无线电通信场合，为了统一起见，使用一个统一的时间，称为通用协调时(UTC, Universal Time Coordinated)。</p>\n<p>(2) GMT</p>\n<p>格林威治标准时间 (Greenwich Mean Time)指位于英国伦敦郊区的皇家格林尼治天文台的标准时间，因为本初子午线被定义在通过那里的经线。(UTC与GMT时间基本相同，本文中不做区分)</p>\n<p>(3) CST</p>\n<p>中国标准时间 (China Standard Time)</p>\n<p>1<br>GMT + 8 = UTC + 8 = CST<br>(4) DST</p>\n<p>夏令时(Daylight Saving Time) 指在夏天太阳升起的比较早时，将时钟拨快一小时，以提早日光的使用。（中国不使用）</p>\n<p>1.2 硬件时钟和系统时钟</p>\n<p>(1) 硬件时钟</p>\n<p>RTC(Real-Time Clock)或CMOS时钟，一般在主板上靠电池供电，服务器断电后也会继续运行。仅保存日期时间数值，无法保存时区和夏令时设置。</p>\n<p>(2) 系统时钟</p>\n<p>一般在服务器启动时复制RTC时间，之后独立运行，保存了时间、时区和夏令时设置。</p>\n<p>二、timedatectl 命令</p>\n<p>2.1 读取时间</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">timedatectl //等同于 timedatectl status</span><br></pre></td></tr></table></figure>\n<p>2.2 设置时间</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">timedatectl set-time &quot;YYYY-MM-DD HH:MM:SS&quot;</span><br></pre></td></tr></table></figure>\n<p>2.3 列出所有时区</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">timedatectl list-timezones</span><br></pre></td></tr></table></figure>\n<p>2.4 设置时区</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">timedatectl set-timezone Asia/Shanghai</span><br></pre></td></tr></table></figure>\n<p>2.5 是否NTP服务器同步</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">timedatectl set-ntp yes //yes或者no</span><br></pre></td></tr></table></figure>\n<p>2.6 将硬件时钟调整为与本地时钟一致</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">timedatectl set-local-rtc 1</span><br><span class=\"line\">hwclock --systohc --localtime //与上面命令效果一致</span><br></pre></td></tr></table></figure>\n<p>注意 硬件时钟默认使用UTC时间，因为硬件时钟不能保存时区和夏令时调整，修改后就无法从硬件时钟中读取出准确标准时间，因此不建议修改。修改后系统会出现警告。</p>\n<p>2.6 硬件时间设置成 UTC：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">timedatectl set-local-rtc 1</span><br><span class=\"line\">hwclock --systohc --utc //与上面命令效果一致</span><br></pre></td></tr></table></figure>\n<p>三、设置系统时间为中国时区并启用NTP同步</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">yum install ntp //安装ntp服务</span><br><span class=\"line\">systemctl enable ntpd //开机启动服务</span><br><span class=\"line\">systemctl start ntpd //启动服务</span><br><span class=\"line\">timedatectl set-timezone Asia/Shanghai //更改时区</span><br><span class=\"line\">timedatectl set-ntp yes //启用ntp同步</span><br><span class=\"line\">ntpq -p //同步时间</span><br></pre></td></tr></table></figure>\n<p>如需更改时间服务器, 修改 /etc/ntp.conf 文件中的服务器地址 server 即可.</p>\n","site":{"data":{}},"excerpt":"","more":"<p>CentOS 7 设置日期和时间</p>\n<p>在CentOS 6版本，时间设置有date、hwclock命令，从CentOS 7开始，使用了一个新的命令timedatectl。</p>\n<p>一、基本概念</p>\n<p>1.1 GMT、UTC、CST、DST 时间</p>\n<p>(1) UTC</p>\n<p>整个地球分为二十四时区，每个时区都有自己的本地时间。在国际无线电通信场合，为了统一起见，使用一个统一的时间，称为通用协调时(UTC, Universal Time Coordinated)。</p>\n<p>(2) GMT</p>\n<p>格林威治标准时间 (Greenwich Mean Time)指位于英国伦敦郊区的皇家格林尼治天文台的标准时间，因为本初子午线被定义在通过那里的经线。(UTC与GMT时间基本相同，本文中不做区分)</p>\n<p>(3) CST</p>\n<p>中国标准时间 (China Standard Time)</p>\n<p>1<br>GMT + 8 = UTC + 8 = CST<br>(4) DST</p>\n<p>夏令时(Daylight Saving Time) 指在夏天太阳升起的比较早时，将时钟拨快一小时，以提早日光的使用。（中国不使用）</p>\n<p>1.2 硬件时钟和系统时钟</p>\n<p>(1) 硬件时钟</p>\n<p>RTC(Real-Time Clock)或CMOS时钟，一般在主板上靠电池供电，服务器断电后也会继续运行。仅保存日期时间数值，无法保存时区和夏令时设置。</p>\n<p>(2) 系统时钟</p>\n<p>一般在服务器启动时复制RTC时间，之后独立运行，保存了时间、时区和夏令时设置。</p>\n<p>二、timedatectl 命令</p>\n<p>2.1 读取时间</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">timedatectl //等同于 timedatectl status</span><br></pre></td></tr></table></figure>\n<p>2.2 设置时间</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">timedatectl set-time &quot;YYYY-MM-DD HH:MM:SS&quot;</span><br></pre></td></tr></table></figure>\n<p>2.3 列出所有时区</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">timedatectl list-timezones</span><br></pre></td></tr></table></figure>\n<p>2.4 设置时区</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">timedatectl set-timezone Asia/Shanghai</span><br></pre></td></tr></table></figure>\n<p>2.5 是否NTP服务器同步</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">timedatectl set-ntp yes //yes或者no</span><br></pre></td></tr></table></figure>\n<p>2.6 将硬件时钟调整为与本地时钟一致</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">timedatectl set-local-rtc 1</span><br><span class=\"line\">hwclock --systohc --localtime //与上面命令效果一致</span><br></pre></td></tr></table></figure>\n<p>注意 硬件时钟默认使用UTC时间，因为硬件时钟不能保存时区和夏令时调整，修改后就无法从硬件时钟中读取出准确标准时间，因此不建议修改。修改后系统会出现警告。</p>\n<p>2.6 硬件时间设置成 UTC：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">timedatectl set-local-rtc 1</span><br><span class=\"line\">hwclock --systohc --utc //与上面命令效果一致</span><br></pre></td></tr></table></figure>\n<p>三、设置系统时间为中国时区并启用NTP同步</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">yum install ntp //安装ntp服务</span><br><span class=\"line\">systemctl enable ntpd //开机启动服务</span><br><span class=\"line\">systemctl start ntpd //启动服务</span><br><span class=\"line\">timedatectl set-timezone Asia/Shanghai //更改时区</span><br><span class=\"line\">timedatectl set-ntp yes //启用ntp同步</span><br><span class=\"line\">ntpq -p //同步时间</span><br></pre></td></tr></table></figure>\n<p>如需更改时间服务器, 修改 /etc/ntp.conf 文件中的服务器地址 server 即可.</p>\n"},{"title":"tidb-operator","date":"2019-03-18T03:22:15.000Z","_content":"\n# 概述\ntidb是一个分布式的数据库，tidb-operator可以让tidb跑在k8s集群上面。  \n本文主要验证tidb使用local pv方式部署在k8s集群上面。\n\n# 安装\n\n实验环境的k8s环境共有三个节点\n\n```\n[root@kube01 ~]# kubectl get nodes\nNAME     STATUS   ROLES    AGE    VERSION\nkube01   Ready    master   3d5h   v1.13.4\nkube02   Ready    master   3d5h   v1.13.4\nkube03   Ready    master   3d5h   v1.13.4\n\n```\n\n\ntidb安装过程中需要用到6个pv，pd需要用到3个1G的pv，tikv需要用到3个10G的pv。  \n环境中有一块20G的空闲磁盘vdc，我们把vdc分成两个分区，一个2G，一个18G。\n\n```\n[root@kube01 ~]# sgdisk -n 1:0:+2G /dev/vdc\nCreating new GPT entries.\nThe operation has completed successfully.\n[root@kube01 ~]# sgdisk -n 2:0:0 /dev/vdc\nThe operation has completed successfully.\n\n```\n\ntidb-operator默认会把挂载在/mnt/disks/vol$i 的分区作为一个PV，所以把我们vdc1和vdc2这两个分区挂载在vol0和vol1下。  \ntidb推荐使用ext4文件系统\n\n```\nmkfs.ext4 /dev/vdc1\nmkfs.ext4 /dev/vdc2\nmount /dev/vdc1 /mnt/disks/vol0/\nmount /dev/vdc1 /mnt/disks/vol1/\n```\n\n通过tidb-opertor提供的local-volumen-provisioner可以把前面的分区变成local pv\n\n```\n[root@kube01 local-dind]# kubectl apply -f local-volume-provisioner.yaml\nstorageclass.storage.k8s.io/local-storage changed\nconfigmap/local-provisioner-config changed\ndaemonset.extensions/local-volume-provisioner changed\nserviceaccount/local-storage-admin changed\nclusterrolebinding.rbac.authorization.k8s.io/local-storage-provisioner-pv-binding changed\nclusterrole.rbac.authorization.k8s.io/local-storage-provisioner-node-clusterrole changed\nclusterrolebinding.rbac.authorization.k8s.io/local-storage-provisioner-node-binding changed\n\n```\n\n通过helm安装tidb-operator\n\n需要修改charts/tidb-operator/values.yaml文件中  \nkubeSchedulerImage: gcr.io/google-containers/hyperkube:v1.13.4  \n镜像的版本和kubelet的版本一致。\n\n```\n\n[root@kube01 manifests]# kubectl apply -f crd.yaml\ncustomresourcedefinition.apiextensions.k8s.io/tidbclusters.pingcap.com created\n\n[root@kube01 tidb-operator]# kubectl get customresourcedefinitions\nNAME                                CREATED AT\ntidbclusters.pingcap.com            2019-03-18T05:53:22Z\n\n\n[root@kube01 tidb-operator]# helm install charts/tidb-operator --name=tidb-operator --namespace=tidb-admin\nNAME:   tidb-operator\nLAST DEPLOYED: Mon Mar 18 14:46:32 2019\nNAMESPACE: tidb-admin\nSTATUS: DEPLOYED\n\nRESOURCES:\n==> v1/ConfigMap\nNAME                   DATA  AGE\ntidb-scheduler-policy  1     0s\n\n==> v1/Pod(related)\nNAME                                      READY  STATUS             RESTARTS  AGE\ntidb-controller-manager-7c56fb85dd-h6k5m  0/1    ContainerCreating  0         0s\ntidb-scheduler-7f8b69d57b-xx8jq           0/2    ContainerCreating  0         0s\n\n==> v1/ServiceAccount\nNAME                     SECRETS  AGE\ntidb-controller-manager  1        0s\ntidb-scheduler           1        0s\n\n==> v1beta1/ClusterRole\nNAME                                   AGE\ntidb-operator:tidb-controller-manager  0s\ntidb-operator:tidb-scheduler           0s\n\n==> v1beta1/ClusterRoleBinding\nNAME                                   AGE\ntidb-operator:tidb-controller-manager  0s\ntidb-operator:tidb-scheduler           0s\n\n==> v1beta1/Deployment\nNAME                     READY  UP-TO-DATE  AVAILABLE  AGE\ntidb-controller-manager  0/1    1           0          0s\ntidb-scheduler           0/1    1           0          0s\n\n\nNOTES:\n1. Make sure tidb-operator components are running\n   kubectl get pods --namespace tidb-admin -l app.kubernetes.io/instance=tidb-operator\n2. Install CRD\n   kubectl apply -f https://raw.githubusercontent.com/pingcap/tidb-operator/master/manifests/crd.yaml\n   kubectl get customresourcedefinitions\n3. Modify tidb-cluster/values.yaml and create a TiDB cluster by installing tidb-cluster charts\n   helm install tidb-cluster\n\n\n[root@kube01 tidb-operator]# kubectl get pods --namespace tidb-admin -l app.kubernetes.io/instance=tidb-operator\nNAME                                       READY   STATUS    RESTARTS   AGE\ntidb-controller-manager-7c56fb85dd-h6k5m   1/1     Running   0          5m11s\ntidb-scheduler-7f8b69d57b-xx8jq            2/2     Running   0          5m11s\n```\n\n通过helm安装tidb-cluster\n\n```\n\n[root@kube01 tidb-operator]# helm install charts/tidb-cluster --name=tidb-cluster --namespace=tidb\nNAME:   tidb-cluster\nLAST DEPLOYED: Mon Mar 18 14:57:35 2019\nNAMESPACE: tidb\nSTATUS: DEPLOYED\n\nRESOURCES:\n==> v1/ConfigMap\nNAME          DATA  AGE\ndemo-monitor  3     0s\ndemo-pd       2     0s\ndemo-tidb     2     0s\ndemo-tikv     2     0s\n\n==> v1/Job\nNAME                       COMPLETIONS  DURATION  AGE\ndemo-monitor-configurator  0/1          0s        0s\ndemo-tidb-initializer      0/1          0s        0s\n\n==> v1/Pod(related)\nNAME                             READY  STATUS             RESTARTS  AGE\ndemo-discovery-5468c7c556-8dcs5  0/1    ContainerCreating  0         0s\ndemo-monitor-84446b7957-rbdl9    0/2    Init:0/1           0         0s\ndemo-monitor-configurator-vz25r  0/1    ContainerCreating  0         0s\ndemo-tidb-initializer-dh8v2      0/1    ContainerCreating  0         0s\n\n==> v1/Secret\nNAME          TYPE    DATA  AGE\ndemo-monitor  Opaque  2     0s\ndemo-tidb     Opaque  1     0s\n\n==> v1/Service\nNAME             TYPE       CLUSTER-IP      EXTERNAL-IP  PORT(S)                         AGE\ndemo-discovery   ClusterIP  172.30.201.100  <none>       10261/TCP                       0s\ndemo-grafana     NodePort   172.30.122.104  <none>       3000:32242/TCP                  0s\ndemo-prometheus  NodePort   172.30.59.221   <none>       9090:32099/TCP                  0s\ndemo-tidb        NodePort   172.30.181.223  <none>       4000:30344/TCP,10080:32651/TCP  0s\n\n==> v1/ServiceAccount\nNAME            SECRETS  AGE\ndemo-discovery  1        0s\ndemo-monitor    1        0s\n\n==> v1alpha1/TidbCluster\nNAME  AGE\ndemo  0s\n\n\n==> v1beta1/Deployment\nNAME            READY  UP-TO-DATE  AVAILABLE  AGE\ndemo-discovery  0/1    1           0          0s\ndemo-monitor    0/1    1           0          0s\n\n==> v1beta1/Role\nNAME            AGE\ndemo-discovery  0s\ndemo-monitor    0s\n\n==> v1beta1/RoleBinding\nNAME            AGE\ndemo-discovery  0s\ndemo-monitor    0s\n\n\nNOTES:\n1. Watch tidb-cluster up and running\n   watch kubectl get pods --namespace tidb -l app.kubernetes.io/instance=tidb-cluster -o wide\n2. List services in the tidb-cluster\n   kubectl get services --namespace tidb -l app.kubernetes.io/instance=tidb-cluster\n3. Wait until tidb-initializer pod becomes completed\n   watch kubectl get po --namespace tidb  -l app.kubernetes.io/component=tidb-initializer\n4. Get the TiDB password\n   PASSWORD=$(kubectl get secret -n tidb demo-tidb -o jsonpath=\"{.data.password}\" | base64 --decode | awk '{print $6}')\n   echo ${PASSWORD}\n5. Access tidb-cluster using the MySQL client\n   kubectl port-forward -n tidb svc/demo-tidb 4000:4000 &\n   mysql -h 127.0.0.1 -P 4000 -u root -D test -p\n6. View monitor dashboard for TiDB cluster\n   kubectl port-forward -n tidb svc/demo-grafana 3000:3000\n   Open browser at http://localhost:3000. The default username and password is admin/admin.\n\n\n[root@kube01 tidb-operator]# kubectl get tidbcluster -n tidb\nNAME   AGE\ndemo   1m\n\n[root@kube01 tidb-operator]# kubectl get statefulset -n tidb\nNAME        READY   AGE\ndemo-pd     3/3     5m41s\ndemo-tidb   2/2     3m16s\ndemo-tikv   3/3     5m\n\n[root@kube01 tidb-operator]# kubectl get service -n tidb\nNAME              TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)                          AGE\ndemo-discovery    ClusterIP   172.30.25.248    <none>        10261/TCP                        6m\ndemo-grafana      NodePort    172.30.103.60    <none>        3000:31597/TCP                   6m\ndemo-pd           ClusterIP   172.30.122.100   <none>        2379/TCP                         6m\ndemo-pd-peer      ClusterIP   None             <none>        2380/TCP                         6m\ndemo-prometheus   NodePort    172.30.147.201   <none>        9090:30429/TCP                   6m\ndemo-tidb         NodePort    172.30.244.61    <none>        4000:30512/TCP,10080:31051/TCP   6m\ndemo-tidb-peer    ClusterIP   None             <none>        10080/TCP                        3m34s\ndemo-tikv-peer    ClusterIP   None             <none>        20160/TCP                        5m18s\n\n\n[root@kube01 tidb-operator]# kubectl get configmap -n tidb\nNAME           DATA   AGE\ndemo-monitor   3      6m20s\ndemo-pd        2      6m20s\ndemo-tidb      2      6m20s\ndemo-tikv      2      6m20s\n\n\n[root@kube01 tidb-operator]# kubectl get pod -n tidb\nNAME                              READY   STATUS      RESTARTS   AGE\ndemo-discovery-5468c7c556-l9xl7   1/1     Running     0          6m41s\ndemo-monitor-84446b7957-4zsnd     2/2     Running     0          6m41s\ndemo-monitor-configurator-rnklq   0/1     Completed   0          6m41s\ndemo-pd-0                         1/1     Running     0          6m40s\ndemo-pd-1                         1/1     Running     0          6m40s\ndemo-pd-2                         1/1     Running     1          6m40s\ndemo-tidb-0                       1/1     Running     0          4m15s\ndemo-tidb-1                       1/1     Running     0          4m15s\ndemo-tidb-initializer-nkng4       0/1     Completed   0          6m41s\ndemo-tikv-0                       2/2     Running     0          5m59s\ndemo-tikv-1                       2/2     Running     0          5m59s\ndemo-tikv-2                       2/2     Running     0          5m59s\n\n\n```\n\n通过mysql client进行验证\n\n```\n[root@kube01 tidb-operator]# kubectl port-forward svc/demo-tidb 4000:4000 --namespace=tidb\nForwarding from 127.0.0.1:4000 -> 4000\n\n\n[root@kube01 ~]# PASSWORD=$(kubectl get secret -n tidb demo-tidb -ojsonpath=\"{.data.password}\" | base64 --decode | awk '{print $6}')\n[root@kube01 ~]# echo ${PASSWORD}\n'IwDSSjpq89'\n[root@kube01 ~]# mysql -h 127.0.0.1 -P 4000 -u root -p\nEnter password:\nWelcome to the MariaDB monitor.  Commands end with ; or \\g.\nYour MySQL connection id is 3\nServer version: 5.7.10-TiDB-v2.1.4 MySQL Community Server (Apache License 2.0)\n\nCopyright (c) 2000, 2018, Oracle, MariaDB Corporation Ab and others.\n\nType 'help;' or '\\h' for help. Type '\\c' to clear the current input statement.\n\nMySQL [(none)]> show databases;\n+--------------------+\n| Database           |\n+--------------------+\n| INFORMATION_SCHEMA |\n| PERFORMANCE_SCHEMA |\n| mysql              |\n| test               |\n+--------------------+\n4 rows in set (0.00 sec)\n\nMySQL [(none)]>\n\n```\n\n# 参考\n\n* [https://github.com/pingcap/tidb-operator/blob/master/docs/local-dind-tutorial.md](https://github.com/pingcap/tidb-operator/blob/master/docs/local-dind-tutorial.md)\n* [https://github.com/pingcap/tidb-operator/blob/master/docs/setup.md](https://github.com/pingcap/tidb-operator/blob/master/docs/setup.md)","source":"_posts/tidb-k8s.md","raw":"---\ntitle: tidb-operator\ndate: 2019-03-18 11:22:15\ntags: ['k8s']\t\n---\n\n# 概述\ntidb是一个分布式的数据库，tidb-operator可以让tidb跑在k8s集群上面。  \n本文主要验证tidb使用local pv方式部署在k8s集群上面。\n\n# 安装\n\n实验环境的k8s环境共有三个节点\n\n```\n[root@kube01 ~]# kubectl get nodes\nNAME     STATUS   ROLES    AGE    VERSION\nkube01   Ready    master   3d5h   v1.13.4\nkube02   Ready    master   3d5h   v1.13.4\nkube03   Ready    master   3d5h   v1.13.4\n\n```\n\n\ntidb安装过程中需要用到6个pv，pd需要用到3个1G的pv，tikv需要用到3个10G的pv。  \n环境中有一块20G的空闲磁盘vdc，我们把vdc分成两个分区，一个2G，一个18G。\n\n```\n[root@kube01 ~]# sgdisk -n 1:0:+2G /dev/vdc\nCreating new GPT entries.\nThe operation has completed successfully.\n[root@kube01 ~]# sgdisk -n 2:0:0 /dev/vdc\nThe operation has completed successfully.\n\n```\n\ntidb-operator默认会把挂载在/mnt/disks/vol$i 的分区作为一个PV，所以把我们vdc1和vdc2这两个分区挂载在vol0和vol1下。  \ntidb推荐使用ext4文件系统\n\n```\nmkfs.ext4 /dev/vdc1\nmkfs.ext4 /dev/vdc2\nmount /dev/vdc1 /mnt/disks/vol0/\nmount /dev/vdc1 /mnt/disks/vol1/\n```\n\n通过tidb-opertor提供的local-volumen-provisioner可以把前面的分区变成local pv\n\n```\n[root@kube01 local-dind]# kubectl apply -f local-volume-provisioner.yaml\nstorageclass.storage.k8s.io/local-storage changed\nconfigmap/local-provisioner-config changed\ndaemonset.extensions/local-volume-provisioner changed\nserviceaccount/local-storage-admin changed\nclusterrolebinding.rbac.authorization.k8s.io/local-storage-provisioner-pv-binding changed\nclusterrole.rbac.authorization.k8s.io/local-storage-provisioner-node-clusterrole changed\nclusterrolebinding.rbac.authorization.k8s.io/local-storage-provisioner-node-binding changed\n\n```\n\n通过helm安装tidb-operator\n\n需要修改charts/tidb-operator/values.yaml文件中  \nkubeSchedulerImage: gcr.io/google-containers/hyperkube:v1.13.4  \n镜像的版本和kubelet的版本一致。\n\n```\n\n[root@kube01 manifests]# kubectl apply -f crd.yaml\ncustomresourcedefinition.apiextensions.k8s.io/tidbclusters.pingcap.com created\n\n[root@kube01 tidb-operator]# kubectl get customresourcedefinitions\nNAME                                CREATED AT\ntidbclusters.pingcap.com            2019-03-18T05:53:22Z\n\n\n[root@kube01 tidb-operator]# helm install charts/tidb-operator --name=tidb-operator --namespace=tidb-admin\nNAME:   tidb-operator\nLAST DEPLOYED: Mon Mar 18 14:46:32 2019\nNAMESPACE: tidb-admin\nSTATUS: DEPLOYED\n\nRESOURCES:\n==> v1/ConfigMap\nNAME                   DATA  AGE\ntidb-scheduler-policy  1     0s\n\n==> v1/Pod(related)\nNAME                                      READY  STATUS             RESTARTS  AGE\ntidb-controller-manager-7c56fb85dd-h6k5m  0/1    ContainerCreating  0         0s\ntidb-scheduler-7f8b69d57b-xx8jq           0/2    ContainerCreating  0         0s\n\n==> v1/ServiceAccount\nNAME                     SECRETS  AGE\ntidb-controller-manager  1        0s\ntidb-scheduler           1        0s\n\n==> v1beta1/ClusterRole\nNAME                                   AGE\ntidb-operator:tidb-controller-manager  0s\ntidb-operator:tidb-scheduler           0s\n\n==> v1beta1/ClusterRoleBinding\nNAME                                   AGE\ntidb-operator:tidb-controller-manager  0s\ntidb-operator:tidb-scheduler           0s\n\n==> v1beta1/Deployment\nNAME                     READY  UP-TO-DATE  AVAILABLE  AGE\ntidb-controller-manager  0/1    1           0          0s\ntidb-scheduler           0/1    1           0          0s\n\n\nNOTES:\n1. Make sure tidb-operator components are running\n   kubectl get pods --namespace tidb-admin -l app.kubernetes.io/instance=tidb-operator\n2. Install CRD\n   kubectl apply -f https://raw.githubusercontent.com/pingcap/tidb-operator/master/manifests/crd.yaml\n   kubectl get customresourcedefinitions\n3. Modify tidb-cluster/values.yaml and create a TiDB cluster by installing tidb-cluster charts\n   helm install tidb-cluster\n\n\n[root@kube01 tidb-operator]# kubectl get pods --namespace tidb-admin -l app.kubernetes.io/instance=tidb-operator\nNAME                                       READY   STATUS    RESTARTS   AGE\ntidb-controller-manager-7c56fb85dd-h6k5m   1/1     Running   0          5m11s\ntidb-scheduler-7f8b69d57b-xx8jq            2/2     Running   0          5m11s\n```\n\n通过helm安装tidb-cluster\n\n```\n\n[root@kube01 tidb-operator]# helm install charts/tidb-cluster --name=tidb-cluster --namespace=tidb\nNAME:   tidb-cluster\nLAST DEPLOYED: Mon Mar 18 14:57:35 2019\nNAMESPACE: tidb\nSTATUS: DEPLOYED\n\nRESOURCES:\n==> v1/ConfigMap\nNAME          DATA  AGE\ndemo-monitor  3     0s\ndemo-pd       2     0s\ndemo-tidb     2     0s\ndemo-tikv     2     0s\n\n==> v1/Job\nNAME                       COMPLETIONS  DURATION  AGE\ndemo-monitor-configurator  0/1          0s        0s\ndemo-tidb-initializer      0/1          0s        0s\n\n==> v1/Pod(related)\nNAME                             READY  STATUS             RESTARTS  AGE\ndemo-discovery-5468c7c556-8dcs5  0/1    ContainerCreating  0         0s\ndemo-monitor-84446b7957-rbdl9    0/2    Init:0/1           0         0s\ndemo-monitor-configurator-vz25r  0/1    ContainerCreating  0         0s\ndemo-tidb-initializer-dh8v2      0/1    ContainerCreating  0         0s\n\n==> v1/Secret\nNAME          TYPE    DATA  AGE\ndemo-monitor  Opaque  2     0s\ndemo-tidb     Opaque  1     0s\n\n==> v1/Service\nNAME             TYPE       CLUSTER-IP      EXTERNAL-IP  PORT(S)                         AGE\ndemo-discovery   ClusterIP  172.30.201.100  <none>       10261/TCP                       0s\ndemo-grafana     NodePort   172.30.122.104  <none>       3000:32242/TCP                  0s\ndemo-prometheus  NodePort   172.30.59.221   <none>       9090:32099/TCP                  0s\ndemo-tidb        NodePort   172.30.181.223  <none>       4000:30344/TCP,10080:32651/TCP  0s\n\n==> v1/ServiceAccount\nNAME            SECRETS  AGE\ndemo-discovery  1        0s\ndemo-monitor    1        0s\n\n==> v1alpha1/TidbCluster\nNAME  AGE\ndemo  0s\n\n\n==> v1beta1/Deployment\nNAME            READY  UP-TO-DATE  AVAILABLE  AGE\ndemo-discovery  0/1    1           0          0s\ndemo-monitor    0/1    1           0          0s\n\n==> v1beta1/Role\nNAME            AGE\ndemo-discovery  0s\ndemo-monitor    0s\n\n==> v1beta1/RoleBinding\nNAME            AGE\ndemo-discovery  0s\ndemo-monitor    0s\n\n\nNOTES:\n1. Watch tidb-cluster up and running\n   watch kubectl get pods --namespace tidb -l app.kubernetes.io/instance=tidb-cluster -o wide\n2. List services in the tidb-cluster\n   kubectl get services --namespace tidb -l app.kubernetes.io/instance=tidb-cluster\n3. Wait until tidb-initializer pod becomes completed\n   watch kubectl get po --namespace tidb  -l app.kubernetes.io/component=tidb-initializer\n4. Get the TiDB password\n   PASSWORD=$(kubectl get secret -n tidb demo-tidb -o jsonpath=\"{.data.password}\" | base64 --decode | awk '{print $6}')\n   echo ${PASSWORD}\n5. Access tidb-cluster using the MySQL client\n   kubectl port-forward -n tidb svc/demo-tidb 4000:4000 &\n   mysql -h 127.0.0.1 -P 4000 -u root -D test -p\n6. View monitor dashboard for TiDB cluster\n   kubectl port-forward -n tidb svc/demo-grafana 3000:3000\n   Open browser at http://localhost:3000. The default username and password is admin/admin.\n\n\n[root@kube01 tidb-operator]# kubectl get tidbcluster -n tidb\nNAME   AGE\ndemo   1m\n\n[root@kube01 tidb-operator]# kubectl get statefulset -n tidb\nNAME        READY   AGE\ndemo-pd     3/3     5m41s\ndemo-tidb   2/2     3m16s\ndemo-tikv   3/3     5m\n\n[root@kube01 tidb-operator]# kubectl get service -n tidb\nNAME              TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)                          AGE\ndemo-discovery    ClusterIP   172.30.25.248    <none>        10261/TCP                        6m\ndemo-grafana      NodePort    172.30.103.60    <none>        3000:31597/TCP                   6m\ndemo-pd           ClusterIP   172.30.122.100   <none>        2379/TCP                         6m\ndemo-pd-peer      ClusterIP   None             <none>        2380/TCP                         6m\ndemo-prometheus   NodePort    172.30.147.201   <none>        9090:30429/TCP                   6m\ndemo-tidb         NodePort    172.30.244.61    <none>        4000:30512/TCP,10080:31051/TCP   6m\ndemo-tidb-peer    ClusterIP   None             <none>        10080/TCP                        3m34s\ndemo-tikv-peer    ClusterIP   None             <none>        20160/TCP                        5m18s\n\n\n[root@kube01 tidb-operator]# kubectl get configmap -n tidb\nNAME           DATA   AGE\ndemo-monitor   3      6m20s\ndemo-pd        2      6m20s\ndemo-tidb      2      6m20s\ndemo-tikv      2      6m20s\n\n\n[root@kube01 tidb-operator]# kubectl get pod -n tidb\nNAME                              READY   STATUS      RESTARTS   AGE\ndemo-discovery-5468c7c556-l9xl7   1/1     Running     0          6m41s\ndemo-monitor-84446b7957-4zsnd     2/2     Running     0          6m41s\ndemo-monitor-configurator-rnklq   0/1     Completed   0          6m41s\ndemo-pd-0                         1/1     Running     0          6m40s\ndemo-pd-1                         1/1     Running     0          6m40s\ndemo-pd-2                         1/1     Running     1          6m40s\ndemo-tidb-0                       1/1     Running     0          4m15s\ndemo-tidb-1                       1/1     Running     0          4m15s\ndemo-tidb-initializer-nkng4       0/1     Completed   0          6m41s\ndemo-tikv-0                       2/2     Running     0          5m59s\ndemo-tikv-1                       2/2     Running     0          5m59s\ndemo-tikv-2                       2/2     Running     0          5m59s\n\n\n```\n\n通过mysql client进行验证\n\n```\n[root@kube01 tidb-operator]# kubectl port-forward svc/demo-tidb 4000:4000 --namespace=tidb\nForwarding from 127.0.0.1:4000 -> 4000\n\n\n[root@kube01 ~]# PASSWORD=$(kubectl get secret -n tidb demo-tidb -ojsonpath=\"{.data.password}\" | base64 --decode | awk '{print $6}')\n[root@kube01 ~]# echo ${PASSWORD}\n'IwDSSjpq89'\n[root@kube01 ~]# mysql -h 127.0.0.1 -P 4000 -u root -p\nEnter password:\nWelcome to the MariaDB monitor.  Commands end with ; or \\g.\nYour MySQL connection id is 3\nServer version: 5.7.10-TiDB-v2.1.4 MySQL Community Server (Apache License 2.0)\n\nCopyright (c) 2000, 2018, Oracle, MariaDB Corporation Ab and others.\n\nType 'help;' or '\\h' for help. Type '\\c' to clear the current input statement.\n\nMySQL [(none)]> show databases;\n+--------------------+\n| Database           |\n+--------------------+\n| INFORMATION_SCHEMA |\n| PERFORMANCE_SCHEMA |\n| mysql              |\n| test               |\n+--------------------+\n4 rows in set (0.00 sec)\n\nMySQL [(none)]>\n\n```\n\n# 参考\n\n* [https://github.com/pingcap/tidb-operator/blob/master/docs/local-dind-tutorial.md](https://github.com/pingcap/tidb-operator/blob/master/docs/local-dind-tutorial.md)\n* [https://github.com/pingcap/tidb-operator/blob/master/docs/setup.md](https://github.com/pingcap/tidb-operator/blob/master/docs/setup.md)","slug":"tidb-k8s","published":1,"updated":"2019-03-18T09:25:26.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck1pzbtln001ptp75rdfx3ue7","content":"<h1 id=\"概述\"><a href=\"#概述\" class=\"headerlink\" title=\"概述\"></a>概述</h1><p>tidb是一个分布式的数据库，tidb-operator可以让tidb跑在k8s集群上面。<br>本文主要验证tidb使用local pv方式部署在k8s集群上面。</p>\n<h1 id=\"安装\"><a href=\"#安装\" class=\"headerlink\" title=\"安装\"></a>安装</h1><p>实验环境的k8s环境共有三个节点</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@kube01 ~]# kubectl get nodes</span><br><span class=\"line\">NAME     STATUS   ROLES    AGE    VERSION</span><br><span class=\"line\">kube01   Ready    master   3d5h   v1.13.4</span><br><span class=\"line\">kube02   Ready    master   3d5h   v1.13.4</span><br><span class=\"line\">kube03   Ready    master   3d5h   v1.13.4</span><br></pre></td></tr></table></figure>\n<p>tidb安装过程中需要用到6个pv，pd需要用到3个1G的pv，tikv需要用到3个10G的pv。<br>环境中有一块20G的空闲磁盘vdc，我们把vdc分成两个分区，一个2G，一个18G。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@kube01 ~]# sgdisk -n 1:0:+2G /dev/vdc</span><br><span class=\"line\">Creating new GPT entries.</span><br><span class=\"line\">The operation has completed successfully.</span><br><span class=\"line\">[root@kube01 ~]# sgdisk -n 2:0:0 /dev/vdc</span><br><span class=\"line\">The operation has completed successfully.</span><br></pre></td></tr></table></figure>\n<p>tidb-operator默认会把挂载在/mnt/disks/vol$i 的分区作为一个PV，所以把我们vdc1和vdc2这两个分区挂载在vol0和vol1下。<br>tidb推荐使用ext4文件系统</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mkfs.ext4 /dev/vdc1</span><br><span class=\"line\">mkfs.ext4 /dev/vdc2</span><br><span class=\"line\">mount /dev/vdc1 /mnt/disks/vol0/</span><br><span class=\"line\">mount /dev/vdc1 /mnt/disks/vol1/</span><br></pre></td></tr></table></figure>\n<p>通过tidb-opertor提供的local-volumen-provisioner可以把前面的分区变成local pv</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@kube01 local-dind]# kubectl apply -f local-volume-provisioner.yaml</span><br><span class=\"line\">storageclass.storage.k8s.io/local-storage changed</span><br><span class=\"line\">configmap/local-provisioner-config changed</span><br><span class=\"line\">daemonset.extensions/local-volume-provisioner changed</span><br><span class=\"line\">serviceaccount/local-storage-admin changed</span><br><span class=\"line\">clusterrolebinding.rbac.authorization.k8s.io/local-storage-provisioner-pv-binding changed</span><br><span class=\"line\">clusterrole.rbac.authorization.k8s.io/local-storage-provisioner-node-clusterrole changed</span><br><span class=\"line\">clusterrolebinding.rbac.authorization.k8s.io/local-storage-provisioner-node-binding changed</span><br></pre></td></tr></table></figure>\n<p>通过helm安装tidb-operator</p>\n<p>需要修改charts/tidb-operator/values.yaml文件中<br>kubeSchedulerImage: gcr.io/google-containers/hyperkube:v1.13.4<br>镜像的版本和kubelet的版本一致。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">[root@kube01 manifests]# kubectl apply -f crd.yaml</span><br><span class=\"line\">customresourcedefinition.apiextensions.k8s.io/tidbclusters.pingcap.com created</span><br><span class=\"line\"></span><br><span class=\"line\">[root@kube01 tidb-operator]# kubectl get customresourcedefinitions</span><br><span class=\"line\">NAME                                CREATED AT</span><br><span class=\"line\">tidbclusters.pingcap.com            2019-03-18T05:53:22Z</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">[root@kube01 tidb-operator]# helm install charts/tidb-operator --name=tidb-operator --namespace=tidb-admin</span><br><span class=\"line\">NAME:   tidb-operator</span><br><span class=\"line\">LAST DEPLOYED: Mon Mar 18 14:46:32 2019</span><br><span class=\"line\">NAMESPACE: tidb-admin</span><br><span class=\"line\">STATUS: DEPLOYED</span><br><span class=\"line\"></span><br><span class=\"line\">RESOURCES:</span><br><span class=\"line\">==&gt; v1/ConfigMap</span><br><span class=\"line\">NAME                   DATA  AGE</span><br><span class=\"line\">tidb-scheduler-policy  1     0s</span><br><span class=\"line\"></span><br><span class=\"line\">==&gt; v1/Pod(related)</span><br><span class=\"line\">NAME                                      READY  STATUS             RESTARTS  AGE</span><br><span class=\"line\">tidb-controller-manager-7c56fb85dd-h6k5m  0/1    ContainerCreating  0         0s</span><br><span class=\"line\">tidb-scheduler-7f8b69d57b-xx8jq           0/2    ContainerCreating  0         0s</span><br><span class=\"line\"></span><br><span class=\"line\">==&gt; v1/ServiceAccount</span><br><span class=\"line\">NAME                     SECRETS  AGE</span><br><span class=\"line\">tidb-controller-manager  1        0s</span><br><span class=\"line\">tidb-scheduler           1        0s</span><br><span class=\"line\"></span><br><span class=\"line\">==&gt; v1beta1/ClusterRole</span><br><span class=\"line\">NAME                                   AGE</span><br><span class=\"line\">tidb-operator:tidb-controller-manager  0s</span><br><span class=\"line\">tidb-operator:tidb-scheduler           0s</span><br><span class=\"line\"></span><br><span class=\"line\">==&gt; v1beta1/ClusterRoleBinding</span><br><span class=\"line\">NAME                                   AGE</span><br><span class=\"line\">tidb-operator:tidb-controller-manager  0s</span><br><span class=\"line\">tidb-operator:tidb-scheduler           0s</span><br><span class=\"line\"></span><br><span class=\"line\">==&gt; v1beta1/Deployment</span><br><span class=\"line\">NAME                     READY  UP-TO-DATE  AVAILABLE  AGE</span><br><span class=\"line\">tidb-controller-manager  0/1    1           0          0s</span><br><span class=\"line\">tidb-scheduler           0/1    1           0          0s</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">NOTES:</span><br><span class=\"line\">1. Make sure tidb-operator components are running</span><br><span class=\"line\">   kubectl get pods --namespace tidb-admin -l app.kubernetes.io/instance=tidb-operator</span><br><span class=\"line\">2. Install CRD</span><br><span class=\"line\">   kubectl apply -f https://raw.githubusercontent.com/pingcap/tidb-operator/master/manifests/crd.yaml</span><br><span class=\"line\">   kubectl get customresourcedefinitions</span><br><span class=\"line\">3. Modify tidb-cluster/values.yaml and create a TiDB cluster by installing tidb-cluster charts</span><br><span class=\"line\">   helm install tidb-cluster</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">[root@kube01 tidb-operator]# kubectl get pods --namespace tidb-admin -l app.kubernetes.io/instance=tidb-operator</span><br><span class=\"line\">NAME                                       READY   STATUS    RESTARTS   AGE</span><br><span class=\"line\">tidb-controller-manager-7c56fb85dd-h6k5m   1/1     Running   0          5m11s</span><br><span class=\"line\">tidb-scheduler-7f8b69d57b-xx8jq            2/2     Running   0          5m11s</span><br></pre></td></tr></table></figure>\n<p>通过helm安装tidb-cluster</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">[root@kube01 tidb-operator]# helm install charts/tidb-cluster --name=tidb-cluster --namespace=tidb</span><br><span class=\"line\">NAME:   tidb-cluster</span><br><span class=\"line\">LAST DEPLOYED: Mon Mar 18 14:57:35 2019</span><br><span class=\"line\">NAMESPACE: tidb</span><br><span class=\"line\">STATUS: DEPLOYED</span><br><span class=\"line\"></span><br><span class=\"line\">RESOURCES:</span><br><span class=\"line\">==&gt; v1/ConfigMap</span><br><span class=\"line\">NAME          DATA  AGE</span><br><span class=\"line\">demo-monitor  3     0s</span><br><span class=\"line\">demo-pd       2     0s</span><br><span class=\"line\">demo-tidb     2     0s</span><br><span class=\"line\">demo-tikv     2     0s</span><br><span class=\"line\"></span><br><span class=\"line\">==&gt; v1/Job</span><br><span class=\"line\">NAME                       COMPLETIONS  DURATION  AGE</span><br><span class=\"line\">demo-monitor-configurator  0/1          0s        0s</span><br><span class=\"line\">demo-tidb-initializer      0/1          0s        0s</span><br><span class=\"line\"></span><br><span class=\"line\">==&gt; v1/Pod(related)</span><br><span class=\"line\">NAME                             READY  STATUS             RESTARTS  AGE</span><br><span class=\"line\">demo-discovery-5468c7c556-8dcs5  0/1    ContainerCreating  0         0s</span><br><span class=\"line\">demo-monitor-84446b7957-rbdl9    0/2    Init:0/1           0         0s</span><br><span class=\"line\">demo-monitor-configurator-vz25r  0/1    ContainerCreating  0         0s</span><br><span class=\"line\">demo-tidb-initializer-dh8v2      0/1    ContainerCreating  0         0s</span><br><span class=\"line\"></span><br><span class=\"line\">==&gt; v1/Secret</span><br><span class=\"line\">NAME          TYPE    DATA  AGE</span><br><span class=\"line\">demo-monitor  Opaque  2     0s</span><br><span class=\"line\">demo-tidb     Opaque  1     0s</span><br><span class=\"line\"></span><br><span class=\"line\">==&gt; v1/Service</span><br><span class=\"line\">NAME             TYPE       CLUSTER-IP      EXTERNAL-IP  PORT(S)                         AGE</span><br><span class=\"line\">demo-discovery   ClusterIP  172.30.201.100  &lt;none&gt;       10261/TCP                       0s</span><br><span class=\"line\">demo-grafana     NodePort   172.30.122.104  &lt;none&gt;       3000:32242/TCP                  0s</span><br><span class=\"line\">demo-prometheus  NodePort   172.30.59.221   &lt;none&gt;       9090:32099/TCP                  0s</span><br><span class=\"line\">demo-tidb        NodePort   172.30.181.223  &lt;none&gt;       4000:30344/TCP,10080:32651/TCP  0s</span><br><span class=\"line\"></span><br><span class=\"line\">==&gt; v1/ServiceAccount</span><br><span class=\"line\">NAME            SECRETS  AGE</span><br><span class=\"line\">demo-discovery  1        0s</span><br><span class=\"line\">demo-monitor    1        0s</span><br><span class=\"line\"></span><br><span class=\"line\">==&gt; v1alpha1/TidbCluster</span><br><span class=\"line\">NAME  AGE</span><br><span class=\"line\">demo  0s</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">==&gt; v1beta1/Deployment</span><br><span class=\"line\">NAME            READY  UP-TO-DATE  AVAILABLE  AGE</span><br><span class=\"line\">demo-discovery  0/1    1           0          0s</span><br><span class=\"line\">demo-monitor    0/1    1           0          0s</span><br><span class=\"line\"></span><br><span class=\"line\">==&gt; v1beta1/Role</span><br><span class=\"line\">NAME            AGE</span><br><span class=\"line\">demo-discovery  0s</span><br><span class=\"line\">demo-monitor    0s</span><br><span class=\"line\"></span><br><span class=\"line\">==&gt; v1beta1/RoleBinding</span><br><span class=\"line\">NAME            AGE</span><br><span class=\"line\">demo-discovery  0s</span><br><span class=\"line\">demo-monitor    0s</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">NOTES:</span><br><span class=\"line\">1. Watch tidb-cluster up and running</span><br><span class=\"line\">   watch kubectl get pods --namespace tidb -l app.kubernetes.io/instance=tidb-cluster -o wide</span><br><span class=\"line\">2. List services in the tidb-cluster</span><br><span class=\"line\">   kubectl get services --namespace tidb -l app.kubernetes.io/instance=tidb-cluster</span><br><span class=\"line\">3. Wait until tidb-initializer pod becomes completed</span><br><span class=\"line\">   watch kubectl get po --namespace tidb  -l app.kubernetes.io/component=tidb-initializer</span><br><span class=\"line\">4. Get the TiDB password</span><br><span class=\"line\">   PASSWORD=$(kubectl get secret -n tidb demo-tidb -o jsonpath=&quot;&#123;.data.password&#125;&quot; | base64 --decode | awk &apos;&#123;print $6&#125;&apos;)</span><br><span class=\"line\">   echo $&#123;PASSWORD&#125;</span><br><span class=\"line\">5. Access tidb-cluster using the MySQL client</span><br><span class=\"line\">   kubectl port-forward -n tidb svc/demo-tidb 4000:4000 &amp;</span><br><span class=\"line\">   mysql -h 127.0.0.1 -P 4000 -u root -D test -p</span><br><span class=\"line\">6. View monitor dashboard for TiDB cluster</span><br><span class=\"line\">   kubectl port-forward -n tidb svc/demo-grafana 3000:3000</span><br><span class=\"line\">   Open browser at http://localhost:3000. The default username and password is admin/admin.</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">[root@kube01 tidb-operator]# kubectl get tidbcluster -n tidb</span><br><span class=\"line\">NAME   AGE</span><br><span class=\"line\">demo   1m</span><br><span class=\"line\"></span><br><span class=\"line\">[root@kube01 tidb-operator]# kubectl get statefulset -n tidb</span><br><span class=\"line\">NAME        READY   AGE</span><br><span class=\"line\">demo-pd     3/3     5m41s</span><br><span class=\"line\">demo-tidb   2/2     3m16s</span><br><span class=\"line\">demo-tikv   3/3     5m</span><br><span class=\"line\"></span><br><span class=\"line\">[root@kube01 tidb-operator]# kubectl get service -n tidb</span><br><span class=\"line\">NAME              TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)                          AGE</span><br><span class=\"line\">demo-discovery    ClusterIP   172.30.25.248    &lt;none&gt;        10261/TCP                        6m</span><br><span class=\"line\">demo-grafana      NodePort    172.30.103.60    &lt;none&gt;        3000:31597/TCP                   6m</span><br><span class=\"line\">demo-pd           ClusterIP   172.30.122.100   &lt;none&gt;        2379/TCP                         6m</span><br><span class=\"line\">demo-pd-peer      ClusterIP   None             &lt;none&gt;        2380/TCP                         6m</span><br><span class=\"line\">demo-prometheus   NodePort    172.30.147.201   &lt;none&gt;        9090:30429/TCP                   6m</span><br><span class=\"line\">demo-tidb         NodePort    172.30.244.61    &lt;none&gt;        4000:30512/TCP,10080:31051/TCP   6m</span><br><span class=\"line\">demo-tidb-peer    ClusterIP   None             &lt;none&gt;        10080/TCP                        3m34s</span><br><span class=\"line\">demo-tikv-peer    ClusterIP   None             &lt;none&gt;        20160/TCP                        5m18s</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">[root@kube01 tidb-operator]# kubectl get configmap -n tidb</span><br><span class=\"line\">NAME           DATA   AGE</span><br><span class=\"line\">demo-monitor   3      6m20s</span><br><span class=\"line\">demo-pd        2      6m20s</span><br><span class=\"line\">demo-tidb      2      6m20s</span><br><span class=\"line\">demo-tikv      2      6m20s</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">[root@kube01 tidb-operator]# kubectl get pod -n tidb</span><br><span class=\"line\">NAME                              READY   STATUS      RESTARTS   AGE</span><br><span class=\"line\">demo-discovery-5468c7c556-l9xl7   1/1     Running     0          6m41s</span><br><span class=\"line\">demo-monitor-84446b7957-4zsnd     2/2     Running     0          6m41s</span><br><span class=\"line\">demo-monitor-configurator-rnklq   0/1     Completed   0          6m41s</span><br><span class=\"line\">demo-pd-0                         1/1     Running     0          6m40s</span><br><span class=\"line\">demo-pd-1                         1/1     Running     0          6m40s</span><br><span class=\"line\">demo-pd-2                         1/1     Running     1          6m40s</span><br><span class=\"line\">demo-tidb-0                       1/1     Running     0          4m15s</span><br><span class=\"line\">demo-tidb-1                       1/1     Running     0          4m15s</span><br><span class=\"line\">demo-tidb-initializer-nkng4       0/1     Completed   0          6m41s</span><br><span class=\"line\">demo-tikv-0                       2/2     Running     0          5m59s</span><br><span class=\"line\">demo-tikv-1                       2/2     Running     0          5m59s</span><br><span class=\"line\">demo-tikv-2                       2/2     Running     0          5m59s</span><br></pre></td></tr></table></figure>\n<p>通过mysql client进行验证</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@kube01 tidb-operator]# kubectl port-forward svc/demo-tidb 4000:4000 --namespace=tidb</span><br><span class=\"line\">Forwarding from 127.0.0.1:4000 -&gt; 4000</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">[root@kube01 ~]# PASSWORD=$(kubectl get secret -n tidb demo-tidb -ojsonpath=&quot;&#123;.data.password&#125;&quot; | base64 --decode | awk &apos;&#123;print $6&#125;&apos;)</span><br><span class=\"line\">[root@kube01 ~]# echo $&#123;PASSWORD&#125;</span><br><span class=\"line\">&apos;IwDSSjpq89&apos;</span><br><span class=\"line\">[root@kube01 ~]# mysql -h 127.0.0.1 -P 4000 -u root -p</span><br><span class=\"line\">Enter password:</span><br><span class=\"line\">Welcome to the MariaDB monitor.  Commands end with ; or \\g.</span><br><span class=\"line\">Your MySQL connection id is 3</span><br><span class=\"line\">Server version: 5.7.10-TiDB-v2.1.4 MySQL Community Server (Apache License 2.0)</span><br><span class=\"line\"></span><br><span class=\"line\">Copyright (c) 2000, 2018, Oracle, MariaDB Corporation Ab and others.</span><br><span class=\"line\"></span><br><span class=\"line\">Type &apos;help;&apos; or &apos;\\h&apos; for help. Type &apos;\\c&apos; to clear the current input statement.</span><br><span class=\"line\"></span><br><span class=\"line\">MySQL [(none)]&gt; show databases;</span><br><span class=\"line\">+--------------------+</span><br><span class=\"line\">| Database           |</span><br><span class=\"line\">+--------------------+</span><br><span class=\"line\">| INFORMATION_SCHEMA |</span><br><span class=\"line\">| PERFORMANCE_SCHEMA |</span><br><span class=\"line\">| mysql              |</span><br><span class=\"line\">| test               |</span><br><span class=\"line\">+--------------------+</span><br><span class=\"line\">4 rows in set (0.00 sec)</span><br><span class=\"line\"></span><br><span class=\"line\">MySQL [(none)]&gt;</span><br></pre></td></tr></table></figure>\n<h1 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h1><ul>\n<li><a href=\"https://github.com/pingcap/tidb-operator/blob/master/docs/local-dind-tutorial.md\" target=\"_blank\" rel=\"noopener\">https://github.com/pingcap/tidb-operator/blob/master/docs/local-dind-tutorial.md</a></li>\n<li><a href=\"https://github.com/pingcap/tidb-operator/blob/master/docs/setup.md\" target=\"_blank\" rel=\"noopener\">https://github.com/pingcap/tidb-operator/blob/master/docs/setup.md</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"概述\"><a href=\"#概述\" class=\"headerlink\" title=\"概述\"></a>概述</h1><p>tidb是一个分布式的数据库，tidb-operator可以让tidb跑在k8s集群上面。<br>本文主要验证tidb使用local pv方式部署在k8s集群上面。</p>\n<h1 id=\"安装\"><a href=\"#安装\" class=\"headerlink\" title=\"安装\"></a>安装</h1><p>实验环境的k8s环境共有三个节点</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@kube01 ~]# kubectl get nodes</span><br><span class=\"line\">NAME     STATUS   ROLES    AGE    VERSION</span><br><span class=\"line\">kube01   Ready    master   3d5h   v1.13.4</span><br><span class=\"line\">kube02   Ready    master   3d5h   v1.13.4</span><br><span class=\"line\">kube03   Ready    master   3d5h   v1.13.4</span><br></pre></td></tr></table></figure>\n<p>tidb安装过程中需要用到6个pv，pd需要用到3个1G的pv，tikv需要用到3个10G的pv。<br>环境中有一块20G的空闲磁盘vdc，我们把vdc分成两个分区，一个2G，一个18G。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@kube01 ~]# sgdisk -n 1:0:+2G /dev/vdc</span><br><span class=\"line\">Creating new GPT entries.</span><br><span class=\"line\">The operation has completed successfully.</span><br><span class=\"line\">[root@kube01 ~]# sgdisk -n 2:0:0 /dev/vdc</span><br><span class=\"line\">The operation has completed successfully.</span><br></pre></td></tr></table></figure>\n<p>tidb-operator默认会把挂载在/mnt/disks/vol$i 的分区作为一个PV，所以把我们vdc1和vdc2这两个分区挂载在vol0和vol1下。<br>tidb推荐使用ext4文件系统</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mkfs.ext4 /dev/vdc1</span><br><span class=\"line\">mkfs.ext4 /dev/vdc2</span><br><span class=\"line\">mount /dev/vdc1 /mnt/disks/vol0/</span><br><span class=\"line\">mount /dev/vdc1 /mnt/disks/vol1/</span><br></pre></td></tr></table></figure>\n<p>通过tidb-opertor提供的local-volumen-provisioner可以把前面的分区变成local pv</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@kube01 local-dind]# kubectl apply -f local-volume-provisioner.yaml</span><br><span class=\"line\">storageclass.storage.k8s.io/local-storage changed</span><br><span class=\"line\">configmap/local-provisioner-config changed</span><br><span class=\"line\">daemonset.extensions/local-volume-provisioner changed</span><br><span class=\"line\">serviceaccount/local-storage-admin changed</span><br><span class=\"line\">clusterrolebinding.rbac.authorization.k8s.io/local-storage-provisioner-pv-binding changed</span><br><span class=\"line\">clusterrole.rbac.authorization.k8s.io/local-storage-provisioner-node-clusterrole changed</span><br><span class=\"line\">clusterrolebinding.rbac.authorization.k8s.io/local-storage-provisioner-node-binding changed</span><br></pre></td></tr></table></figure>\n<p>通过helm安装tidb-operator</p>\n<p>需要修改charts/tidb-operator/values.yaml文件中<br>kubeSchedulerImage: gcr.io/google-containers/hyperkube:v1.13.4<br>镜像的版本和kubelet的版本一致。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">[root@kube01 manifests]# kubectl apply -f crd.yaml</span><br><span class=\"line\">customresourcedefinition.apiextensions.k8s.io/tidbclusters.pingcap.com created</span><br><span class=\"line\"></span><br><span class=\"line\">[root@kube01 tidb-operator]# kubectl get customresourcedefinitions</span><br><span class=\"line\">NAME                                CREATED AT</span><br><span class=\"line\">tidbclusters.pingcap.com            2019-03-18T05:53:22Z</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">[root@kube01 tidb-operator]# helm install charts/tidb-operator --name=tidb-operator --namespace=tidb-admin</span><br><span class=\"line\">NAME:   tidb-operator</span><br><span class=\"line\">LAST DEPLOYED: Mon Mar 18 14:46:32 2019</span><br><span class=\"line\">NAMESPACE: tidb-admin</span><br><span class=\"line\">STATUS: DEPLOYED</span><br><span class=\"line\"></span><br><span class=\"line\">RESOURCES:</span><br><span class=\"line\">==&gt; v1/ConfigMap</span><br><span class=\"line\">NAME                   DATA  AGE</span><br><span class=\"line\">tidb-scheduler-policy  1     0s</span><br><span class=\"line\"></span><br><span class=\"line\">==&gt; v1/Pod(related)</span><br><span class=\"line\">NAME                                      READY  STATUS             RESTARTS  AGE</span><br><span class=\"line\">tidb-controller-manager-7c56fb85dd-h6k5m  0/1    ContainerCreating  0         0s</span><br><span class=\"line\">tidb-scheduler-7f8b69d57b-xx8jq           0/2    ContainerCreating  0         0s</span><br><span class=\"line\"></span><br><span class=\"line\">==&gt; v1/ServiceAccount</span><br><span class=\"line\">NAME                     SECRETS  AGE</span><br><span class=\"line\">tidb-controller-manager  1        0s</span><br><span class=\"line\">tidb-scheduler           1        0s</span><br><span class=\"line\"></span><br><span class=\"line\">==&gt; v1beta1/ClusterRole</span><br><span class=\"line\">NAME                                   AGE</span><br><span class=\"line\">tidb-operator:tidb-controller-manager  0s</span><br><span class=\"line\">tidb-operator:tidb-scheduler           0s</span><br><span class=\"line\"></span><br><span class=\"line\">==&gt; v1beta1/ClusterRoleBinding</span><br><span class=\"line\">NAME                                   AGE</span><br><span class=\"line\">tidb-operator:tidb-controller-manager  0s</span><br><span class=\"line\">tidb-operator:tidb-scheduler           0s</span><br><span class=\"line\"></span><br><span class=\"line\">==&gt; v1beta1/Deployment</span><br><span class=\"line\">NAME                     READY  UP-TO-DATE  AVAILABLE  AGE</span><br><span class=\"line\">tidb-controller-manager  0/1    1           0          0s</span><br><span class=\"line\">tidb-scheduler           0/1    1           0          0s</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">NOTES:</span><br><span class=\"line\">1. Make sure tidb-operator components are running</span><br><span class=\"line\">   kubectl get pods --namespace tidb-admin -l app.kubernetes.io/instance=tidb-operator</span><br><span class=\"line\">2. Install CRD</span><br><span class=\"line\">   kubectl apply -f https://raw.githubusercontent.com/pingcap/tidb-operator/master/manifests/crd.yaml</span><br><span class=\"line\">   kubectl get customresourcedefinitions</span><br><span class=\"line\">3. Modify tidb-cluster/values.yaml and create a TiDB cluster by installing tidb-cluster charts</span><br><span class=\"line\">   helm install tidb-cluster</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">[root@kube01 tidb-operator]# kubectl get pods --namespace tidb-admin -l app.kubernetes.io/instance=tidb-operator</span><br><span class=\"line\">NAME                                       READY   STATUS    RESTARTS   AGE</span><br><span class=\"line\">tidb-controller-manager-7c56fb85dd-h6k5m   1/1     Running   0          5m11s</span><br><span class=\"line\">tidb-scheduler-7f8b69d57b-xx8jq            2/2     Running   0          5m11s</span><br></pre></td></tr></table></figure>\n<p>通过helm安装tidb-cluster</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">[root@kube01 tidb-operator]# helm install charts/tidb-cluster --name=tidb-cluster --namespace=tidb</span><br><span class=\"line\">NAME:   tidb-cluster</span><br><span class=\"line\">LAST DEPLOYED: Mon Mar 18 14:57:35 2019</span><br><span class=\"line\">NAMESPACE: tidb</span><br><span class=\"line\">STATUS: DEPLOYED</span><br><span class=\"line\"></span><br><span class=\"line\">RESOURCES:</span><br><span class=\"line\">==&gt; v1/ConfigMap</span><br><span class=\"line\">NAME          DATA  AGE</span><br><span class=\"line\">demo-monitor  3     0s</span><br><span class=\"line\">demo-pd       2     0s</span><br><span class=\"line\">demo-tidb     2     0s</span><br><span class=\"line\">demo-tikv     2     0s</span><br><span class=\"line\"></span><br><span class=\"line\">==&gt; v1/Job</span><br><span class=\"line\">NAME                       COMPLETIONS  DURATION  AGE</span><br><span class=\"line\">demo-monitor-configurator  0/1          0s        0s</span><br><span class=\"line\">demo-tidb-initializer      0/1          0s        0s</span><br><span class=\"line\"></span><br><span class=\"line\">==&gt; v1/Pod(related)</span><br><span class=\"line\">NAME                             READY  STATUS             RESTARTS  AGE</span><br><span class=\"line\">demo-discovery-5468c7c556-8dcs5  0/1    ContainerCreating  0         0s</span><br><span class=\"line\">demo-monitor-84446b7957-rbdl9    0/2    Init:0/1           0         0s</span><br><span class=\"line\">demo-monitor-configurator-vz25r  0/1    ContainerCreating  0         0s</span><br><span class=\"line\">demo-tidb-initializer-dh8v2      0/1    ContainerCreating  0         0s</span><br><span class=\"line\"></span><br><span class=\"line\">==&gt; v1/Secret</span><br><span class=\"line\">NAME          TYPE    DATA  AGE</span><br><span class=\"line\">demo-monitor  Opaque  2     0s</span><br><span class=\"line\">demo-tidb     Opaque  1     0s</span><br><span class=\"line\"></span><br><span class=\"line\">==&gt; v1/Service</span><br><span class=\"line\">NAME             TYPE       CLUSTER-IP      EXTERNAL-IP  PORT(S)                         AGE</span><br><span class=\"line\">demo-discovery   ClusterIP  172.30.201.100  &lt;none&gt;       10261/TCP                       0s</span><br><span class=\"line\">demo-grafana     NodePort   172.30.122.104  &lt;none&gt;       3000:32242/TCP                  0s</span><br><span class=\"line\">demo-prometheus  NodePort   172.30.59.221   &lt;none&gt;       9090:32099/TCP                  0s</span><br><span class=\"line\">demo-tidb        NodePort   172.30.181.223  &lt;none&gt;       4000:30344/TCP,10080:32651/TCP  0s</span><br><span class=\"line\"></span><br><span class=\"line\">==&gt; v1/ServiceAccount</span><br><span class=\"line\">NAME            SECRETS  AGE</span><br><span class=\"line\">demo-discovery  1        0s</span><br><span class=\"line\">demo-monitor    1        0s</span><br><span class=\"line\"></span><br><span class=\"line\">==&gt; v1alpha1/TidbCluster</span><br><span class=\"line\">NAME  AGE</span><br><span class=\"line\">demo  0s</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">==&gt; v1beta1/Deployment</span><br><span class=\"line\">NAME            READY  UP-TO-DATE  AVAILABLE  AGE</span><br><span class=\"line\">demo-discovery  0/1    1           0          0s</span><br><span class=\"line\">demo-monitor    0/1    1           0          0s</span><br><span class=\"line\"></span><br><span class=\"line\">==&gt; v1beta1/Role</span><br><span class=\"line\">NAME            AGE</span><br><span class=\"line\">demo-discovery  0s</span><br><span class=\"line\">demo-monitor    0s</span><br><span class=\"line\"></span><br><span class=\"line\">==&gt; v1beta1/RoleBinding</span><br><span class=\"line\">NAME            AGE</span><br><span class=\"line\">demo-discovery  0s</span><br><span class=\"line\">demo-monitor    0s</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">NOTES:</span><br><span class=\"line\">1. Watch tidb-cluster up and running</span><br><span class=\"line\">   watch kubectl get pods --namespace tidb -l app.kubernetes.io/instance=tidb-cluster -o wide</span><br><span class=\"line\">2. List services in the tidb-cluster</span><br><span class=\"line\">   kubectl get services --namespace tidb -l app.kubernetes.io/instance=tidb-cluster</span><br><span class=\"line\">3. Wait until tidb-initializer pod becomes completed</span><br><span class=\"line\">   watch kubectl get po --namespace tidb  -l app.kubernetes.io/component=tidb-initializer</span><br><span class=\"line\">4. Get the TiDB password</span><br><span class=\"line\">   PASSWORD=$(kubectl get secret -n tidb demo-tidb -o jsonpath=&quot;&#123;.data.password&#125;&quot; | base64 --decode | awk &apos;&#123;print $6&#125;&apos;)</span><br><span class=\"line\">   echo $&#123;PASSWORD&#125;</span><br><span class=\"line\">5. Access tidb-cluster using the MySQL client</span><br><span class=\"line\">   kubectl port-forward -n tidb svc/demo-tidb 4000:4000 &amp;</span><br><span class=\"line\">   mysql -h 127.0.0.1 -P 4000 -u root -D test -p</span><br><span class=\"line\">6. View monitor dashboard for TiDB cluster</span><br><span class=\"line\">   kubectl port-forward -n tidb svc/demo-grafana 3000:3000</span><br><span class=\"line\">   Open browser at http://localhost:3000. The default username and password is admin/admin.</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">[root@kube01 tidb-operator]# kubectl get tidbcluster -n tidb</span><br><span class=\"line\">NAME   AGE</span><br><span class=\"line\">demo   1m</span><br><span class=\"line\"></span><br><span class=\"line\">[root@kube01 tidb-operator]# kubectl get statefulset -n tidb</span><br><span class=\"line\">NAME        READY   AGE</span><br><span class=\"line\">demo-pd     3/3     5m41s</span><br><span class=\"line\">demo-tidb   2/2     3m16s</span><br><span class=\"line\">demo-tikv   3/3     5m</span><br><span class=\"line\"></span><br><span class=\"line\">[root@kube01 tidb-operator]# kubectl get service -n tidb</span><br><span class=\"line\">NAME              TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)                          AGE</span><br><span class=\"line\">demo-discovery    ClusterIP   172.30.25.248    &lt;none&gt;        10261/TCP                        6m</span><br><span class=\"line\">demo-grafana      NodePort    172.30.103.60    &lt;none&gt;        3000:31597/TCP                   6m</span><br><span class=\"line\">demo-pd           ClusterIP   172.30.122.100   &lt;none&gt;        2379/TCP                         6m</span><br><span class=\"line\">demo-pd-peer      ClusterIP   None             &lt;none&gt;        2380/TCP                         6m</span><br><span class=\"line\">demo-prometheus   NodePort    172.30.147.201   &lt;none&gt;        9090:30429/TCP                   6m</span><br><span class=\"line\">demo-tidb         NodePort    172.30.244.61    &lt;none&gt;        4000:30512/TCP,10080:31051/TCP   6m</span><br><span class=\"line\">demo-tidb-peer    ClusterIP   None             &lt;none&gt;        10080/TCP                        3m34s</span><br><span class=\"line\">demo-tikv-peer    ClusterIP   None             &lt;none&gt;        20160/TCP                        5m18s</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">[root@kube01 tidb-operator]# kubectl get configmap -n tidb</span><br><span class=\"line\">NAME           DATA   AGE</span><br><span class=\"line\">demo-monitor   3      6m20s</span><br><span class=\"line\">demo-pd        2      6m20s</span><br><span class=\"line\">demo-tidb      2      6m20s</span><br><span class=\"line\">demo-tikv      2      6m20s</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">[root@kube01 tidb-operator]# kubectl get pod -n tidb</span><br><span class=\"line\">NAME                              READY   STATUS      RESTARTS   AGE</span><br><span class=\"line\">demo-discovery-5468c7c556-l9xl7   1/1     Running     0          6m41s</span><br><span class=\"line\">demo-monitor-84446b7957-4zsnd     2/2     Running     0          6m41s</span><br><span class=\"line\">demo-monitor-configurator-rnklq   0/1     Completed   0          6m41s</span><br><span class=\"line\">demo-pd-0                         1/1     Running     0          6m40s</span><br><span class=\"line\">demo-pd-1                         1/1     Running     0          6m40s</span><br><span class=\"line\">demo-pd-2                         1/1     Running     1          6m40s</span><br><span class=\"line\">demo-tidb-0                       1/1     Running     0          4m15s</span><br><span class=\"line\">demo-tidb-1                       1/1     Running     0          4m15s</span><br><span class=\"line\">demo-tidb-initializer-nkng4       0/1     Completed   0          6m41s</span><br><span class=\"line\">demo-tikv-0                       2/2     Running     0          5m59s</span><br><span class=\"line\">demo-tikv-1                       2/2     Running     0          5m59s</span><br><span class=\"line\">demo-tikv-2                       2/2     Running     0          5m59s</span><br></pre></td></tr></table></figure>\n<p>通过mysql client进行验证</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@kube01 tidb-operator]# kubectl port-forward svc/demo-tidb 4000:4000 --namespace=tidb</span><br><span class=\"line\">Forwarding from 127.0.0.1:4000 -&gt; 4000</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">[root@kube01 ~]# PASSWORD=$(kubectl get secret -n tidb demo-tidb -ojsonpath=&quot;&#123;.data.password&#125;&quot; | base64 --decode | awk &apos;&#123;print $6&#125;&apos;)</span><br><span class=\"line\">[root@kube01 ~]# echo $&#123;PASSWORD&#125;</span><br><span class=\"line\">&apos;IwDSSjpq89&apos;</span><br><span class=\"line\">[root@kube01 ~]# mysql -h 127.0.0.1 -P 4000 -u root -p</span><br><span class=\"line\">Enter password:</span><br><span class=\"line\">Welcome to the MariaDB monitor.  Commands end with ; or \\g.</span><br><span class=\"line\">Your MySQL connection id is 3</span><br><span class=\"line\">Server version: 5.7.10-TiDB-v2.1.4 MySQL Community Server (Apache License 2.0)</span><br><span class=\"line\"></span><br><span class=\"line\">Copyright (c) 2000, 2018, Oracle, MariaDB Corporation Ab and others.</span><br><span class=\"line\"></span><br><span class=\"line\">Type &apos;help;&apos; or &apos;\\h&apos; for help. Type &apos;\\c&apos; to clear the current input statement.</span><br><span class=\"line\"></span><br><span class=\"line\">MySQL [(none)]&gt; show databases;</span><br><span class=\"line\">+--------------------+</span><br><span class=\"line\">| Database           |</span><br><span class=\"line\">+--------------------+</span><br><span class=\"line\">| INFORMATION_SCHEMA |</span><br><span class=\"line\">| PERFORMANCE_SCHEMA |</span><br><span class=\"line\">| mysql              |</span><br><span class=\"line\">| test               |</span><br><span class=\"line\">+--------------------+</span><br><span class=\"line\">4 rows in set (0.00 sec)</span><br><span class=\"line\"></span><br><span class=\"line\">MySQL [(none)]&gt;</span><br></pre></td></tr></table></figure>\n<h1 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h1><ul>\n<li><a href=\"https://github.com/pingcap/tidb-operator/blob/master/docs/local-dind-tutorial.md\" target=\"_blank\" rel=\"noopener\">https://github.com/pingcap/tidb-operator/blob/master/docs/local-dind-tutorial.md</a></li>\n<li><a href=\"https://github.com/pingcap/tidb-operator/blob/master/docs/setup.md\" target=\"_blank\" rel=\"noopener\">https://github.com/pingcap/tidb-operator/blob/master/docs/setup.md</a></li>\n</ul>\n"}],"PostAsset":[{"_id":"source/_posts/disk-extend/disk4.png","slug":"disk4.png","post":"ck1pzbtgm0004tp75xb925oiw","modified":0,"renderable":0},{"_id":"source/_posts/disk-extend/disk7.png","slug":"disk7.png","post":"ck1pzbtgm0004tp75xb925oiw","modified":0,"renderable":0},{"_id":"source/_posts/disk-extend/disk1.png","slug":"disk1.png","post":"ck1pzbtgm0004tp75xb925oiw","modified":0,"renderable":0},{"_id":"source/_posts/disk-extend/disk6.png","slug":"disk6.png","post":"ck1pzbtgm0004tp75xb925oiw","modified":0,"renderable":0},{"_id":"source/_posts/disk-extend/disk2.png","slug":"disk2.png","post":"ck1pzbtgm0004tp75xb925oiw","modified":0,"renderable":0},{"_id":"source/_posts/disk-extend/disk8.png","slug":"disk8.png","post":"ck1pzbtgm0004tp75xb925oiw","modified":0,"renderable":0},{"_id":"source/_posts/disk-extend/disk9.png","slug":"disk9.png","post":"ck1pzbtgm0004tp75xb925oiw","modified":0,"renderable":0},{"_id":"source/_posts/linux-performance-tools/linux_perf_tools_full.pdf","slug":"linux_perf_tools_full.pdf","post":"ck1pzbtgw000ftp75ky0txdlr","modified":0,"renderable":0},{"_id":"source/_posts/ceph-deploy/cephfs.png","slug":"cephfs.png","post":"ck1pzbtgj0002tp758efsfpwk","modified":0,"renderable":0},{"_id":"source/_posts/ceph-deploy/cephstatus.png","slug":"cephstatus.png","post":"ck1pzbtgj0002tp758efsfpwk","modified":0,"renderable":0},{"_id":"source/_posts/nextcloud-ceph/nextcloud1.png","slug":"nextcloud1.png","post":"ck1pzbth0000htp75t7s4kb3x","modified":0,"renderable":0},{"_id":"source/_posts/nextcloud-ceph/nextcloud2.png","slug":"nextcloud2.png","post":"ck1pzbth0000htp75t7s4kb3x","modified":0,"renderable":0},{"_id":"source/_posts/nextcloud-ceph/nextcloud3.png","slug":"nextcloud3.png","post":"ck1pzbth0000htp75t7s4kb3x","modified":0,"renderable":0},{"_id":"source/_posts/nextcloud-ceph/nextcloud4.png","slug":"nextcloud4.png","post":"ck1pzbth0000htp75t7s4kb3x","modified":0,"renderable":0},{"_id":"source/_posts/nextcloud-ceph/nextcloud5.png","slug":"nextcloud5.png","post":"ck1pzbth0000htp75t7s4kb3x","modified":0,"renderable":0},{"_id":"source/_posts/nextcloud-ceph/nextcloud6.png","slug":"nextcloud6.png","post":"ck1pzbth0000htp75t7s4kb3x","modified":0,"renderable":0},{"_id":"source/_posts/disk-extend/disk3.png","slug":"disk3.png","post":"ck1pzbtgm0004tp75xb925oiw","modified":0,"renderable":0},{"_id":"source/_posts/disk-extend/disk5.png","slug":"disk5.png","post":"ck1pzbtgm0004tp75xb925oiw","modified":0,"renderable":0},{"_id":"source/_posts/linux-performance-tools/linux_perf_tools_full.png","slug":"linux_perf_tools_full.png","post":"ck1pzbtgw000ftp75ky0txdlr","modified":1,"renderable":0}],"PostCategory":[],"PostTag":[{"post_id":"ck1pzbtgn0005tp75uykrv7vu","tag_id":"ck1pzbtgk0003tp75hmjpz5lv","_id":"ck1pzbtgr0008tp75zzhbyrts"},{"post_id":"ck1pzbtgh0001tp75l29uodaw","tag_id":"ck1pzbtgk0003tp75hmjpz5lv","_id":"ck1pzbtgs000atp754vsoqo42"},{"post_id":"ck1pzbtgj0002tp758efsfpwk","tag_id":"ck1pzbtgk0003tp75hmjpz5lv","_id":"ck1pzbtgu000dtp75p0ofw4i2"},{"post_id":"ck1pzbtgm0004tp75xb925oiw","tag_id":"ck1pzbtgu000ctp75tpgnj8h9","_id":"ck1pzbth1000itp75smjt5ypz"},{"post_id":"ck1pzbtgo0006tp75lm8823fa","tag_id":"ck1pzbtgx000gtp7563jektl3","_id":"ck1pzbth5000mtp75hbfulgmk"},{"post_id":"ck1pzbtgr0009tp75od5c3fhr","tag_id":"ck1pzbth4000ktp75x0rda3a2","_id":"ck1pzbth7000qtp75dzisszv3"},{"post_id":"ck1pzbth6000ptp75kbjr704f","tag_id":"ck1pzbtgk0003tp75hmjpz5lv","_id":"ck1pzbth7000stp754uyokubu"},{"post_id":"ck1pzbth7000rtp75r1kg9cse","tag_id":"ck1pzbtgk0003tp75hmjpz5lv","_id":"ck1pzbth8000vtp75k5jbg6cs"},{"post_id":"ck1pzbth7000ttp75opc1o4xh","tag_id":"ck1pzbtgk0003tp75hmjpz5lv","_id":"ck1pzbth9000xtp751fmadx5y"},{"post_id":"ck1pzbth7000ttp75opc1o4xh","tag_id":"ck1pzbth4000ktp75x0rda3a2","_id":"ck1pzbtha0010tp75og5t26h3"},{"post_id":"ck1pzbth8000wtp75vkjz8fzh","tag_id":"ck1pzbth6000otp75698aekss","_id":"ck1pzbthb0012tp75s9jcrrhn"},{"post_id":"ck1pzbtgu000etp75r4ztix7f","tag_id":"ck1pzbth6000otp75698aekss","_id":"ck1pzbthc0015tp75o81hzhco"},{"post_id":"ck1pzbtgu000etp75r4ztix7f","tag_id":"ck1pzbth8000utp750i1ljyp8","_id":"ck1pzbthc0016tp75eba0km5g"},{"post_id":"ck1pzbtgu000etp75r4ztix7f","tag_id":"ck1pzbtha000ztp75qaugbbo4","_id":"ck1pzbthd0018tp75l9mx83o9"},{"post_id":"ck1pzbtgw000ftp75ky0txdlr","tag_id":"ck1pzbth6000otp75698aekss","_id":"ck1pzbthd0019tp756c58t6rs"},{"post_id":"ck1pzbth3000jtp75zvhmar6d","tag_id":"ck1pzbth6000otp75698aekss","_id":"ck1pzbthe001dtp75lr0wjupe"},{"post_id":"ck1pzbth3000jtp75zvhmar6d","tag_id":"ck1pzbth8000utp750i1ljyp8","_id":"ck1pzbthe001etp75itok4smn"},{"post_id":"ck1pzbth3000jtp75zvhmar6d","tag_id":"ck1pzbtha000ztp75qaugbbo4","_id":"ck1pzbthe001gtp75r48jxofm"},{"post_id":"ck1pzbth4000ltp750lf21v15","tag_id":"ck1pzbthe001ctp75d8v2hwdb","_id":"ck1pzbthf001htp75qila9iee"},{"post_id":"ck1pzbth5000ntp75gxqxhlwi","tag_id":"ck1pzbth6000otp75698aekss","_id":"ck1pzbthf001jtp75t1plmr9t"},{"post_id":"ck1pzbthb0013tp75wetcdil3","tag_id":"ck1pzbthf001itp7503xh44s3","_id":"ck1pzbthf001ktp75c5tumj7b"},{"post_id":"ck1pzbtln001ptp75rdfx3ue7","tag_id":"ck1pzbth4000ktp75x0rda3a2","_id":"ck1pzbtlp001qtp75apq3z16t"},{"post_id":"ck1pzbtlb001ltp7523pqp5kx","tag_id":"ck1pzbtlm001otp755ayxkclb","_id":"ck1pzbtlq001rtp7532s7cn70"}],"Tag":[{"name":"ceph","_id":"ck1pzbtgk0003tp75hmjpz5lv"},{"name":"centos","_id":"ck1pzbtgu000ctp75tpgnj8h9"},{"name":"git","_id":"ck1pzbtgx000gtp7563jektl3"},{"name":"k8s","_id":"ck1pzbth4000ktp75x0rda3a2"},{"name":"linux","_id":"ck1pzbth6000otp75698aekss"},{"name":"mysql","_id":"ck1pzbth8000utp750i1ljyp8"},{"name":"ha","_id":"ck1pzbtha000ztp75qaugbbo4"},{"name":"redis","_id":"ck1pzbthe001ctp75d8v2hwdb"},{"name":"sql","_id":"ck1pzbthf001itp7503xh44s3"},{"name":"python","_id":"ck1pzbtlm001otp755ayxkclb"}]}}